{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt\n",
    "import matplotlib as mpl\n",
    "from datetime import timedelta\n",
    "\n",
    "# enable for turning_point_alone.pdf\n",
    "# EXTRA_STUFF_ENABLED = False\n",
    "\n",
    "# enable for turning_point_no_cost.pdf\n",
    "EXTRA_STUFF_ENABLED = True\n",
    "\n",
    "\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "plt.rcParams[\"text.usetex\"] =  True\n",
    "plt.rcParams[\"text.usetex\"] =  False\n",
    "if EXTRA_STUFF_ENABLED: \n",
    "    plt.rcParams.update({'font.size': 18})\n",
    "else:\n",
    "    plt.rcParams.update({'font.size': 12})\n",
    "\n",
    "# plt.rcParams.update({\n",
    "#     \"pgf.texsystem\": \"pdflatex\",\n",
    "#     \"font.family\": \"serif\",\n",
    "#     \"font.serif\": [\"Times\"],\n",
    "#     \"text.usetex\": True,\n",
    "#     \"pgf.rcfonts\": False,\n",
    "# })\n",
    "\n",
    "# Load the CSV file\n",
    "# df_data = pd.read_csv('monthly_efficiency.csv', parse_dates=['date'])\n",
    "df_data = pd.read_csv('../bitcoinforum/6_merging/monthly_stuff.csv', parse_dates=['date'])\n",
    "\n",
    "# Filter the data to include only dates after '2011-02-01'\n",
    "# df_data = df_data[df_data['date'] > '2011-02-01']\n",
    "\n",
    "# Calculate the quarterly average of the efficiency\n",
    "df_data['quarter'] = (df_data['date'] - timedelta(days=45)).dt.to_period('Q')\n",
    "quarterly_data = df_data.groupby('quarter')['efficiency'].mean().reset_index()\n",
    "quarterly_data['quarter'] = quarterly_data['quarter'].dt.to_timestamp()\n",
    "\n",
    "# Set the 'quarter' column as the index\n",
    "quarterly_data.set_index('quarter', inplace=True)\n",
    "\n",
    "# Resample the data to daily frequency, creating NaN values for new days\n",
    "daily_data = quarterly_data.resample('D').asfreq()\n",
    "\n",
    "# Interpolate the missing data points\n",
    "daily_data_interpolated = daily_data.interpolate(method='linear')\n",
    "\n",
    "# Extract the relevant columns\n",
    "df_efficiency = daily_data_interpolated['efficiency'].dropna()\n",
    "df_date = df_efficiency.index\n",
    "\n",
    "# Ensure the lengths match\n",
    "count_row_date = df_date.shape[0]\n",
    "count_row_efficiency = df_efficiency.shape[0]\n",
    "if count_row_date != count_row_efficiency:\n",
    "    df_efficiency = df_efficiency.iloc[:-(count_row_efficiency - count_row_date)]\n",
    "\n",
    "# Log-transform the efficiency data\n",
    "df_efficiency_log = np.log10(df_efficiency)\n",
    "\n",
    "def point_line_distance(point, start, end):\n",
    "    if start == end:\n",
    "        return sqrt((point[0] - start[0]) ** 2 + (point[1] - start[1]) ** 2)\n",
    "    else:\n",
    "        n = abs((end[0] - start[0]) * (start[1] - point[1]) - (start[0] - point[0]) * (end[1] - start[1]))\n",
    "        d = sqrt((end[0] - start[0]) ** 2 + (end[1] - start[1]) ** 2)\n",
    "        return n / d\n",
    "\n",
    "def ramer_douglas_peucker(points, epsilon):\n",
    "    dmax = 0.0\n",
    "    index = 0\n",
    "    for i in range(1, len(points) - 1):\n",
    "        d = point_line_distance(points[i], points[0], points[-1])\n",
    "        if d > dmax:\n",
    "            index = i\n",
    "            dmax = d\n",
    "    if dmax >= epsilon:\n",
    "        results = ramer_douglas_peucker(points[:index+1], epsilon)[:-1] + ramer_douglas_peucker(points[index:], epsilon)\n",
    "    else:\n",
    "        results = [points[0], points[-1]]\n",
    "    return results\n",
    "\n",
    "def angle(dir):\n",
    "    dir2 = dir[1:]\n",
    "    dir1 = dir[:-1]\n",
    "    return np.arccos((dir1*dir2).sum(axis=1)/(np.sqrt((dir1**2).sum(axis=1)*(dir2**2).sum(axis=1))))\n",
    "\n",
    "# Ramer–Douglas–Peucker algorithm\n",
    "tolerance = 1.3\n",
    "min_angle = 0.0\n",
    "number_days_list = list(range(count_row_date))\n",
    "points = list(zip(number_days_list, df_efficiency_log))\n",
    "simplified = np.array(ramer_douglas_peucker(points, tolerance))\n",
    "directions = np.diff(simplified, axis=0)\n",
    "theta = angle(directions)\n",
    "idx = np.where(theta > min_angle)[0] + 1\n",
    "\n",
    "# Prepare max efficiency data for step plot\n",
    "df_max_efficiency = df_data.set_index('date')['max_efficiency'].dropna()\n",
    "df_max_efficiency = df_max_efficiency.reindex(df_date, method='ffill')\n",
    "\n",
    "# Plotting the figure with turning point\n",
    "# plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "x = df_date\n",
    "y_efficiency = [10 ** y for y in df_efficiency_log]\n",
    "y_max_efficiency = df_max_efficiency\n",
    "simpli_x, simpli_y = simplified.T\n",
    "turn_point_row = int(simpli_x[1])\n",
    "simpli_x = [df_date[int(simpli_x[d])] for d in range(len(simpli_x))]\n",
    "simpli_y = [10 ** y for y in simpli_y]\n",
    "\n",
    "print('Turning point on row:', turn_point_row, 'which is date:', simpli_x[1], 'at', simpli_y[1], 'TH/J')\n",
    "\n",
    "# Create a figure with a custom layout\n",
    "if EXTRA_STUFF_ENABLED:\n",
    "    fig = plt.figure(figsize=(15, 6))\n",
    "else:\n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "if EXTRA_STUFF_ENABLED:\n",
    "    gs = fig.add_gridspec(1, 2, width_ratios=[7, 3])\n",
    "else:\n",
    "    gs = fig.add_gridspec(1, 1)\n",
    "\n",
    "# Main plot (a)\n",
    "ax_main = fig.add_subplot(gs[0])\n",
    "ax_main.plot(x, y_efficiency, 'k-', linewidth=0.5, label='Efficiency obtained with LLM (TH/J)')\n",
    "if EXTRA_STUFF_ENABLED:\n",
    "    ax_main.step(x, y_max_efficiency, 'b-', linewidth=0.5, where='post', label='Max Efficiency achievable (TH/J)')\n",
    "else:\n",
    "    ax_main.plot(simpli_x, simpli_y, c='0.5', linewidth=0.7, linestyle='dashed', label='RDP simplification')\n",
    "\n",
    "\n",
    "turning_point_date = simpli_x[int(idx[0])]\n",
    "transition_start = turning_point_date - pd.Timedelta(days=182.5)\n",
    "transition_end = turning_point_date + pd.Timedelta(days=182.5)\n",
    "\n",
    "# Highlight the transition zone\n",
    "if EXTRA_STUFF_ENABLED:\n",
    "    transition_zone = ax_main.axvspan(transition_start, transition_end, color='gray', alpha=0.3, label='Transition zone')\n",
    "\n",
    "# Plot the turning point\n",
    "ax_main.plot(turning_point_date, simpli_y[int(idx[0])], 'ko', markersize=5, label='Turning point')\n",
    "\n",
    "# Plot the fitted line segments\n",
    "# ax_main.plot(simpli_x[:int(idx[0])+1], simpli_y[:int(idx[0])+1], 'k-', linewidth=1.5, label='Pre-turning point')\n",
    "\n",
    "if EXTRA_STUFF_ENABLED:\n",
    "    ax_main.plot(simpli_x[int(idx[0]):], simpli_y[int(idx[0]):], 'orange', linewidth=1.5, label=\"Koomey's post-2000 law\")\n",
    "\n",
    "\n",
    "# Formatting the x-axis\n",
    "ax_main.xaxis.set_major_locator(mpl.dates.YearLocator(base=1))\n",
    "# ax_main.xaxis.set_major_formatter(mpl.dates.DateFormatter(\"01.01.%Y\"))\n",
    "ax_main.xaxis.set_major_formatter(mpl.dates.DateFormatter(\"%Y\"))\n",
    "ax_main.tick_params(axis='x', rotation=30)\n",
    "\n",
    "# Set y-axis to log scale\n",
    "ax_main.set_yscale('log')\n",
    "ax_main.set_ylabel('Power efficiency (TH/J)')\n",
    "ax_main.legend(loc='best')\n",
    "\n",
    "# Grid settings\n",
    "ax_main.xaxis.grid(True, 'minor', linestyle='--', linewidth=0.1)\n",
    "ax_main.yaxis.grid(True, 'minor', linestyle='--', linewidth=0.1)\n",
    "ax_main.xaxis.grid(True, 'major', linestyle='--', linewidth=0.25, color='k')\n",
    "ax_main.yaxis.grid(True, 'major', linestyle='--', linewidth=0.25, color='k')\n",
    "\n",
    "# Add \"a)\" text\n",
    "if EXTRA_STUFF_ENABLED:\n",
    "    ax_main.text(0.01, 0.99, 'a)', transform=ax_main.transAxes, fontsize=12, verticalalignment='top', horizontalalignment='left')\n",
    "\n",
    "\n",
    "# Inset plot (b)\n",
    "if EXTRA_STUFF_ENABLED:\n",
    "    # df_data2 = pd.read_excel('Bitcoin Paper Datasheet.xlsx', engine='openpyxl', sheet_name='Turning Point')\n",
    "    # df_hashrate, df_date2 = df_data2['Hashrate (TH/s)'].dropna(), df_data2['Date'].dropna()\n",
    "    df_hashrate_ = pd.read_csv('datasheet/hashrate.csv')\n",
    "    df_hashrate, df_date2 = df_hashrate_['Hashrate (TH/s)'], pd.to_datetime(df_hashrate_['Date'])\n",
    "\n",
    "    count_row_date, count_row_hashrate = df_date2.shape[0], df_hashrate.shape[0]\n",
    "    if count_row_date != count_row_hashrate: df_hashrate = df_hashrate.iloc[:-(count_row_hashrate - count_row_date)]\n",
    "\n",
    "    ax_inset = fig.add_subplot(gs[1])\n",
    "    ax_inset.plot(df_date2, df_hashrate, 'k-', linewidth=0.3, label='Hardware evolution')\n",
    "    ax_inset.set_ylim(10**(int(np.log10(np.min(df_hashrate))) + 2), 10**(int(np.log10(np.max(df_hashrate))) + 1))\n",
    "    ax_inset.set_xlim(min(df_date2), max(df_date2))\n",
    "    ax_inset.tick_params(axis='x', rotation=30)\n",
    "    ax_inset.xaxis.set_major_locator(mpl.dates.YearLocator(base=2))\n",
    "    ax_inset.xaxis.set_major_formatter(mpl.dates.DateFormatter(\"%Y\"))\n",
    "    ax_inset.plot(simpli_x[int(idx)], df_hashrate[turn_point_row], 'ko', markersize=3)\n",
    "    ax_inset.set_yscale('log')\n",
    "    ax_inset.set_ylabel('Hashrate (TH/s)')\n",
    "    ax_inset.xaxis.grid(True, 'minor', linestyle='--', linewidth=0.1)\n",
    "    ax_inset.yaxis.grid(True, 'minor', linestyle='--', linewidth=0.1)\n",
    "    ax_inset.xaxis.grid(True, 'major', linestyle='--', linewidth=0.25, color='k')\n",
    "    ax_inset.yaxis.grid(True, 'major', linestyle='--', linewidth=0.25, color='k')\n",
    "\n",
    "    # Add \"b)\" text\n",
    "    ax_inset.text(0.01, 0.99, 'b)', transform=ax_inset.transAxes, fontsize=12, verticalalignment='top', horizontalalignment='left')\n",
    "\n",
    "if EXTRA_STUFF_ENABLED:\n",
    "    plt.savefig('pdfs/turning_point_no_cost.pdf', format='pdf')\n",
    "else:\n",
    "    plt.savefig('pdfs/turning_point_alone.pdf', format='pdf')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Split the data into two parts using the turning point row\n",
    "efficiency_pre_turn = df_efficiency_log[:turn_point_row]\n",
    "efficiency_post_turn = df_efficiency_log[turn_point_row:]\n",
    "\n",
    "# Create the x values for the two parts\n",
    "x_pre_turn = np.arange(len(efficiency_pre_turn)).reshape(-1, 1)\n",
    "x_post_turn = np.arange(len(efficiency_post_turn)).reshape(-1, 1)\n",
    "\n",
    "# Fit linear models to each part\n",
    "model_pre_turn = LinearRegression().fit(x_pre_turn, efficiency_pre_turn)\n",
    "model_post_turn = LinearRegression().fit(x_post_turn, efficiency_post_turn)\n",
    "\n",
    "# Predict the efficiency values using the fitted models\n",
    "efficiency_pre_turn_pred = model_pre_turn.predict(x_pre_turn)\n",
    "efficiency_post_turn_pred = model_post_turn.predict(x_post_turn)\n",
    "\n",
    "# Compute the R^2 values\n",
    "r2_pre_turn = r2_score(efficiency_pre_turn, efficiency_pre_turn_pred)\n",
    "r2_post_turn = r2_score(efficiency_post_turn, efficiency_post_turn_pred)\n",
    "\n",
    "# Extract the coefficients for the exponential models\n",
    "a1 = 10 ** model_pre_turn.intercept_\n",
    "b1 = model_pre_turn.coef_[0]\n",
    "a2 = 10 ** model_post_turn.intercept_\n",
    "b2 = model_post_turn.coef_[0]\n",
    "\n",
    "# Define the dates for the regimes\n",
    "start_date_pre_turn = df_date[0]\n",
    "end_date_pre_turn = df_date[turn_point_row - 1]\n",
    "start_date_post_turn = df_date[turn_point_row]\n",
    "end_date_post_turn = df_date[-1]\n",
    "\n",
    "# Define the transition period\n",
    "transition_start = turning_point_date - pd.Timedelta(days=182.5)\n",
    "transition_end = turning_point_date + pd.Timedelta(days=182.5)\n",
    "\n",
    "# Print the results in LaTeX format\n",
    "print(f\"For the first regime before the turning point, $\\\\mathrm{{R^2}}$ = {r2_pre_turn:.4f} from {start_date_pre_turn.strftime('%B %Y')} to {end_date_pre_turn.strftime('%B %Y')}, $\\\\mathrm{{eff_1(t) = {a1:.2e}\\\\times e^{{{b1:.2e} \\times t}}}}$.\")\n",
    "print(f\"For the second regime following Koomey's post-2000 law, $\\\\mathrm{{R^2}}$ = {r2_post_turn:.4f} from {start_date_post_turn.strftime('%B %Y')} to {end_date_post_turn.strftime('%B %Y')}, $\\\\mathrm{{eff_2(t) = {a2:.2e}\\\\times e^{{{b2:.2e} \\times t}}}}$.\")\n",
    "print(f\"The transition period is between {transition_start.strftime('%B %Y')} and {transition_end.strftime('%B %Y')}. The unit t is one day and starts from 0 in {start_date_pre_turn.strftime('%B %Y')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"bias for the pre-turning point data: \", model_pre_turn.intercept_)\n",
    "print(\"coefficient for the pre-turning point data: \", model_pre_turn.coef_)\n",
    "print(\"bias for the post-turning point data: \", model_post_turn.intercept_)\n",
    "print(\"coefficient for the post-turning point data: \", model_post_turn.coef_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
