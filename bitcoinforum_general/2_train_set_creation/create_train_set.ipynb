{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import gzip\n",
    "import pickle\n",
    "from openai import OpenAI\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_openai_response(prompt):\n",
    "    tokens = 1000\n",
    "    model=\"gpt-4-turbo-preview\"\n",
    "    # model=\"gpt-3.5-turbo-0125\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "            ],\n",
    "        temperature=0,\n",
    "        max_tokens=tokens,\n",
    "        top_p=1,\n",
    "    )\n",
    "    choice = response.choices[0]\n",
    "\n",
    "    text = choice.message.content\n",
    "\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_thread(row):\n",
    "    try:\n",
    "        date = row[\"date\"]\n",
    "\n",
    "        thread = \"\"\n",
    "        thread += \"Date: \" + date[:7] + \"\\n\"\n",
    "        thread += \"Topic: \" + row[\"topic\"] + \"\\n\"        \n",
    "        thread += \"### Original post:\\n\"\n",
    "        i = 1\n",
    "        for post in row[\"post\"].split(\"<sep>\"):\n",
    "            if len(post) > 1200:\n",
    "                thread += post[:1200] + \"<rest of post truncated>\\n\\n\"\n",
    "                thread += f\"### Reply {i}:\\n\"\n",
    "                i += 1\n",
    "            elif len(post) < 5:\n",
    "                pass\n",
    "            else:\n",
    "                thread += post + \"\\n\\n\"\n",
    "                thread += f\"### Reply {i}:\\n\"\n",
    "                i += 1\n",
    "        #remove the last line\n",
    "        thread = thread[:-len(f\"### Reply {i-1}:\\n\")]\n",
    "        if len(thread) > 5000:\n",
    "            thread = thread[:5000] + \"<rest of thread truncated>\\n\"\n",
    "\n",
    "        return row[\"index\"], date, thread\n",
    "\n",
    "    except:\n",
    "        print(\"Error processing thread:\" + str(row[\"index\"]))\n",
    "        return None, None, None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../1_forum_dataset/cleaned-data.csv\") # topic date post dates index\n",
    "# remove threads where date is below 2010\n",
    "df = df[df[\"date\"] >= \"2010-01-01\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "path = \"./\"\n",
    "file_name = \"dataset.csv\"\n",
    "\n",
    "already_processed_thread_ids = []\n",
    "\n",
    "if not os.path.exists(path+file_name):\n",
    "    dataset = pd.DataFrame(columns=['index','input','output'])    \n",
    "else:\n",
    "    dataset = pd.read_csv(path+file_name)\n",
    "    already_processed_thread_ids = dataset['index'].tolist()\n",
    "\n",
    "# for each unique year, sample x threads\n",
    "x = 100\n",
    "df2 = df.sample(60000,random_state=44)\n",
    "rows = pd.DataFrame()\n",
    "unique_years = np.arange(2009, 2024+1)\n",
    "year_counts = {year: 0 for year in unique_years}\n",
    "for i in range(len(df2)):\n",
    "    index, date, thread = process_thread(df2.iloc[i])\n",
    "    if index is None:\n",
    "        continue\n",
    "    year = int(date[:4])\n",
    "    if year_counts[year] < x:\n",
    "        rows = pd.concat([rows, pd.DataFrame(df2.iloc[i]).T], ignore_index=True)\n",
    "        year_counts[year] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_rows', None)\n",
    "# rows.sort_values(by=\"date\", inplace=True)\n",
    "# rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = \"\"\"User:\n",
    "# Here is a bitcoin forum thread:\n",
    "\n",
    "# ```thread\n",
    "# {}\n",
    "# ```\n",
    "\n",
    "\n",
    "# Here is a list of categories:\n",
    "\n",
    "# optimistic_speculation\n",
    "#    - Optimistic threads discussing investment strategies / price predictions.\n",
    "   \n",
    "# pessimistic_speculation\n",
    "#    - Pessimistic threads discussing investment strategies / price predictions.\n",
    "\n",
    "# bitcoin_adoption\n",
    "#    - Discussions on countries adopting Bitcoin as legal tender and regulatory changes.\n",
    "\n",
    "# bitcoin_technology\n",
    "#    - Technical discussions on Bitcoin's underlying technology and security.\n",
    "\n",
    "# financial_products\n",
    "#    - Threads related to Bitcoin exchanges, ETFs, and other financial products related to Bitcoin.\n",
    "\n",
    "# bitcoin_challenges\n",
    "#    - Debates and discussions on the challenges facing Bitcoin.\n",
    "\n",
    "# scams\n",
    "#    - Threads discussing scams, fraud and ransoms in the Bitcoin space.\n",
    "\n",
    "# bitcoin_mining\n",
    "#    - Discussions on the process of mining Bitcoin.\n",
    "\n",
    "# altcoins\n",
    "#    - Discussions about other cryptocurrencies.\n",
    "\n",
    "# educational_resources\n",
    "#     - Threads offering educational resources for new Bitcoin users and investors.\n",
    "\n",
    "# other\n",
    "#     - For threads that do not fit into any of the above categories.\n",
    "\n",
    "\n",
    "# Reply with a formatted JSON document containing a single field called \"categories\". This field should be an array of strings with 1 to 3 categories that best describe the thread.\n",
    "\n",
    "\n",
    "# Assistant:\n",
    "# Sure! Here is the requested JSON document:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"User:\n",
    "Here is a bitcoin forum thread:\n",
    "\n",
    "```thread\n",
    "{}\n",
    "```\n",
    "\n",
    "\n",
    "Here is a list of categories:\n",
    "\n",
    "speculation\n",
    "- Discussions about speculations on price movements.\n",
    " \n",
    "adoption\n",
    "- Discussions about Bitcoin's adoption, underlying technology, mining process and security.\n",
    " \n",
    "altcoins\n",
    "- Discussions about cryptocurrencies other than Bitcoin.\n",
    "\n",
    "none\n",
    "- Discussions that do not fit into any of the above categories.\n",
    "\n",
    "\n",
    "\n",
    "Reply with a formatted JSON document containing the following fields:\n",
    "-A field called \"category\". This field should be a string with the category that best describes the thread.\n",
    "-A field called \"sentiment\". This field should be a string with the sentiment of the thread. The possible sentiments are \"strongly positive\", \"positive\", \"neutral\", \"negative\", and \"strongly negative\".\n",
    "\n",
    "\n",
    "Assistant:\n",
    "Sure! Here is the requested JSON document:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stuff(data, skip=True):\n",
    "    indices, dates, threads = [], [], []\n",
    "    for j in range(len(data)):\n",
    "        row = data.iloc[j]\n",
    "        if(len(str(row[\"post\"])) < 50):\n",
    "            print(f\"skipping {j} as it is too short\")\n",
    "            continue\n",
    "\n",
    "        id, date, thread = process_thread(row)\n",
    "\n",
    "        if id in already_processed_thread_ids and skip:\n",
    "            print(f\"Skipping thread {id} as it is already processed\")\n",
    "            continue\n",
    "\n",
    "        indices.append(id)\n",
    "        dates.append(date)\n",
    "        threads.append(thread)\n",
    "\n",
    "    return indices, dates, threads\n",
    "\n",
    "indices, dates, threads = get_stuff(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "done = 0\n",
    "# for (date, thread) in tqdm(zip(dates, threads), total=len(dates)):\n",
    "for (threadid, date, thread) in zip(indices, dates, threads):\n",
    "\n",
    "    \n",
    "    print(f\"processing thread id {threadid}\\n\\n\"+ thread + \"\\n\\n\")\n",
    "    print(f\"done {done}/{len(indices)}\\n\\n\")\n",
    "\n",
    "    prompt2 = prompt.format(thread)\n",
    "    \n",
    "\n",
    "    response = get_openai_response(prompt2)\n",
    "\n",
    "    print(\"model response: \\n\\n\"+response+\"\\n\\n\\n\")\n",
    "\n",
    "    if not response.__contains__(\"```json\"):\n",
    "        print(\"ERROR: response does not contain JSON\")\n",
    "        continue\n",
    "\n",
    "    response = response.replace(\"```json\\n\",\"\")\n",
    "    response = response.split(\"```\")[0].strip()\n",
    "\n",
    "    print(\"parsed response: \\n\\n\"+response+\"\\n\\n\\n\")\n",
    "\n",
    "    try:\n",
    "        _ = json.loads(response)\n",
    "    except:\n",
    "        print(\"ERROR: could not parse response as JSON\")\n",
    "        continue\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Append the new rows to the dataset\n",
    "    input = prompt2\n",
    "    output = response\n",
    "    dataset = pd.concat([dataset, pd.DataFrame({'index': [threadid],'input': [input], 'output': [output]})], ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "    dataset.to_csv(path+file_name, index=False)\n",
    "    done+=1\n",
    "\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the inputs to do inference later\n",
    "indices, dates, threads = get_stuff(df, skip=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = pd.DataFrame(columns=['index','date','input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (threadid, date, thread) in zip(indices, dates, threads):\n",
    "    prompt2 = prompt.format(thread)\n",
    "    inputs = pd.concat([inputs, pd.DataFrame({'index': [threadid],'date': [date],'input': [prompt2]})], ignore_index=True)\n",
    "\n",
    "inputs.to_csv(path+\"inputs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
