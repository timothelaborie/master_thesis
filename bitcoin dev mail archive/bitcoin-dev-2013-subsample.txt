On Tue, Feb 12, 2013 at 12:42:37PM -0500, Gavin Andresen wrote:

So what exactly was the OP_RETURN bug anyway? I know it has something to
do with not executing the scriptSig and scriptPubKey separately
(https://bitcointalk.org/index.php?topic=58579.msg691432#msg691432) but
commit 7f7f07 that you reference isn't in the tree, nor is 0.3.5 tagged.


You know, come to think of it, OP_FALSE doesn't get used by standard
transactions either, and it's behavior is a little odd in how it does
push to the stack. So lets make the standard OP_INVALIDOPCODE,
specifically 0xFF, and put it at the start of the scriptPubKey.


That's a good point. It would encourage efforts to identify as many
Bitcoin nodes as possible, particularly miners, and I don't think we
really want to incentivise that. It's not a problem unique to this
proposal - compromised private keys and SIGHASH_NONE (1) - but
fidelity bonds will give people incentive to develop the infrastructure
to exploit it.

    1) Speaking of, maybe I'm missing something, but if I have a
    transaction with one or more txin's and sign every signature with
    SIGHASH_SINGLE, what stops an attacker from adding their own txout
    at the end and diverting the mining fee to themselves?

Having said that, if we both make empty scriptPubKeys standard, and add
code so that miners will always try to spend the outputs for themselves
at the same time, we can get rid of this problem by removing the
incentive. It would also still make non-fidelity-bond uses viable as
well.

Of course, if you want to go down that path, we might as well add code
to detect and spend fidelity bonds too, and make the publish
transactions IsStandard(). Basically for every script in a confirmed
block check if any pushdata op happens to be a script that we would be
willing to add to the mempool at nBlockHeight + N. (assuming current
utxo set) If so, add it to the mempool now. N should be at least 100
blocks I think for the same reason that coinbase tx's take 100 blocks to
spend. The limit also means the size of the mempool can't get larger
than MAX_BLOCK_SIZE * N. Meanwhile IsStandard() would allow the
scriptPubKey OP_INVALIDOPCODE <valid serialized tx>

P2SH already treats data as scripts, so treating data as entire tx's
isn't that big of a leap. Also since the txout is unspendable, the
Satoshi criteria that block-reorgs should not make child tx's vanish is
still met. (though tx mutability sort of breaks this anyway)


We would however open quite a few cans of worms:

1) We just made non-final !IsStandard() for a reason.

2) What if there are transactions already in the mempool that spend the
txin's of the sacrifice? If we ignore them, we've just created another
way to double-spend unconfirmed transactions. On the other hand, if we
don't ignore them, we've just created a way to give us a chance to mine
the sacrifice for ourselves.

Personally I'm with you Gavin and think assuming miners are greedy is
best, but lets just say I probably shouldn't write an implementation
with a function named IsTxOutStealable()?

2a) What if multiple sacrifice publications exist spending the same
txin's? We should have deterministic behavior and mine the most valuable
one. If you don't do that, the attackers effective hashpower is
increased. (and thus the true sacrifice value of the bond decreases)

2b) ...but this is actually an annoying optmization problem. You could
create a whole bunch of sacrifices, each spending two or more inputs,
one small, one large. Then create one large sacrifice, that spends all
the *small* inputs. If the value of the large sacrifice is less than the
combined totals of the smaller sacrifices, you should be mining the
small ones rather than the large for maximum return.

3) With the 10KB limit on scripts, a naive IsStandard() could wind up
recursing about 200 times; we probably should say recursive publish
transactions are non-standard.

3b) ...on the other hand, if they are non-standard, implementations that
use fidelity bonds better make sure they don't accept such monsters.

We probably should just define one standard sacrifice tx form with one
txin, one txout, and a standard P2SH scriptPubKey, but miners can still
do their own thing and cause problems in determining the true value
sacrificed if they don't get the optimization problem right.

Fidelity bonds needs a lot more thought, and a testnet implementation...

-- 
'peter'[:-1]@petertodd.org
-------------------------------------
On Fri, Oct 25, 2013 at 02:02:35PM +0200, Andreas Petersson wrote:

Anyway, as I've said repeatedly my problem with fee estimation is that
it needs to be combined with some form of transaction replacement to
give users a way to recover from bad estimates, not that I think the
idea shouldn't be implemented at all. After all, we alrady have fee
estimation: wallet authors and users manully estimate fees!

This particular case is a nasty one re: recovering from a bad estimate,
and it's exactly why the payment protocol is designed for the sender to
give the receiver a copy of every transaction they make so the receiver
can be held responsible for getting them mined, eg. with
child-pays-for-parent, out-of-band fee payment, or maybe even by adding
inputs to the transaction. (SIGHASH_ANYONECANPAY)

-- 
'peter'[:-1]@petertodd.org
0000000000000001231d6e04b4b18f85fa0ad00e837727e7141eaa8cfecc734b
-------------------------------------
While I like the idea of a client using a DHT blockchain or UTXO list, I
don't think that the reference client is the place for it. But it would
make for a very interesting experimental project!


On 29 April 2013 13:36, Gregory Maxwell <gmaxwell@gmail.com> wrote:

-------------------------------------
On Mon, May 06, 2013 at 06:47:22PM +0200, Mike Hearn wrote:

You mean scam you with a zero-conf transaction that hasn't actually been
broadcast?

You know how I feel about zero-conf.


We already depend on OpenSSL, why not just use standard SSL?

Define a per-node compressed pubkey to pass around, and then do whatever
is easiest to get the actual SSL up and running. If we have to use that
pubkey to in-turn sign for a secondary RSA key or whatever due to
compatibility, no big deal.

Define a new service bit SSL and if you connect to a SSL supporting node
switch to SSL within the same TCP connection.


Obfusication probably isn't the hard part, it's SPV bloom filter privacy
that is the tough one, but probably a problem better handled by Tor.


For phone stuff you should work with The Guardian Project - they've
implemented Tor on Android among other things and want to find easier
ways for apps to use it.

-- 
'peter'[:-1]@petertodd.org
000000000000014671272e3a4dd966bb56d4a9a27751b5cd4dc75dc931660cb5
-------------------------------------
I vote "yes" to have MultiBit replace Bitcoin-Qt as the recommended
desktop wallet app. I think most users will be happier with it.

If I'm wrong, it is easy to change back.


-------------------------------------
On Sun, Oct 20, 2013 at 06:43:16PM -0400, Peter Todd wrote:

Figures, I'm told that's exactly how they were first done -
https://github.com/genjix/bips - only people found it inconvenient and
used the wiki instead.

Pathetic IMO for standards, but it wouldn't exactly be the first time
I've seen strong resistance to using revision control. (I quite
literally work with rocket scientists/satellite engineers who can't be
convinced to use it)

I dunno, maybe something using git submodules or subtrees - letting the
individual BIP "owners" make changes frequently until they're happy -
might have more social acceptance.

-- 
'peter'[:-1]@petertodd.org
000000000000000aff52788645172e4acca1d9fc9387ebe4074d9ce275273b44
-------------------------------------
Nearly all of these new(er) user-mode transports run over UDP, so you can
hole-punch and port forward just the same. Some which don't can
nevertheless be tunneled, to the same effect.

Ultimately I don't have any skin in this game though. Just trying to save
someone from reinventing a perfectly good wheel ;)


On Sat, Mar 23, 2013 at 5:57 PM, Jay F <jayf@outlook.com> wrote:

-------------------------------------
Andreas has uploaded Android builds that use the new bloom filtering and
peer selection code (also, dependency analysis of transactions).

The performance gain is very cool. The app feels dramatically faster to
start up and sync. Because the app syncs on charge when I opened it around
lunchtime it had only 7 hours of data to sync (42 blocks) and it brought up
6 peer connections, found a 0.7.99 node and synced all in <2 seconds. That
was on wifi.

The next lowest hanging perf fruit is almost certainly to optimize disk
accesses. Flash on Android devices seems to be much slower than laptop
flash storage, and current bitcoinj is very inefficient in how it writes
(one write per block header!). This matters a lot when doing fast catchup
for first time users.

The BIP is now a little bit stale, but only slightly.


On Wed, Jan 16, 2013 at 4:00 PM, Matt Corallo <bitcoin-list@bluematt.me>wrote:

-------------------------------------
Indeed, and for a higher level answer, see here:

https://en.bitcoin.it/wiki/Contracts


On Fri, Jun 21, 2013 at 6:03 AM, Patrick Strateman
<patrick@intersango.com>wrote:

-------------------------------------
One very real issue for alt-currencies that don't peg to Bitcoin is that
market liquidity is a bitch. By almost all standards current global Bitcoin
liquidity is already very, very low. Too low for many transactions that
come across my desk at least.

There are a lot of reasons for that low liquidity, but to try and float a
new pair for which the likely initial counter-asset is going to be Bitcoin
means minuscule liquidity.

Peter



On Sat, Jul 13, 2013 at 2:53 AM, Jorge Timn <jtimon@monetize.io> wrote:




-- 

------------------------------

[image: CoinLab Logo]PETER VESSENES
CEO

*peter@coinlab.com * /  206.486.6856  / SKYPE: vessenes
900 Winslow Way East / SUITE 100  /  Bainbridge Island, WA 98110
-------------------------------------
In my fidelity bond protocol (1) I'm proposing the use of two possible
new features:

The first is the use of OP_RETURN at the end of a scriptPubKey to
designate that the txout can be immediately pruned as it is obviously
unspendable. My use-case is the publish part of the two-step
publish-sacrifice protocol. I specifically want to use OP_RETURN rather
than a spendable scriptPubKey like <serialized tx> <pubkey> OP_CHECKSIG
so that implementors can not get lazy and fail to actually write the
code to spend the non-standard outputs created, thus polluting the UTXO
set. Simply using <serialized tx> by itself as the scriptPubKey -
spendable with an empty scriptSig - is another possiblity, but I suspect
no-one will want to spend the tx fees to clean up those txouts; note how
long it took for someone to bother doing that with p2pools share chain
hash txout, and the effort(2) seems to have been a one-time experiment.
Of course, P2Pool itself could use this mechanism too.

OP_RETURN marks the script as invalid upon execution, and since a script
is invalid if an OP_IF or OP_ELSE is not terminated with OP_ENDIF it is
guaranteed to execute. (there is no op-code that marks a script as valid
and returns immediately) OP_FALSE is another possibility too; I don't
see clear advantages for one or the other modulo OP_FALSE's more
intuitive name.

Finally OP_VERIF and OP_VERNOTIF say that "Transaction is invalid even
when occuring in an unexecuted OP_IF branch" on the wiki, although a
look at EvalScript() leaves me less than convinced this is true.  More
to the point, the mechanism should be something that is as unlikely as
possible to have different behavior in alternate implementations.
(remember that often only valid transactions are put in unittests by
lazy implementors)

OP_RETURN doesn't need any special support in the reference client yet
nor am I suggesting to make it a standard transaction type, but I would
like some feedback on if the idea itself is reasonable.


The second idea is the use of an empty scriptPubKey to create trivially
spendable outputs; provide the the scriptKey OP_TRUE or similar. For
fidelity bonds the advantage is to create a mechanism where even
non-miners have a chance at taking the funds sacrificed, and thus
increase the incentive to scan the blockchain for sacrifices and makes
it more likely for the sacrifice to be a true sacrifice of value. An
additional advantage is you avoid having to provide the txin to prove
the value of the mining fee. The advantage over just using a pubkey with
a known secret key is that the transaction size is shorter; remember
that the sacrifice transaction has to be published as serialized data in
a prior transaction.

In the future another use would be as a way of multiple parties to
collectively sign an assurance contract(3) donating to miners. This is
effectively a mining fee because miners who chose to include the
transaction can always chose to include an additional transfer from the
txout to a scriptPubKey only they can spend.

For the purpose of fidelity bonds ideally an empty scriptPubKey spent by
the scriptSig OP_TRUE would be made a standard transaction type to make
collecting the funds as easy as possible until miners start doing so
themselves. Having it a standard transaction type would also make it
easier for miners to implement the code to do this themselves; in
particular this discourages them from just allowing all non-standard
transactions. The main disadvantage I see is that it makes it easier for
people with buggy custom transaction code to accidentally lose their
funds.

Again, thoughts?


1) https://github.com/petertodd/trustbits/blob/master/fidelitybond.md
2) See the transactions associated with 1HfA1KHC7bT1hnPPCjpj9CB4koLM4Hz8Va
3) https://en.bitcoin.it/wiki/Contracts#Example_3:_Assurance_contracts

-- 
'peter'[:-1]@petertodd.org
-------------------------------------
On Thu, Aug 15, 2013 at 12:49 PM, Wladimir <laanwj@gmail.com> wrote:

As far as I can see, that state is gone, and is now passed in a
separate object to the transaction-creation methods.

I'd like to see it go in, as I believe it can be helpful in
understanding the difference between the high-level abstraction
(wallet) and the underlying implementation (individual coins) -
something that many people are confused about. I think that's even a
more important advantage than the ability for micro-management it
offers. Multiwallet would be more appropriate for avoiding linkage
between identities, but it seems there's little progress on that front
now.

-- 
Pieter


-------------------------------------
On Wed, Feb 13, 2013 at 7:28 PM, Gregory Maxwell <gmaxwell@gmail.com> wrote:


I understand your arguments, but don't agree with many of your conclusions.

The requirement for everyone to hear the history doesn't get talked


One of the beauties of bitcoin is that the miners have a very strong
incentive to distribute as widely and as quickly as possible the blocks
they find...they also have a very strong incentive to hear about the blocks
that others find.  There will not be an issue with blocks being "jealously
guarded"...what miners will want is a good feed of transactions that they
want to mine.  They will be willing to pay for those feeds (either by
sharing the proceeds with highly connected "relay" nodes or by operating
highly connected nodes themselves).  Because miners will only want to pay
to get a feed of profitable transactions, they will not pay to receive
transactions whose miner fee does not cover the "relay" fee (by which I
mean the fee or cost associated with the bandwidth and validation that a
transaction requires) with some amount of profit.  This means that the
relay node will not fetch and propagate those transactions whose fee is too
small (unless there was some other fee structure outside the miners fee).

These are relatively easy businesses to operate...which means there will be
a lot of them and they'll compete on fees (with wallets automatically
discovering the cheapest of the services).  If the businesses of relaying
and mining ever became too centralized, other businesses with a vested
interest in the success of bitcoin would take the necessary steps to ensure
there remained adequate decentralization.

It's important to remember that the centralization that currently exists in
the fiat currency world benefits one set of businesses to the detriment of
many others.  Having a functioning and trustworthy payment system benefits
far more people and businesses than a centralized system would.

It is good to be wary of these potential issues, but I don't see how the
economics are likely to yield the outcome you fear.  And, really, there's
not a lot that can be done to prevent economics from dictating the ultimate
outcome.  In fact, what I write above is not so much about what I think
*should* be built, it's more about what I *predict* will be built.
-------------------------------------


That seems reasonable.

The other message should be implementable today, I think? If numBroadcastPeers > 0 post 0.10.3 then you know the tx made it out to the internet.

Unfortunately if nodes start to diverge a lot in terms of what they will accept, then transmitted is no longer a clean binary yes/no thing. Guess well have to jump that hurdle when we come to it.


The payment protocol at least would need some notion of fee, or possibly (better?) the ability for a recipient to specify some inputs as well as some outputs.

Originally I think we were hoping for child-pays-for-parent. I guess that needs someone to sit down and focus on it for a while, assuming we still think thats a good idea.
-------------------------------------
Hi Bazyli,

Just did a fresh build based on git (Xcode) - had one issue: the paillier and account tests were missing - please comment them out in tests/CMakeLists.txt, then coinexplorer should build nicely.

Note I did a git push as well, so you need to do a git pull first.

/Michael

-------------------------------------
On Tue, Jul 23, 2013 at 9:07 PM, Gregory Maxwell <gmaxwell@gmail.com> wrote:
*before someone corrects me, it's not LE everywhere (I meant
"manywhere" :P)â€” there is just enough BE to keep you on your toes. :P


-------------------------------------
On Sun, May 12, 2013 at 8:35 AM, Jay F <jayf@outlook.com> wrote:


I opened   https://github.com/bitcoin/bitcoin/issues/2641 for this issue.

-- 
Pieter
-------------------------------------
On Sunday, November 03, 2013 12:29:28 AM Allen Piscitello wrote:

Well, there's no use case to sign with an address that has already been sent 
coins. The main problem with enforcing this is that you can't exactly stop 
someone from sending to an "identity" address.

Luke


-------------------------------------
On 6 November 2013 06:33, kjj <bitcoin-devel@jerviss.org> wrote:


Thanks for posting this bounty.  I'm interested in working on it, and will
give it a try.  I also have some other commitments, so I suspect you guys
will finish it first tho... but if not, I'll post details of the simulator.


-------------------------------------
On Mon, Oct 21, 2013 at 11:59 PM, Jean-Paul Kogelman
<jeanpaulkogelman@me.com> wrote:

Take care, the information in the wiki is woefully incomplete.


-------------------------------------
Jesus, please stop this. :(

-wendell

grabhive.com | twitter.com/grabhive | gpg: 6C0C9411

On Aug 9, 2013, at 9:01 PM, Randolph D. wrote:



-------------------------------------
We're with uBTC too. Been waiting for the signal to do this, let's do it right after the fee system is improved.

-wendell

grabhive.com | twitter.com/hivewallet | gpg: 6C0C9411

On Nov 15, 2013, at 6:03 AM, Jeff Garzik wrote:




-------------------------------------
If you're only interested in storing the best chain then a fairly simple
schema is possible.

CREATE TABLE blocks (
    hash bytea NOT NULL PRIMARY KEY,
    index integer NOT NULL UNIQUE,
    CONSTRAINT block_hash_size_check CHECK ((octet_length(hash) = (256 /
8)))
);

CREATE TABLE transaction_inputs (
    output_transaction_id bytea NOT NULL,
    output_index integer NOT NULL,
    block_index integer NOT NULL,
    CONSTRAINT transaction_id_size_check CHECK
((octet_length(output_transaction_id) = (256 / 8))),
    PRIMARY KEY (output_transaction_id, output_index)
);

CREATE INDEX transaction_inputs_block_index_idx ON transaction_inputs
USING btree (block_index)

CREATE TABLE transaction_outputs (
    transaction_id bytea NOT NULL,
    index integer NOT NULL,
    amount numeric(16,8) NOT NULL,
    type character varying NOT NULL,
    addresses character varying[],
    block_index integer NOT NULL,
    spent boolean DEFAULT false NOT NULL,
    CONSTRAINT transaction_id_size_check CHECK
((octet_length(transaction_id) = (256 / 8))),
    PRIMARY KEY (transaction_id, index)
);

CREATE INDEX transaction_outputs_addresses_idx ON transaction_outputs
USING gin (addresses);
CREATE INDEX transaction_outputs_block_index_idx ON transaction_outputs
USING btree (block_index);

On 06/05/2013 05:53 PM, Marko Otbalkana wrote:

-------------------------------------
Prefix the script with OP_RETURN. Otherwise you are still contributing
to blockchain bloat.

Mark

On 9/13/13 5:51 PM, Turkey Breast wrote:


-------------------------------------
If you want package authentication, you should at least throw in some
digital signing, not just a checksum. With a compromised host, both the
checksum and binaries can be changed undetectably, but if there's a
signature made by a key that is not kept on the host, there's no way to
fake a valid binary.

There may be other issues people would want to bring up, but surely just
a checksum is not sufficient.

on 08/05/2013 10:39 AM Wendell said the following:
in our wallet app.
an updater for security reasons... Has been thought out in more detail
since that decision was made?
a Tor hidden service, whose only function is to output a checksum of the
update package. The theory is that if it is well-secured, it will at
least be immune to tampering at the physical hosting level.



-------------------------------------
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 11/15/13 5:19 PM, Drak wrote:

It's not about being technically correct. It is about protecting the
user from grave breaches of privacy. It is for their own benefit that
they should not be reusing addresses, and if they understood why they
wouldn't.

Unfortunately calling it a "bitcoin address" and including an "address
book" in the reference client has had the effect of making people
think that these objects are like paypal address, or email addresses,
but they are not and they should not be treated the same.

Mark

-----BEGIN PGP SIGNATURE-----
Version: GnuPG/MacGPG2 v2.0.19 (Darwin)
Comment: GPGTools - http://gpgtools.org
Comment: Using GnuPG with Thunderbird - http://www.enigmail.net/

iQIcBAEBAgAGBQJShsr4AAoJEAdzVfsmodw46nIP/AlDcJh2ET9qYT2ZvddciTk3
dtQDArCkwCW3kYbVjIFT8YtNFftEfkq/qBNnILipLJNN49QduAIlt3aetEE6eJBZ
oqYOV2R7GW2yhLDv/GrT6GnB1C9nQ4OuKC6RNpXX4bMpZSrbP9yfyyLqecF1tMBV
i8De4XLz1uUvZOo/jwHNeYy/BAZktwdk5hWlgG2yKebRbqVX1Xv70Qb1cPpBgCWm
uRDL3bqdZuh6i8NNDQpBqMJ/MP4ZWpIgdHkfO6a3QCq3H0JXyug4t5lkNngCrAI3
KGlSOuYK4Fsfw97xQUBFIaSYFOU+yPDRQK4UGcTqWPLt5YHzUxBFNkOXSnVReudq
Em/wlbDkPqm7R6by54fVkG85snJrwmTbD7uxGz2fe1LyzB3HhdOTZyZ1KiyDHqGA
zDUFxmH0XNhvVcJvcSFlc38A54oOHTJmfJ3rxJU/q0/5N3ZIBdF8fQ4xIvXXDeeA
dO+tul5q78tbO6xyTrbsHO8JRYt4Un8Hjc5mkdqp9gzA8beJFm5+jMZlGBfdl5jR
lS9sW7QBxr6m+n2PJ97i+1CgoxTfzOh3jyj93G6Hqx3reTfCu5fSWUhwRnFzJXav
qqPBP4Cl+6ocK7+4V1lyfAzMqpYx+GCJ1JZhD0hhwrGglgVPfE0bz7BUGea8U3+T
0pCTlkhWzEbzDp7NtFdY
=ShxL
-----END PGP SIGNATURE-----


-------------------------------------
- Mention github instead of wiki
- Add markdown as allowed format
- Fix some weirdnesses such as "A BIP editor must subscribe to the
gmaxwell@gmail.com list.". Remove the repetition and create a new section
which lists the BIP editors (currently only gmaxwell).
- Prefer discussion on mailing list to forum

This is just a cleanup and change for the github move. I have not changed
the process to jgarzik's new proposed process (
http://sourceforge.net/mailarchive/forum.php?thread_name=CAAS2fgROsymXnXTrfLTLTQ%3DEDwaAFu%2BxrrD4Q-Gye5XWze7vFw%40mail.gmail.com&forum_name=bitcoin-development),
this can be done in a later separate change.

See pull request here:
https://github.com/bitcoin/bips/pull/1

Regards,
Wladimir
-------------------------------------
Well a reversed upgrade is an upgrade that went wrong ;)

Anyway, the incident makes it even more important for people to upgrade, well except, perhaps, for miners...

Forks are caused by rejection criteria, hence: 
1. If you introduce new rejection criteria in an upgrade miners should upgrade _first_.
2. If you loosen some rejection criteria miners should upgrade _last_.
3. If you keep the same criteria assume 2.

/M

On 12/03/2013, at 13:11, Mike Hearn <mike@plan99.net> wrote:




-------------------------------------
On Mon, Oct 28, 2013 at 1:14 PM, Adam Back <adam@cypherspace.org> wrote:



A bit late is one way to put it. All these topics and more were discussed
to death a year ago when the payment protocol was first being designed.
Bluntly, I think we're all sick of it. You are welcome to PGP sign your
payment requests if you want to. If not, then please see my FAQ for
discussion:

   https://bitcointalk.org/index.php?topic=300809.msg3225143#msg3225143

tl;dr - the right way to tackle governments getting bogus certs issued is
certificate transparency. All other suggestions tend to boil down to
"here's some handwaving that doesn't actually solve the problem".

By the way, the evidence from the Snowden case rather reinforces the
strength of the CA system. Did we see stories about bulk usage of fake
certificates? No. What we read is that the increased usage of SSL was a
major game-changer for intelligence agencies. They "solve" SSL by compiling
databases of private keys they obtain in various ways. True to form when
the FBI wanted access to LavaBit, they tried to obtain his private keys
rather than just push a convenient "give me a fake cert" button, and when
it became known that Lavabit had to hand over their key, GoDaddy revoked
their certificate. Industry policies forced their hand and those policies
don't have a get-out clause for the FBI.

It's without a doubt that there are government-issued fake certs floating
about, somewhere, just due to the scale of hacking that's been taking
place. However, demanding perfection in a system that handles security for
over a billion people and tens of millions of operators is unreasonable.
All we can ask for is that it it's being improved, which through
initiatives like cert transparency, it is.

Please, let's call time on these discussions. They long ago ceased to have
any value.
-------------------------------------
What if we have a massive (like many orders of magnitude) drop in network harsh rate?  Might such a function be useful to salvage the (non-functioning) network? Same for IRC bootstrapping.  How do we pick ourselves up off the ground in case of the equivalent of a great depression in network hash rate (or some jerk spending $100M just to drive the difficulty up and then turning his hardware off?).

-----Original Message-----
From: bitcoin-development-bounces@lists.sourceforge.net [mailto:bitcoin-development-bounces@lists.sourceforge.net] On Behalf Of bitcoin-development-request@lists.sourceforge.net
Sent: Monday, August 19, 2013 3:16 PM
To: bitcoin-development@lists.sourceforge.net
Subject: Bitcoin-development Digest, Vol 27, Issue 28

Send Bitcoin-development mailing list submissions to
	bitcoin-development@lists.sourceforge.net

To subscribe or unsubscribe via the World Wide Web, visit
	https://lists.sourceforge.net/lists/listinfo/bitcoin-development
or, via email, send a message with subject or body 'help' to
	bitcoin-development-request@lists.sourceforge.net

You can reach the person managing the list at
	bitcoin-development-owner@lists.sourceforge.net

When replying, please edit your Subject line so it is more specific than "Re: Contents of Bitcoin-development digest..."


Today's Topics:

   1. Proposal: remove "getwork" RPC from bitcoind (Jeff Garzik)
   2. Re: Proposal: remove "getwork" RPC from	bitcoind (Frank F)
   3. Re: Proposal: remove "getwork" RPC from	bitcoind (Luke-Jr)
   4. Re: Proposal: remove "getwork" RPC from	bitcoind (Pieter Wuille)
   5. Re: Proposal: remove "getwork" RPC from bitcoind (Matt Corallo)
   6. Re: Proposal: remove "getwork" RPC from	bitcoind (Frank F)


----------------------------------------------------------------------

Message: 1
Date: Mon, 19 Aug 2013 12:27:01 -0400
From: Jeff Garzik <jgarzik@bitpay.com>
Subject: [Bitcoin-development] Proposal: remove "getwork" RPC from
	bitcoind
To: Bitcoin Dev <bitcoin-development@lists.sourceforge.net>
Message-ID:
	<CAJHLa0MnnWw=qiYC0nJcY=BdTDcAjGtraJ+kazoG7_bHW-HBtw@mail.gmail.com>
Content-Type: text/plain; charset=ISO-8859-1

Pull request https://github.com/bitcoin/bitcoin/pull/2905 proposes to remove "getwork" RPC from bitcoind: https://en.bitcoin.it/wiki/Getwork

On mainnet, almost everybody uses a pool (and therefore, not "getwork"
directly to bitcoind).  Those few who solo mine use a pool server to talk to bitcoind via "getblocktemplate" or other means.  Tests show that attempts to solo mine on mainnet via "getwork" lead to delays and problems.

On testnet, getwork has a better chance of continuing to work.
Nevertheless, the same tools (open source pool servers or p2pool) are available for testnet, obviating the continued need to support getwork.

However, at one time, getwork to bitcoind was widely used.  I wanted to poke the audience, to gauge response to removing "getwork."  If a driving use case remains of which we're unaware, speak up, please.  We don't want to break anybody needlessly.

--
Jeff Garzik
Senior Software Engineer and open source evangelist
BitPay, Inc.      https://bitpay.com/



------------------------------

Message: 2
Date: Mon, 19 Aug 2013 15:09:41 -0500
From: Frank F <frankf44@gmail.com>
Subject: Re: [Bitcoin-development] Proposal: remove "getwork" RPC from
	bitcoind
Cc: Bitcoin Dev <bitcoin-development@lists.sourceforge.net>
Message-ID:
	<CALxyHsXoCqL8dNXeayibfbR7-JU6Ke19gJJ1fToboULdUa155Q@mail.gmail.com>
Content-Type: text/plain; charset="iso-8859-1"

I strongly object to removing the only mechanism that allows anyone to say
that bitcoin is p2p, in the truest sense of the word. Moves like this that
favor only the pool operators and private mining interests are signs that
bitcoin is headed towards a monopoly/cartel model, and that would be a
tragic outcome for something that holds a great promise. Nobody knows what
mining will look like in the future, and denying the individual novice the
ability to mine at a small scale, even if we may think it is inefficient
now, is not a good path to start down.

If there are technical problems with getwork, maybe they should be
addressed and fixed instead of outright abandoned.


On Mon, Aug 19, 2013 at 11:27 AM, Jeff Garzik <jgarzik@bitpay.com> wrote:




-- 
*MONEY IS OVER!*
                                IF YOU WANT IT<http://www.zeitgeistmovie.com/>
=====================================================
The causes of my servitude can be traced to the tyranny of money.
-Serj Tankian
-------------- next part --------------
An HTML attachment was scrubbed...

------------------------------

Message: 3
Date: Mon, 19 Aug 2013 20:13:00 +0000
From: "Luke-Jr" <luke@dashjr.org>
Subject: Re: [Bitcoin-development] Proposal: remove "getwork" RPC from
	bitcoind
To: bitcoin-development@lists.sourceforge.net
Message-ID: <201308192013.02806.luke@dashjr.org>
Content-Type: Text/Plain;  charset="iso-8859-15"

On Monday, August 19, 2013 8:09:41 PM Frank F wrote:

You missed getblocktemplate. It does everything getwork did and more.

Individual solo miners aren't being locked out at all. This is just removal of 
a protocol that has been obsolete for well over a year now.

Luke



------------------------------

Message: 4
Date: Mon, 19 Aug 2013 22:14:36 +0200
From: Pieter Wuille <pieter.wuille@gmail.com>
Subject: Re: [Bitcoin-development] Proposal: remove "getwork" RPC from
	bitcoind
To: Frank F <frankf44@gmail.com>
Cc: Bitcoin Dev <bitcoin-development@lists.sourceforge.net>
Message-ID:
	<CAPg+sBjMdZfHpZrvHwMx6oQsS0yJaXVjTnyRwf6VCdnWTHQZaw@mail.gmail.com>
Content-Type: text/plain; charset=ISO-8859-1

On Mon, Aug 19, 2013 at 10:09 PM, Frank F <frankf44@gmail.com> wrote:

They were addressed and fixed in a successor API, getblocktemplate.
It's even more decentralization-friendly, as it allows the caller to
see what transactions the daemon is trying to put into a block, and
even modify it.

The suggestion here is not to remove functionality - only to remove an
obsolete API for doing so.

-- 
Pieter



------------------------------

Message: 5
Date: Mon, 19 Aug 2013 16:15:08 -0400
From: Matt Corallo <bitcoin-list@bluematt.me>
Subject: Re: [Bitcoin-development] Proposal: remove "getwork" RPC from
	bitcoind
To: Jeff Garzik <jgarzik@bitpay.com>
Cc: Bitcoin Dev <bitcoin-development@lists.sourceforge.net>
Message-ID: <1376943308.27037.7.camel@localhost.localdomain>
Content-Type: text/plain; charset="UTF-8"

ACK, I see no reason to leave broken things in that a) arent necessary
and b) no one has the developer resources to fix.

Matt

On Mon, 2013-08-19 at 12:27 -0400, Jeff Garzik wrote:





------------------------------

Message: 6
Date: Mon, 19 Aug 2013 15:16:17 -0500
From: Frank F <frankf44@gmail.com>
Subject: Re: [Bitcoin-development] Proposal: remove "getwork" RPC from
	bitcoind
Cc: Bitcoin Dev <bitcoin-development@lists.sourceforge.net>
Message-ID:
	<CALxyHsV=LWY+TzZG-XBQ6HNhxFEezjFhW++aJ7oVbVGEJWW0nw@mail.gmail.com>
Content-Type: text/plain; charset="iso-8859-1"

Thank you for setting me straight. Please forgive my ignorance.


On Mon, Aug 19, 2013 at 3:14 PM, Pieter Wuille <pieter.wuille@gmail.com>wrote:




-- 
*MONEY IS OVER!*
                                IF YOU WANT IT<http://www.zeitgeistmovie.com/>
=====================================================
The causes of my servitude can be traced to the tyranny of money.
-Serj Tankian
-------------- next part --------------
An HTML attachment was scrubbed...

------------------------------

------------------------------------------------------------------------------
Introducing Performance Central, a new site from SourceForge and 
AppDynamics. Performance Central is your source for news, insights, 
analysis and resources for efficient Application Performance Management. 
Visit us today!
http://pubads.g.doubleclick.net/gampad/clk?id=48897511&iu=/4140/ostg.clktrk

------------------------------

_______________________________________________
Bitcoin-development mailing list
Bitcoin-development@lists.sourceforge.net
https://lists.sourceforge.net/lists/listinfo/bitcoin-development


End of Bitcoin-development Digest, Vol 27, Issue 28
***************************************************


-------------------------------------
We've reflected many comments about BIP39 wordlist from the community and I
think the wordlist is much better now. Specifically we removed many of
theoretically offensive words as well as we implemented algorithm for
detecting words with similar characters (cat/eat) and we resolved these
duplicities. I'm now quite happy with the wordlist and I want to ask you
for next (final?) round of comments.

hardening (against bruteforcing) using Rijndael cipher. This has been
chosen because its blocksize can be 128, 192 or 256 bits, so it fits length
of desired seeds. Also there are Rijndael implementations in every
language. Btw password protection has one interesting feature - plausible
deniability. It allows user to have one mnemonic and by using it with
different passwords, it will generate different BIP32 wallets.... (wink
wink)

I want to be pretty clear that we need to close this topic somehow, because
we want to use such algorithm in Trezor (which deadline is coming quick)
and also other wallet developers want to implement such algorithm into
clients to be compatible with Trezor. There were quite strict requirements
for such algorithm (like the possibility to convert mnemonic to seed as
well as seed to mnemonic) and I think we found a good solution. I'm wildly
asking you for constructive comments, but saying "it's a crap, I don't like
it" won't help anything.

Thanks,
slush


On Thu, Sep 12, 2013 at 6:02 PM, Matthew Mitchell <
matthewmitchell@godofgod.co.uk> wrote:

-------------------------------------
On 2 April 2013 00:10, Will <will@phase.net> wrote:


Very good points, and I think you're absolutely right.

But just running the numbers, to get the picture, based of scheiner's
statistics:

http://www.schneier.com/blog/archives/2012/10/when_will_we_se.html

We're talking about a million terrahashes = 2^60 right?

With the block chain, you only have a 10 minute window, but with source
code you have a longer time to prepare.

Couldnt this be done with an ASIC in about a week?



-------------------------------------
I'm working on a project that requires users to exchange public keys (for
multisig transactions).

It seems that hex encoding is usually used to display public keys (i.e. in
bitaddress and brainwallet), which results in longer strings and lacks the
4-bytes verification.

A standard way to encode public keys as base58-check addresses would make
it easier and safer to display and exchange public keys. All that is really
needed is deciding on a prefix byte.

Perhaps we can use 0x37/0x38, which results in the letter P (for "Public")?
It seems like those bytes aren't used for anything yet.

Thanks,
Nadav
-------------------------------------
On Wed, Dec 04, 2013 at 12:09:42PM +0100, Mike Hearn wrote:

replace-by-fee is no less speculative than your original proposals;
you're also trying to convince people that things should work
differently re: fees

-- 
'peter'[:-1]@petertodd.org
000000000000000f9102d27cfd61ea9e8bb324593593ca3ce6ba53153ff251b3
-------------------------------------
On Mon, Aug 19, 2013 at 12:00:23AM +0200, Mike Hearn wrote:

Bloom filtering isn't lossless so to speak.

A better analogy would be making re-sharing an optinal part of the
BitTorrent specification, and then expecting that the majority of users
would never upload data to peers that needed it.

-- 
'peter'[:-1]@petertodd.org
-------------------------------------
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256

So, vendors hat on, what would it take for, say, BitPay to implement merge avoidance and coinjoin together?

At the dark wallet hackathon when we were talking usability we decided that the main way to get coinjoin working well is to take advantage of non-time-critical payments to act as counterparties to time-critical payments. For instance BitPay could schedule a vendor payment to happen in full by some time in the future, say 1 day, and send the funds in one or more joins. The actual amounts sent in each tx are then picked to match the amounts desired by the counterparty who needs funds sent right now.

We expect this to be first implemented just as a "anonymize my coins" button for wallet software on always on machines; getting vendors on board would be gravy.

We may even allow joins to happen when one party pays less fees than the other, although this is tricky: the main Sybil resistance of coinjoin is fees so you don't want to overdo it. OTOH the idea of the NSA and Chinese equivalent wasting money completing each others joins is hilarious...


Jeff Garzik <jgarzik@bitpay.com> wrote:
-----BEGIN PGP SIGNATURE-----
Version: APG v1.0.9

iQFQBAEBCAA6BQJSqxz9MxxQZXRlciBUb2RkIChsb3cgc2VjdXJpdHkga2V5KSA8
cGV0ZUBwZXRlcnRvZGQub3JnPgAKCRAZnIM7qOfwhTMBB/9L8h5NuSHxsC6W5ptm
gucxg2AbCwReuWQzRzqW42TYKQ7MnAhpfLLbSQrewNoXRP4H/j6aG8uWOt+z7fZf
pJZ9K8kxmSltHm8SJcmPLTb62yazEKQXF5TDsdpgBdH14M/pFsjUR4H2hypW8k4T
gcEAIhymZvlXev1NXDMh6rbuw0LtRTBE4NgE2buCuFzp0sEwTNTLxMU1WenMXfRQ
PooSBn8UoAVNw7Vztnag0T0f5D45VFNJBvQ8m42ee0u3gvMCa4JNRTBM49N2U9qc
Gk6WAvDakOf7FwaJiNMYoDpGyWphx6g697j28NnfB2q2hdjUVnZF+UVuBzkjnNwD
Y40/
=4dxZ
-----END PGP SIGNATURE-----



-------------------------------------
On 14 October 2013 20:08, Adam Back <adam@cypherspace.org> wrote:


I think there may be a simpler way to do this.

Create a new genesis block for a staging network, but in all other aspects,
as far as possible, keep the properties the same as bitcoin.

Do not actively be opposed to it being traded, but people need to know
that, although there is no intention to reset the chain, new and
potentially not fully tested, changes can be rolled into the network.
Anyone mining staging coins should be prepared for the value to go to zero.

Perhaps also a "straw poll" voting system could be set up for those that
own staging coins could sign messages saying which patches they would like
to test out next.  When patches are stable in the staging area, they could
be "promoted" to the main net ...


-------------------------------------

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

If a technical solution could be found, I don't doubt that it will
quickly become the only legal way to do transfers in the U.S.

Peter, you are Executive Director of the Bitcoin Foundation. I would
like to know that your efforts are focused on fighting this archaic
world view, not bending over backwards to comply with it.

Mark
On 6/5/13 5:19 PM, Peter Vessenes wrote:
large corporations taking money from consumers over fraudulent
reversals. Actually, I won't, I just said it.
without any protocol change, as an opt-in?
promises for signing. If it doesn't receive a cancel message, it will
sign at the end of the time.
registry, so you could see if you were going to have a delay period when
you saw a transaction go out.
trusted escrow service, and is vulnerable to griefing, but I thought I'd
see if some of the brighter minds than me can come up with a layer-on
approach here.
my coins in a one day reversible system, because I would have warning if
someone wanted to try and spend them, and could do something about it.
I'm not sure if it gets me anything over a standard escrow arrangement,
though.
SKYPE: vessenes
------------------------------------------------------------------------------

-----BEGIN PGP SIGNATURE-----
Version: GnuPG/MacGPG2 v2.0.19 (Darwin)
Comment: GPGTools - http://gpgtools.org
Comment: Using GnuPG with Thunderbird - http://www.enigmail.net/

iQIcBAEBAgAGBQJRsNJyAAoJEAdzVfsmodw4KBgP/A0ozXRdY0YbaFYL5tyWp+xO
OdOKbVFSQynHMws+CyA47x/DgiUbzrRwmx3fN7N67pPizYpjQLfJEwNkr6oy0Ga6
bbubYIz+TLI7sPS0B+ENg6XboChP+ZE7TPC56SyNgPUALwzsvcGZEYCHwwvIUx3F
EcUtXTw+VsBu935nRTvKj2HXruU94CaCiapS0knvgWg1/sB/PRFDQzu+fbBiLSL0
xWiuRaPs4dt+LCK2rfYtysKSv2S0FjOOwZ/Cj2J3KRtqTOnTSE2MZNAfNcMGA89u
LwWAfZohXywk2mBOk6avYxi5I0nNOndzfKQZgyHMH6zYdIP8B4gtBMxNP4CtsLaH
GWNdvYcxILcbeYqJUqlZfJamKkI0rAxgdk20YSaCAgU6rmJ8PQ4Ryl4uTS5i0xOb
xfMmHT68SOsvfL8XWobpMidVIUA+vKDZbd5AmJ9RCvJV5mj0Mrt/nJQM04NEQmtE
gb29fA1vh+nNKkPoVkyU02ghBYznurV+GMd5iFe8LObg6WxcIImadI1tdPpgINoK
glHeUl0zGXsbZDodk7imeZA3DXIf5xa9LfoVmJZrMMB/c3SQqRMwtUX04dMYQiCG
Gq4eisPXrUwepZ6hSgXqGktXYKn9dIlXR43zl4+ZBDjsAIiRiipK12WCz3pUTDow
/Xcx2iVrRWcZQefxJ3dz
=o0rL
-----END PGP SIGNATURE-----

-------------------------------------
I agree that this can be deferred until there is an actual new field without any harm. But then remember to update the BIP37 too saying that it is optional only if flag added in BIPXX is not present.

Your argument is that this complexity is already there so why not preserve it. I think eliminating complexity (that has no benefit) strengthens the system.

Tams Blummer
http://bitsofproof.com

On 20.06.2013, at 09:36, Mike Hearn <mike@plan99.net> wrote:


-------------------------------------
On Fri, Apr 05, 2013 at 12:13:23PM +0200, Melvin Carvalho wrote:

Vandalize the chain how? By delibrately triggering bugs? (like the old
OP_CHECKSIG abuse problem) Regardless of whether or not the
vulnerability requires multiple blocks in a row, the underlying problem
should be fixed.

By putting illegal data into it? Fundementally we have no way to prevent
people from doing that other than by making it expensive. An attacker
having a lot of hashing power just means they can do so faster and a bit
cheaper.

-- 
'peter'[:-1]@petertodd.org
-------------------------------------
On Sun, Apr 07, 2013 at 06:01:13PM +0200, Mike Hearn wrote:

The majority (~90%) is negative R or S values (which are just interpreted as
unsigned by OpenSSL, but if the top byte has its highest bit set, it must be
preceeded by a 0x00 accordinging to DER). A smaller number uses excessively
padded R or S value (with a 0x00 in front when it's not necessary). Finally
there are 4 signatures with an incorrect length marker in the beginning
(which likely means they contain some garbage at the end).

-- 
Pieter



-------------------------------------


On Oct 26, 2013, at 11:01 AM, Jean-Paul Kogelman <jeanpaulkogelman@me.com> wrote:


No. Enums or fixed length strings just make it harder to extend, for no benefit (bandwidth of 'reject' messages doesn't matter, they will be rare and are not relayed).



-------------------------------------
Gavin Andresen recently suggested a design for a wallet protected by
two-factor authentication via one-time-passwords with the aid of a
third-party service to counter-sign 2-of-2 protected wallets.(1) The
design is useful when the user can't sign transactions on a second
device, such as a phone, but can provide one-time-passwords. (possibly
generated on a smart phone or stored on paper) However involving a
third-party has privacy and availability risks. Here is an alternate
design, also using one-time-passwords, that removes the requirement for
a third-party, along with other advantages and disadvantages.


User experience
===============

The user has a wallet with a separate balances for savings and a smaller
day-to-day spending amount. Transactions spending the day-to-day balance
do not need two-factor authorization, while spending the savings balance
does. As the day-to-day balance becomes low the user is able to top it
up by authorizing the movement of discrete multiples of some amount from
savings to spending. That authorization requires one one-time-password
per multiple being moved.


Implementation
==============

Savings use P2SH outputs matching the following scriptPubKey form:

HASH160 <H(nonce_i)> EQUALVERIFY <pubkey> CHECKSIG

spent with:

<sig> <nonce_i>

The way the pubkey/seckey is generated is unimportant, although some
kind of deterministic scheme is preferable. Nonces on the other hand are
generated deterministically using a counter-based one-time-password
scheme that takes some secret seed and an integer i.  A large number of
H(nonce_n) are generated in advance and moved to the computer holding
the wallet. (generating them on that computer is also possible, but
obviously risks the secret seed being compromised)

A brute-force attack to spend a signed txout requires the attacker to
find a preimage, thus the security level is the number of bits for the
nonce; 64 bits is sufficient. (remember the birthday attack doesn't
apply here) Unfortunately the most popular one-time-password scheme, the
RFC6238 used in Google Authenticator, only outputs six digits numbers,
well below the security level required. (Google Auth is generally used
in a time-mode, but also has a counter mode)

The older RFC2289 however turns the passwords into six words from a 2048
entry wordlist, giving a 64-bit nonce with 2-bits of checksum. RFC2289
implementations are also well suited to paper print-outs and generally
make it easy to do so. RFC2289 as written uses SHA1, however the
suspected vulnerabilities in SHA1 are partial-preimage collisions, not
relevant in this application.

In a sense the user is now acting as an oracle answering the question of
whether or not funds should be allowed to move from savings to spending,
without being responsible for where those funds are allowed to go. As
described in (2) it is easy to create a whole range of conditions by
using multiple nonces if the use-case demanded. For instance a corporate
environment may want multiple parties to be required to authorize the
funds to move, possible with multiple nonces.

It's interesting to note how in some cases it may be preferable that the
authorization is simply authorization to spend without any other
involvement. Here the party acting as an oracle not only doesn't need to
know where funds are going but can even authorize the spend in advance
without two-way communication - possibly even prior to the funds being
received in the first place. This authorization can be easily given
manually, for instance over the phone, and the accounting to keep track
of the total amount authorized can be easily done with pen and paper -
something not possible with CHECKMULTISIG wallets.


Funding the wallet
==================

As with any multi-party wallet receiving funds must also be handled
carefully to ensure an attacker can't fool the user into giving the
sender the wrong address. This requires the involvement of all parties
required to authorize an outgoing payment. In addition here the
protection only works if funds sent to the wallet are split up into the
discrete authorization amounts the user wishes. (possibly with more than
one amount level)

There hasn't been as much thought put into these systems as there has
been on payment protocols between a customer and a merchant, but the
basic idea is to have more than one device participate in the generation
of payment request signed somehow. For fund splitting the request can be
that the funds are paid to multiple txouts in one go.  For recurring
payments the request could have some mechanism for multiple addresses to
be specified for future use. Fall-back to a standard multi-signature
wallet is possible as well.

More research is needed.


1) https://gist.github.com/gavinandresen/5616606
2) https://bitcointalk.org/index.php?topic=260898.msg2804469#msg2804469

-- 
'peter'[:-1]@petertodd.org
000000000000006447c7d824b1952ba36ad1f34351be6904c30247591156460c
-------------------------------------
On Wed, Jul 17, 2013 at 02:37:11PM +0200, Tamas Blummer wrote:

Yes


Widespread dependence on SPV mode is very dangerous for Bitcoin in
general due to that reason. Fraud proofs may help, but they're also
another layer of never-before-tested crypto on top of an already poorly
understood technology, bitcoin itself.

-- 
'peter'[:-1]@petertodd.org
-------------------------------------
On Fri, Feb 22, 2013 at 11:08:51PM +0000, I wrote:


On Mon, Feb 25, 2013 at 09:23:53AM -0800, Andrew Poelstra wrote:


I realise on reflection that what I really want is not automatic
transmissions, but a means to revoke an address.

The problem is that after transfering the coins from the compromised
addresses to a new, hopefully safe address, what to do about the fact
that third parties might still try to send me coins to an old,
compromised address.  So what I think I'm suggesting is that there
should be an address revocation protocol, such that clients will give
an error if their user tries to send coins to a revoked address.

Unless we think that direct payments to addresses will become
completely obsolete once the payment protocol is in use, in which case
(maybe) this functionality belongs in the payment protocol instead -
but I remain unconvinced of that.

I'm not envisaging something as drastic as changing the rules to make
transactions to revoked addresses invalid - just an overlay protocol.
Although to be useful such a protocol would have to be pretty much
universally implemented by clients.

Thoughts?

roy


-------------------------------------
On Sun, Dec 8, 2013, at 03:11 PM, Drak wrote:

It's not just about trust, there is the robustness factor: what if he
becomes sick, unavailable, hit by a bus? Others need the ability to
pickup and run with it. The control over the domain (including ability
to renew registration, alter nameservers) needs to be with more than
one person. That's why I suggest using the same people who have control
over the software project at sf,github


The bitcoin.org domain is controlled by me, Sirius, and an anonymous
person. Control will not be lost if Sirius becomes unavailable.

SSL is probably a good idea, and it's probably also a good idea to
separate bitcoin.org from Github. I don't know that I trust Github. I'm
sure that you can find a sponsor for a dedicated server. Let us know if
DNS changes to bitcoin.org are required.
-------------------------------------
On Tue, Jul 16, 2013 at 04:16:23PM +0200, Wendell wrote:

Keep in mind that SPV mode is newer than many realize: bloom filters are
a 0.8 feature, itself released only last Febuary. As John Dillon posted
earlier this week in "Protecting Bitcoin against network-wide DoS
attack" the Bitcoin codebase will have to implement much better anti-DoS
attack defences soon, and in a decentralized system there aren't any
options other than requiring peers to either do work (useful or not) or
sacrifice something of value. SPV peers can't do useful work, leaving
only sacrifice - to what extent and how much is unknown. In addition SPV
nodes have serious privacy issues because their peers know that any
transaction sent to them by the SPV node is guaranteed to be from the
node rather than relayed; bloom filters are only really helpful with
payment protocols that don't exist yet and don't apply to merchants.
Then you have MITM problems, vulnerability to fake blocks etc.

It'll be awhile before we know how serious these issues are in practice,
and we're likely to find new issues we didn't think of too. In any case
Bitcoin is far better off if we make it easy to run a full node,
donating whatever resources you can. Fortunately there's a whole
continuum between SPV and full nodes.

The way you do this is by maintaining partial UTXO sets. The trick is
that if you have verified every block in some range i to j, every time
you see a txout created by a transaction, and not subsequently spent,
you can be sure that at height j the txout existed. If height j is the
current block, you can be sure the txout exists provided that the chain
itself is valid. Any transaction that only spends txouts in this partial
set is a transaction you can fully verify and safely relay; for other
transactions you just don't know and have to wait until you see them in
a block.

So what's useful about that? Basically it means your node starts with
the same security level, and usefulness to the network, as a SPV node.
But over time you keep downloading blocks as they are created, and with
whatever bandwidth you have left (out of some user-configurable
allocation) you download additional blocks going further and further
back in time. Gradually your UTXO set becomes more complete, and over
time you can verify a higher and higher % of all valid transactions.
Eventually your node becomes a full node, but in the meantime it was
still useful for the user, and still contributed to the network by
relaying blocks and an increasingly large subset of all transactions.
(optionally you can store a subset of the chain history too for other
nodes to bootstrap from) You've also got better security because you
*are* validating blocks, starting off incompletely, and increasingly
completely until your finally validating fully. Privacy is improved, for
both you and others, by mixing your transactions with others and adding
to the overall anonymity set.

In the future we'll have miners commit a hash of the UTXO set, and that
gives us even more options to, for instance, have relayed transactions
include proof that their inputs were valid, allowing all nodes to relay
them safely.


As for specifics, you need to maintain a UTXO set, and in addition a set
of spent txouts (the STXO set) for which you haven't seen the
transaction that created the txout. As download newer blocks you update
the UTXO set; as you download older blocks you update the UTXO set and
STXO set.

Nodes now advertise this new variable to their peers:

nOldestBlock - The oldest block that we've validated. (and all
subsequent blocks)

We'll also want the ability to advertise what sub-ranges of the
blockchain data we have on hand:

listArchivedBlockRanges - lists of (begin, end pairs)

Nodes should drop all but the largest n pairs, say 5 or something. The
index -1 is reserved to indicate the last block to make it easy to
advertise that you have every block starting at some height to the most
recent. (reserving -n with n as the last block might be a better choice
to show intent, but still allow for specific proofs when we get node
identities)

We probably want to define a NODE_PARTIAL service bit or something; I'll
have to re-read Pieter Wuille's proposal and think about it. Nodes
should NOT advertize NODE_NETWORK unless they have the full chain and
have verified it.

Nodes with partial peers should only relay transactions to those peers
if the transactions spend inputs the peers know about - remember how
even an SPV node has that information if it's not spending unconfirmed
inputs it didn't create. Nodes will have to update their peers
periodically as nOldestBlock changes. That said it may also be
worthwhile to simply relay all transactions in some cases too - a
reasonable way to approach this might be to set a bloom filter for tx's
that you *definitely* want, and if you are interested in everything,
just set the filter to all 1's. If someone comes up with a reasonable
micropayment or proof-of-work system even relaying txs that you haven't
validated is fine - the proof-of-work and prioritization will prevent
DoS attacks just fine.

Remember that if you're running a partial node, it can get new blocks
from any partial node, and it can retrieve historic blockchain data from
any partial node that has archived the sequence of blocks you need next.
On a large scale this is similar to how in BitTorrent you can serve data
to your peers the moment you get it - a significant scalability
improvement for the network as a whole. Even if a large % of the network
was partial nodes running for just a few hours a day the whole system
would work fine due to how partial nodes can serve each other the data
they need.

On startup you can act as a SPV node temporarily, grabbing asking for
filtered blocks matching your wallet, and then go back and get the full
blocks, or just download the full blocks right away. That's a tradeoff
on how long the node has been off.

Anyway, it's a bit more code compared to pure-SPV, but it results in a
much more scalable Bitcoin, and if you can spare the modest bandwidth
requirements to keep up with the blockchain it'll result in much better
robustness against DoS attacks for you and Bitcoin in general.

-- 
'peter'[:-1]@petertodd.org
-------------------------------------
On Mon, May 06, 2013 at 10:19:35AM +0200, Mike Hearn wrote:

I think John's actually has a point here. If we're judging the quality of a
protocol change by how compatible it is with DNS seeding, then we're clearly not
using DNS seeding as seeding anymore (=getting an entry point into the P2P
network), but as a mechanism for choosing (all) peers.

Eventually, I think it makes sense to move to a system where you get seeds from
a DNS (or other mechanism), connect to one or a few of the results, do a getaddr,
fill your peer IP database with it, and disconnect from the DNS seeded peer.

This probably means we need to look at ways to optimize current peer exchange,
but that's certainly welcome in any case.

-- 
Pieter



-------------------------------------
On Sun, Dec 8, 2013 at 2:17 AM, SaÃ¯vann Carignan <saivann@gmail.com> wrote:


Good idea.
If anything, these days, not using https is sort of a smell for sites that
security is not being taken seriously.

Wladimir
-------------------------------------
On Wed, May 15, 2013 at 6:24 PM, Gavin <gavinandresen@gmail.com> wrote:

Sort of, but in a guy fawkes signature you use the commitment to hide
the preimage that proves you had authority to spend a coin.   Adam
proposes you do this in order to hide _which coin you're spending_.

This has obvious anti-DOS complications, but Adam deftly dodged my
initial attempts to shoot him down on these grounds by pointing out
that you could mix blinded and blinded inputs and have priority and
transaction fees come from only the unblinded ones.

Effectively,  it means that so long as you could convince the network
to let you spend some coins, you could also spend other ones along for
the ride and the network wouldn't know which ones those were until it
was too late for it to pretend it never saw them.

I think there are all kinds of weird economic implications to thisâ€” a
blinded payment would seem to have a different utility level to an
unblinded one: you can't use it for feesâ€” except you can unblind it at
any time.  And the discontinuousness  ("two types of inputs") and that
it would enable mining gibberish (though perhaps not data storage, if
you see my preimage solution to that) seems awkward and I think I have
to spend some time internalizing it before I can really think through
the implications.


-------------------------------------
One of the big topics of recent past on IRC is "malleability" of
transactions:  to what extent can someone /else /change your signed
transaction without affecting its validity?  In the past I used to
consider this just annoying, but not so malicious.  But in terms of HFT,
it sounds like malicious behavior is possible:

To recap the procedure:

(1)  Alice creates a transaction, Tx1, for 10 BTC to a 2-of-2-{Alice,
Bob} address.  It has a locktime of 30 days in the future.
(2)  Before signing the transaction, she gets Bob to sign a transaction,
Tx2, from 2-of-2-{Alice, Bob} back to herself.   That transaction
references the Tx1 by hash.
(3)  Any time in the next 30 days, Alice can sign an alternate Tx2
transactions reducing the amount returned to self and increasing amount
to Bob, as a method of paying Bob more.  Bob doesn't need to broadcast
anything except for the last one, 29 days later.

It was originally conceived that Bob couldn't do anything malicious,
because Alice gets Bob to sign Tx2-spending-Tx1 before she gives him
Tx1.  The problem is that Bob can follow her process, then
broadcast/mine Tx1' (Tx1-prime), which has a different number of 0x00
pad bytes in the signatures, or "flips the sign" of one of the s-values
in the signature, thus changing the hash of Tx1.

By doing this, Bob has now created a transaction, Tx1', that Tx2 no
longer returns to Alice.  It's not flat-out theft, because Tx1 still
sends to a 2-of-2 address requiring both of their signatures.  But Bob
didn't risk anything to do this, besides his reputation/trust.  He now
has Alice's money locked and can hold it for ransom, since she needs his
signature to do move it.  He could offer his signature for half of it.

Of course, these types of HFT contracts will usually be between parties
that have some mutual respect/history.  Thus, they are not usually
zero-trust.   But we should find a way to try to close that, if
possible.  For instance, if the malleability was reduced to one bit, you
could just have Bob sign two different transactions before Alice
broadcasts Tx1.  The two tx would be from either variant.  But I know
there's too many bits of malleability in the transaction serialization
for that to work.  Is there any way to avoid this?

-Alan



On 04/17/2013 05:48 AM, Mike Hearn wrote:

-------------------------------------
By the way, I have a download of the Bitcoin-Qt client and signature
verification running in a cron job.


On Thu, Apr 4, 2013 at 10:11 AM, Mike Hearn <mike@plan99.net> wrote:

-------------------------------------
The threat of a SHA1 collision attack to insert a malicious pull request
are tiny compared with the other threats - e.g. github being compromised,
one of the core developers' passwords being compromised, one of the core
developers going rogue, sourceforge (distribution site) being compromised
etc etc... believe me there's a lot more to worry about than a SHA1
attack...

Not meaning to scare, just to put things in perspective - this is why we
all need to peer review each others commits and keep an eye out for
suspicious commits, leverage the benefits of this project being open source
and easily peer reviewed.

Will


On 1 April 2013 23:52, Melvin Carvalho <melvincarvalho@gmail.com> wrote:

-------------------------------------
On Wed, Mar 13, 2013 at 12:56:29PM +0000, Luke-Jr wrote:

If we're going to consider doing this, at minimum we need to also
include a separate limit for how much the UTXO set can be grown by each
block, calculated as the size of the scriptPubKey + constant metadata.
(tx hash, index #, nValue, nVersion, nHeight should cover it)

A P2SH transaction txout would measure 71bytes under that model. Given
that we haven't even shown we can limit the creation of txouts that can
not be spent economically caution would dictate setting the UTXO growth
limit fairly low, say 1/4th of the block limit.

-- 
'peter'[:-1]@petertodd.org
-------------------------------------
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 25/06/13 19:57, Gavin Andresen wrote:

The
"splash" banner shows "0.8.3-BETA".

- -- 
Jess Cea Avin                         _/_/      _/_/_/        _/_/_/
jcea@jcea.es - http://www.jcea.es/     _/_/    _/_/  _/_/    _/_/  _/_/
Twitter: @jcea                        _/_/    _/_/          _/_/_/_/_/
jabber / xmpp:jcea@jabber.org  _/_/  _/_/    _/_/          _/_/  _/_/
"Things are not so easy"      _/_/  _/_/    _/_/  _/_/    _/_/  _/_/
"My name is Dump, Core Dump"   _/_/_/        _/_/_/      _/_/  _/_/
"El amor es poner tu felicidad en la felicidad de otro" - Leibniz
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.10 (GNU/Linux)
Comment: Using GnuPG with Thunderbird - http://www.enigmail.net/

iQCVAwUBUcokFZlgi5GaxT1NAQJ+HQP7Bs387bwW6sXrOx98Y2bkQBJfciaS/eyD
HvHho9xfoOcaCwuigh2lI78i2vxoVUa30sM0m/g4+isyJZDVLpbUENhy3bx0MAD/
4YAjJXdwScDI15m6xvAf706BDst2kXcWw/pudZQiX4Kw9YEs7rUWvdPS5BE6PXbK
QyCcBcrH7fo=
=+cZD
-----END PGP SIGNATURE-----


-------------------------------------
On Thu, Feb 14, 2013 at 1:07 AM, Peter Todd <pete@petertodd.org> wrote:


Perhaps, but a miner trying to target just over 50% of the network will run
the very real risk that they'll only reach 49%.

What about the case for centralization if the block size remains capped?  I
see a far greater risk of centralization in that scenario than if the cap
were to be removed.  The reason is very simple, bitcoin would ultimately
become useful only for very high value, settlement transactions.  Only the
mega corporations and banks would be using it directly, everyone else would
be doing daily transacting in centrally issued currencies of one form or
another.  As the banks and mega corps learned about the utility of bitcoin
and began to use it en masse, they would start to take the whole network
off the public internet and put it on a higher speed and more reliable
backbone.  Those corporations would establish mining agreements among
themselves to ensure none of the participants could take over the system
and compromise it, while at the same time keeping the operational costs to
a minimum.  Bitcoin is now a great alternative to the wire transfer system,
but has no value to the average person wanted to have cheap and private
transactions over the Internet.  Maybe Litecoin starts to fill that niche.
-------------------------------------
On Sun, Dec 01, 2013 at 07:18:07PM +0100, Mike Hearn wrote:

Maybe, maybe not. We have no idea what fees will be because the system's
entire capacity is, and always will be, limited. That's just how
fundementally unscalable systems with huge global state work. What
demand will be for that limited capacity is unknown.



No, Luke's existing code uses good algorithms with O(n) scaling for n
transactions. The inefficiency is needing a second transaction, bloating
the blockchain and driving up fees.

-- 
'peter'[:-1]@petertodd.org
000000000000000f9102d27cfd61ea9e8bb324593593ca3ce6ba53153ff251b3
-------------------------------------
On Tue, Jun 04, 2013 at 02:49:54PM -0400, Jeff Garzik wrote:

"High" is relative.

I could make a 100BTC apparently sacrifice via fees by just waiting a
month or two for my mining hardware to find a block that had a
pre-prepared fake sacrifice. It'd cost me roughly 1BTC when you take
orphans into account. Similarly I could hack into a pool and have them
do it on my behalf, or a pool could just offer the service for a fee.

I already worry enough that announce-commit sacrifices to mining fees
aren't secure enough given the potential of a few large pools teaming
up to create them cheaply, let alone what you're talking about...


Hey Luke: so what's the going rate to get Eligius to mine a fake mining
fee sacrifice? Can I get a discount on repeat orders? :)

-- 
'peter'[:-1]@petertodd.org
000000000000014c5bfacfca559fd6a9519dcd338f9fca6590eda7d156120013
-------------------------------------
When did I say DoS was unimportant? I just wrote a giant email explaining
how it can be resolved.

I think it's worth pointing out that Bitcoin was launched with no DoS
protection at all, and it's still here. There are still obvious DoS bugs
being fixed with every release. So yes, it's important to robustify the
code, but not to the extent of not having any features. If Satoshi had
taken that perspective Bitcoin might not exist at all. We can have our cake
and eat it.

RE: shutting down services dependent on replacement. No, good users of
replacement would still end up taking priority over the constantly churning
DoS replacements. The most you can shut down is one contract. Obviously, if
there's no form of tx replacement at all then the "tried and doesn't work"
state is the same as "never tried", which doesn't seem like a win.

The testnet is trivially DoSable today by anyone who cares to do so, there
are hardly any nodes and most people get coins from the faucet. Look at how
quickly people got upset when somebody drained it. As Jeff has pointed out,
there could theoretically be a "nextnet" but the overhead of setting one up
doesn't seem worth it. If somebody wanted to troll developers they could
easily DoS testnet and nextnet simultaneously with bandwidth to spare.



Yes, I noticed it a few days ago when making some notes, but figured I
would indeed make an prototype implementation and then just put all the
details and latest protocols on the wiki at once. As nobody indeed noticed
the bug for years apparently nobody else is working on this so it didn't
seem urgent to update.

Your proposed alternative doesn't seem any different DoS wise. Someone can
still broadcast a long series of incrementally different transactions and
have miners replace them. So you still need prioritisation of work. It's
useful anyway for other reasons. And as you point out yourself, it's still
susceptible to the problem that you end up running out of money because
it's all been spent on fees.

BTW $500 is rather low for the amount of work required. If you added a zero
onto that there might be more takers.
-------------------------------------
I was reading there are some commands to access a peer's mempool state.  
The purpose being to allow miners to recover faster after a reboot, I  
think?

Reading peer mempool definitely allows recovering faster after a reboot.  
So does persisting mempool in a database locally. But what can you learn  
about a node from its mempool? Basically, are there distinguishing  
features in the mempool, or could there be?

Are there transactions you can receive which go into your own mempool but  
which you don't forward? How about 'nLockTime' transactions?

Is this new feature off by default? Which clients support it?

By the way, are there recommended places to go to compare features  
implemented by different wallet software?

Sorry, so many questions...



-------------------------------------
Maybe now that bitcoin is growing out of the toy phase it's an idea to
start gpg signing commits, like the Linux kernel (
https://lwn.net/Articles/466468/).

But I suppose then we can't use github anymore to merge as-is and need
manual steps?

Wladimir




On Tue, Apr 2, 2013 at 12:54 AM, Roy Badami <roy@gnomon.org.uk> wrote:

-------------------------------------
This is exactly what I was planning to do with the inappropriately-named 
"Ultimate Blockchain Compression 
<https://bitcointalk.org/index.php?topic=88208.0>".  I wanted to 
reorganize the blockchain data into an authenticated tree, indexed by 
TxOut script (address), instead of tx-hash.  Much like a regular merkle 
tree, you can store the root in the block header, and communicate 
branches of that tree to nodes, to prove inclusion (and exclusion!) of 
TxOuts for any given script/address.  Additionally, you can include at 
each node, the sum of BTC in all nodes below it, which offers some other 
nice benefits.

I think this idea is has epic upside-potential for bitcoin if it works 
-- even "SPV" nodes could query their unspent TxOut list for their 
wallet from any untrusted peer and compare the result directly to the 
blockheaders/POW.  Given nothing but the headers, you can verify the 
balance of 100 addresses with 250 kB.  But also epic failure-potential 
in terms of feasibility and cost-to-benefit for miners.  For it to 
really work, it's gotta be part of the mainnet validation rules, but no 
way it can be evaluated realistically without some kind of "staging".  
Therefore, I had proposed that this be merge-mined on a "meta-chain" 
first...get a bunch of miners on board to agree to merge mine and see it 
in action.  It seemed like a perfectly non-disruptive way to prove out a 
particular idea before we actually consider making a protocol change 
that significant.  Even if it stayed on its own meta chain, as long as 
there is some significant amount of hashpower working on it, it can 
still be a useful tool.

Unfortunately, my experience with merged mining is minimal, so I'm still 
not clear how feasible/reliable it is as an alternative to direct 
blockchain integration.  That's a discussion I'd like to have.

-Alan


On 5/19/2013 11:08 AM, Peter Vessenes wrote:

-------------------------------------
As of today, a full implementation of micropayment channels has been merged
onto bitcoinj's master branch (to be released in the next version). It is
designed to make it easy for users to create payment channel servers and
clients based on the design at
https://en.bitcoin.it/wiki/Contracts#Example_7:_Rapidly-adjusted_.28micro.29payments_to_a_pre-determined_party,
by creating a simple TCP socket and exchanging protobufs to initialize and
make payments.

It supports various levels of abstractions, allowing users to drive the
state machines which do basic channel init/verification themselves, allow
bitcoinj to handle all the complexity of channel management/expiry/etc and
simply exchange protobufs over whatever whatever connection they wish to
make with the server, or let bitcoinj handle opening a TCP socket and do
all the work. See
https://code.google.com/p/bitcoinj/wiki/WorkingWithMicropayments for
details on how to use the implementation in bitcoinj.

A more full protocol description will be written up in the form of a BIP as
the code matures a bit more (with the hope that other implementations can
appear), but, generally:

1. Client and server exchange version handshake, and client may
optionally request that an existing channel be reopened (the channels last
for 24 hours by default, so if the connection gets killed, reopening an
existing channel is useful).
2. The protocol described on the wiki is followed, exchanging
(canonical!) signatures and transactions until a multisignature contract is
established and broadcast which locks money into the channel, and a refund
transaction is created and signed which allows the client to spend the
entire multisignature transaction to wherever they want
(SIGHASH_NONE|SIGHASH_ANYONECANPAY) after some lock time (by default, 24
hours). Both client and server store a copy of the channel in their wallet
so that if the app itself crashes the refund transaction can still be
broadcast/the channel can still be resumed. At this point either the whole wallet should be backed up or the total value in payment channels at any
given time should be kept reasonably low (because payment channels are
designed to combine micropayments into confirmable payments, this shouldn't be an issue)
3. The client increments payments by sending the server new signatures
spending the multisig contract partially back to themselves and allowing
the server to do what they want with the rest
(SIGHASH_SINGLE|SIGHASH_ANYONECANPAY).
4. When the client sends a CLOSE message or the channel approaches the
refund transaction unlock time, the server adds any necessary fees to the
latest payment transaction and broadcasts it, closing the channel, disconnecting the client if the connection is still open and removing the stored channel state from its wallet.

See https://code.google.com/p/bitcoinj/source/browse/core/src/paymentchannel.proto for the protobuf/protocol description.


-------------------------------------
If you're considering a datagram protocol, you might be interested in some
more modern alternatives to UDP:

UDT: Breaking the Data Transfer Bottleneck
http://udt.sourceforge.net/

Stream Control Transmission Protocol
http://en.wikipedia.org/wiki/Stream_Control_Transmission_Protocol



On Sat, Mar 23, 2013 at 12:17 AM, Jeff Garzik <jgarzik@exmulti.com> wrote:

-------------------------------------
This is great, thanks for doing it. Tip sent your way.

Graphs of how propagation data change over time would also be helpful (as
well as raw data so we can calculate overhead per kilobyte and so on). I
know there are only two days worth of data, but for future, it'd be good.

I think the next part of figuring out why there's such huge disparity is
instrumenting bitcoind to find out where the time goes when relaying a
block.


On Sun, Nov 24, 2013 at 5:26 PM, Gregory Maxwell <gmaxwell@gmail.com> wrote:

-------------------------------------

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Off-and-on for the past couple years, Jorge Timn and I have been
developing an extension of the Bitcoin and (pre-OpenCoin) Ripple
distributed protocols which enable user-specified bearer instruments,
distributed peer-to-peer exchange, off-chain accounting, auctions,
derivatives and transitive transactions, and the multitude of financial
contracts having such primitives would make possible. The specification
is now reasonably complete enough that we would like to receive input
from the community. The PDF is available for viewing here:

http://freico.in/docs/freimarkets-v0.0.1.pdf

We're looking for public comments about this or related approaches. In
particular we've spent a fair chunk of time working out how to handle
coordination of private accounting servers with the public chain and
derivatives contracts, both of which are basically cryptographic
protocols expressed as bitcoin scripts. Input from any of the resident
cryptographers would be very appreciated.

Happy hacking,
Mark Friedenbach
-----BEGIN PGP SIGNATURE-----
Version: GnuPG/MacGPG2 v2.0.19 (Darwin)
Comment: GPGTools - http://gpgtools.org
Comment: Using GnuPG with Thunderbird - http://www.enigmail.net/

iQIcBAEBAgAGBQJSF/rKAAoJEAdzVfsmodw4xVYP/jLoB6eDlgREawfbcW6kXe4s
25YnP19Hvk0NBk0Fv9G6zhAaOdHlR4dkcq2TueAqGHA+Drtp06eVkWDfqQOioGjx
LrQF6ct9AbBZNN8glo7+JY70hecbEgWeW77cSrDTFxQAWwNnq0hVwVFb6++9rY9+
6Q4jwJtqawWlMYRlFOiK1VW/MvI2WV4bypAjuOYsTnXZ8eFjyO+obZYUuMs6JUWd
XojkDeL60NB6JHVoeyx270bvbP1Of5ErLZRuhC26MA9K4S6jlgfvLCqYBHnjRMHI
KI/K7wqcpbbyldCSIcIsVtSrwBZRUgYfUFEFXvFjwzC0EwgGFwQC3pCqTWzskpo4
KS8ZMpgr7BjI+M0GSpRyh5x0aqZkptaaogCssHzoykmEwm6dyK8cdtdhtFAsGAMs
dYpftZ/NJ17tOkUd22TXpIxWPckFBOmuV/hlr0wFpj50glttMH/8NwqKtGcjO21e
ecuiJzXbjCGlFpKIG+JI5BOXvEeD5VoegsfLTwA9Egkuhh8FXyiqIPUEEV0W1DAC
0CIsX8XmWnKeRBWWa/2AHVuSQlBlut9gX1zRElaU5YSW58zsE3UeVPvSOJOh6ZKZ
eLkRjzuyDrpuJiRKXFdTS857grUhYs+E5xeVkkZWy+q3XqQ7LofcZjp3Xt8tmx4j
LSaZTewUL15MjQR0Ow8a
=xyHR
-----END PGP SIGNATURE-----



-------------------------------------
On 10 June 2013 10:35, Pieter Wuille <pieter.wuille@gmail.com> wrote:


OK I accept that the timestamping is one CPU one vote.  However rule
changes seem rather arbitrary.

Towit if you use a voting/consensus system and want to destroy bitcion it
seems quite easy.

Iterate on picking a rule chance that will divide the consensus in such a
way as to create ensuing chaos.

I think voting is too easy gamed for it it to be meaningful other than a
straw poll.

If there's a bug, and everyone is unanimous that it's a bug, it can be
fixed.

If there's a controversial rule change, we should be extremely cautious and
not do it unless there's a very good reason.  Keeping to satoshi's model as
much as possible without introducing human factors, unnecessarily.


-------------------------------------

On Mar 11, 2013, at 12:54 PM, Mike Hearn <mike@plan99.net> wrote:

The problem of UTXO in principal scales with the block size limit. Thus it should be fixed BEFORE you consider increasing the block size limit. Otherwise you just kick the can down the road, making it bigger.


Problem is the skewed incentive structure. Rational miners will always include dust output with fees, because the eternal cost of UTXO is payed by the network and future miners, not the current/individual miner.

On Mar 11, 2013, at 7:01 AM, 	Jorge Timn <jtimonmv@gmail.com> wrote:


this.


You could delegate the decision to the user with a rule like:

if (output<fee):
 limit lifetime of the UTXO to 10 years.
if (output>fee):
 unlimited lifetime

Then, when a user creates a transaction, he can decide whether he wants to have limited or unlimited lifetime. The rationale for limiting the lifetime for (output<fee) transactions is that they may have no inherent economic incentive to be spend.



-------------------------------------
On Thu, Oct 31, 2013 at 10:13 AM, Thomas Voegtlin <thomasv1@gmx.de> wrote:


Well, as we're the first pioneers of bip32, let's start using it in some
sane way and I'm sure the others will join. Just because they don't want to
incompatible software.

Actually I quite like that you're not wasting bip32 space by using some
dynamic allocatons in higher address space, so I'm happy to follow your
rules and I think we can agree on generic discover algorithm which maybe
won't be optimal, but will find all used addresses and won't need any
additional information directly in mnemonic.

As I wrote in previous post, in worst case I can imagine dropdown list on
import dialog, which will ask user which software has been handling the
seed before, to speedup the scan. But for now I don't see this necessary at
all.

Also, I can imagine that bip32 itself might be superseeded in the future.
Although I can imagine that as well, I hope that it won't be the case. We
need to unite and integrate instead of making incompatible applications.

One disadvantage of bip32 is that in fact it is too much flexible, so we
even falled into the necessity of defining version of discovery algorithm.
Lets set up best practices how to use it and other will follow instead of
creating zillion cross-incompatible algorithms which won't understand each
to other.



Hardening and password protection are two unrelated requirements. Again,
there are some scenarios in which use can leak part of the mnemonic to
attacker, so hardening prevent to bruteforce the rest information by
attacker, even if the mnemonic isn't passphrase protected.

I'm especially refering to our algorithm of mnemonic import to Trezor
during disaster recovery (when Trezor is destroyed and user wants to import
the seed to another one), so that leak isn't just a theoretical concept,
but real-word scenario.



for metadata, then I guess strenghtening can be part of it. That's

Actually creating optional features of such algorithm only make things
complicated (and less cross-compatible). Every software still needs to
implement such hardening even if it is optional feature, to be compatible
with other clients. Then I don't see any reason why to have it optional.

Don't forget that the proposal uses only 4 bits of version, which isn't too
much combination for all these optional features ;-).

I too wonder why the transformation needs to be bidirectional in bip39.
Well, I wrote longer answer in previous  email. tl;dr; there's quite easy
way how to make the algorithm bi-directional, so I don't see a necessity to
drop potentially useful feature for no good reason.

I was thinking about your proposal and I realized that both our solutions
solves a bit different problem. Lets summarize features (and forget to
wordlist fights for moment):

bip39:
+ bi-directional
+ passphrase protected
+ shorter mnemonic or shorter wordlist
- predefined wordlist

ThomasV proposal:
+ any software can has its own preferred worlist
? passphrase protected
- one-direction only
- longer mnemonic or longer wordlist

Back to wordlist fights
a) actually I think that the wordlist choice is far less important than it
may look at first glance. Thomas thinks that bip39 wordlist is disaster, me
and many other thinks it is ok, but mainly that it is very subjective.

b) I see the beauty of "custom wordlists" in Thomas proposal, still if it
means the algorithm is uni-direction only, it is very strong disadvantage
to our usecase.

c) I advocated our wordlist mainly because we put a lot of effort into it
and after many weeks of tuning it is already done; not because I think that
one method of picking the words is superior to other. I mean - if Thomas
can offer any other plain-english wordlist which he'll be happy with, I'll
vote for dropping our own wordlist and to use Thomas's version for the deal
that he'll accept our need for bi-directionality and he agrees on the rest
of bip39 ;-).

Marek
-------------------------------------
Why not just use the transaction hash itself for the lookup? Also, presumably you'd want to encrypt the data so that only the recipient of the transaction can do this lookup.

-Eric

On Sep 6, 2013, at 8:07 AM, Wendell <w@grabhive.com> wrote:


-------------------------------------
On Tue, May 21, 2013 at 11:37 PM, zooko <zooko@zooko.com> wrote:

Note that testnet operates under the threat of being reset at any
time, if someone comes along and destroys its usefulness with spam or
mining or whatnot.  That guarantees it remains a testing tool, and not
a real alt-currency.  The current testnet is the third iteration,
hence you see "testnet3" in some source code.

This option is always available for any merge-mined chain as well,
ensuring little real value is assigned to the test chain.

But that is a binary decision:  If you don't have a reset-the-chain
policy, you have a de facto "it is a real currency" policy.



A fork of the bitcoin.git codebase has the nice attribute of making it
easy to "upstream" any useful changes that are not specific to that
one alt-coin.



What's neat about bitcoin is that it invented a whole new /category/
of technology.  It's not just /an/ invention, but opened up all this
new experimentation with the new concept of money itself.

However for the bitcoin.git reference implementation, it makes more
sense to focus on supporting existing bitcoin users.  That permits
alt-coins to bubble up (or not) organically, and at the same time
reduces user confusion.  We have enough trouble explaining the basics
of bitcoin to the world; trying to keep follow every alt-coin
bandwagon just muddies the waters from a messaging standpoint.

alt-coin changes fall into two categories:
1) Rule changes.  We don't want these.
2) Generic bug fixes, cleanups, changes etc.  It would be nice to see
improvements bubble up, benefitting everybody.


-- 
Jeff Garzik
exMULTI, Inc.
jgarzik@exmulti.com


-------------------------------------
Assuming a new install and first time connection to the net,
is using 0.8.x [1] safe to use, for all (or select?) purposes,
regarding the current fork issue?

If not, is there a recommended branch, tag, or commit, for
all such (or select?) purposes, until such time as an upgrade
alert is broadcasted?

Thanks.

[1] Regarding possible 0.8.x flavors...

There are only 'branch master' and 'tag v0.8.0' here:
https://github.com/bitcoin/bitcoin

There are no 0.8.x branch or tags here yet:
https://git.gitorious.org/bitcoin/bitcoind-stable


-------------------------------------
On Fri, Nov 22, 2013 at 12:49 PM, Jeff Garzik <jgarzik@bitpay.com> wrote:

Is there a reason not to have a parallel get rpc to get the current list?


-------------------------------------
Consensus in #bitcoin-dev chat is that it is time to do a 0.8.2 release. A
few important bugs have been fixed, and the goal will be to get a 0.8.2
final release before the May 15'th hard fork deadline.

Pieter has already started going through the issues list; help with
testing, debugging, and fixing high-priority issues is very welcome. I'll
also be going through the issues list and marking any issues I think need
to be fixed with the '0.8.2' milestone.

If translation work needs to be done, now is a great time to do it.

We still don't have a basic QA checklist for testing of release candidates;
I'll commit to spending a little of the remaining "Bitcoin Testing Project"
bitcoins to whoever contributes to creating one.

-- 
--
Gavin Andresen
-------------------------------------
On Thu, Aug 08, 2013 at 07:10:05AM +1000, Gavin Andresen wrote:

If we're going to allow payments to fail without being broadcast (but
where the wallet can't in general prove that the receiver hasn't seen
the transaction) then I would argue that it becomes highly desirable
that the wallet invalidates the transaction at the earliest
opportunity by spending the outputs in a pay-to-self transaction.

Otherwise malicious receivers, or temporary failures, could result in
the user being told that the transfer didn't happen, but then the
coins actually leaving the wallet anyway a short time later.

roy


-------------------------------------

Yes. There were a number of lock cycles that didn't cause issues so
much when traffic was lower and as Bitcoin got more popular it became
a critical problem. I redid a lot of the concurrency to fix that, and
now all the core locks are cycle detecting so regressions should be
detected fairly fast. I'm still making changes to the concurrency
design but mostly to improve the API at this point, not fix bugs.

There is one deadlock I'm still aware of, thanks to Netty. However
it's very rare and was only reported by someone who kept a server
running for many days in a row. We want to junk Netty soon anyway.
It's a network library but it doesn't really add much value for our
use case and it turned out to have some serious design issues
internally.


Yeah. That's not the primary privacy issue with bitcoinj though. I'm
much, much more concerned about leaks via the block chain than the
network layer. Especially as Tor is basically a giant man in the
middle, without any kind of authentication you can easily end up
connected to a sybil network without any idea. I'd be surprised if Tor
usage was very high amongst Bitcoin users.


It does actually, but the iconography is not very clear. I'm not
convinced any users really care about the difference between two and
three blocks these days. Maybe exchanges and other security-critical
applications do, but I doubt desktop users do.

It's not a library limitation anyway, it's a case of how best to
present information to a user who is not familiar with how Bitcoin
works. "Safe" and "Not safe" is still a rather misleading distinction
given the general absence of double spends against mempool
transactions, but it's still a lot more meaningful than "2 confirms"
vs "3 confirms", something that would just make a new user ask what
the heck a confirm is.


-------------------------------------
On Mon, Nov 04, 2013 at 04:27:58PM +0100, Mike Hearn wrote:

Re-read my proposal - the whole point of it is to give a way to quickly
come to consensus about which side of the fork has the majority of
hashing power. It doesn't, and doesn't need to, reliable determine what
the hashing power actually is on either side. Rather it's a feedback
mechanism that creates a clear majority consensus in a short amount of
time with the use of only a small amount of bandwidth. (~5KB/10minutes)

-- 
'peter'[:-1]@petertodd.org
00000000000000079c8a642234cb452cbe261fcdb5885af604471c458c257956
-------------------------------------
On Wed, Feb 6, 2013 at 8:33 AM, Mike Hearn <mike@plan99.net> wrote:

I asked for permissions to unlock it but haven't heard backâ€” will prod.


-------------------------------------
Rationale
=======

Given the recent rise in value there seems to be anecdotal evidence that 1
bitcoin being so high is putting off a lot of normal buyers, because they
feel that putting down $400+ and only getting "1 coin", or having to buy in
multiples of 1 whole coin, is too much.. only after it being explained that
they can buy fractional amounts to they regain interest, apparently
happening increasingly.


Straw Poll
========

6 months ago there was a straw poll on this

https://bitcointalk.org/index.php?topic=220322.0

Roughly 2/3 of respondents favoured switching

A further 20% said to switch after it hits 1000

Satoshi's comments:
================

Eventually at most only 21 million coins for 6.8 billion people in the
world if it really gets huge.

But don't worry, there are another 6 decimal places that aren't shown, for
a total of 8 decimal places internally.  It shows 1.00 but internally it's
1.00000000.  If there's massive deflation in the future, the software could
show more decimal places.

If it gets tiresome working with small numbers, we could change where the
display shows the decimal point.  Same amount of money, just different
convention for where the ","'s and "."'s go.  e.g. moving the decimal place
3 places would mean if you had 1.00000 before, now it shows it as 1,000.00.

https://bitcointalk.org/index.php?topic=44.msg267#msg267


Would now be a good time to start thinking about changing the default
display in the software.  Perhaps initially it could be a dropdown display
option, then at some point mbtc becomes the default?
-------------------------------------
The original Bloom filtering spec did not make this feature optional for
the same reason gzip isn't an optional part of the PNG specification. I see
no reason to revisit that. It's definitely not the case that making every
possible feature optional is smart design, often it's the opposite.

If in future there are nodes that for some reason can't technically support
this feature, then there'd be a stronger rationale for something like this.
However no such nodes exist, nor are they likely to in future given that
it's a simple feature to implement.

For these reason I oppose this BIP.


On Sun, Aug 18, 2013 at 4:59 AM, Peter Todd <pete@petertodd.org> wrote:

-------------------------------------
It would be nice if that modularization effort would first and foremost focus on defining the protocols and APIs of the various modules (their responsibilities and patterns of interaction), rather than merely refactoring existing code.

Such an approach has many benefits.  

First, it promotes diversity of implementations.  Diverse implementations are now possible because the correctness of an implementation is now determined entirely by the compliance of its external behavior with the stated protocols and not its internal design. Thus this approach allows for equivalent but alternate implementations. Consequently, this approach -

1. increases the available pool of developers
2. reduces the impact any one implementation defect can have on the overall Bitcoin infrastructure
3. allows enhancement/optimization work of modules to proceed more easily as coupling with external modules is reduced

Second, and just as important, it allows analysis and critiquing of Bitcoin's infrastructure to be undertaken at a higher level than source code: i.e. abstract entities of the protocols and APIs.  Such scrutiny is important to being able to effectively manage the evolution of a system's architecture.

Its been my first-hand experience across many projects that this strategy contributes directly to significant improvements to quality when developing large, distributed, complex software systems.  Indeed, its considered a best practice when developing enterprise-grade software.

I would be happy to collaborate with others in such an undertaking.

- Brenton



On May 16, 2013, at 3:02 AM, bitcoingrant@gmx.com wrote:


-------------------------------------
Gregory Maxwell <gmaxwell@gmail.com> writes:


Thanks - I'll look forward to this being portable someday.  Right now it
sounds similar to "a windows binary but you can use wine" with
substitution of variables :-) People may want to look at the NetBSD
build system, which I think achieves bit-identical builds from different
hosts (but I haven't really checked), by having the toolchain be part of
the source and building cross-compilers from host to target and then
using those to build the system.


Thanks for the explanation - that indeed makes sense.


Well, if you insist on not having updates and bugfixes, then either it's
the included version or there's a special package just for you.
Typically packaging systems don't like included versions because often a
package will have a security bug fixed long before there are updates of
packages that bundle that fixed version.    But given bitcoin's special
needs, that means you have to stay on top of these dependent included
packages and re-release if there are security fixes (that don't break
consensus).


It would be nice if the regression tests were installed and it were
normal culturallly for end-users to run them.


Thanks again for the explanation; I understand where you are coming from
now.



-------------------------------------
On 09/04/2013 15:39, Caleb James DeLisle wrote:

Do you mean firewalls or something like snort or other deep packet
inspection for the tcp sockets statement? I dont see much of an issue
with either.

set up your own private testnet and have a play with this

http://www.eicar.org/83-0-Anti-Malware-Testfile.html

The eicar test virus.


I have tried a few ways of getting the eicar string into the blockchain
(on a private testnet) and getting it flagged by AV, however it is a bit
tricky (the getting it flagged bit). and tbh you would exclude the
bitcoin directory and runtime from antivirus scans so i stopped bothering.

I am making vague assumptions about using windows with antivirus. (and
linux for deep packet inspection, but the idea is the same whatever.)

I found no greater attack surface area (in the blockchain) than
cookies... thinking about it a bit more, there is a bit more potential
as a bounce pad/egg drop location but not much - no heap spraying as
such, or d/c tors, or heap header structs, etc. Im sure someone is sure
to come up with something very clever tho. just not me.

cheers,

steve




-------------------------------------
On Thu, May 16, 2013 at 7:26 AM, Ricardo Filipe
<ricardojdfilipe@gmail.com> wrote:

That's just about the worst thing you could do for bitcoin.  DoS one
part of the DHT, you DoS the entire blockchain by breaking the chain.

-- 
Jeff Garzik
exMULTI, Inc.
jgarzik@exmulti.com


-------------------------------------

Chaining a custom cert onto the end doesn't work, at least not if your
"end" is the SSL cert. Chaining it to the SSL cert defeats the OP's
intention of "cold signing", as the SSL private key is usually kept
online, therefore can't be used to sign a pubkey that is supposed to
stay offline. Hence the idea of the "hack", to get two independent
things signed by the CA in just one cert: 1) your SSL pubkey, 2) your
custom cert (by including its cryptograhic hash). This hack seems the
easiest possible solution.

It also seems the only solution if you want to stick with domain-names
as identifiers for the payment protocol (and I think you do). A cleaner
way would be to get a cert signed by your CA that contains an extended
"bitcoin" attribute in compliance with X.509, but this seems a little
far off.

So I am in favor of the "hack" (properly thought out where to place the
hash).

ps. In the long run I would of course like to see payee identities based
on alt-chains rather than domain-names plus CAs. But that's rather a
concern for v3 than v2. Of course, you can also chain custom certs to
non-SSL identities like PGP-keys. You probably don't want to do that,
but it would solve Melvin Carvalho's problem of sending to RSA keys
(assuming the RSA key holder previously published his custom cert with a
cert server). 

-- 
Timo Hanke
PGP AB967DA8, Key fingerprint = 1EFF 69BC 6FB7 8744 14DB  631D 1BB5 D6E3 AB96 7DA8


-------------------------------------
BitcoinJ is storing parsed blocks (not the whole chunks of bytes) in H2, an
embedded SQL database for Java.


On 5 June 2013 19:53, Marko Otbalkana <marko.otbalkana@gmail.com> wrote:

-------------------------------------
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Transactions != blocks. There is no need for a "merge" block.

You are free to trade transactions off-line, so long as you are
certain the other parties are not secretly double-spending coins they
send you on the block chain.

When connection to the bitcoin network is re-established, you simply
transmit the transactions and in the regular course of things they
make their way into one of the next blocks.

Any transactions which derive from the double-spent one are invalid.
But that's your problem, not the miners - chase after Bob and get him
to give you the money he owes.

On 12/17/2013 02:41 PM, Troy Benjegerdes wrote:
Rapidly troubleshoot problems before they affect your business. Most IT
_______________________________________________
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.14 (GNU/Linux)
Comment: GPGTools - http://gpgtools.org
Comment: Using GnuPG with Thunderbird - http://www.enigmail.net/

iQIcBAEBAgAGBQJSsNTOAAoJEAdzVfsmodw4rBUP/jBFvPks4h0k1GQEPQPYvqNa
3OhuSlC9EfHmjXxftj6j0lH6JO60BFIoA3P76oFycQRqzNSw3YoldQ1MttpNAAZg
ftiJJjYcuVmDYYWxfWPZN7ZsHrrhGkMn+i0PB1vXU3PB3sStb18vhbIoTZmwH7Rk
vaUaX8EKFh6R8Y+6nqFMKu8eALaFQPJFP1aNo31ixsFFJrl02zQeIZiTbrOensEj
6AhXm2oYRqB1aolMmy/m5zcA3IicayJ6seoCQcRhPty6G2l+/4opgATdEBjzgczW
Yhw20YkayyvPa+Fsqwad5AzgGYbm7OA0U6mO/pfeNhglNSt/TGfuSPe1oM9hWt9/
8gP3PG4O4Fxi+gOAlNABgmoRKvQK8T3TX+eoayxPJiLxi+5l3+1CK0FK1+mKPThr
heFrc5e9QlUIgATOpLYSs/elgAFM6N2Sez+RNiOg201M10VVKqXzBgZRQ+IYRRk6
jbaBKxsQ/ql5+2vwaUkplg/6Y6rfvRItQ+8xwXEvxazPAAh3Mp0fPbqas+F0e1Ie
SwVTq517iV7eu+kMxOJEqaCky8ihbaUmshjeEccXdbodpygxCR2dZ0xAkvwXYtnK
+ZjLQ7o8ySZs89Jvdx8H2fsu6m3hS/7Mm+zJVGV/hLHLoL7IrYPzTHcOHv8eT106
IYM30Hv+vDrt+f8ZRZ80
=09Pt
-----END PGP SIGNATURE-----


-------------------------------------
On Tue, Jul 23, 2013 at 10:30:13AM +0100, Andy Parkins wrote:

On Tue, Jul 23, 2013 at 10:27:19AM +0200, Andreas Schildbach wrote:

The REST API has nothing to do with SPV clients; it's similar to the RPC
interface and won't be exposed to the network as a whole.

Increasing the resource usage by SPV clients on full nodes is undesirable; we
have a lot of work to do regarding DoS attacks. John Dillon's comments here on
using micro-transactions to compensate full-nodes for maintaining expensive
blockchain indexes are worth reading:
https://github.com/bitcoin/bitcoin/pull/2802#issuecomment-20232958

In any case UTXO data currently requires you to have full trust in
whomever is providing you with it, and that situation will continue
until UTXO commitments are implemented - if they are implemented.

-- 
'peter'[:-1]@petertodd.org
000000000000007bea8b46717ec4acb05830bcb6222497366dd72b02ddc80569
-------------------------------------
There is a good writeup of how to perform the workaround in Windows at
https://bitcointalk.org/index.php?topic=290922.msg3117923#msg3117923


-------------------------------------
On Tue, May 14, 2013 at 9:16 PM, Melvin Carvalho
<melvincarvalho@gmail.com> wrote:

Well, no, and yes. It doesn't work like that.

If you have your own domain, you can store your key there as a TXT entry.

$ dig +short harald._pka.schil.ly. TXT

and even use it automatically:
$ gpg  --auto-key-locate pka -r email@address.domain

H


-------------------------------------
On Thu, Dec 12, 2013 at 7:20 PM, Gavin Andresen <gavinandresen@gmail.com> wrote:

Absolutely.  This is a key address-non-reuse case we really need to
solve.  Miner payouts, BitPay salary payouts, etc. all use a
statically provided, manually changed address.

Rotating through multiple outputs is a stopgap -- but IMO a useful
one.  HD wallets will solve this in a better way, but existing randkey
systems will be around for a long time.

-- 
Jeff Garzik
Bitcoin core developer and open source evangelist
BitPay, Inc.      https://bitpay.com/


-------------------------------------
On Mon, Mar 25, 2013 at 1:49 PM, Roy Badami <roy@gnomon.org.uk> wrote:

That is quite drastic enough, as it requires adding more perpetual
data that must remain in fast lookup for all validating nodes (the set
of revoked 'addresses').

Keep in mind that this is only improvement for what is a usually
inadvisable usage of Bitcoin to begin with... you should not be
reusing addresses.


-------------------------------------
On Mon, May 6, 2013 at 11:04 AM, Adam Back <adam@cypherspace.org> wrote:

Uh.  It currently costs about 2016*25*$120 = six million dollars to
reduce the difficulty in your isolated fork by a factor of 4.

To reduce it by a factor of 1000 (what would be required to make a
parallel fork that you could maintain in realtime with a single avalon
device) the cost is  sum(2016*25/4^n*120,n,0,ceil(log4(1000))) or
about eight million dollars.

Surely you can think of attacks on Bitcoin which are less expensive
than eight million dollars. :P


Protecting against thatâ€” making sure any such attack has to start from
a high difficultyâ€” is, in my opinion, the biggest continued
justification for checkpoints.


They are signed.


No, it doesn't. It has centrally controlled directories that publish
an official Truth of the Network. Someone can isolate you and thus DOS
you, but they can't put you on a fantasy tor network.  But ...
centeralized.


It does, and we also consider decentralization a core value. But even
the tor project would like to decentralize more.


-------------------------------------
On Mon, Dec 9, 2013 at 7:23 PM, Ryan Carboni <ryan.jc.pc@gmail.com> wrote:

Your proposal has been met with widespread laughter.  Were I not ill
with the flu, mockery would ensue as well.

-- 
Jeff Garzik
Bitcoin core developer and open source evangelist
BitPay, Inc.      https://bitpay.com/


-------------------------------------
0.8.4 release candidate 2 is available at:
  https://sourceforge.net/projects/bitcoin/files/Bitcoin/bitcoin-0.8.4/test/

This is a maintenance release to fix a critical bug and fix three minor
security issues; it contains very few changes from the 0.8.3 release.

The two changes that need testing:

1) OSX FD_FULLSYNC leveldb corruption fix. If you have had trouble with
database corruption on OSX, please try this release and let us know if it
seems to help. Also let us know if you experience any performance problems
with this release.

2) Bloom filter optimization. If you have code that uses the bloom-filtered
block (merkleblock) protocol, please try it against this release and let us
know if you run into any issues.


PS: a critical last-minute bug was found in release candidate 1; it was
never released.

-- 
--
Gavin Andresen
-------------------------------------
On Mon, Oct 28, 2013 at 12:37:30PM -0700, Jeremy Spilman wrote:

It's a bit more risky from a cryptography perspective, but provided your
wallet implementation is done correctly the extra risk is pretty much
theoretical. However this has caused real-world coin loss in the past in
the case of the Android PRNG flaw - re-using nonces in ECC signing
causes the private key to be revealed.

I think the real issue here is that John doesn't appear to have asked
any of the people whose signatures can release the funds if they were
willing to take part. If he had done that, he could have, and should
have, gotten separate pubkeys for the purpose of the bounty like was
done for Gregory Maxwell's CoinJoin bounty. Instead by not asking he is
in reality if not in theory placing demands on people who haven't
consented, particularly for the 1BTC bounty where he doesn't control any
of the private keys required to release the funds. IMO this is rude and
I encourage people not to do this.


Well, the issue with not disambiguating bounties is that if further
funds are sent to the bounty address it's unclear how do you handle
those funds. Note how he specified a specific txout for the 1BTC bounty,
but specified an address for the 4BTC bounty.


We're not that far off: I could cook up a Python script to do the
signature accumulation and signing in a few hours. There's just not all
that much demand yet to fully polish the UI's, and in any case, it'll
differ for every specific application.

FWIW blockchain.info added multisig escrow support ages ago, then
removed it not long after because usage was near zero.

-- 
'peter'[:-1]@petertodd.org
0000000000000001daf527009e07f452eee5dca920d3a9253b682d8bd26783ff
-------------------------------------
On 08/19/2013 10:34 PM, Jeff Garzik wrote:


Here, too. If I'm too impatient to wait for the next block that is.

I think it'd be a pity if the easy way to mine blocks would be removed.




-------------------------------------
Jorge, thanks for bitcoinx tip, I didn't know about it and it's certainly
related. I'll have a closer look
Regarding Ripple, I tried it but as far as I can tell, it doesn't have any
contract enforcement (by technical means) built in.


On 11 February 2013 05:03, Jorge TimÃ³n <jtimonmv@gmail.com> wrote:

-------------------------------------
I can provide the server hardware and colocation (space, power, and  
bandwidth) if dedicated 50Mbit in 55 S. Market, San Jose, CA data center  
is acceptable.

If it needs more bandwidth than that, in a few months I hope to be getting  
space in LA with 1Gbit, but I can't commit to that now.


-------------------------------------
On Mon, Jul 29, 2013 at 02:00:10AM -0400, Jeff Garzik wrote:

We're talking about two use-cases here: wallets protected by
authorization tokens for multi-factor security, and allowing funds to be
controlled by oracles that attest that events have happened allowing the
funds to move.

The latter application especially demands a specialized wallet, yet can
only possibly work with non-standard script formats.

IMO bringing the issue of wallet standardization into this discussion is
kinda silly and premature; if you don't want to use those features, then
you're wallet can ignore them. As for the people that are, they can come
up with appropriate standards for their needs.

After all John's suggesting only allowing the loosened IsStandard()
rules within P2SH, so until the txout is spent all *any* wallet sees is
a P2SH address with no information as to what scriptPubKey is needed to
spend it.

-- 
'peter'[:-1]@petertodd.org
00000000000000220b76f98fc9414043f765ec48dba3fb556e096caffbaae8ec
-------------------------------------
I'm thinking we should actually make the change we talked about before
and have the filtered block sent before the transaction data.

For one, it's not intuitive (API wise) that you'd get a callback
saying "new pending tx" immediately before another callback saying "tx
was confirmed", but that's what the current setup makes most natural.
To fix it we'd have to notice that a tx message wasn't requested by
us, buffer it, and wait for the corresponding filteredblock message.
It seems cleaner to receive a filteredblock and then for any tx that
matches it, attach it to the FilteredBlock object and wait until it is
full up, then pass it to the wallet code all at once.

Another issue is that to risk analyze unconfirmed transactions you
really have to download all dependencies. That has to be triggered by
seeing an unconfirmed transaction. It's dumb to start this process for
a tx that is actually in the chain, so you need to have some notion of
whether it came from a filtered block anyway. I only realized this
today.

I think when we discussed this before, the justification for having it
work the current way was that it was simpler to integrate with the SPV
client code if it was done this way around. But I don't think it's
really simpler. There are enough odd side effects of doing it this
way, that I feel it'd be better to tweak the protocol now whilst we
have the chance.

On Wed, Jan 16, 2013 at 4:00 PM, Matt Corallo <bitcoin-list@bluematt.me> wrote:


-------------------------------------
Oh, I forgot to one practical aspect; the way how the mnemonic is "mined"
in Thomas proposal prevents usage in embedded devices, because difficulty
of generating proper mnemonic is simply too high for embedded
microcontrollers. Maybe this can be solved somehow by modifying the
proposal, but right now it is a showstopper for us.

Marek

On Thu, Oct 31, 2013 at 12:11 PM, slush <slush@centrum.cz> wrote:

-------------------------------------
There's no problem, but there's no benefit either. It also locks us in to a
potentially problematic guarantee - what if in future we want to have, say,
two optional new pieces of data in two different messages. We don't want to
require that if version > X then you have to implement all features up to
and including that point.

Essentially the number of fields in a message is like a little version
number, just for that message. It adds flexibility to keep it that way, and
there's no downside, seeing as that bridge was already crossed and people
with parsers that can't handle it need to fix their code anyway.

So I have a slight preference for keeping things the way they are, it keeps
things flexible for future and costs nothing.



On Thu, Jun 20, 2013 at 11:06 AM, Pieter Wuille <pieter.wuille@gmail.com>wrote:

-------------------------------------
On Wed, Feb 13, 2013 at 10:42 AM, Gregory Maxwell <gmaxwell@gmail.com>wrote:


I disagree with Gregory on this.  I believe that Bitcoin CAN meet its
security and decentralization promises without any hard limit on block
size.

I had a fruitful discussion about this with an economist friend this
weekend, and I'll eventually getting around to writing up why I believe
raising the block size limit will not be a problem.

-- 
--
Gavin Andresen
-------------------------------------
https://togami.com/~warren/archive/2013/example-bitcoind-dos-mitigation-via-iptables.txt
*Anti-DoS Low Hanging Fruit: source IP or subnet connection limits*
If you disallow the same IP and/or subnet from establishing too many TCP
connections with your node, it becomes more expensive for attackers to use
a single host exhaust a target node's resources.  This iptables firewall
based example has almost zero drawbacks, but it is too complicated for most
people to deploy.  Yes, there is a small chance that you will block
legitimate connections, but there are plenty of other nodes for random
connections to choose from.  Configurable per source IP and source subnet
limits with sane defaults enforced by bitcoind itself would be a big
improvement over the current situation where one host address can consume
limited resources of many target nodes.

This doesn't remove the risk of a network-wide connection exhaustion attack
by a determined attacker, but it at least makes multiple types of attacks a
lot more expensive.  This also doesn't do much against the io
vulnerability, which would require major redesigns to prevent in Bitcoin.

https://github.com/litecoin-project/litecoin/commit/db4d8e21d99551bef4c807aa1534a074e4b7964d
*Want to safely delay the block size limit increase for another year or two?
*  This patch alone enables that.



On Fri, Aug 16, 2013 at 2:24 AM, Mike Hearn <mike@plan99.net> wrote:

-------------------------------------
On Mon, Mar 25, 2013 at 02:10:53PM -0700, Gregory Maxwell wrote:

Maybe it should be possible for addresses to contain expiry dates, so
that revocation lists don't need to hang around forever.


It may be inadvisable but in many cases it is pretty much unavoidable
as Bitcoin stands today.  Granted, the payment protocol will help with
that in many use cases...

roy


-------------------------------------
On Thu, May 09, 2013 at 01:27:33AM +0000, John Dillon wrote:

Remember that interpreting the timestamp on a block for the purposes of
timestamping is a lot more subtle than it appears at first.

Any node will accept a block with a timestamp no more than two hours
ahead of what it thinks the current time is. That time is adjusted by
the median of the timestamps reported by your peers. For instance the
RPC call getinfo returns, among other things:

{
    "timeoffset" : -1,
}

That is saying my node's wall clock time is 1 second behind the median
reported by it's peers - pretty good!


Naively you might think this means block timestamps are accurate to
within 2 hours right? Well, it's not so simple. Nodes will accept any
block with any timestamp *after* the median of the last 11 blocks. From
CBlock::AcceptBlock():

    // Check timestamp against prev
    if (GetBlockTime() <= pindexPrev->GetMedianTimePast())
        return state.Invalid(error("AcceptBlock() : block's timestamp is too early"));

So in theory a miner could prevent that block from moving forward,
although if they do they drive up the difficulty, so all miners have an
incentive to set the timestamp accurately.

There are two types of timestamps possible: proofs that data existed
before a time, and proofs that data existed after. With the former type
the *later* the proof says the data existed, the more conservative the
assumptions behind the proof. So simply adding two hours to the block's
timestamp is relatively reasonable. (this assumes the attack managed to
mine a single block, and all nodes have accurate clocks)


The latter type, where you prove data existed after a given time, is a
much more tricky thing to apply. The genesis block is a great example
with that famous newspaper headline:

    The Times 03/Jan/2009 Chancellor on brink of second bailout for
    banks

As I mentioned in my other (private) email to you a few minutes ago, the
sig of my emails has the latest block hash in each one. The basic idea
is called a random beacon; NIST has a good description and a project to
create one:

http://www.nist.gov/itl/csd/ct/nist_beacon.cfm

Now technically speaking a random beacon is actually a more
sophisticated concept than just timestamping, the random beacon's value
is public and distributed widely, but for timestamping the idea is
basically to have an unpredictable number known to have been produced at
a certain time.

So you know this email was written after block #235235, timestamp
2013-05-09 01:21:52 right? Not so fast. All you actually know is the PGP
*signature* was created after that time, because the actual text of the
email is independent of the beacon nonce. (dunno if I have the correct
terminology here FWIW)

For a blockchain it's easy enough, the blocks naturally depend on a
genesis block, but applying the concept more generally is tricky and
application dependent; consider for example proving you created a
keypair after some data, which might be a useful thing to prove if the
secret key was created in some tamperproof hardware that you know has
left the factory and is in your possesion. It's easy to see how to do
this with ECC: just use the same techniques as in HD wallets to derive
keys.

To use the blockchain as a secure random beacon you need to make two
assumptions, 50% of the hashing power is controlled by honest miners,
and those honest miners have accurate clocks. With those assumptions you
can work out what is the minimum possible time the block could have been
accepted by the GetMedianTimePast() function and you are good to go.

What do people do in practice? Well look at
http://vog.github.io/bitcoinproof/, they just give the timestamp and
nothing else. Same for OpenTimestamps. (although I'm adding this email
to my notes, half the reason it's so detailed...)


Back to the block header time... Frankly, the easiest thing to do is
just have a flag day where blocks after a certain height are considered
to have a different epoch from the standard 1970 one when computing
their time. Boring, but it works fine and only needs to be updated every
few decades.


You're midstate idea is very clever though and could come in handy in
the future for different purposes. Eventually we should discuss this
with the ASIC manufacturers - if it can be implemented as a firmware or
FPGA upgrade in the field all the better.

-- 
'peter'[:-1]@petertodd.org
000000000000010a10e05e172442e0675a818d17b62c1ed041a4572002ca051e
-------------------------------------
Strange, I didn't receive the response from sipa in separate message, so
I'll respond to him at first place.

Le 26/10/2013 23:30, Pieter Wuille a crit :

Although many strange practices how to use whole bip32 space are possible,
I think that we may (should?) agree on some "good enough" way how to
discover already used addresses in bip32 space. I read Electrum sources
about bip32 and I see that Electrum still uses quite flat structure (fixed
amount of branches, indexes from 0 to n), which is of course very sane way.

So if I migrate seed to another (non-Electrum) software, I only need to
discover close neighbourhood of the path "0", similarly like Electrum is
doing with "gap limit" in plain old Electrum algorithm, except in two
dimensions (paths 0, 1, 2, 3, 4, 5, 0/0, 0/1, 0/2, 0/3, 0/4, 0/5, 1/0, 1/1,
...5/5 for gap limit "5"). I don't say such operation is cheap, but this
discovery needs to be done only during the import.

For the reason that I think this is the only sane algorithm of general use
of bip32 space, I still don't see why we do need some extra metadata. I
would understand this if Electrum will use for some strange reason
addresses in higher address space like 2^32-1 or so, but this is not going
to happen at least in Electrum.


Well, I can imagine that the bip32 compatible software will do full scan of
address space using some gap factor (actually I think "5" is too low by
default) or it can ask for wallet metadata like which software used such
tree before, to speedup scanning process.

I see that Thomas wants to make this automatic and hidden to user and
generally I agree that hiding the compexity to user is a good practice, but
actually this particular situation sounds to me as an exact oposite of
original statement "no metadata in mnemonic".


ECDSA has one very nice option - (almost) any random data can be used as a
private key. There are very nice schemas possible by using this feature and
requiring private key to be specially crafted just because the user wanted
to use mnemonic schema is very strong limitation to me.

To be specific, we (in cooperation with / inspired by Timo Hanke) developed
method how to prove that the seed generated by Trezor has been created
using combination of computer-provided entropy and device-provided entropy,
without leaking full private information to other computer, just because we
want Trezor to be blackbox-testable and fully deterministic (seed
generation is currently the only operation which uses any source of RNG).

To limit the complexity of such algorithm it is better to produce plain
seed (128, 192 or 256 bits, depends on settings) and then transform the
result of such "deterministic seed" to mnemonic, so for us the
bi-directionality is quite strong requirement. *Maybe* it would be possible
to combine such algorithm and one-way mnemonic together, but it would
complicate the design and I'm sure you understand that we want to keep
things as clear and simple as possible, especially while handling with seed
generation.


Agree (hardening is default in bip39).


Marek
-------------------------------------

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

John,

What you are recommending is a drastic change that the conservative
bitcoin developers probably wouldn't get behind (but let's see). However
proof-of-stake voting on protocol soft-forks has vast implications even
beyond the block size limit. Within Freicoin, we have looked at is as a
possibility for determining how to distribute the demurrage, a proposal
we are calling 'Republicoin' due to the fact that with proxy voting we
expect a system to emerge similar to the government budgeting in
parliamentary republics. Distributed, non-coersive government by
protocol, if you will.

So anyway, even if you get shot down, please continue to pursue this
proposal. It very likely has uses that you haven't thought of yet.

Cheers,
Mark

On 6/9/13 9:09 PM, John Dillon wrote:
can not
because
miners to
majority of
Essentially for
larger
median of
for the
"lost"
their age
old will be
day old
simply to
after 52,560
included to
identifying votes
tree of
compute
the vote
remembers their
median in a
still be
provided the
additional votes
vote to
the wishes
themselves
given
mechanism
prevent DoS
votes
authoritative as
mine as
block
soft-fork)
of the
considered to
end of
gradually and
miner
being spent.
allowing
hard-fork is
could
a given
buying is
"honest"
participants
vote to
high. (note
the limit
stay. But
whatever that
------------------------------------------------------------------------------

-----BEGIN PGP SIGNATURE-----
Version: GnuPG/MacGPG2 v2.0.19 (Darwin)
Comment: GPGTools - http://gpgtools.org
Comment: Using GnuPG with Thunderbird - http://www.enigmail.net/

iQIcBAEBAgAGBQJRtgLYAAoJEAdzVfsmodw4vWEQAIWxuEXMZb80qTMFyvWiR0Tt
Cn/yx8iG2tPa4xGUq0ypwBU3doFEzYBj3bMyQuluGRP7BBhGat4qhrmI/qGVwYXW
RSQdbdgnp4DXhaOD2QzYh/5zDbN/1jCkuxyUvx/QNAeNEpmN1BoDKhDlM/ywCKdj
qfFZWj30pTzADJiY7P5upCu3TiYuQtTWTHlap2c4fToNsLxAMiLZJTOE1Ytdc31Q
O8iwkV7eFlueawtfFLh/dNz5zVKXSOoNz1sFmgjkO3QQaSqSzinBE1z3vR9QYL+A
R7X1v0sQXDpE0XiPymWE8adjGIai3CBUVZcvnJrPtUznydmpe+OvLf3UZE+QfCuJ
tLP9u42e+gjOb6r9qp4tLZBGlTR2moY/IPtVs8KiMDWt9Nq1fO94IBGyJgFYOxRn
Zq6/funKTO6SO8d+ppQ158s2faVmN3OKMrn6BNnfddWD3/EBhGzEDzuNuNAvfKqQ
nrqEusWrfOZOh66pIs6qvROSamaC42FXMUwBU0wA3W3MEuQhXrGM1S2huKykgZ9W
WsOpC6ng6j5H5dSIs4tvnsDY9hUa9zWIB1+i368pXDv8biOs7ULKEP3mdC1q+4YD
tM/MkC0xKax2zG4wbbez8FpwTpUOOznpYPMZqXkLOkGCAdiAyg2UnLPduudaAkQz
adXXe284XHjjOcZUDvGw
=trsn
-----END PGP SIGNATURE-----

-------------------------------------
This sounds like an ideal compromise.


On Mon, Aug 19, 2013 at 3:16 PM, Gregory Maxwell <gmaxwell@gmail.com> wrote:




-- 
*MONEY IS OVER!*
                                IF YOU WANT IT<http://www.zeitgeistmovie.com/>
=====================================================
The causes of my servitude can be traced to the tyranny of money.
-Serj Tankian
-------------------------------------
We do automatic refunds. When bitcoins arrive after an offer has expired
(which happens quite often with webwallets that don't broadcast
transactions immediately), we return all the bitcoins to a specified
bitcoin-address. This happens a couple of times per day and can amount
to a couple of hundred bitcoins per offer.



On 04/30/2013 11:17 AM, Mike Hearn wrote:



-------------------------------------
On Wed, Jul 24, 2013 at 8:32 AM, zooko <zooko@zooko.com> wrote:

Maybe!  A widespread consensus failure causes people to lose money
even absent malice. How much depends on a bunch of details, including
the luck of attackers.

The total ramifications are as much social as they are technical so
it's hard to reason over the outcomes beyond "at a minimum, it's not
good".

A really bad splitting event could results in large amounts of Bitcoin
being stolen through reversals. Obviously the system itself would keep
on ticking once the issue was resolved... but if millions of dollars
at recent prices in coins were stolen,  would people want to keep
using it?

The most dire outcomes are (very?) unlikely, but they're not necessary
to recognize that risk mitigation is important.

It's good to be careful here just to avoid the bad outcomes we are
sure will happen (because we've experienced them before):   Hundreds
of dollars worth of coin income 'lost' per minute to miners on the
losing side of a 50/50 fork, hours long disruption of the lives of
dozens of people in the Bitcoin technical ecosystem (many of whom are
volunteer OSS developers), hours of disruption (no payments processed)
to Bitcoin users and businesses.  These are the best case outcomes in
a substantial non-transient hard forking event.

I think one of the challenges in talking about this stuff is correctly
framing these risks.  Bitcoin is a novel technology that lacks a lot
of the recourse that other systems haveâ€” No Bitcoin central bank to
create a bit of inflation to paper over a glitch,  eliminating those
kinds of centralized "fixes" is much of the point, after allâ€”  so with
the idea of starry eyed people taking out second mortgages on their
kids kidneys to buy up coin clearly in my mind I do think it's
important to be clear about the full range of risk:  It's _possible_
that due to some amazing sequences of technical screwups that by next
week most everyone could consider Bitcoin worthless. I think it's
important to be frank about those risks.  ... but it's also not good
to be chicken little, calling doom on anyone who wants to change the
color of the GUI. :P   Navigating it is hard, and generally I'd prefer
that if there is any misunderstanding people overestimate the risks a
littleâ€” so long as things stay in the realm of the possibleâ€” rather
than underestimate them.


-------------------------------------
On Tue, May 7, 2013 at 2:28 PM, Gavin Andresen <gavinandresen@gmail.com>wrote:

Yes, sweep (send all the coins from this addresses to me) should certainly
be added. Maybe even a way to do it periodically, though but that would
require remembering the key.

Importing private keys into the wallet will not be added as a user-friendly
option, as it is dangerous and potentially confusing.

As for (1), I think a better solution would to add a list of commands whose
arguments are censored in the console screen and command line history. At
least `importprivkey`, `walletpassphrase`, `walletpassphrasechange` should
likely be in that list.

Wladimir
-------------------------------------

I'm using the term "high frequency trading" because Satoshi did. Like the
way he used the word "contract" it is perhaps a bit misleading, but we lack
anything better to describe this new concept.

Today HFT typically means companies that submits tons of micro-trades to
centralised asset exchanges to try and exploit statistically expected
correlations. HFT using tx replacement has nothing to do this with - it is
instead a way that N parties can negotiate amongst themselves as fast as
they can compute and verify signatures.

Here is how Satoshi explained it to me, in his words:

An unrecorded open transaction can keep being replaced until nLockTime.  It
may contain payments by multiple parties.  Each input owner signs their
input.  For a new version to be written, each must sign a higher sequence
number (see IsNewerThan).  By signing, an input owner says "I agree to put
my money in, if everyone puts their money in and the outputs are this."
 There are other options in SignatureHash such as SIGHASH_SINGLE which
means "I agree, as long as this one output (i.e. mine) is what I want, I
don't care what you do with the other outputs.".  If that's written with a
high nSequenceNumber, the party can bow out of the negotiation except for
that one stipulation, or sign SIGHASH_NONE and bow out completely.

The parties could create a pre-agreed default option by creating a higher
nSequenceNumber tx using OP_CHECKMULTISIG that requires a subset of parties
to sign to complete the signature.  The parties hold this tx in reserve and
if need be, pass it around until it has enough signatures.

One use of nLockTime is high frequency trades between a set of parties.
 They can keep updating a tx by unanimous agreement.  The party giving
money would be the first to sign the next version.  If one party stops
agreeing to changes, then the last state will be recorded at nLockTime.  If
desired, a default transaction can be prepared after each version so n-1
parties can push an unresponsive party out.  Intermediate transactions do
not need to be broadcast.  Only the final outcome gets recorded by the
network.  Just before nLockTime, the parties and a few witness nodes
broadcast the highest sequence tx they saw.
-------------------------------------
On Sat, Oct 5, 2013 at 4:31 AM, Gavin Andresen <gavinandresen@gmail.com>wrote:


Thanks, although I wasn't thinking specifically of you. The fee pull is
pretty well laid out. It just reminded me that it seems to be a common
issue I've had over the past year or so, across projects and people.



Yes, I don't know if github supports any kind of SSO. I will investigate.
As for learning another tool, well, when the current tool kind of sucks I
don't see any way around that one :)



Perhaps just have a separate section for people who helped review above the
current section? It seems a bit mean not to credit occasional contributors
who fixed bugs or maintained something important but didn't review
complicated changes to the core.
-------------------------------------
That would be annoying for testing. Regtest mode allows you to create a new
block by just running "setgenerate true" (it switches itself off after
creating a block). If you had to set up a complicated set of separate
programs just to do regtest mode that'd be a step backwards, IMO.


On Thu, Aug 22, 2013 at 3:18 PM, Jeff Garzik <jgarzik@bitpay.com> wrote:

-------------------------------------

That is a really bad idea.  If there is not a CLEAR answer to "who admins
it", there will be a bunch of "I thought YOU were applying security
patches... no, I thought YOU were..." the first time it gets hacked.

So, the question is:  who wants to take responsibility for keeping
bitcoin.org safe and secure?

I am not going to do that, I've got too many other things to worry about.
It is exactly the type of thing the Foundation was setup to do, but if
y'all want to create some other organization to do it, then please make it
happen.

-- 
--
Gavin Andresen
-------------------------------------
On Monday, June 10, 2013 9:09:13 PM Peter Todd wrote:

This is basically done.


The plan was to tell the pool it doesn't need to send transactions at all, and 
only work on the ones from bitcoind. Currently, share submissions are just the 
block header and coinbase transaction; in this case, however, the miner will 
need to send merkle links also, possibly just once via a block proposal in 
advance.


Currently, BFGMiner is doing submission to the pool, waiting for a response, 
then submitting to a local bitcoind. This is because the pool might need to 
receive/record the share before it processes the block on bitcoind, or you 
could lose credit for it. The response from the pool is rather small (a single 
TCP packet), so this shouldn't delay much longer.


Might as well just use higher difficulty shares (each one audited) for the 
same effect. Block proposals allow the miner to tell the pool its transaction 
set once (per txset change) for any number of shares.

IF bandwidth becomes a real problem, I have a draft of a "GBT 2.0" that does 
some more improvement in this area.


I don't follow.


libblkmaker's API was designed for this from the start, so it should be fairly 
easily implemented.


Failover already functions, but probably could use a rewrite...

Luke


-------------------------------------
On Fri, Nov 15, 2013 at 02:19:56PM -0500, Peter Todd wrote:

Oh right, you're using the actual block interval, not the steady state
one.

-- 
'peter'[:-1]@petertodd.org
00000000000000056032432f186a8276d3feecb805d064c1def85905670a453b
-------------------------------------
On 5 November 2013 22:07, Quinn Harris <btcdev@quinnharris.me> wrote:



Well in that case, you could make it unpredictable by choosing based on a
hash of the blockhash and chose the lowest from two. There is no way for
Alice to know if Bob's resulting hash will be higher or lower than hers
since she does not know Bob's blockhash in advance and therefore she would
be better broadcasting her block immediately.

You could even add another unpredictable factor: deciding the rules of
whether higher or lower wins by hashing both competing blockhashes. If the
leading two hex digits are below 128 lower wins, and if above, higher wins.

Drak
-------------------------------------
my initial idea (not sure if it is good) was to have an asymetric market.
lets say you want to create altcoin ALC. ALC are merge-mined with btc,
though without block reward.
to create 1 ALC you have two choices: destroy 1 BTC, or buy 1 ALC for a
floating amount from an exchange.

in my book, this would automatically lead to a slightly lower price for
1 ALC, and an automatic ceiling of 1 BTC, since you could always
sacrifice BTC to gain ALC.
but it would not diverge drastically lower, since apparently somebody
was willing to destroy 1 BTC to create it. maybe it could even trade
slightly higher because traded ALC could be spendable instantly while
sacrificed ALC would need a 120 blocks maturing period.
the "beauty" of that system is also it does not inflate the
cryptocurrency realm.

Andreas

Am 14.06.2013 23:10, schrieb Luke-Jr:



-------------------------------------
Hello everyone,

In the previous thread, I expressed interest in seeing an SPV bitcoind, further stating that I would fund such work. Mike Hearn followed up with some of Satoshi's old code for this, which is now quite broken. The offer and interest on my side still stand, as more diversity in SPV options seems like the right way to go.

Time-permitting, I would really appreciate feedback from knowledgable parties about the possible approaches to an SPV bitcoind. We at Hive ideally want to see something that could one be merge into master, rather than a fork.

-wendell

grabhive.com | twitter.com/grabhive



-------------------------------------
If you have two parties who want to form a persistent relationship, by exchanging and verifying public keys beforehand, then I think the canonical way to do this with BIP32 is for the parties to exchange PubKey and *ChainCode*.

I donâ€™t understand the use case for handing out individual multipliers, if what you desire is a persistent relationship. If each party dedicates a child-wallet for receiving coins, and saves a PubKey/ChainCode for sending coins, the two parties can transaction securely forever without ever exchanging any more information, and without any address reuse.

I think ideally, the default behavior is that wallets always dedicate a new child node {PubKey, ChainCode} to each party they transact with. At the presentation layer, you have a â€œcontactâ€ and each contact has a transaction history. You can send coins to a contact at any time, and internally the wallet picks the next address in their sequence. Any funds received on pubkeys from contactâ€™s sequence are attributed to that contact. The wallet can organize the contacts, and roll-up the transaction history into â€˜ledgersâ€™ and â€˜balancesâ€™ however they want â€“ it could be based on the underlying BIP32 hierarchy or perhaps not. The cost of watching large a number of pubkeys, even if you â€˜look aheadâ€™ 100 pubkeys for each contact, is relatively small versus the benefits.

What might be nice is a â€˜Contact Requestâ€™ protocol, basically the same as a PaymentRequest but no actual payments are sent, just child wallets created:

message Contact {
    optional uint32 contact_version = 1 [default = 1];
    optional string pki_type = 2 [default = "none"];
    optional bytes pki_data = 3;
    required bytes serialized_contact_details = 4;
    optional bytes signature = 5;
}

message ContactDetails {
    optional string network = 1 [default = "main"];
    required bytes pubkey = 2;
    required bytes chaincode = 3;
    optional string memo = 4;
    optional string response_url = 5;
}

Alice sends a Contact+ContactDetails to Bob.  If Bob accepts, he sends his own Contact+ContactDetails (without a response_url) back to Alice. Basically just like adding a contact to your IM contacts.

Alice could send a Contact+ContactDetails to Bob without a response_url, in which case after accepting the contact, Bob could send funds to Alice, but not receive funds.

You could probably pack the whole message inside a bitcoin:// URI if you wanted to.

Thanks,
--Jeremy
-------------------------------------
Partial UTXO sets is a neat idea. Unfortunately my intuition is that many
SPV wallets only remain open for <1 minute at a time because the user wants
to see they received money, or to send it. It'd be neat to get some
telemetry from the Android wallet for this - I will ask Andreas to let
users opt in to usage statistics.

So for anti-DoS I think smart prioritisation heuristics are the way to go
again. Perhaps by letting clients have an "identity" that they provide to a
node when it's load shedding. Clients that have been seen before, have a
track record of not being abusive etc get priority and new clients that
were never seen before get dropped. Coming up with a way to do that whilst
preserving privacy sounds like an interesting cryptographic challenge.


On Wed, Jul 17, 2013 at 12:58 PM, Peter Todd <pete@petertodd.org> wrote:

-------------------------------------
On Thursday, November 14, 2013 11:11:26 PM Mark Friedenbach wrote:

Keys are often reused, so not sure that conveys the single-use much better.
Reason I suggested invoice id is because nobody wants to pay the same invoice 
twice.

Luke


-------------------------------------
Sure thing, I'm looking for a good way to publish these measurements,
but I haven't found a good option yet. They are rather large in size,
so I'd rather not serve them along with the website as it hasn't got
the capacity. Any suggestions? If the demand is not huge I could
provide them on a per user basis.
--
Christian Decker


On Sun, Nov 24, 2013 at 5:26 PM, Gregory Maxwell <gmaxwell@gmail.com> wrote:


-------------------------------------
The current version requires a signed cert yes. Whether that's difficult or
not depends on the policies of the cert authorities. Ultimately all they
have to do is verify an email address by sending it a clickable link, which
is why StartSSL do it for free. Probably they aren't optimised for
usability, but there's no technical reason why one couldn't be. It's a
competitive market, after all.

There's also the option of extending the payment protocol to support other
forms of PKI. But from a technical perspective the X.509 PKI is fine.
Someone can always set up their own CA for the Bitcoin community and
convince wallet developers to include their root cert, after all.


On Mon, Sep 9, 2013 at 9:26 AM, Wendell <w@grabhive.com> wrote:

-------------------------------------
On Mon, Nov 4, 2013 at 3:26 AM, Mike Hearn <mike@plan99.net> wrote:

Yea, I've proposed this too (both in the past and in the context of
this). I don't think, however, that the announcements need to be the
miners themselvesâ€” but instead just need to be nodes that the miners
think are good (and, for their own sakeâ€” ones they're well connected
to).

Miner's could keep a list of address messages nodes they
like/are-connected to, perhaps prioritizing their own nodes, than
exclude ones which are already in the most recent blocks, and include
the best remaining. Of course, if it's using address messages (or
perhaps a new address message syntax) it would automatically support
hidden services.

They should probably be included as OP_RETURN outputs in coinbase
transactions, maybe only limited (by what other clients pay attention
to) to one or two per block.

This should make it harder to get partitioned from the majority
hashrate (or partition the majority hashrate from itself), though
these hosts would be DOS targets, so it isn't a silver bullet.

Making the majority hashrate self-unpartitionabilty stronger is
possibleâ€” have miners add an encryption key to their coinbase
transactions, then have subsequent miners mine encrypted addr messages
to single other block sources to automatically weave a miner darknet
with access controlled by successful block creation. But I doubt it's
worth the complexity of bandwidth.


-------------------------------------

When Persona is supported by all the key players in a transaction Mozilla
doesn't get anything, do they? You can easily run your own IDP on a
personal server if you're the kind of person who likes to do that, then run
Firefox so you have a native implementation and the Mozilla servers aren't
involved. The keys never leave your computers.

Whilst X.509 certs can indeed be issued for any arbitrary string, you still
need a CA that will do it for you, and that's typically not so trivial. CAs
aren't meant for widespread end user adoption, really, whereas Persona is.

I don't think Persona is any more or less centralised than other PKIs,
really, just easier to use. Ultimately the string you're verifying is a
user@host pair, so the host is centralised via DNS and to verify the
assertions it vends, you must use SSL to connect to it, so under the hood
the regular SSL PKI is still there.
-------------------------------------
Has anyone been thinking about providing tools to allow users to cope
with key compromise - or more generally, to manage key retirement etc?

atm, if you suspect that your keys may be liable to compromise then
what would you have to do?  You'd have to create a new wallet (on a
new computer?  or is it easy to have two coexisting installs on one
computer?)  And then you'd have to make one or more payments from the
old wallet to the new wallet, to transfer the coins.  It's a pain, and
you've lost your address book, your transaction history, etc.  And
unless you keep the old wallet about, too, you're a bit stuck if
someone makes a payment to one of the old addresses.  It's something
that most users would baulk at unless they're really sure they're at
significant risk.

Of course, there are a spectrum of scenarios, ranging from having an
unencrypted wallet stolen by someone who knows what it is, through to
deciding that the passphrase you used to use when you only had a few
dollars worth of BTC maybe isn't good enough now you've got tens of
thousands of dollars worth of coins.  Or maybe you have no reason to
suspect there is a risk of compromise, but just have a corporate key
management policy that recommends retiring keys after a period of
time.

What would be really nice is for bitcoin to have a big key compromise
button, which would automatically transfer all coins to newly
generated addresses (optionally with a pause between generation and
transaction - to allow for a new wallet backup).  Optionally, too, the
compromised/retired addresses could be marked with a flag such that if
someone sends coins to that address bitcoind immediately generates a
transaction to transfer the coins to address(es) which are good.

I know deterministic wallets have many proponents - but personally I
like having a bag of keys - with the idea that over a period of time,
old keys will routinely be retired and their balances automatically
transfered to newly generated keys.  If someone really manages to
crack the passphrase on that 10-year-old wallet backup they got hold
of, then if would be nice to minimise the damage they could do...

And, of course, I want a big panic button that allows me to
automatically transfer all my coins to new addresses ASAP if I
suddenly do something stupid, like accidentally type my passphrase
into my IRC window :-)

Thoughts?  Is this functionality that there is any interest in
developing within the official client?  If there is any interest in
this then obviously the first step would be to specify exactly what
functionality is wanted...

roy


-------------------------------------
There have been proposals to use the blockchain to establish
"identities". firstbits is a simple example. I would like to announce a
project that extends this idea to turn the blockchain into a "root CA"
that can sign arbitrary certificates. The purpose is to use these
certificates in the payment protocol, where some might consider
traditional centralized root CAs unsatisfactory. 

Code is here: https://github.com/bcpki

Technical specification and full-length examples are found in the wiki.
I therefore spare myself from repeating the details here, even though,
of course, discussion about those details is welcome on this list.

Excerpt from README.md follows:

First, we have drafted a quite general specification for bitcoin certificates (protobuf messages) that allow for a variety of payment protocols (e.g. static as well as customer-side-generated payment addresses).
This part has surely been done elsewhere as well and is orthogonal to the goal of this project.
What is new here is the signatures _under_ the certificates.

We have patched the bitcoind to handle certificates, submit signatures to the blockchain, verify certificates against the blockchain, pay directly to certificates (with various payment methods), revoke certificates.
Signatures in the blockchain are stored entirely in the UTXO set (i.e. the unspend, unprunable outputs). 
This seems to make signature lookup and verification reasonably fast: 
it took us 10s in the mainnet test we performed (lookup is instant on the testnet, of course).

Payment methods include: static bitcoin addresses, client-side derived
payment addresses (pay-to-contract), pay-to-contract with multisig destinations (P2SH)

Full-length real-world examples for all payment methods are provided in the tutorial pages.
These examples have actually been carried out on testnet3.

For further details and specifications see the wiki.

timo hanke


-------------------------------------
On Mon, Aug 19, 2013 at 4:33 PM, Warren Togami Jr. <wtogami@gmail.com> wrote:

The internal miner is still actively used for testnet, here.

-- 
Jeff Garzik
Senior Software Engineer and open source evangelist
BitPay, Inc.      https://bitpay.com/


-------------------------------------
You can prove ownership of a private key by signing a challenger-generated
nonce with the public part and giving the signature back to the challenger
- same as with any asymmetric crypto system.

As I already noted, the payment protocol is designed to solve that problem.
You could design a BIP that extended the payment protocol to include
information about the person who generated it.


On Tue, Sep 17, 2013 at 11:30 AM, Wendell <w@grabhive.com> wrote:

-------------------------------------

Correction:
bitcoin:[<label>/]<address>[:<amount>][;[<label>/]<address>[:<amount>]][?message=<message>]



-------------------------------------
A part of my reason for sending this email was a quick discussion I had 
with Gavin at the BitCoin conference.  I was under the strong impression 
that double spend notification was something he approved of and was 
considering implementing himself.

In the case of a double spend, If the receiving end gets a timely 
notification (few seconds) it isn't that important that any one of the 
two (or more) transactions is chosen over another.  The receiving side 
can treat a double spend as a failed transaction as it should be proof 
that the buyer is acting maliciously or has had their private keys 
compromised.

I am aware Peter Todd has implemented replace by fee and is operating a 
node on testnet doing this.  I think he is rightly pointing out that the 
current behaviour of dropping all second spends is based largely on the 
good will of nodes and can absolutly contradict the perceived self 
interest of those running miners.  Accordingly relying on this behaviour 
can be precarious. It was from reading his emails to this list or 
bitcointalk that I recognized how essential it was to not transmit the 
second transaction if double spend notification had any hope of being 
worth much.

This is controversial because reliable 0-conf transactions are desirable 
but as you said there really is no way to ensure significant integrity 
in a decentralized way.  Replace by fee would make what transactions get 
into blocks more predictable and eliminate any expectation of reliable 0 
conf transactions.  The question is if this consistency is a better 
choice than a double spend notification that is far from perfect but 
today its still useful and in practice can probably be trusted as much 
as credit cards.

A more strict version of replace by fee could be implemented that only 
replaces transactions with ones that don't reduce any output quantity 
and accordingly require introducing a new input.  This would allow 
increasing transaction fees on a transaction without hurting someone who 
trusted a 0 conf transaction.  This seems like feature bloat to me but 
it wouldn't reduce 0 conf integrity.

Unfortunately, I don't see a way to make everyone happy on this issue.  
Though, I expect everyone would either prefer double spend notification 
or always replace by higher fee over what we have now.

- Quinn



On 05/20/2013 07:24 PM, Robert Backhaus wrote:

-------------------------------------
Here's a quick update on where we're up to.

Thanks to Matts excellent work, I was able to test his bitcoinj and
bitcoin-qt work together today. There are a few minor tweaks needed,
but I feel like we're maybe a week away from having all the code in a
mergeable state. Here is the remaining work:

- There are a couple of bugfixes needed on the bitcoinj side: the
fallback to downloading full blocks is problematic and needs to be
deleted, there's an API change we want

- Adjust the default FP rate requested by BCJ to be 0.0001, this is
appropriate for the latest blocks in the chain and yields 0-5 false
positives per block

- Introduce a new part to the filter protocol that allows clients to
control auto-expansion. This turned out to be very volatile, we saw
jumps from 0-3 FPs per block to 500 in the space of 1 block, perhaps
if a SatoshiDice transaction got into the filter. A simple yes/no flag
can suffice for now, but a better solution would be for the client to
submit templates for output scripts that would trigger auto-adding the
matched outpoint - autoexpansion is only needed in the case where the
input script doesn't contain any predictable data. For pay-to-address
and P2SH it does, so expansion doesn't help. Matt said he'd hopefully
try to look at this soon.

With auto-expansion disabled, the FP rate adjusted and a bugfix on the
bcj side I was able to sync a wallet using a bloom filtered chain.

Although it's tight, I think this work should go into 0.8 - it'll be
much more compelling to advertise it this way, we can say "Upgrade to
0.8 and help network performance for everyone". And in the case that
we discover a showstopper problem, we just don't deploy the code that
uses the new messages into clients.


-------------------------------------




________________________________
Message: 6
Date: Thu, 22 Aug 2013 17:30:13 +0200
From: Wladimir <laanwj@gmail.com>
Subject: Re: [Bitcoin-development] Proposal: remove "getwork" RPC from
 bitcoind

Message-ID:
 <CA+s+GJC4o5V5p+FY+bgWVUt5umebn4_37bTihfX2q1GF05S=VA@mail.gmail.com>
Content-Type: text/plain; charset="utf-8"

On Thu, Aug 22, 2013 at 3:33 PM, Mike Hearn <mike@plan99.net> wrote:


There is some consensus that when the internal miner is to be removed, a
simple miner should be packaged with the main repository as separate
program (the "reference miner"?). The only change is that it does no longer
need to burden the core code
(see also the discussion here: https://github.com/bitcoin/bitcoin/pull/2917).


Wladimir
__________________________________________________________
I see no burden to the code when it is not mining, if that is what you mean by
burden. The miner code's hashes/sec are a function of how much CPU time it 
gets. When I am gcc compiling, I see the hashes/sec drop, but bitcoind keeps 
up easily side by side with http://blockchain.info/ latest transactions and 
new blocks. And I only have a single core AMD Athlon 1.8GHz cpu.

I would hate to admit how many browser windows and tabs I have open too,
and an IDE (LOL)!I will admit that I have modified the miner code a little, 
to use (potentially) every allowable nonce and to check for a new block 
in a timed fashion and be less aggressive, 8 bytes of 0 instead of 4, in checking 
for a potential solution. 

Ron
-------------------------------------
On Sun, Jul 14, 2013 at 07:05:26PM +0000, John Dillon wrote:

Small comment: the current implementation in the reference client uses a custom
script encoder for the UTXO database, which stores every (valid) send-to-pubkey
as 33 bytes and every send-to-pubkeyhash or send-to-scripthash as 21 bytes.
So for "standard" address payment, there is no storage impact of using P2SH
instead.

-- 
Pieter



-------------------------------------
I too would be against the foundation taking control of hosting or the
domain. I have no reason at this time not to trust them, by checks and
balances are a good thing.
On Dec 8, 2013 12:29 PM, "Mike Hearn" <mike@plan99.net> wrote:

-------------------------------------
On Tue, Mar 12, 2013 at 11:10:47AM +0100, Mike Hearn wrote:

I'm sure if "mass node death" becomes an issue miners will have plenty
of incentive to temporarily, or permanently, setup some high-memory and
high-bandwidth nodes to accept transactions. The DNS seeds sort by
reliability so it won't be long before nodes are connecting to them.

My home machine has 16GB of ram, bigger than the whole blockchain.

-- 
'peter'[:-1]@petertodd.org
-------------------------------------
Bitcoin's volatility is not a symptom of its architecture, but a reflection
of the collective knowledge of its future acceptance. Currently that
knowledge is based on very volatile sources: how some senator feels about
it this morning, which direction departments in the Chinese government are
leaning. The issue is that proof-of-work is missing from society's end. As
time goes on, laws, regulations and policies will start to form, people
will challenge them, they will be reviewed and updated, they will be
challenged again on different grounds, re-reviewed, and so on. Each of
those confirmations will make it that much harder to change earlier
confirmations. It won't matter anymore what some senator thinks this
morning because she will have months of hard-work ahead of her before she
can affect any change. It also doesn't matter if the rulings are positive
or negative, just having them will add stability to Bitcoin at some value
between $0.0001 to $100,000 per coin.




On Tue, Dec 10, 2013 at 4:38 AM, Jorge Timn <jtimon@monetize.io> wrote:

-------------------------------------
Hi Alan,

What you describe in the ultimate blockchain compression I have already
coded the authenticated datastructure part of in libcoin
(https://github.com/libcoin/libcoin) - next step is to include a p2pool
style mining, where a parallel chain serves several purposes:
1. to validate the root hash at a higher frequency than the 10 min
2. to enable distributed mining, easily (part of libcoind)
3. to utilize the soft fork by defining the root hash in coinbase blocks
as v3 and once we cross the limit all blocks are v3.

I will have a closer look at you bitcoin talk post to see how well my
approach and ideas fit to yours.

Michael

On 20/5/13 08:34 , Alan Reiner wrote:



-------------------------------------
On Fri, Oct 4, 2013 at 1:35 PM, Peter Todd <pete@petertodd.org> wrote:

On that note, this 2003 example of an attempt to backdoor the Linux
kernel is pertinent:

http://lwn.net/Articles/57135/

The backdoor in question came down to a single missing character,
easily overlooked by a reviewer if a spotlight hadn't been thrown on
it for other reasons. Compromising a Bitcoin implementation isn't
going to be as easy as that, one would hope, but certainly it seems
only a matter of time until there's an attempt at it.

Following these code review discussions with much interest.

-- 
Arto Bendiken | @bendiken | http://ar.to/


-------------------------------------
On Mon, Aug 19, 2013 at 2:13 AM, Peter Todd <pete@petertodd.org> wrote:



Well, I'm glad we're making progress towards this kind of model :)

If I had to write a scoring function for node importance, I'd start by
making nodes I connected to more important than nodes that connected to me.
That should prevent the kind of attacks you're talking about. You can then
score within those subsets with greater subtlety, like using how long the
connection has been active (or extending that with signed timestamps).

This doesn't have any in-built bias against SPV nodes, which is probably
very hard to technically implement anyway. But it encodes the intuitive
notion that nodes I selected myself are less likely to be DoS attackers
than nodes which connected to me.

But the trick is to implement the prioritisation code. The usual way to do
this is to have a thread pool that pops requests off a queue. You can
either have multiple queues for different priority bands, or code that
locks the queue and re-orders it when something new is added. I tend to
find the multiple queues approach simpler, especially, it's simpler to
export statistics about that via RPC that make it easy to understand what's
going on underneath the hood.

So IMHO a patch to address I/O exhaustion should look something like this:

   1. Add a thread pool of 2-3 threads (to give the kernel room to overlap
   IO) which take in CBlock load requests and then do the load/parse/filter in
   the background.

   2. Each thread starts by blocking on a counting semaphore which
   represents the total number of requests.

   3. The network thread message loop is adjusted so it can receive some
   kind of futures/callbacks/closure object (I guess Boost provides this,
   alternatively we could switch to using C++11). The closures should also
   have the score of the node they were created for (note: score not a CNode*
   as that complicates memory management).

   4. At the start of the network loop a thread-local (or global) variable
   is set that contains the nodes current score, which is just an n-of-m score
   where M is the total number of connected nodes and N is the ranked
   importance. At that point any code that needs to prioritise nodes off
   against each other can just check that variable whilst doing work. The
   network loop looks at which file descriptors are select()able and their
   scores, which closures are pending execution and their scores, then decides
   whether to handle new network data or run a closure. If there is a draw
   between the scores, closures take priority to reduce memory pressure and
   lower latency.

   5. Handling of "getdata" then ends up calling a function that requests a
   load of a block from disk, and runs a closure when it's finished. The
   closure inherits the nodes current score, of course, so when the block load
   is completed execution of the rest of the getdata handling takes priority
   over handling new traffic from network nodes. When the closure executes, it
   writes the loaded/filtered data out over the network socket and deletes

The function that takes a CBlockIndex and yields a future<CBlock> or
closure or whatever would internally lock the job queue(s), add the new
task and then do a stable sort of the queue using the scoring function,
which in this case would simply use the node score as the job score.

It's a fair amount of work, but should ensure that "good" nodes outcompete
"bad" nodes for disk IO. Any other disk IO operations can be done in the
same way. Note that the bulk of LevelDB write work is already handled on a
background thread. The foreground thread only writes a log entry to disk
and updates some in-memory data structures.
-------------------------------------
On Sun, Apr 14, 2013 at 05:26:37AM +0000, Luke-Jr wrote:

Sure, which is why I have the header byte so that when we do come up
with a chain of keys thing, that in turn can get it's own magic number
allocated.

FWIW I have an application now where a multisig signmessage would be
useful.

-- 
'peter'[:-1]@petertodd.org
-------------------------------------
I think this US/other cultural issue is complicating things more than we
appreciate.

I am trying to imagine in my head how all this will work and what it will
look like with allow_fee, and I just can't see it. Merchants want customers
to pay the sticker price, deviance from that social norm is extremely rare
even after the credit card company contracts that required it have been
invalidated. The only time it happens to me is when buying flight tickets
with credit cards: but it's only for that method, other payment methods are
still treated as "free" a.k.a interior fees.

If you walk into a physical shop and try to pay a large bill with bags of
pennies, the merchant won't enter into a complicated agreement where they
agree to split the cost of processing with you. They will just reject the
payment out of hand and tell you to get real. It has to be that way because
otherwise the shop would carry the cost of counting all the pennies and
hauling them around, not the buyer (who "knows" he put the right number of
pennies in the bags).

As a buyer, I do not care about whether my transaction will confirm. If I
try to pay with dust, there is no incentive for me to attach a higher fee
than allow_fee to make that confirm, especially if the merchant has no way
to reject the payment. What's more, as Jeremy points out, no clean fail
mechanism means large piles of manual work and lots of disputes due to
payments not clearing before the exchange rate shifts and other things like
that.

Trying to make the success of payment confirmation a two-person dance seems
to have so many edge cases it makes my head hurt. For most pay-to-merchant
cases, it has to be the receivers job to get a transaction confirmed, and
if the sender doesn't follow the instructions a payment should hard fail
and require trying again. If Bitcoin-Qt can't handle that today, that does
seem like a problem.

In the case of a transaction with too-low fee, either the payer can


You can't do that. When a tx doesn't have the right fee attached you're out
of luck today, except for the fact that some pools run with a custom child
pays for parent patch. So respending it would bump priority for some miners
and not others.
-------------------------------------
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256

It's been pointed out recently how a fairly cheap attack on the Bitcoin network
would be to take advantage of the fact that we limit the number of incoming
connections, but don't require anything of those connections. This means an
attacker can simply repeatedly query the the DNS seeds for new addresses and
make enough incoming connections that those nodes can not accept further
clients. nMaxConnections defaults to 125, and beyond that there is the limit on
file descriptors, as well as possible limits by stateful firewalls. (how much
memory/cpu does an incoming connection require?) The DNS seeds themselves crawl
the network on your behalf, and let you direct the attack starting at the nodes
new SPV clients are most likely to connect too.

The cost to the attacker is minimal, 1 INV message per transaction and block,
and some gossiped peer addresses.  Currently that should be on the order of 30
bytes a second. The attacker can do even better by pretending to be an SPV
client, thus reducing their incoming bandwidth consumption to nearly nothing,
yet increasing resource usage on the node.

Peter estimated you would need just 200 or so well distributed IP addresses to
make it impossible to use an SPV client. In fact as far as I can tell for
incoming connections we don't force incoming connections to be well
distributed, so the attack could be done by simply one server with enough
amount of bandwidth. Estimates of the total number of nodes out there on
mainnet are in the tens of thousands, let's say 25,000 for arguments sake. 125
connections to every one of those nodes would only cost the attacker 94MB/s of
incoming bandwidth, easily attainable by a few cheap EC2 nodes, and on EC2
incoming bandwidth is free. The SPV version of the attack would let the
attacker spend as little as they wished.

Obviously if we want to make it possible for SPV nodes to reliably connect to
the network we need to give them a way to prove they have sacrificed some
limited resource to allow nodes to distinguish legit users from attackers.
Failing that, we need to make attacks sufficiently expensive to discourage
bored script-kiddies, much the same way flooding the network with transactions
is sufficiently expensive due to fees that such attacks are impractical.

Now something to keep in mind is whatever we ask SPV nodes to sacrifice must
not be reusable. For instance proof-of-stake *doesn't* work without consensus
because an attacker can reuse the proof for multiple connections. Similarly IP
addresses don't work, requring incoming connections to be "well distributed" in
IP space isn't a bad idea, but it doesn't buy much DoS resistance. Fees paid by
confirmed transactions do work, but only if something links the transaction to
the specific connection.

We also want whatever the nodes to sacrifice to be something not much more
costly to the client than to the attacker. Bandwidth isn't reusable, but an
attacker with EC2 or a botnet has vastly lower costs for bandwidth than a user
with an Android wallet on a phone.


For a non-SPV-mode client we can easily do anti-DoS by requiring the peer to do
"useful work". As the incoming connections slots get used up, simply kick off
the incoming peers who have relayed the least fee-paying transactions and valid
blocks, keeping the peers who have relayed the most. We can continue to use the
usual, randomized, logic for outgoing peers to attempt to preserve the
randomized structure of the bitcoin network. Without an ongoing attack nodes
making new connections are unaffected, and during an attack new connections are
made somewhat easier by the increased numbers of incoming slots made available
as the attackers connections timeout.

Yes an attacker can simply relay some high-fee transactions to keep their nodes
from being kicked off, but in that case are they really an attacker? I reject
the argument that we are letting them de-randomize the structure of the network
because as I've shown they can already do that with little expenditure.


For SPV nodes again in the absense of an attack such anti-DoS code has no
effect. When an attack is launched the SPV client can simply create some
high-fee transactions with their own coins to get connection priority. SPV
nodes already have serious privacy issues, so I don't see the creation of
transactions as a big deal. Re-use is an issue, but nodes can take into account
how long it takes for another nodes to advertise the transactions when dealing
with SPV peers. Better systems can be implemented later, such as micropayment
channels and coinbase probabalistic payments, that don't result in blockchain
transactions just for the sake of anti-DoS.


A demo of the attack against would be useful. Pieter Wuille's bitcoin-seeder
code could probably be re-used as it already has the required functionality of
making large numbers of connections. In fact, simply running multiple instances
of it could do the trick.
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBCAAGBQJR4yHgAAoJEEWCsU4mNhiPRvkH/3fl5brCe+1cBUoFtAnVHV+0
dezNeXo+nAbDg8XCkF6cmFkDBSgTj8l2iy0N1pfCq1XDXmqfM5p+CtxIBuIwwURc
KnpwNnRwoQ0JKYFonmaM0rQgOcXnRvyNq2DVL/b/fA6X3I5nignWNFDtzpvFhM+J
IjhEVbu5S25c+O8LFlJV0ujjBgnR/8gJ0xV2fvdsaisAVHly1n9QWa1FEnMz7hp9
wfXPBh8tnehKnsspyeAEq5Yc/Yyow97CdwOqPVknI0rhes0OWR8ORcJ2NkBZm/Pn
rUFFMwAme/K1f3PqW1+EpM4gG/pJvg+xU5E5KdqgnjsQLoEGWtMcxEdAeCoBuNI=
=jzfg
-----END PGP SIGNATURE-----


-------------------------------------
On Mon, Dec 9, 2013 at 4:42 PM, Drak <drak@zikula.org> wrote:


Yes, it is.

Wladimir
-------------------------------------
On Tue, May 14, 2013 at 5:25 AM, Adam Back <adam@cypherspace.org> wrote:

That evaluation largely depends on the needs of the service in question.

In my decentralized identity (SIN) example, you merely need to prove
to the cloud that you sacrificed some bitcoins to any-miner.  The
confirmed, in-chain, non-coinbase transaction becomes the root node
for off-chain identity data.

The penalty for the user withholding the sacrifice transaction is that
their SIN is not created.  That incentive may not exist in that way,
in another service.


Just referring to a standard, fee-bearing, user-created bitcoin
transaction, where output_value < input_value.  The fee is paid to the
first miner who includes that transaction in a block, as part of the
protocol.

-- 
Jeff Garzik
exMULTI, Inc.
jgarzik@exmulti.com


-------------------------------------
Wow there's a lot here to think about. I'm pretty sure I haven't grasped  
the full implications yet.

I see it proposes to also introduce additional BIPs describing the use of  
the data stucture for stateless validation & mining, the UBC address index  
for "SPV+" operating modes, document timestamping and merged mining.

Can the BIP stand alone as a BIP without some specific changes to the  
protocol or end-user accessible features defined within it? It seems like  
an extremely useful data stucture, but as I understand it the purpose of  
BIPS is defining interoperability points, not implementation details?

Unless the tree itself is becoming part of the protocol, seems like its  
spec, test vectors, and reference implementation can live elsewhere, but I  
would love to read about BIPS which use this tree to accomplish some  
amazing scalability or security benefits.




-------------------------------------

Yeah, OK. Let's see how much progress Gary makes. Supporting HD wallets is
the trickiest part and I don't know how much time I will have - the Android
RNG issue and getting bcj 0.10 released have sucked up a lot of my time
lately and I need to refocus on other things for a bit. But between the guy
who volunteered to do payment protocol, and Gary doing TrezorJ, and Matija
already having done the core algorithms, I'm hoping the only parts I'll
have to do are integrating the HD code with the core wallet code. Possibly
if we're running out of time I can do a real basic HD wallet implementation
that only iterates a key once and doesn't generate new keys for each
transaction, as that's really the trickiest part (because of the need for
lookahead/behind and memory bloat on phones).
-------------------------------------
You can cut down the JVM to be a few megabytes if you're aggressive about
it. But for a desktop app I'm not sure it's really necessary these days. A
few megabytes used to make a noticeable difference to success rates but
bandwidth improved a lot since then.

Portability to android is a given, it's already Java based. IOS is a non
starter until apple is convinced to allow wallet apps into the App store,
language is not the issue there.

There is no point manually rewriting bitcoinj to c++ when j2c does such a
great job already. You would want to at last start from what it generates
even if you fork from there.
On 15 Jul 2013 20:19, "Jonas Schnelli" <jonas.schnelli@include7.ch> wrote:

-------------------------------------
On 21 May 2013 01:59, Mark Friedenbach <mark@monetize.io> wrote:


This is essentially name spacing.  As registries grow namespaces become
more important.  In bitcoin's quest for decentrality there's also the
question of who maintains the registry.

Some out of band algo/hash could work so long as there was a one to one
relationship between the described object and the UUID.  In this case the
gensis block may not uniquely identify a coin.

The normal way to namespace a registry on the internet is to allow it to be
a URI.  In this case an http style uri has the added bonus side effect that
it can be dereferencable and both human and machine readable.  So yes
something like org.bitcoin.* is good, just simply growing things to http
style uris is cleaner, imho


-------------------------------------
On Sun, Apr 7, 2013 at 10:43 AM, Oliver Egginger <bitcoin@olivere.de> wrote:

Many new users have started using the reference client which downloads
the whole blockchain from peers. There currently isn't a throttling
mechanism [1] so it's possible to quickly eat up your bandwidth. You
can try QoS on your router or use the -nolisten command line flag. You
will still relay transactions, just not serve the whole blockchain.

[1] https://github.com/bitcoin/bitcoin/issues/273


-------------------------------------
It needs people to use either a dedicated app or a wallet with the right
features. I've gone back and forth on whether it's better to have wallets
become featureful things or to have lots of separate apps. There are pro's
and con's to each.

Fortunately bitcoinj makes bringing up a new GUI wallet app quite easy
(well ... if you're writing it in java ;). So having a dedicated app just
for managing your pledges is quite straightforward.

At that point it's about contracts programming:

https://code.google.com/p/bitcoinj/wiki/WorkingWithContracts
-------------------------------------

On 2013-10-19, at 4:21 PM, Jean-Paul Kogelman <jeanpaulkogelman@me.com> wrote:


That would be 2013. sorry.

-------------------------------------
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256

On Thu, Jun 27, 2013 at 6:41 PM, Gregory Maxwell <gmaxwell@gmail.com> wrote:

Possible non-validation data that can be usefully propagated:

1) Block headers.

2) *Confirmed* transactions linked to an aformentioned blockheader.

3) Proof-of-work/sacrifice limited P2P messages, for instance to
co-ordinate trust-free-mixes or act as a communication channel for
micropayment channels.

4) With UTXO existance proof support propagate transactions
accompanied by proofs that all inputs exist. This would also allow for
implementation of Peter's low-bandwidth decentralized P2Pool proposal.

5) UTXO fraud proofs. (one day)


Strictly speaking #2 doesn't even need the protocol to be changed
actually as it can be handled entirely within the existing INV/getdata
mechanism. Sure someone could throw away a lot of hashing power and
get an invalid block propagated, but really so what? SPV nodes should
always take confirmations with a grain of salt anyway.
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBCAAGBQJRzWx8AAoJEEWCsU4mNhiPlTkIAJKzFsT65o6LoU70hbaBsu3g
aBdjYZSCnJ9+qWI2tqqUBedq2etbt71hAfWNnTXvFus+0iVB1HWJClW155319vuH
Xi1m9G3O0NzX1d+cssMPxFBHsl4Rz6XYICrYyVEe2X554Zawdg6I53+1INHRfsBT
1vmq5Bxgopt0Tk9Vf8HNdRt/IXZJaPYm1PEzJHFppuOvl5+Fpypy3t/QXdsP8puP
LnRdL7Bxfu3BSWrSRZo7l5Fpww3Y/vdNYCL4jDD/ME+36wi4CUM3psL8lsk81lB4
3t/ytF4y/adT/dEEtMj7BGWS0TIMMH0NyeCjqBdStiQsVfoowLCVfpuDzouZ6yY=
=TI1m
-----END PGP SIGNATURE-----


-------------------------------------

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1


On 7/23/13 3:29 AM, Andreas Schildbach wrote:
Anyone who wants HTTP authentication or TLS can wrap it with nginx, or
something similar. In the process they could put appropriate
restrictions in place on incoming requests, and the onus would be on
them, not us to keep it secure.

Mark
-----BEGIN PGP SIGNATURE-----
Version: GnuPG/MacGPG2 v2.0.19 (Darwin)
Comment: GPGTools - http://gpgtools.org
Comment: Using GnuPG with Thunderbird - http://www.enigmail.net/

iQIcBAEBAgAGBQJR7ttWAAoJEAdzVfsmodw4UmIP/36lK2TDc7mLTT8rbflJhl3v
TL4CFKhXj6OuzG7tyino3Djs4EQnyk+CbpfOmJ8kYr29GPaZttuDJhYXtJqQBQCi
DPq79ktudHnVMLPirEs7dUrLo+TAqhYX+8Sj+eTlW+p6YZg3JbkOAIPJG7597OK4
zzU8Oxr0XKJFfGscKfkPThxJboNqzJYGl3otHUMXM4HsbIRYmrx4QSr8y7dsVgTd
YZnD4bJO+eY4ZPzCcFdkPD/8bXQyKC5nPOH8/79lARNLESwB4OW79uf9q86EuH2O
jZQ1qwpRNHblrNWS1/U2E4+7hEidvgZBwQhj+HbWgKiPWh4Df1lEXq6bLQQwdn6/
b+jfiwg7xpb7eB2M4gPZ0uF/1TIcGJN3+LWEULFNTT/vsjyD/UU63ahZ1kVv7X0m
W1NrbKjXxDbip+x3N7HLIu3zqAAaa0ele7OysyFCL6ZlwwafwJiEZZgHn2Iw7I1L
S7lYBbFoLfXlOMVXNaKHPEV5gQEveMROJVBtnWkqShPQM0N/+Z+TXZes37up0GVo
d7ptPfNbUNDTFc8Jj3+5rIyy3dUvSyMJlHZhsLmtCUnbQ867ZOgeUS52a8XQ+nJY
8IsShLfLk6fRWmHrwo9lzZQ/TbbUNyoUje0Ns6iL7G3IZwDqJH3kAGb/bkj/piDu
tPNcN8bkYeNobTFIH+o4
=jV80
-----END PGP SIGNATURE-----



-------------------------------------
This kind of thing - providing external audits of customer accounts
without revealing private data - would be generally useful beyond
taxation. If you have any solutions, I'd be interested to hear them
(although bitcoin-dev is probably not the right place yet).

Mark

On 9/29/13 2:37 AM, Adam Back wrote:


-------------------------------------
On 10/09/13 23:03, Matthew Mitchell wrote:

I revisited the wordlist and replaced around 67 words that can be
found offensive in some context.

-- 
Best Regards / S pozdravom,

Pavol Rusnak <stick@gk2.sk>


-------------------------------------
There are definitely ways to keep the pay-to address secure even if the web
server is compromised, just perhaps not perfectly clean standard X.509 ways
under the current ecosystem which would be easier for everyone to agree on.

 - If a more trusted cert is an EV end cert, and a less trusted is a DV end
cert (not chained off the EV) then it's easy for the wallet to distinguish
between the two, and they are both valid certs. EV signs pubKey offline, DV
used hot on the web server.
 - If the more trusted cert is an EV or DV end cert, and the less trusted
cert is chained off that end cert, it's technically 'invalid' so again its
obvious which one is more/less trusted, but it's easier for an attacker to
get their own DV end cert for your domain.
 - The third way is getting the pubKey into the cert attributes, such as
encoding the pubKey, or a fingerprint of the pubKey, as a Subject Alternate
Name, so the attacker would need to get their own cert to change the
address, meaning it's not as critical if your cert key is stolen.

On the wallet side, it comes down to additional validation code paths which
get triggered by some detection logic. For example, if you pass PubKey and
InvoiceID in the Payment Request, the wallet needs to know if it should
check for a Subject Alternate Name in the cert for a fingerprint of the
PubKey, how the fingerprint is calculated, and then verify the Address is
indeed PubKey * InvoiceID.  I think falsely rejecting a legacy Payment
Request would get the extra validation code path commented out pretty
quickly.

I really like Mike Hearn's idea of 'You have paid this recipient 4 times'
but also agree completely on the crying wolf due to expiration or
revocation. At least such a message could be based on the domain name only,
to try to prevent phishing with similar domain names, then there's no
expiration issue. Slightly more restrictive would be domain + CA, again not
considering expiration, but pinning the pay count to the CA seems to have
little downside and makes it harder for an attacker to get their own cert
for your domain if you choose your CA 'wisely'.

I assume the ship has sailed on v1, but if we can get consensus on how we
want this to work in the near-term, we can start prototyping it and maybe
get this available sooner than later. In any case we should be confirm v1
doesn't do anything to prevent this from working in a clean, extensible
manor, which I think means prototyping it and seeing the new Payment
Request is handled transparently by v1 code.

Right now I'm leaning towards writing a prototype using a single cert with
a fingerprint of PubKey in the Subject Alternate Name, and getting PubKey
and InvoiceID in the Payment Request.  Gavin, would the best way to work on
this be to just fork your code on Github?

Thanks,
--Jeremy
-------------------------------------
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256

As you all know keeping the size of the UTXO set small is critical, and more
recently we've also had problems with distasteful data being added to the UTXO
set. (http://garzikrants.blogspot.se/2013_04_01_archive.html) Gregory Maxwell
has an excellent solution to the distasteful data problem in the form of P2SH^2
(http://comments.gmane.org/gmane.comp.bitcoin.devel/1996) and Peter Todd
pointed out how we can implement it with the existing P2SH form. We're also
going to be implementing some kind of OP_RETURN <data> soon which handles the
timestamping and similar use-cases, again without UTXO impact.

Right now the only scriptPubKey form with any significant use is the
checksighash. Bare pubkey gets used by the odd miner, and by Deepbit due to
their ancient codebase. The former isn't an issue as the miner mines the txout
themselves, and the latter shouldn't find updating to be a big deal.
OP_CHECKMULTISIG is used by Peter Todd's timestamper, but that can be changed
to OP_RETURN without difficulty. However all that will (hopefully!) soon change
as hardware wallets and the payment protocol make hardware wallets worthwhile,
and we should make sure these protocols take the extra step of using P2SH
before we get locked into a bunch OP_CHECKMULTISIG implementations.

We also have the problem that the IsStandard() code accepts up to 120 bytes of
junk data as a pubkey, allowing injection of 240 bytes of *spendable* data into
the UTXO set with bare OP_CHECKMULTISIG. This capability has to be stopped.

Thus I'm offering a reward of 1BTC for whomever creates a patch to change
IsStandard() to accept only P2SH and pubkeyhash in a raw scriptSig, allowing
other forms only when used with P2SH. I'm offering a further 1BTC to whomever
gets such a patch accepted into mainline. It's a pretty easy patch, so I'm
asking that all core-developers (that includes you Peter) hold off for one week
to give less experienced developers a crack at it. If for some reason you want
to remain anonymous that is ok by me as well provided you assign copyright to
me. I do expect unittests. Should be about half a day to a days work.

Long-term we should be using P2SH with an inner OP_CHECKSIG for most addresses
as it's a 1 byte savings. Change addresses can have this done first, although
bitcoinj support will help so that satoshidice and similar sites can pay to
P2SH change. As for multisig's P2SH overhead for a 1-of-2 and 2-of-2 and
3-of-3, is 10%, 8.6% and 6.2% respectively, all pretty minor, especially if you
assume the blocksize limit will be raised.
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBCAAGBQJR4vX+AAoJEEWCsU4mNhiPg/EIAKWFaMsugbY4zZ+dpgnaTcUr
D1ZnY5PogETVqcwuXdVdHe2zCUcBhejsBe8ic9vp8OnttXTxo8uXJp9xBuq9VYBN
vXMyGKtxacLL5WS5ShAWnWS47xLf9wnKCJSGX0nqaETIQEUgqCMjTGspZNOpC9W0
fKBIDi4cZbpXn1EQx45v9vplZhFg+vBQV/Ia2/5rjZLPFvdqZoSBruOVTB/X2SDU
Hq36DQkRFblp/s3Ktv9c3yUQ8HocRIXD8jKRsE+uCNfEeI2b9oLpPp1cPsOvjveI
McJnHod8EDzxwbm6abK2cxHWBpGmBa5AABsRmQfpJK+u7GDQoPqzfJ68M1otZjk=
=uP4n
-----END PGP SIGNATURE-----


-------------------------------------
On 2013-10-19, at 1:40 PM, Gregory Maxwell <gmaxwell@gmail.com> wrote:


I have a question regarding this part. I wrote a BIP for base 58 encoding / encryption of BIP 32 root keys. The BIP page states that we shouldn't add to this list ourselves, but should contact you for a BIP number. I have contacted you a couple times on bitcointalk for a BIP number, but haven't received a response (or do those requests explicitly have to go to your email address)? 

Proposal in question: https://bitcointalk.org/index.php?topic=258678.0


Cheers,

jp

-------------------------------------
On Tue, Jul 23, 2013 at 7:35 PM, zooko <zooko@zooko.com> wrote:

Bummer, because this was a explicit consideration while writing it and
a concern several people had with the initial draft Mike did.

We're very much aware that upstreams frequently cry (wolf) at the
mutilation of their unique and precious snowflake.

The intention was that second paragraph acknowledging the many good
motivations for the existing norms and the third paragraph talking
about consensus systems would address these concernsâ€” showing that we
aren't totally clueless, and pointing out that we have an actually
unusual situation. In intermediate drafts they were longer and more
elaborate, but we were struggling against length and trying to avoid
delving into a highly technical discussion which would lose anyone who
wasn't already very interested.

We also compromised on an initial approach of "please don't package
this at all" to "please understand first", in part at the protest of
our gentoo package (which also bundles leveldb but hard locks it to an
exact version in the package system with exact build flags, which is a
sophisticated compromise which might not generalize to other
distributors) maintainer (uh, Luke-Jr, not exactly the most
representative sample).

As a first step it's at least important to know that there is a
concern here shared by a bunch of people. Helping talk people through
understanding it is part of the job here.  I certainly didn't expect
the discussion to stop with the letter but getting it out there is a
way to start the discussion and make it more likely that we have it
again with the next packager who comes around.

I guess the first priority though is avoiding gratuitously offending
people.  Can anyone point out any specific tweaks that would reduce
initial bristling?

On Tue, Jul 23, 2013 at 6:45 PM, Douglas Huff <dhuff@jrbobdobbs.org> wrote:

Oh be nice. If any of this were easy it would all be _done_ already. :)

There is naturally some tension when people with different priorities
and backgrounds interact, ... I've seen a lot of upstreams run into
disagreements with packagers the result is usually better for
everyone.


-------------------------------------
I think the right way to integrate BIP32 and BIP70 would be to specify
output scripts as normal for backwards compatibility, and then allow each
output to have an additional xpubkey and iteration count field. The
iteration counts could be unsigned.

Unfortunately to add data that isn't signed requires a backwards
incompatible change to the protocol :( There isn't currently any area that
isn't covered by the signature. We would have to add one, and then have a
matching array of iteration counts for each xpubkey that was specified in
the output.

I wonder if we should make a last minute change to BIP70 before wallets
have shipped and merchant support starts, something like

message PaymentRequest {
  optional byte unsigned_data = 6;
}

that would be deleted like the signature is before reserialization.



On Thu, Dec 12, 2013 at 9:28 AM, Paul Rabahy <prabahy@gmail.com> wrote:

-------------------------------------
Now-merged pull request #2702 appears to have put the master branch on an 
unofficial Ripple fork of LevelDB, rather than merely updating us to LevelDB 
1.12.0. While Vinnie did somewhat disclose this, I don't see any evidence the 
nature of this was fully understood by others. As I understood the pull 
request, the "Ripple and Bitcoin fork" was just LevelDB with the changes we 
had already made. Mike's comments on the pull request (his audit) suggest that 
this may have been the case in an earlier revision of it. But in fact, there 
appear to be a number of other changes included in what was finally merged a 
few weeks ago. Furthermore, Ripple's fork did not do a proper git merge of 
upstream, thus there is a break in git history, and, more importantly, a 
number of upstream fixes (including some we have had reported to the Bitcoin 
issue tracker) were not included in this merge.

I've pushed three branches to https://github.com/luke-jr/leveldb :
  bitcoin-1.5   Our old/unreleased LevelDB 1.5 fork, for reference
  bitcoin       Our LevelDB 1.7 fork, included in 0.8.x
  bitcoin-up    Our LevelDB 1.7 fork, merged with upstream LevelDB 1.12

A diff from current master (Ripple LevelDB 1.12 fork) to bitcoin-up:
  https://gist.github.com/luke-jr/6248543

Thoughts?

Luke
-------------------------------------
On Tue, Nov 5, 2013 at 1:07 PM, Alessandro Parisi <startithub@gmail.com> wrote:

That is quite ignorant.  Bitcoin is far more complex than standard IT
security "fix ASAP" mantra.  Distributed consensus is a new field of
computer science, and blindly applying standard logic to bitcoin will
quickly result in large problems.

Every fix has the chance of changing the game theory or economics of
bitcoin.  A change to the core consensus protocol within bitcoin --
mining -- is even more game-theory- and economically-critical to the
core system.  Changes thus have more impact, where any change
potentially reduces bitcoin's value to zero in the worst case.

Bitcoin is akin to medical device or avionics software.  We cannot
just change at will, without significant research, analysis and
testing.   "It is a bug, it must be fixed ASAP" is ignorant and
dangerous.

Further, this is at present a THEORETICAL problem, and the solution
presented has some obvious flaws, that would make our current, WORKING
SYSTEM more fragile, and less secure.

-- 
Jeff Garzik
Senior Software Engineer and open source evangelist
BitPay, Inc.      https://bitpay.com/


-------------------------------------
Modern Java versions let you bundle the app with a stripped down JVM. I
don't know if Jim does that, but I think it's an obvious step towards
making MultiBit friendlier and easier to use.

BTW I believe most secure browsers (Chrome, Firefox) have banned the applet
plugin or severely restrained it anyway. So even if you install the JVM and
plugin together there is not an issue.


On Tue, Jul 9, 2013 at 3:20 AM, Caleb James DeLisle <
calebdelisle@lavabit.com> wrote:

-------------------------------------
On Sun, Apr 28, 2013 at 6:29 PM, Mike Hearn <mike@plan99.net> wrote:


Sure, that's why eventually several levels may be useful.

Adding new fields to the addr message and relaying those fields to newer

That's a more flexible model, indeed. I'm not sure how important speed of
propagation will be though - it may be very slow, given that there are
100000s of IPs circulating, and only a few are relayed in one go between
nodes. Even then, I'd like to see the "relay/validation" responsibility
split off from the "serve historic data" one, and have separate service
bits for those.



Disconnecting in case something is requested that isn't served seems like
an acceptable behaviour, yes. A specific message indicating data is pruned
may be more flexible, but more complex to handle too.

What is the use case for NODE_VALIDATE? Nodes that throw away blocks almost

NODE_VALIDATE doesn't say anything about which blocks are available, it
just means it relays and validates (and thus is not an SPV node). It can be
combined with NODE_BLOCKS_2016 if those blocks are also served.

The reason for splitting them is that I think over time these may be
handled by different implementations. You could have stupid
storage/bandwidth nodes that just keep the blockchain around, and others
that validate it. Even if that doesn't happen implementation-wise, I think
these are sufficiently independent functions to start thinking about them
as such.

-- 
Pieter
-------------------------------------
I think you misunderstood my statement. If time > 3 days, and after 4
blocks have been mined, then difficulty would be reset.

In theory, one would have to isolate roughly one percent of the Bitcoin
network's hashing power to do so. Which would indicate an attack by a state
actor as opposed to anything else. Arguably, the safest way to run Bitcoin
is through a proprietary dial-up network.


On Sun, Dec 22, 2013 at 7:22 PM, Mark Friedenbach <mark@monetize.io> wrote:

-------------------------------------
I've posted a somewhat blue-skies idea on troll^wBitcointalk that some
here might find interesting:

https://bitcointalk.org/index.php?topic=277389.0


-------------------------------------
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256


100% miner fee is not a proof of anything because the miner could have created
that transaction for themselves. You must have proof that all miners had an
equal opportunity at collecting the fee, and the only way to do that is by
Peter's announce-commit protocol, or his unspendable until after n blocks
proposal.

Also the idea of a zero-output transaction is silly. In almost all cases you
are making the sarifice to link that act to an identity, and linking that act
to arbitrary data is far more flexible than any scheme relying on the pubkeys
that paid for the transaction. With a arbitrary data you can slice up the
sacrifice for instance with a merkle-sum-tree, as well as hide what the
sacrifice was for to preserve anonymity. The extra cost in size of the provably
unspendable OP_RETURN scriptPubKey is minimal for the rare time when it isn't
required.
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBCAAGBQJRrf/BAAoJEEWCsU4mNhiP7+MH/RGfo2k+Zd0VoGzv3KSTzBrM
auK9Do2fYp2YvMnT/JFYbz2MgbTcCiKGyZfxjaH+zrqdTFgkgAE53midIv/Rd5/w
kjjifJuqw5AyIN6ANA1TuLQ64elPOXXymsaMqWO8ou0angG6DBI/LZZEG7SXM7+I
Jwk3MXLhFswvvuRif4G2C9v29WqSj4XRxxl3o63ziSYvZPPCHLYHAL9BJaMpDhaw
LxebM088RofzJAoGL1QIeQhDS3aAK4jKSZtJ/6+fwYZQB2Qc3sa1v9IAcCQHE+M3
6oQY0tzEEFg9+xdnSM7J6pW7qW28nFS8Fdr6UkUUlwhI5c4KnIKCtQa3o1mYDFE=
=SHWS
-----END PGP SIGNATURE-----


-------------------------------------
Hey Peter, something seems wrong with your above analysis: I think a miner
would withhold his block not because it leads to a greater probability of
winning the next one, but because it increases his expected revenue.

Suppose a cabal with fraction q of the total hashing power is n blocks
ahead on a secret branch of that has mined r_tot coins, and let r_next be
its next block's reward.  If the cabal chooses not to broadcast its secret
chain until at least the next block, its expected revenue after the next
block is found is

(1 - (1-q)^(n+1))*(r_tot + r_next)

If it does broadcast, its expected revenue after the next block is found is

r_tot + q * r_next

If the cabal seeks only to maximize immediate revenue, then after a bit of
algebra we find that it will withhold its chain if

q > 1 - ( 1 + r_tot / r_next )^(-1/n)

So if the cabal has just mined his first block off of the public chain,
i.e. n = 1, and if the block reward is relatively stable, i.e. r_next =
r_tot, then it needs q > 50% to profitably withhold, not the 29.2% you
calculated.

withholds again, then he must grow q to compensate for the increase in
r_tot, and any decrease in n.  So generally publication becomes
increasingly in the cabal's interest, and secret chains will tend not to
grow too large (intuition tells me that simulations using the above formula
should bear this out).

This seem correct to you?


On Thu, Nov 7, 2013 at 9:14 AM, Mike Hearn <mike@plan99.net> wrote:

-------------------------------------
Interesting observation, thanks.

I'd think any competent implementation of such an identity scheme would not
involve end users directly handling randomized nonsense words, however. I
always imagined a sacrifice as being a file that you make with a GUI tool
and load into a browser extension.


On Thu, Oct 3, 2013 at 3:35 PM, Daniel Lidstrom <lidstrom83@gmail.com>wrote:

-------------------------------------
anyone tested the secure encrypted p2p email: http://bitmail.sf.net

SVN here:

svn checkout svn://svn.code.sf.net/p/spot-on/code/ spot-on-code

http://sourceforge.net/p/spot-on/code/commit_browser
-------------------------------------
Yes. Someone decided to actually delete the people who had signed so far
and replace it with a request for PGP signing - no. Not everyone even uses
PGP, which is overkill for this anyway.

I'm going to roll the document back and lock it. Sorry, I had hoped people
would respect my request to not fiddle with the content, which they did not
do.

If you'd like to have your name on it, let me know or post here and I'll
add it.


On Tue, Jul 23, 2013 at 10:14 PM, Gregory Maxwell <gmaxwell@gmail.com>wrote:

-------------------------------------
As an FYI, I've sent Wendell and co some example code for how to use CPPJVM
to use bitcoinj from native code. A rather rough Hello World app looks like
this:

https://github.com/mikehearn/cppjvm/blob/master/mytest/bcj-hello-world.cpp

So, fairly C++ like.

Further discussion of this should take place on the bitcoinj mailing list.
-------------------------------------
Hi Jeremy,

The main reason is to stick as close to BIP 0038 as possible, allowing implementers to reuse existing code paths. This proposal and BIP 0032 don't really put any restrictions on content of the seed itself (as can be seen in test vector 1).

jp

On Jul 19, 2013, at 11:09 AM, Jeremy Spilman <jeremy@taplink.co> wrote:

Very clear write-up Jean!

Quick question - what is the purpose of step 10 of the encryption process -- why XOR the master seed with some bytes of the hashed passphrase before encrypting the XOR'd master seed with the remaining bytes of the hashed passphrase? Versus simply encrypting the master seed with the hashed passphrase of equal length to the seed?

Does this basically serve the fucntion of an IV?

Do you really need this since the master seed must be high entropy random bytes in the first place?

Thanks,
--Jeremy

On Fri, 19 Jul 2013 10:46:44 -0700, Jean-Paul Kogelman <jeanpaulkogelman@me.com> wrote:


Hi everyone,

I'm looking for feedback on the proposal below.

Kind regards,

Jean-Paul

---
BIP:Â 
Title: Base58 encoded HD Wallet master seed with optional encryption
Author: Jean-Paul Kogelman
Status: Draft
Type: Informational
Created: 17-07-2013

Abstract

This proposal describes a method for encoding and optionally encrypting a Bitcoin Hierarchical Deterministic (HD) Wallet master seed. Encoded master seeds are intended for use on paper wallets. Each string contains all the information needed to verify and reconstitute an HD wallet except for the optional passphrase. The encrypted version uses salting and scrypt to resist brute-force attacks.

The method provides two encoding methodologies in 3 lengths each (16, 32 and 64 byte seeds). One is a clear version of the master seed with verification information for integrity checking and the other is an encrypted representation.

A 32-bit hash of the resulting master Bitcoin public address is encoded in plain text within each seed record, so in the case of an encrypted seed, it can be correlated to a Bitcoin public address with reasonable probability by someone not knowing the passphrase. The complete Bitcoin public address can be derived through successful decoding and optional decryption of the master seed record.


Motivation

The extended private keys proposed in BIP 0032 are long, fixed length records and don't offer any form of security. The master seed used to generate the HD wallet is typically shorter than the extended master private key that results from it.Â 

A compact representation of the master seed is easier to handle and a 2-factor version of the master seed record allows for safe storage and the creation of paper wallets by 3rd parties.Â 


Copyright

This proposal is hereby placed in the public domain.


Rationale

User story: As a Bitcoin user who uses HD wallets, I would like the ability to store my wallet master seed in a compact form as a paper wallet.

User story: As a Bitcoin user who uses HD wallets, I would like the ability to have a 3rd party create a paper wallet with my master seed in it, without having access to the funds stored in the wallet.

User story: As a Bitcoin user who uses HD wallets, I would like the ability to choose the strength of the master seed depending on my security requirements and how I wish to store it.Â 


Specification

This proposal makes use of the following functions and definitions:

AES256Encrypt, AES256Decrypt: the simple form of the well-known AES block cipher without consideration for initialization vectors or block chaining. Each of these functions takes a 256-bit key and a variable legth of input and deterministically yields output data of similar length to the input.

SHA256: a well-known hashing algorithm that takes an arbitrary number of bytes as input and deterministically yields a 32-byte hash.

RIPEMD160: a well known hashing algorithm that takes an arbitrary number of bytes as input and deterministically yields a 20-byte hash.

scrypt: A well-known key derivation algorithm. It takes the following parameters: (string) password, (string) salt, (int) n, (int) r, (int) p, (int) length, and deterministically yields an array of bytes whose length is equal to the length parameter.

HMAC-SHA512: Produces a 64 byte (512 bit) hash based message authentication code using the SHA512 hash function using a seed (in our case we will use a byte representation of "Bitcoin seed") and an aribtrary input message. The output will be 64 bytes.

Base58Check: a method for encoding arrays of bytes using 58 alphanumeric characters commonly used in the Bitcoin ecosystem.

G, N: Constants defined as part of the secp256k1 elliptic curve. G is an elliptic curve point, and N is a large positive integer.

Prefix

It is proposed that the resulting Base58Check-encoded string start with either "WS" for clear master seed records or "ws" for 2-factor master seed records. The prefixes "WS" and "ws" were chosen as abreviations of the term "Wallet Seed" and upper case to indicate whether it's a clear representation and lower case when it's a 2-factor representation.Â 

To keep the size of the encrypted key equal to the clear version, no initialization vectors (IVs) are used in the AES encryption. Rather, suitable values for IV-like use are derived using scrypt from the passphrase and from using a 32-bit hash of the resulting Bitcoin public address as salt.

Proposed specification

There are 2 seed record representations with 3 lengths each, resulting in a total of 6 different object identifier prefixes.Â 

Prefix 0x1093: Clear 16 byte master seed, total length: 22 bytes
Prefix 0x1E68: Clear 32 byte master seed, total length: 38 bytes
Prefix 0x665A: Clear 64 byte master seed, total length: 70 bytes

Prefix 0x1EE4: 2-factor 16 byte master seed, total length: 22 bytes
Prefix 0x38AE: 2-factor 32 byte master seed, total length: 38 bytes
Prefix 0xBECB: 2-factor 64 byte master seed, total length: 70 bytes

These are constant bytes that appear at the beginning of the Base58Check-encoded record, and their presence causes the resulting string to have a predictable prefix.

How the user sees it: 35, 57 or 101 characters always starting with either "WS" or "ws".

Count of payload bytes (beyond prefix): 20, 36 or 68

Payload format:
4 bytes: SHA256(SHA256(master_bitcoin_public_address))[0...3], used both for typo checking and as salt.
16, 32 or 64 bytes: either a clear representation or an encrypted representation of the master seed.

Range in Base58Check encoding for clear 16 byte master seed (prefix WS):
Minimum value: WSJ5JnjiRZT8b15aZr6GGWzt2VMBPapmhBQ (based on 0x10 0x93 plus twenty 0x00's)
Maximum value: WShQumr1iGdbTpWiesWbb189p7rSLBiq3EJ (based on 0x10 0x93 plus twenty 0xFF's)

Range in Base58Check encoding for clear 32 byte master seed (prefix WS):
Minimum value: WS7SqjMWhDGCagcZxCk317LLWyWUny7465ENGKEKuxBf5sFvRHmRRfCgr (based on 0x1E 0x68 plus thirty-six 0x00's)
Maximum value: WSLAbo8WHEQr1Z1cv26Z5njh5URHMo9fPiDFYE2NpCwmAoPZwDxzm3PjB (based on 0x1E 0x68 plus thirty-six 0xFF's)

Range in Base58Check encoding for clear 64 byte master seed (prefix WS):
Minimum value: WS2cMzM9WrogWVLKYFzTaTXZnYCryY31uptmdevXuRFBXTWJhmt4No9Eejoj3apqyU5RkyXsGHFPbZd14oz7Fv1Mi85kadBD4TPsL (based on 0x66 0x5A plus sixty-eight 0x00's)
Maximum value: WS6PXJ1HoJXn9hyLz8uXQEy2ZajAVaFDTViXhZDthwYbhyvfHRqjwU4FoGpepCbuuycAwMFbgoZB6E48baqD1c9PdMNUZCSSBmfE7 (based on 0x66 0x5A plus sixty-eight 0xFF's)

Range in Base58Check encoding for 2-factor 16 byte master seed (prefix ws):
Minimum value: ws1nyTi9KjdRkJda4Yh1KkXSLC8SZ6kKzEM (based on 0x1E 0xE4 plus twenty 0x00's)
Maximum value: wsR8aSpScSotd84i9a7LeEei7pdhVkeciX8 (based on 0x1E 0xE4 plus twenty 0xFF's)

Range in Base58Check encoding for 2-factor 32 byte master seed (prefix ws):
Minimum value: wsC8sayZpTpeX3k6jcCMeTedDapXkXd7SZpRJbSjdeqKBJ2Vnrm1xyfD3 (based on 0x38 0xAE plus thirty-six 0x00's)
Maximum value: wsQrdekZQUyHwv99hRYsj93yn5jLKMfikCoJaWEnXubRGEA9Jnxg5KaPW (based on 0x38 0xAE plus thirty-six 0xFF's)

Range in Base58Check encoding for 2-factor 64 byte master seed (prefix ws):
Minimum value: ws4XTrriTEyyy2TrGWv9R7o94CyBiN69S2VxiK5tVW9htEi48w54sQ43JChCmadoGtYpZSu7vqbbQTMemCSyyToyLPPMjughcXNxE (based on 0xBE 0xCB plus sixty-eight 0x00's)
Maximum value: ws8JdAWrjgi5cF6siPqDEuEbqFVVEQJLyhKinDPFJ2T84m8Qib2kS4y4Sji8YCQsDQ5ZjpcrMMuNu7nnHyJ5j9x1Fcg5iUwvZ7krH (based on 0xBE 0xCB plus sixty-eight 0xFF's)

Generation of master seed:

1. Take either an existing 16, 32 or 64 byte master seed S, or generate one from a (P)RNG.
2. Calculate I = HMAC-SHA512(key = "Bitcoin seed", msg = S)
3. Split I into two 32-byte sequences, IL and IR.
4. Use IL as master secret key. IR, the master chain code is not relevant here.
5. In case IL is 0 or >= N, the master key is invalid. Go back to step 1 if generating, or in case of a provided master seed, return an error.
6. Compute the public key K = IL*G
7. Calculate the master Bitcoin public address A = Base58Check(RIPEMD160(SHA256(K)))
8. Calculate the salt = SHA256(SHA256(A))[0...3]

Encryption:

9. Derive a hash H from the passphrase using scrypt
Â  Â  - Parameters: passphrase is the passphrase itself encoded in UTF-8, salt = salt, n = 16384, r = 8, p = 8, length = seed length + 32
10. The first number of bytes in H, equal to length of seed S are used to xor seed S. Call the result X.
11. Do AES256Encrypt(message = X, key = last 32 bytes of H), call this encrypted_seed.


The encrypted_master_seed is the Base58Check-encoded concatenation of the following, which totals 2 + 4 + seed length bytes (22, 38 or 70 bytes):

encrypted_master_seed = prefix + salt + encrypted_seed

The clear version is:

master_seed = prefix + salt + seed S


Decryption:

1. Collect encrypted_master_seed and passphrase from user.
2. Perform step 9 of encryption with the passphrase and the salt from the encrypted_master_seed.
3. With the encrypted_seed from encrypted_master_seed do AES256Decrypt(message = encrypted_seed, key = last 32 bytes of H), call this decrypted_seed.
4. With the first number of bytes in H, equal to the length of the decrypted_seed, perform the xor operation on decrypted_seed and call the result S.
5. Perform generation steps 2 until 8 and verify that the generated salt is equal to the salt from encrypted_master_seed.


Suggestions for implementers of proposal with alt-chains

This proposal involves hashing of a text representation of a public address which for Bitcoin includes the leading '1'. Alt-chains can easily be denoted simply by using the alt-chain's preferred format for representing an address. Alt-chain implementers may also change the prefix such that encoded master seeds do not start with "WS" or "ws".


Bitcoin testnet representation

This proposal does not cover separate Bitcoin testnet representations of encoded master seeds, although since the 4 salt bytes are based on a double SHA256 of the Bitcoin public address, they will be different for Bitcoin testnet public addresses and validation will fail.Â 


Reference implementation

TODO


Test vectors

Test 1:

Seed Â  Â  Â : 000102030405060708090a0b0c0d0e0f
Clear Â  Â  : WSZsLQ5c1uKrRQugbrZNYsvMhRixiaWaVmJ
Password Â : Satoshi
Encrypted : wsHb15443fYPmneEXskd6wUZeP15fCiA69n
Address Â  : 15mKKb2eos1hWa6tisdPwwDC1a5J1y9nma
xprv Â  Â  Â : xprv9s21ZrQH143K3QTDL4LXw2F7HEK3wJUD2nW2nRk4stbPy6cq3jPPqjiChkVvvNKmPGJxWUtg6LnF5kejMRNNU3TGtRBeJgk33yuGBxrMPHi
xpub Â  Â  Â : xpub661MyMwAqRbcFtXgS5sYJABqqG9YLmC4Q1Rdap9gSE8NqtwybGhePY2gZ29ESFjqJoCu1Rupje8YtGqsefD265TMg7usUDFdp6W1EGMcet8

Test 2:

Seed Â  Â  Â : 7f0ad7d595be13e6fe4cf1fa0fbb6ae9c26c5d9b09920709414982b6363d5844
Clear Â  Â  : WSB7z3izBZwDoaAUA4mDpEHzAZsA5zfTWu3cCxhkaLtZ4Ur6n6mXsgpMK
Password Â : Nakamoto
Encrypted : wsFp1uM2gFhd2PuRzmNFReRud71hgmVwPoc7cGpxuvgETRsv8J1wHNANJ
Address Â  : 1A54ECavJaJAoLGqqNrPd9Y3cvSvkL2Roz
xprv Â  Â  Â : xprv9s21ZrQH143K3f9hMVvcbY4EX4CfxsEtc6C5BMkZtgGpTGpxAscoq7SLSAcL6k5dxaZ9s4SChrtfSFoKpijuwAnhuPn76eva6W8bDr118t3
xpub Â  Â  Â : xpub661MyMwAqRbcG9EATXTcxfzy563ANKxjyK7fykABT1ooL5A6iQw4NukpHShDxYgeso4NHscFmqcVEtdUt61c8RCf7FqXK9z6sgfkQvYBQPP

Test 3:

Seed Â  Â  Â : fffcf9f6f3f0edeae7e4e1dedbd8d5d2cfccc9c6c3c0bdbab7b4b1aeaba8a5a29f9c999693908d8a8784817e7b7875726f6c696663605d5a5754514e4b484542
Clear Â  Â  : WS6186bsAkSaGRjRZ1UGyCGigxsXPvnYGSqNHJYmauV9X4W8tLJke1DH8UP8YMsDLdsjwgodcghjjKqkWQmk3t7qDbNMJVBDKcD2s
Password Â : Vires In Numeris
Encrypted : ws7vDy7RjqMvcPX7GeakKvdK6vDKGhRSjQtaRfKUVQrJXwwetLSeTdNgGzn5BKZZqz1BBdaHBFYfLvNUSxDaoP1ojJMMJD9UnQuwt
Address Â  : 1JEoxevbLLG8cVqeoGKQiAwoWbNYSUyYjg
xprv Â  Â  Â : xprv9s21ZrQH143K31xYSDQpPDxsXRTUcvj2iNHm5NUtrGiGG5e2DtALGdso3pGz6ssrdK4PFmM8NSpSBHNqPqm55Qn3LqFtT2emdEXVYsCzC2U
xpub Â  Â  Â : xpub661MyMwAqRbcFW31YEwpkMuc5THy2PSt5bDMsktWQcFF8syAmRUapSCGu8ED9W6oDMSgv6Zz8idoc4a6mr8BDzTJY47LJhkJ8UB7WEGuduB

Test 4:

Seed Â  Â  Â : 6ca4a27ac660c683340f59353b1375a9
Clear Â  Â  : WSXnfK5CJbDoSwcqMfz7Xqy3avuPHSxDQQk
Password Â : è¡ä¸­æœ¬
Encrypted : wsFWKz3c5eeHRwtJveSdFvwUrmoNVkJ5ns2
Address Â  : 1JVncPbsdB2s4zHim3VdAWNkZ8JANBZ1U9
xprv Â  Â  Â : xprv9s21ZrQH143K3mJ4upPSDfXdA34yNjem6PSsXT63vm8dq8ikUJv4iiTD3PrSKtdGZXFVD689z5T7knXo55BjcHS2WL3Syp2DbGgnbgxw2QA
xpub Â  Â  Â : xpub661MyMwAqRbcGFNY1qvSaoUMi4uTnCNcTcNUKqVfV6fchw3u1rEKGWmgtfUMRKLgUHNZ7dfsh8Ys6SLwUojZqScFBQL3dFGF3QywNLJVZ2o


Acknowledgements

Mike Caldwell for BIP 0038, which this proposal borrows heavily from.


See Also

BIP 0032 Hierarchical Deterministic Wallets: https://en.bitcoin.it/wiki/BIP_0032
BIP 0038 Passphrase-protected private key: https://en.bitcoin.it/wiki/BIP_0038




-------------------------------------
On 1 April 2013 11:35, Harald Schilly <harald@schil.ly> wrote:



Thanks for the pointers.  I am aware of most of this work, indeed I speak
regularly to many of the authors.

I will reuse as much as possible, but some terms will be bitcoin specific.

I came across:

https://en.bitcoin.it/wiki/Bitcoin_glossary

Which is really nice.

Question is where to host it.  I have 3 ideas so far

1. bitcoin.org -- logical, but no https and github doesnt let you set mime
types

2. w3id.org -- new site could be a good permanent location

3. bitcoin.it wiki -- has https but im unsure i can set a mime type, anyone
know who maintains this?


-------------------------------------
On Wed, May 22, 2013 at 6:27 AM, Melvin Carvalho
<melvincarvalho@gmail.com> wrote:

What does this mean?  It seems extremely unlikely that two different
genesis blocks will have the same hash.

-- 
Jeff Garzik
exMULTI, Inc.
jgarzik@exmulti.com


-------------------------------------
On Wed, Feb 13, 2013 at 6:44 PM, Stephen Pair <stephen@bitpay.com> wrote:

Then perhaps I totally misunderstood what you were suggesting.  I
believed you were saying blocksize would be controlled by people
having to pay to receive and pay to have blocks forwarded.


The only fee-or-cost they're worrying about is their own marginal
costs.  This says nothing about the externalized cost of the hundreds
of thousands of other nodes which also must validate the block they
produce, many of which are not minersâ€” if we are well distributedâ€” and
thus don't have any way to monetize fees.  And even if they are all
miners for some reason,  if these fees are paying the ever growing
validation/storage costs what expenditure is left for the proof of
work that makes Bitcoin resistant to reversal?

If the cost is soaked up by validation/forwarding then the capacity to
run a validating node ends up being the barrier to entry and
difficulty would be very low... which sounds fine until you realize
that an attacker doesn't have validation costs, and that selfish
("optimally rational") miners could just eschew validation (who cares
if you lose some blocks to invalidity if you're producing them so much
cheaper than the honest players?).


What I want is for economics to dictate a positive outcome. They can
do this how the system is currently constructed where the economics of
using the system are clearly aligned with securing it.


-------------------------------------
On Mon, May 6, 2013 at 12:12 PM, Peter Todd <pete@petertodd.org> wrote:

Indeed, the DNS seeds are just servers run by trusted individuals anyway.

In either case, bitcoinj definitely wants fixing for its over-reliance
on DNS seeds.  This has been noted as a problem for a while.

-- 
Jeff Garzik
exMULTI, Inc.
jgarzik@exmulti.com


-------------------------------------
You're just closed minded.


On Mon, Dec 9, 2013 at 3:10 PM, Jeff Garzik <jgarzik@bitpay.com> wrote:

-------------------------------------
On Mon, Aug 19, 2013 at 10:09 PM, Frank F <frankf44@gmail.com> wrote:

They were addressed and fixed in a successor API, getblocktemplate.
It's even more decentralization-friendly, as it allows the caller to
see what transactions the daemon is trying to put into a block, and
even modify it.

The suggestion here is not to remove functionality - only to remove an
obsolete API for doing so.

-- 
Pieter


-------------------------------------

On 06/19/2013 10:25 AM, Timo Hanke wrote:

It's an interesting observation, but it looks like the most-obvious
attack vector is discrete log problem:  spoofing a relationship between
a target public key and one that you control.   For instance, if you see
{PubA, Mult} produces PubB and you have PubC already in your control
that you want to "prove" [maliciously] is related to PubB, then you have
to find the multiplier, M that solves:  M*PubC = PubB.  That's a
discrete logarithm problem.

I'm not as familiar as you are, with the available operations on
elliptic curves, but it sounds like you can produce essentially-random
pairs of {PubX, Mult} pairs that give the same PubB, but you won't have
the private key associated with those public keys.  It's an interesting
point, and there may be a reason to be concerned about it.  Though, I
don't see it yet.

-Alan


-------------------------------------
On Mon, Jun 17, 2013 at 11:16:01AM -0400, Jeff Garzik wrote:

Actually the two are orthogonal: a low-priority no-fee tx might result
because it was from a customer paying a merchant via the payment
protocol. The merchant can then respend that tx with a fee to cover
both, but with the current mempool arrangement if the no-fee tx load is
high actually getting that first tx to propagate so the second can will
be difficult.

A nice way to do this would be to accept tx's into your mempool
indiscriminately but delay broadcasting INV messages until you find
child tx's that make the low-profit ones worth mining. When you do find
a child with a sufficiently high fee, send an INVGROUP message to notify
your peers of the new opportunity. Different nodes will have different
ideas of what priority TX deserves to be broadcast, but here provided
the group meets the threshold a peer will always find out.


Whether or not that is a improvement is a really complex question, even
without taking failure into account. If you agressively prioritize peers
that are the most connected and keep your # of peers reasonably low you
can afford the memory to keep track of what tx's your peers already know
about so to save on round trips for TX hash's they don't have. On the
other hand if you have a large number of peers and can't do that, or
need to cut down on bandwidth used up by the INV floods and have a
probabalistic scheme, you are risking more round-trip latency.

Not to mention the nasty problem of how *relying* on TX hashes to keep
your bandwidth down means that anything disrupting that system suddenly
has a big impact on the network. I don't think we really understand all
the nuances of that - look at how few people realize that you need
multiples of average bandwidth to have sufficient emergency bandwidth
available to catch up in the event of a chain fork.

-- 
'peter'[:-1]@petertodd.org
00000000000000a1c290ce20953d864a4b9c603abc8a9c77a04429c89c5e9fac
-------------------------------------
RE: 141.101.113.245

http://whois.domaintools.com/141.101.113.245
gives it as CloudFlare - I suspect it is protecting
Mt Gox when we make our get for currency ticker info.


On Thu, Jun 27, 2013, at 08:18 PM, Jim wrote:


-- 
https://multibit.org    Money, reinvented


-------------------------------------
Let's re-add the list as this is a topic of general interest.

On Tue, Jul 16, 2013 at 11:36 AM, Jonas Schnelli <jonas.schnelli@include7.ch


Making bitcoind/Bitcoin-Qt support SPV mode was the original plan some
years ago, Satoshi even sent me some code he wrote that did the first
parts, but it was incomplete.

At the time, I decided to do a separate implementation for a few different
reasons. One is that my understanding of his code wasn't so good back then
and I lacked confidence to change it. Especially as there were no unit
tests back then (and still aren't any for most of it), making invasive
changes to the core validation code was and is highly risky. A separate
code base seemed to reduce the risk a lot.

Another reason is that Satoshi encouraged me to write a simple
re-implementation that people could learn from. And I wanted a documented,
object oriented API that people could use to build a variety of apps.

Yet another reason was bitcoind is security critical code that scrapes
complex data structures from untrusted sources on the internet, and it's
written in an unmanaged language. Ordinarily this would be a recipe for
disaster as a single overflow or memory management error could lead to
hacking and theft on a massive scale. It's like taking a chainsaw and using
it to carve an ice sculpture. Satoshi, incredibly, pulled it off, mostly by
using advanced C++ features that made his code hard to read for many people
and by being very, very careful. I was not convinced I could do such a good
job and was worried about accidentally introducing vulnerabilities.

A final reason is that it was clear that the bitcoind codebase would need
serious changes for mobiles, beyond that required for ordinary SPV support.
For example, Satoshi's code assumes it has access to block headers via a
std::map and that assumption is made in a lot of places. On Android phones,
you can't fit all the block headers in RAM. bitcoinj uses a circular ring
buffer of the last N thousand headers for this reason. It's quite different
to how bitcoind works.

All that said, it was a ton of work and it's still unclear that it was the
right call.

Anyway, your situation is a little different. Firstly you don't care about
mobiles, your app is intended for desktops. So the changes required are
less invasive. Also, there are more unit tests and more people with a good
understanding of the code these days, so perhaps the risk of introducing
bugs is lower. And these days we have some nice APIs for building apps so
that need is already met.

If you wanted to implement SPV mode in bitcoind, Gavin or I could send you
Satoshi's old patch although of course it is no longer usable. It would
indicate the basic cut lines though.
-------------------------------------
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256

On Wed, Jul 24, 2013 at 11:55 AM, Tier Nolan <tier.nolan@gmail.com> wrote:

As Peter said, "much" should be quantified.

Remember that there is a statistical distribution here, what is the probability
of how many seconds per headers?


Sounds like you are changing economics and requiring miners to have even better
network connections. This is not a thing to do lightly and it probably a bad
idea.


I understand Pieter Wuille is working on letting Bitcoin propagate and make use
of pure block headers, a step towards SPV and partial UTXO mode.

Orphan measurement would be very useful for a lot of reasons, how about you
think about that first? It wouldn't have the potential data rate issues either
and should be a very simple change. Just set some threshold relative to the
height of the best block where you will not further propagate and orphan
block(header) and prior to that limit do so freely. I believe the change would
be 100% compatible with the P2P protocol as it is based on inventories.
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBCAAGBQJR9WXdAAoJEEWCsU4mNhiPBUYIALgg3ylA5mkciT3W/kb+qXCp
spYlPwAU/HVUrd/p6Ra6xAOOa224BE018FHRx7cJ31AQdVPsKhC1XiQCeYMv14Cj
5LstO2VTzxLovfs1lTVnekt+xVo6EHP47Qhmhdfo1AQWHS2njIp2lT9gAlNgMYoI
Twu0FLfJFwg14HlueLhTNvGo3TeVpGhTV3HYTbjWGBuPeroaaPCKKQOy/jmA9mnZ
1x4MjQZ+AkGA3+vrinyRZ1FQsp1pOUZMZx5UFYDOOPS3TysxttiHF/Vkdmy9dNVf
5zbXrEDImlariRnyxCf6sn4Fpu9H9bt6yttCez6NHqAoZCwciXyo+UrZjFawSVg=
=8gci
-----END PGP SIGNATURE-----


-------------------------------------
On 9 Feb 2013 00:50, "Gavin Andresen" <gavinandresen@gmail.com> wrote:

#2243 should fix that, I think.

-- 
Pieter
-------------------------------------
On Mon, Nov 4, 2013 at 3:26 PM, Peter Todd <pete@petertodd.org> wrote:


So you're back to a complicated sybil attack. I don't follow your thought
process here - I didn't say anything about numerical advantage. The attack
outlined in the paper *requires* you to be able to race the rest of the
network and win some non-trivial fraction of the time. If you can't do that
then all it means is that when you try to release a private block to
compete with the other found block, you're quite likely to lose and you
sacrifice the block rewards by doing so.



There's no stable way to know that. The whole purpose of the block chain to
establish the majority. I think your near-miss headers solution is
circular/unstable for that reason, it's essentially a recursive solution.



But you can't reliably estimate that. You can't even reliably estimate the
speed of the overall network especially not on a short term basis like a
block interval.
-------------------------------------
On Sun, Jun 2, 2013 at 2:13 AM, Peter Todd <pete@petertodd.org> wrote:

That seems fair.

In general, people are actively bloating the UTXO set with unspendable
outputs (that cannot be 100% proven unspendable).  Provably
unspendable seems like an improvement on long term UTXO health.

It is a fair criticism that this inches the incentives, a bit, towards
timestamping and other non-currency uses.  But those uses (a) cannot
be prevented and (b) have already been automated anyway (e.g. the
python upload/download tools stored in-chain).

I do think the overwhelming majority of users are invested in
bitcoin-the-currency (or bitcoin-the-commodity, take your pick), i.e.
the value proposition.  That's our 98% use case.  Given the relative
volumes of traffic, timestamping/data storage/messaging is essentially
getting a free ride.  So IMO it is worth continuing to explore
/disincentives/ for use of the blockchain for data storage and
messaging, for the rare times where a clear currency-or-data-storage
incentive is available.

-- 
Jeff Garzik
Senior Software Engineer and open source evangelist
BitPay, Inc.      https://bitpay.com/


-------------------------------------
On Fri, Aug 16, 2013 at 04:36:20PM +0200, Mike Hearn wrote:

UPNP seems to work well for the reference client. What's the situation
there on Android?

I leave my phone plugged in and connected via wifi for most of the day;
lots of people do that.

The user interface for this stuff is very simple: "How much bandwidth
will you contribute back? If you contribute more bandwidth back, other
peers will prioritize you and your wallet will be more reliable."

-- 
'peter'[:-1]@petertodd.org
000000000000003cfc051263917373a1cab2655994b97c54a625021f52c84658
-------------------------------------
On Tue, Jul 23, 2013 at 10:27:19AM +0200, Andreas Schildbach wrote:

Depends what you mean by expose.

Maintaining an address/script-indexed UTXO is generally useful, in
particular for things like sweeping addresses. I certainly have
less problems with 'exposing' this than exposing a fully-indexed
block chain history.

However, and I expect that's what your question is about, this isn't
really useful for SPV (or less) nodes, as there is no way to
authenticate this data. If you can fake a UTXO entry, you can make
a peer believe anything about their balance, potentially resulting
in creating a valid transaction that sends change it didn't know
was there as fee to miners. Other than for normal block chain data,
there is no way to detect this without at least partial validation.

The only way to do this safely at an SPV security assumption, is by
having an address-indexed committed merkle UTXO-set tree, like the
one proposed by Alan Reiner, and being implemented by Mark
Friedenback. I know Michael Gronager has something similar implemented,
but I don't know whether it is script-indexed. To be actually useful,
it likely needs to be enforced by miners - putting a significant
burden on validation nodes. Still, if it can be done efficiently,
I think this would be worth it, but more research is needed first in
any case.

Regarding sweeping keys in the first place - I think using those,
and relying on address-indexed UTXO sets or blockchains to import
them, is an idea that doesn't scale very well in the first place.
If it is for things like scratch card or physical coins, with a
pre-set value, the obvious solution IMHO is storing the crediting
transaction with its merkle path together with the key. If that's
not possible, just the txid:vout of the credit output can suffice.
Yes, that's more data than is necessary now, but it's so much more
trivial to use.

-- 
Pieter



-------------------------------------
In the low-subsidy future fees will be the main source of income for
miners. Thus in some circumstances large miners may even have a reason
to delibrately try to mine a block that would orphan the current best
block. A simple example would be what would happen if a 1000BTC fee tx
was created, but more realistic examples would be just due to a large
number of tx's with decent fees.

However, with limited block-sizes such a strategy runs into a problem at
a point: you can't fit more tx's into your block so you can't increase
the fees collected by it even if you wanted too. Best strategy will soon
be to accept it and move on.


The second thing that could help defeat that strategy is if clients use
nLockTime by default. Clients should always create their transactions
with nLockTime set such that only the next block can include the
transaction, or if the transaction isn't time sensitive, possibly even
farther in the future.

Remember that to get ahead, you need to mine two blocks, and with
nLockTime the first block could only gain the transactions in the block
it orphans, so any further transactions could only go in the second.
With limited blocksizes that creates even more pressure in that the
block becomes full.

I don't see any reason why nLockTime in this fashion would harm clients,
so I think it's a perfectly reasonable thing to do and provides some
nice benefits down the road.

-- 
'peter'[:-1]@petertodd.org
-------------------------------------
Linux builds of 0.8.0rc1 are in good shape; easily gitian-reproduceable.

Windows builds are varying with every compile, and I think I finally
figured out why: we are not passing the -frandom-seed flag down into
the leveldb build (I used objdump to dump two different binaries, and
they differed only in the names of some leveldb objects). That should
be an easy makefile fix.

The OSX build is in pretty good shape, but needs
https://github.com/bitcoin/bitcoin/pull/2286 to compile.

So: I think the path forward is to announce 0.8.0rc1 with the binaries
we've got, to get more testing.

Then before final release (or rc2, if that is needed) pull #2286 and
create and pull a patch to fix the windows non-determinism problem.

I'm done for today, but should have time to sign the windows setup.exe
and send out a rc1 announcement tomorrow.

-- 
--
Gavin Andresen


-------------------------------------
On Tue, Dec 10, 2013 at 8:01 AM, Ryan Carboni <ryan.jc.pc@gmail.com> wrote:

That is like saying "We need a way to travel around the world quickly.
There will be an anti-gravity technology; how this works is not something
I'm personally focused on."

Or, in other words, you are ignoring exactly the sticky, difficult problem
that would have to be solved for your proposal to have any chance of
working.

-- 
--
Gavin Andresen
-------------------------------------
On Wednesday, May 22, 2013 2:20:22 PM Jeff Garzik wrote:

In some cases, multiple currencies can use the same blockchain (not just the 
singular genesis block). This use case *is* something we want to encourage - 
no reason for people to make an entirely new blockchain if their altcoin fits 
within the scope of Bitcoin or another existing altchain.


-------------------------------------
Personally, I would be more inclined to submit and work on a BIP if it was
in GitHub. It's a regular home from home for me now.


On 5 December 2013 14:43, Jeff Garzik <jgarzik@bitpay.com> wrote:

-------------------------------------
On Fri, Jul 05, 2013 at 04:01:40PM +0200, Adam Back wrote:

Yeah, there's been a lot of doom and gloom about zerocoin that is
frankly unwarrented. For instance people seem to think it's impossible
to make a blockchain with zerocoin due to the long time it takes to
verify transactions, about 1.5 seconds, and never realize that
verification can be parallelized.

Anyway the way to do it is to get out of the model of large blocks and
think about individual transactions. Make each transaction into its own
block, and have each transaction refer to the previous one in history.
(zerocoin is inherently linear due to the anonymity)

Verification does *not* need to be done by every node on every
transaction. Make the act of creating a transaction cost something and
include the previous state of the accumulator as part of a transaction.
Participants verify some subset of all transactions, and should they
find fraud they broadcast a proof. Optionally, but highly recomended,
make it profitable to find fraud, being careful to ensure that it's
never profitable to create fraud then find it yourself.

Anyway Bitcoin is limited to 7tx/s average so even without probabalistic
verification it'd be perfectly acceptable to just limit transactions to
one every few seconds provided you keep your "blocksize" down to one
transaction so the rate isn't bursty. You're going to want to be
cautious about bandwidth requirements anyway to make sure participants
can stay anonymous.

As you suggest creating zerocoins from provably sacrificing bitcoins is
the correct approach. The consensus algorithm should be that you
sacrifice zerocoins (specifically fractions there-of - note how I'm
assuming support for non-single-zerocoin amounts) and whatever chain has
the highest total sacrifice wins. One way to think about
proof-of-sacrifice is it's really proof-of-work, transferred. It also
has the *big* advantage that to double-spend, or for that matter 51% the
chain, you have to outspend everyone with a stake in the viability of
the blockchain: they can sacrifice their zerocoins to combat you. In the
case of a double-spend to rip off an online merchant the total amount
you could profit is the same as the total amount they would rationally
spend to stop you, and soon there will be collateral damage too
increasing the amount third-parties are willing to sacrifice to stop
you. You can't win.

Of course, this does mean that even unsuccesful sacrifices need to be
costly. You can make this acceptable to users by allowing a sacrifice to
be reused, but only for the exact same transaction it was originally
committed to.

Sacrifices in this manner are *not* proof of stake. You really are
giving up something by publishing the information that proves you made
the sacrifice as that information can always be included in the
consensus thereby taking away a limited resource. (your zerocoins) It's
more heavily dependent on jam-free networks, and doesn't play nice with
SPV, but zero-knowledge proofs will may help the latter. (you've got
Bitcoin itself to act as a random beacon remember)

Speaking of, another similar approach is to take advantage of how a
Bitcoin sacrifice can be made publicly visible. Create a txout of some
value like the following:

    OP_RETURN <prev-ztc-blockhash> <blockhash> <ztc-created>

Now even if you fail to publish your blocks, at least the whole world
knows how much they need to outspend to be sure you can't 51% attack the
network. This approach and not-btc sacrifices can go hand in hand too,
especially if nodes follow rules where they consider btc txout
sacrifices as "fixed" and only subject to change by the bitcoin
blockchain re-organizing. Advantages and disadvantages to both
approaches. (remember that visible tx's can be censored by miners)

Sacrifice to mining fees may be acceptable in the future too, but only
if OP_DEPTH is implemented so as to not give Bitcoin miners bad
incentives. (the sacrificed coins should go to fees *months* or even
*years* after they have been sacrificed)

Turning zerocoins back into Bitcoins is just supply and demand: sell
them. You'll always lose a bit given by definition the maximum exchange
rate is 1:1, but anonymity may be worth it. Others have written about
cross-chain trading protocols, and I'll point out they are easier to
implement if one chain has full visibility into what's happening on the
other; zerocoin is most likely to be implemented as an extension to the
bitcoin client itself.

Finally if the transaction rate is too slow there's nothing wrong with
running multiple parallel zerocoin blockchains, although given the
usecase of moving your funds through zerocoin for anonymity, and using
the clean coins that come out the other side, there's no reason to think
the zerocoin chain transaction rate needs to be especially high anyway.

-- 
'peter'[:-1]@petertodd.org
0000000000000013b2f7ee77027f583b765ad9811dfe3d0adc801e295fd9acdf
-------------------------------------
On Saturday, March 23, 2013 5:28:55 PM Jeff Garzik wrote:

Not for producing coinbases (where BIP 34 is implemented).


-------------------------------------
I strongly object to removing the only mechanism that allows anyone to say
that bitcoin is p2p, in the truest sense of the word. Moves like this that
favor only the pool operators and private mining interests are signs that
bitcoin is headed towards a monopoly/cartel model, and that would be a
tragic outcome for something that holds a great promise. Nobody knows what
mining will look like in the future, and denying the individual novice the
ability to mine at a small scale, even if we may think it is inefficient
now, is not a good path to start down.

If there are technical problems with getwork, maybe they should be
addressed and fixed instead of outright abandoned.


On Mon, Aug 19, 2013 at 11:27 AM, Jeff Garzik <jgarzik@bitpay.com> wrote:




-- 
*MONEY IS OVER!*
                                IF YOU WANT IT<http://www.zeitgeistmovie.com/>
=====================================================
The causes of my servitude can be traced to the tyranny of money.
-Serj Tankian
-------------------------------------
On Mon, May 6, 2013 at 3:51 PM, Adam Back <adam@cypherspace.org> wrote:

Or you can just let it mine honestly and take the Bitcoins. This is
fast (doesn't require weeks of them somehow not noticing that they're
isolated), and yields the values I listed as 'costs' if you would have
otherwise been able to use it to mine the difficulty down to 1.  Cost
is just as much foregone income from the alternative attack you could
have done instead.


At least for attacks that drive the difficulty down it does.

If you want to talk about abusing a pool or creating a partition in
order to create short reorgsâ€” I agree, those don't have to be long
lived and you can find many messages where I've written on that
subject.

It's inconsiderate to propose one attack and when I respond to it
changing the attack out from under me. :(  I would have responded
entirely differently if you'd proposed people segmenting the network
and creating short reorgs instead of mining the difficulty down.


Every 2016 blocks can at most lower the difficulty by a factor of 4,
thats where the log4 (number of 2016 groups needed) and 4^n (factor in
cost reduction for each group) come from in the formulas I gave
previously.


http://sourceforge.net/projects/bitcoin/files/Bitcoin/bitcoin-0.8.1/SHA256SUMS.asc/download

The signatures can't be inside the tarball because they sign the tarball.

Seems like the website redesign managed to hide the signatures pretty
good. They're in the release announcements in any case, but that
should be fixed.  Even when they were prominently placed, practically
no one checked them. As a result they are mostly security theater in
practice :(, â€” soâ€” unfortunately, is SSL: there are many CA's who will
give anyone a cert with your name on it who can give them a couple
hundred bucks and MITM HTTP (not HTTPS!) between the CA's
authentication server and your webserver. Bitcoin.org is hosted by
github, even if it had SSL and even if the CA infrastructure weren't a
joke, the number of ways to compromise that hosting enviroment would
IMO make SSL mostly a false sense of security.

The gpg signatures and gitian downloader signatures provide good
security if actually used, solving the "getting people to use them"
problem is an open question.

And I agree, this stuff is a bigger issue than many other things like
mining the difficulty down.


-------------------------------------
On Sun, Jul 14, 2013 at 07:33:06PM +0000, Luke-Jr wrote:

I don't think that's what John means.

If you have hash power for the parent chain, mining invalid blocks for the
merge-mined chain costs you nothing. Yes, they will be invalid, but you've
lost nothing.

The basic assumption underlying mining security is that it is more profitable
to collaborate with mining a chain (and profit from the block payout) than to
attack it. In the case of merged mining, this assumption is not valid.

-- 
Pieter



-------------------------------------
Who would be the best person to interview who could explain this issue and
workaround/resolution?

I'd like to get an audio segment for the Let's Talk Bitcoin show ASAP, as
this will be a big concern for many users who will not know what to do or
be able to understand the problem.

Any volunteers for a 15 min audio interview in the next 2 days?


On Sun, Aug 11, 2013 at 9:28 AM, Mike Hearn <mike@plan99.net> wrote:

-------------------------------------
On 4/9/2013 4:09 AM, Peter Todd wrote:
It depends on how clever the spammers get encoding stuff. If law 
enforcement forensic tools can pull a jpeg header + child porn out of 
the blockchain, then there's a problem that needs mitigation.


-------------------------------------
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256

It has been suggested that we leave the decision of what the blocksize to be
entirely up to miners. However this leaves a parameter that affects every
Bitcoin participant in the control of a small minority. Of course we can not
force miners to increase the blocksize if they choose to decrease it, because
the contents of the blocks they make are their decision and their decision
only. However proposals to leave the maximum size unlimited to allow miners to
force us to accept arbitrarily large blocks even if the will of the majority of
Bitcoin participants is that they wish to remain able to validate the
blockchain.

What we need is a way to balance this asymetrical power relationship.

Proof-of-stake voting gives us a way of achieving that balance. Essentially for
a miner to prove that the majority will of the poeple is to accept a larger
blocksize they must prove that the majority has in fact voted for that
increase. The upper limit on the blocksize is then determined by the median of
all votes, where each txout in the UTXO set is one vote, weighted by txout
value. A txout without a corresponding vote is considered to be a vote for the
status quo. To allow the voting process to continue even if coins are "lost"
votes, including default votes, are weighted inversely according to their age
in years after 1 year. IE a vote with weight 1BTC that is 1.5 years old will be
recorded the same as a <1 year old vote weighted as 0.67BTC, and a 1 day old
and 6 months old UTXO are treated equivalently. The 1 year minimum is simply to
make voting required no more than once per year. (of course, a real
implementation should do all of these figures by block height, IE after 52,560
blocks instead of after 1 year)

A vote will consist of a txout with a scriptPubKey of the following form:

    OP_RETURN magic vote_id txid vout vote scriptSig

Where scriptSig is a valid signature for a transaction with nLockTime
500,000,000-1 spending txid:vout to scriptPubKey:

    OP_HASH160 H(OP_RETURN magic vote_id txid vout vote) OP_EQUAL

vote_id is the ID of the specific vote being made, and magic is included to
allow UTXO proof implementations a as yet unspecified way of identifying votes
and including the weighted median as part of the UTXO tree sums. (it also
allows SPV clients to verify the vote if the UTXO set is a Patricia tree of
scriptPubKeys) vote is just the numerical vote itself. The vote must compute
the median, rather than the mean, so as to not allow someone to skew the vote
by simply setting their value extremely high. Someone who still remembers their
statistics classes should chime in on the right way to compute a median in a
merkle-sum-tree.

The slightly unusual construction of votes makes implementation by wallet
software as simple as possible within existing code-paths. Votes could still be
constructed even in wallets lacking specific voting capability provided the
wallet software does have the ability to set nLockTime.

Of course in the future the voting mechanism can be used for additional votes
with an additional vote_id. For instance the Bitcoin community could vote to
increase the inflation subsidy, another example of a situation where the wishes
of miners may conflict with the wishes of the broader community.

Users may of course actually create these specially encoded txouts themselves
and get them into the blockchain.  However doing so is not needed as a given
vote is only required to actually be in the chain by a miner wishing to
increase the blocksize. Thus we should extend the P2P protocol with a mechanism
by which votes can be broadcast independently of transactions. To prevent DoS
attacks only votes with known vote_id's will be accepted, and only for
txid:vout's already in the blockchain, and a record of txouts for whom votes
have already broadcast will be kept. (this record need not be authoritative as
its purpose is only to prevent DoS attacks) Miners wishing to increase the
blocksize can record these votes and include them in the blocks they mine as
required. To reduce the cost of including votes in blocks 5% of every block
should be assigned to voting only. (this can be implemented by a soft-fork)

For any given block actual limit in effect is then the rolling median of the
blocks in the last year. At the beginning of every year the value considered to
be the status quo resets to the mean of the limit at the beginning and end of
the interval.  (again, by "year" we really mean 52,560 blocks) The rolling
median and periodic reset process ensures that the limit changes gradually and
is not influenced by temporary events such as hacks to large exchanges or
malicious wallet software.  The rolling median also ensures that for a miner
the act of including a vote is never wasted due to the txout later being spent.

Implementing the voting system can happen prior to an actual hard-fork allowing
for an increase and can be an important part of determining if the hard-fork is
required at all.

Coercion and vote buying is of course possible in this system. A miner could
say that they will only accept transactions accompanied by a vote for a given
limit. However in a decentralized system completely preventing vote buying is
of course impossble, and the design of Bitcoin itself has a fundemental
assumption that a majority of miners will behave in a specific kind of "honest"
way.

A voting process ensures that any increase to the blocksize genuinely
represents the desires of the Bitcoin community, and the process described
above ensures that any changes happen at a rate that gives all participants
time to react. The process also gives a mechanism for the community to vote to
decrease the limit if it turns out that the new one was in fact too high. (note
how the way the status quo is set ensures the default action is for the limit
to gradually decrease even if everyone stops voting)

As many of you know I have been quite vocal that the 1MB limit should stay. But
I would be happy to support the outcome of a vote done properly, whatever that
outcome may be.
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBCAAGBQJRtVFBAAoJEEWCsU4mNhiP6EAIAMjq4UgXxmEjOgHWf0KcmwmH
Ra/I3oY7krvg/lu1YCa+ACMBdoca9WODySUIe7R3niphKXEnknHGUIf8tm/Vrq4H
gPF4cgYEr18EYTVtvT9J1pZUB4f5dxkXXNpcQ60juaz9KervFQMOGnpr6Fyxi3dS
ghObNYcr3D2v1fjx56sp7BCNn0XHxTb1ZLUJB0BZhDKlamfgcxruKMbpsZmACJUj
gTNLNweaAomBIH++j7cnXeB0jZc/1ilv8qLA/f3TGb43FDkAQcvvSjGijI+OJOm6
Fh/WRBav1BJiV6PKs9xuHXsaxZ/T7Fb8Wg8EynSi0mSj47QXdKZgeZCi3XlSyxM=
=aKBD
-----END PGP SIGNATURE-----


-------------------------------------
On Mon, Aug 19, 2013 at 1:16 PM, Gregory Maxwell <gmaxwell@gmail.com> wrote:

I am naughty and should clarify.  I had ass.u.me.d that Jeff's patch
also removed the internal CPU miner, because doing so is necessary for
actually getting rid of most of the getwork code. It doesn't actually.

Though this doesn't change the fact that the internal miner is mostly
a pretext for integrated mining.  Since it only really works on
testnet it also means our testnet testing using it is not a good test
of the actual production software.  I'd rather remove the internal
miner too, getting rid of the extra code and complexity, and package
up a GBT miner which would actually be usable on the mainnet.


-------------------------------------
Could this modularization effort lead to a special compiled bitcoind 
simulator that runs many virtual instances of a node on the same system 
(possibly same process)? The simulator would cache crypto computation 
results (ECDSA, SSH-256) to significantly speed up processing 
transactions and blocks between the virtual nodes.  The virtual nodes 
would also need to share the same block data in memory when possible.  
This would also require significant additional work to simulate the 
network and possibly computational limits.

The transactions on the existing block chain could be replayed into 
randomly chosen virtual nodes to help ensure any code changes would not 
have caused problems with historic transactions.  You could even record 
all the messages for some time on many real nodes and use that as test 
data for the simulator.  Many other test programs could be devised to 
quickly simulate other network activity.

This wouldn't completely replace the test network but could provide 
greater and quicker confidence that code changes are safe.

- Quinn


On 05/16/2013 04:02 AM, bitcoingrant@gmx.com wrote:

-------------------------------------
I think this is a good idea; I just pushed new unit test test_similarity()
to github which finds such similar words. Right now it identifies ~90
similar pairs in current wordlist, I'll update wordlist tomorrow to pass
this test.

slush

On Sat, Oct 19, 2013 at 1:52 AM, jan <jan.marecek@gmail.com> wrote:

-------------------------------------
wonder if it would be good idea to have a alias to wallet id nameserver in
the client software where a person can use a english name to describe a
wallet public key address?  and the software can use it to look up the
wallet id.

wallet ids are hard to remember/recall.

-chris
http://tawhakisoft.com/
-------------------------------------

Re-reading what I wrote, it's not really clear.

Even if possible, the intermediate cert setup still wouldn't work for most
merchants but I didn't make that clear. It might work for EV certs. For
most sites that are just DV there's nothing you can do because CA
verification is just "do you control this domain name". So if your web
server is compromised it's game over. They can issue themselves a new cert,
and what's more, unless wallets are checking revocation lists you can't
stop them signing as you until their certificate expires.

The process for getting an EV cert is harder and there, an offline
restricted intermediate cert might make more sense because you could have a
compromised SSL key whilst not having a compromised identity, but it's
still not possible with todays CA policies.
-------------------------------------
"We propose a simple, backwards-compatible change to the Bitcoin
protocol to address this problem and raise the threshold. Specifically,
when a miner learns of competing branches of the same length, it should
propagate all of them, and choose which one to mine on uniformly at random."

So only in the case of two competing chains... The "Selfish Miner" today
has an advantage knowing which chain the other will work on, and by
simply choosing the other they get their advantage making it likely that
it is the other that will waste their effort. By using the random scheme
this advantage is gone.

Note again that it is only in the case of two competing chains, which
will happen on average every 60 blocks. So it is only roughly once every
60 block that you change from choosing one chain to doing a 50% random.

A rough calculation on earnings will be that you loose roughly 1/(2*60)
~ 1% of your blocks using this scheme. But at the same time you make it
harder for such an attack to happen. (This number might be slightly
higher, as working in parallel on both chains will make the two chains
last longer, so agree that we need a bit more analysis...)

I also agree that it is a kind of a Sybil attack, but I think we should
accept the risk of a Sybil attack but of course minimize it, rather than
introducing various social network (ip addresses) solutions, which in
one way or the other always have some central auth / oracle assumption.



On 4/11/13, 13:03 , Mike Hearn wrote:



-------------------------------------
Yes I would like to bundle a JVM as it would simplify the user
experience.

There are a few downsides though:
+ all the build packaging will need redoing and retesting.
+ it will bump up the MultiBit download from about 11MB to 30-40MB 
(I think). This drops the maximum copies of MultiBit the multibit.org 
server can deliver per day from around 90,000 to 30,000ish. 
The multibit.org server maxes out at 1 TB of bandwidth per day.

Currently there is no provision to update anything automatically.
I would like to start having Bitcoin signed files that MultiBit can
check
and update (initially the checkpoints file, I18N files - NOT code
at first because of the security implications). I think this needs to be 
in place before bundling a JVM so that users don't have to
keep redownloading it.

Having lists of all the artifacts signed and them having SHA256 hashes 
then makes it practical/ safe to start mirroring the code. I can see
each mirror crosschecking the others that the SHA256s are correct
for instance. This would increase the maximum number of 
downloads we could cope with.


On Tue, Jul 9, 2013, at 11:36 AM, Mike Hearn wrote:


-- 
https://multibit.org    Money, reinvented


-------------------------------------
Forward secrecy:
I was definitively already interested in using this.

Binaries:
Sourceforge is not encrypted, actually. Although binaries hosting /
sharing could be a separate subject discussed later I think.

Revocation:
I guess we could just buy another SSL cert from another CA (I mean, if
that really happens). There's a few ones that are not US based.

Decentralization:
So long as we actually use DNS, the website is centralized :( However,
its content isn't (can be forked on GitHub), but regarding the domain
name, there is not much we can do against this AFAIK.

SaÃ¯vann



Le 2013-12-07 22:38, Odinn Cyberguerrilla a Ã©crit :


-------------------------------------
On Mon, Nov 04, 2013 at 02:12:44PM -0500, Ittay wrote:

Speaking of, I'm going to take back my solution as well; I misunderstood
your paper.

So here's your argument in a ELI5 nutshell:

Alice is a miner with some amount of hashing power. She has the ability
to detect new blocks on the network extremely effectively for whatever
reason; in short she has unusually good knowledge of the state of the
network. She is also very good at publishing her blocks and getting them
to the majority of hashing power in very little time; she has unusually
good connectivity to all miners. (low-latency and high bandwidth)

She's so good at this that when she finds a new block, she keeps it a
secret! She can get away with this because she knows that the moment Bob
finds a block, she can immediately broadcast it to the rest of the
network before the other block propagates. Instead of building on Bob's
blocks, almost everyone builds on Alice's block, depriving Bob of the
revenue. Gradually Alice gets more and more miners because Bob, and
other pools, don't pay out as much.

You propose a rule where essentially miners extend Bob's block 50% of
the time, and show in your paper how that leads to a scenario where
Alice needs to have at leastr 1/4 of the total hashing power to
succesfully pull this attack off anyway.


What I did succesfully show is that for a short-term rational miner
they're still better off mining to extend the block they hear about
first rather than using your pick-one-at-random rule, because when you
hear about a block is important information about whether or not the
majority is mining on it. This is true even if others are using the
pick-one-at-random rule. (they're better defecting than doing what's
right for the whole network) Even worse is that miners have a rational
incentive to broadcast such near-target headers to try to encourage
other miners to work on the same fork that they are working on. The
near-target idea came about for a totally different reason, so it's
something that might wind up being implemented anyway.

Mike Hearn's idea of making it easy to identify nodes associated with
hashing power is still wrong. Although again, it's something that miners
themselves have rational incentives to do. (you always want to encourage
others to send you their blocks, and you also want to be able to send
your blocks to the majority of hashing power as quickly as possible)

Where the idea goes wrong is it makes it easier for Alice to identify
hashing power, specifically where she needs to send her blocks to
distribute them to the majority as quickly as possible. The second
problem occurs if those nodes also distribute blocks to connecting
peers: this makes it easy for Alice to be sure she'll hear about a new
block as soon as possible by connecting to every one of those peers with
a high-speed, low-latency connection. Bizzarely the idea does work if
the advertised nodes only accept blocks, and never send blocks - instead
miners would *only* send their blocks to other miners who have proven
their hashing power, and do so essentially largest miner to smallest.
Now unless Alice already is a large miner, her strategy can't work.  Of
course this will strongly encourage further centralization of pools. But
it is in the interests of rational miners sadly.

That blocks take a finite amount of time to propagate makes the problem
worse: for Alice to learn that another block has been mined only
requires her to receive the small 80 byte header from a peer; she
doesn't need the whole block. She thus can know the block exists well
before it has a chance to propagate fully. Even if every miner were
directly peered to every other as some suggest, Alice could simply make
smaller blocks, faster propagating than everyone else and use especially
low-latency connections to win the race.

On the other hand, the Bitcoin protocol is currently designed such that
a miner can mine a block without knowing the previous block in full.
Given the large block reward and/or a supply of transactions they knew
no other miner had a rational miner would start trying to extend the
longest chain they know about prior to actually receiving and validating
the full block. Again, when miners start doing this - perhaps out of
desperation due to low revenue - as long as Alice has the lowest latency
network she'll win. (she doesn't even need to have the highest bandwidth
in this case) We can change the protocol to force miners to fully
validate blocks prior to mining extensions, but that only forces Alice
to get more bandwidth - she still wins.

Speaking of low-latency, latency not only centralizes control in a
single pool, it centralizes pools and even mining hardware itself in a
single physical location. Anyone at the edges of the propagation network
will get comparatively less revenue than those in the center, gradually
tightening the network, even without selfish mining. Alice's strategy of
course should be to position her nodes in the geographical center. It's
worth noting how if Alice is the one with the lowest average latency,
she will win against any other miner trying to persue the same selfish
miner strategy that she is using.


Finally nLockTime makes the selfish miner strategy even more profitable.
You may not be aware, but it's possible to make a transaction that can't
be mined until some time in the future, measured by either block height
or block timestamp. I've proposed to use this mechanism in
announce/commit sacrifices: you create a transaction that can't be mined
until some point in the future that sacrifices a large amount to mining
fees, and then prior to that point you include it in the blockchain as
data, proving the whole world knew about your transaction. The idea was
that which miner managed to include the transaction, and collect the
reward, would be random. However whenever Alice is able to maintain a
lead over other miners she's able to reliably mine significantly more of
those valuable transactions, further increasing her revenue over other
miners.


I must say, you've really opened a can of worms...

-- 
'peter'[:-1]@petertodd.org
000000000000000379e2a349ccee65efc29d43e2c742f8e4a9247d68025ace84
-------------------------------------
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256


I think that the course of action is quite simple:

1.  Upgrade all the clients to implement the lock limits. (in code,
not at the DB exception layer).  A bit of research is needed to work
out exactly what these limits are so we can maximise the number of
transactions.

2. Fix the DB layer, and test that all the clients can support 1MB blocks.

3. Once we are confident that the network supports 1MB blocks, set a
date where the lock limits are removed.

For me, everyone signed up to bitcoin thinking that there was a 1MB /
block limit.  The lock limits were unexpected, and could be considered
extremely uncontroversial to remove.

The discussion of larger blocks (i.e. > 1MB ),  that I happen to
disagree with,  is not relevant to the discussion of the removal of
the lock limits.


-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.19 (MingW32)
Comment: Using GnuPG with Thunderbird - http://www.enigmail.net/

iF4EAREIAAYFAlFBF0QACgkQBJ8cMDO159aWbwEAs8Ldt8hRpzjS4HdrH3U9Jnaq
MWhifXqkJuVC0TVCz3EBAOAfSogdSS7rJvtfV8FqTIox1ek/xJxuHvZdonUnQN1K
=I5Cf
-----END PGP SIGNATURE-----


-------------------------------------
On Mon, Nov 04, 2013 at 04:45:24PM -0500, Alan Reiner wrote:

Right, but as I said, I think this is likely to become a contest of who
can create the lowest latency mining operation, or to be more precise,
who can get the best ratio of latency per dollar.

Unfortunately even with totally "honest" mining winning orphan rates is
a function of latency; what this paper has done is mainly show a
remarkably effective way of leveraging low-latency and very good
visibility to the network.

Regardless, globe-spanning low-latency networks cost a lot of money, so
if they are something that makes mining more profitable, for whatever
reason, that's an effect that will incentivise pools to grow larger and
more centralized.


Yeah, there's a lot of possible solutions, but what I'm seeing looking
at them is they all tend to be not economically rational, in the short
term, or even worse, they actually incentivize mining pools to get
larger. For instance anything that tries to prevent Alice from sybiling
the network by forcing nodes to prove they have mining capacity just
means that larger miners will have an advantage over smaller ones in
getting their blocks propagated as fast as possible. Once Alice does
have a reasonable amount of mining capacity, she can still use the
selfish miner attack to grow larger and more profitable.

-- 
'peter'[:-1]@petertodd.org
000000000000000aae6d13639c5b4555eeda301ebcbc53f12e8a633e267c8331
-------------------------------------
On Mon, Sep 9, 2013 at 1:53 AM, Gregory Maxwell <gmaxwell@gmail.com> wrote:

I now have a patch up for review.

https://github.com/bitcoin/bitcoin/pull/2982


(You should wait until other developers have had a chance to review
before rushing out and applying it. The checklevel=2 workaround is
adequate for now.)


-------------------------------------
Apparently that won't help. That's just embeding the existing tor code and rerouting internal Cocoa internet communication via tors proxy.
What guys need is bigger configurability in tor itself. I can understand that. It's doable tough.

Gosh, why a day has only 24h? :) 

/b

grabhive.com (http://grabhive.com) | twitter.com/grabhive (http://twitter.com/grabhive) | gpg: A1D5047E


On Tuesday, 30 July 2013 at 19:02, Wendell wrote:



-------------------------------------
On Wed, Sep 25, 2013 at 1:33 PM, Andreas Schildbach
<andreas@schildbach.de>wrote:


OK, it might fit if you don't use any of the features the protocol provides
:) You can try it here:

https://bitcoincore.org/~gavin/createpaymentrequest.php


certificate or a fingerprint to the QR code.

It's not "utterly broken", that's over-dramatic. It's just the best that
can be done with todays technology. I wrote about the SSL PKI and how it's
being upgraded here:

https://bitcointalk.org/index.php?topic=300809.0

If you're thinking about governments and so on subverting CA's, then there
is a plan for handling that (outside the Bitcoin world) called certificate
transparency which is being implemented now.

Now when you are getting a QR code from the web, it's already being served
over HTTPS. So if you're up against an attacker who can break a CA in order
to steal your money, then you already lose, the QRcode itself as MITMd.

In the Bluetooth case we might have to keep the address around and use it
to do ECDHE or something like that. The current BT support doesn't need
that because it's just blasting out a tx, the entire protocol is write
only. Once it's reading data as well then it'll need a custom security
layer.
-------------------------------------
On Tue, Jul 23, 2013 at 12:29 PM, Andreas Schildbach
<andreas@schildbach.de> wrote:

I don't object to using a trusted server for this if people want that,
but I don't think the reference client should encourage this.

Apart from that, exposing this HTTP-based interface publicly has its
own problems, like security risks and potential DoS risks. If
anything, we should be reducing the attack surface rather than
increase it. IMHO, the only thing that should be exposed in the P2P
protocol, which is inevitable, and already has some DoS protections.

I like this HTTP interface, but it should really only be used for
trusted local applications and debugging.

-- 
Pieter


-------------------------------------
I found a tiny error in 0.8.6rc1.  The leveldb subtree merge was done
incorrectly leaving an errant db/ directory in the base of bitcoin instead
of src/leveldb.  See my earlier mail on 0.8.6 for suggested subtree squash
and merge syntax.  (On plane now...)

Warren
On Dec 5, 2013 10:53 PM, "Gavin Andresen" <gavinandresen@gmail.com> wrote:

-------------------------------------
Mike Hearn wrote:


Yeah, let's build a backbone, or a cloud, and then we could have Google run it!

Come on, Mike, your conflict-of-interest as an employee is hanging out in the open, flapping in the breeze here... Don't you think it's a bit obvious for somebody in your position to advocate centralization of infrastructure, especially when it comes to bitcoin?


On the other hand, I guess your blind trust in IP addresses as a solid foundation for security is why you were so shocked when the NSA hacked your "backbone".
-------------------------------------
On Sat, Oct 19, 2013 at 3:29 PM, Luke-Jr <luke@dashjr.org> wrote:

FWIW, he did post to the mailing list and he got an underwhelming response:

http://sourceforge.net/mailarchive/forum.php?thread_name=20ec1e35-3051-45d6-b449-e4a4d5c06dc8%40me.com&forum_name=bitcoin-development

When I responded to him on BCT I said "I was about to suggest you hit
the mailing list for some initial comments firstâ€” but I see you've
done that. I'll issue a number in a couple days once there has been a
little chance for some discussion.".

Since much discussion didn't materialize I went and gave it a
technical once over, posting to the forum.  In hindsight, I probably
should have also posted my review to the mailing list, which might
have served to restart some additional discussion.


-------------------------------------
I was concerned about this issue so we sponsored BlueMatt to implement an
address database for bitcoinj.  In the future it won't be entirely reliant
on what DNS tells it.

Warren

On Tue, Dec 24, 2013 at 6:02 AM, Peter Todd <pete@petertodd.org> wrote:

-------------------------------------
Why use ripple and not just use the testnet? 

The advantageous of allowing testnet to be used as an alt-coin are That Non standard transactions can be tested in a pseudo live environment where because the coins have some nominal value people are incentivized to try and steal and come up with clever ways of gamin the system. This sort of knowledge would be invaluable if non standard transactions are ever going to become a reality on main net. 

It also allows developers a chance to develop in advance new technologies and services that currently won't run on bitcoin main net but might be enabled in the future at which point they can switch over to main net. Additionally without any development happening with non standard transactions as currently there is no economic incentive , there might be a strong argument to never bother enabling non standard transactions as the risk of doing so might not justify in many people's minds  the benefits as if no one develops anything in advance  most users might not find the theoretical possibilities worth the risk, thus permanently hobbling the full potential of satoshis idea. Rather if testnet were allowed to act as an alt coin something cool might be developed that the main net users might desire enough to overcome the inertia of the status quo. 

Additionally it should be considered that the time in the future when non standard transactions might be enabled  might be so far in the future when bitcoin has hit mass adoption and changing anything might require far more political negotiations between users and devs then currently. Meaning that perhaps much more proof of functionality and value as well as testing might e required. 

Dennison

Sent from my iPhone

On Jun 15, 2013, at 1:18 PM, Melvin Carvalho <melvincarvalho@gmail.com> wrote:

-------------------------------------
"sweep private key" is the missing functionality.

I agree, it would be nice to have.


On Tue, May 7, 2013 at 8:16 AM, Adam Back <adam@cypherspace.org> wrote:

-- 
--
Gavin Andresen
-------------------------------------
On Tuesday, March 12, 2013 9:47:00 AM Peter Todd wrote:

Side note: Adding fees is already possible by respending change, at least for 
miners running an Eligius branch (both 0.6.0 and 0.8.0).

Luke


-------------------------------------
Hello Everybody,

Over the last few months we have been steadily adding
functionality to MultiBit including:
+ encrypted wallets
+ sign and verify message
+ stability improvements and bug fixes.

As a result of these efforts I think MultiBit is now
suitable for the entry level Bitcoin user. I propose 
that we put MultiBit as the default desktop client 
on the bitcoin.org "Choose your wallet" page.

I think a typical new user comes to bitcoin.org from a 
google search or a Bitcoin news article. We want them to 
peruse the bitcoin.org site and try out a wallet. They 
should be able to get MultiBit up and running in a tea break. 
Then perhaps they get a colleague to send them some bitcoin 
from an Android phone by zapping a QR code. 

We say: "Welcome to the Bitcoin economy !"


There is plenty MultiBit cannot do of course. However if
in the first ten minutes we get the new user interested 
there is a good chance they will go on to explore other 
Bitcoin wallets and solutions. 

Let me know if you think this is a good idea (or not!)
and if you have any questions.

Jim

https://multibit.org


-------------------------------------
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256


Unless the government told them too.


The employer example actually shows something important: between a worker and
an employer double-spending already irrelevant. People get paid after they work
their two weeks not before, so the double-spend is already irrelevant.

However when your employer pays you on the blockchain until the transaction
confirms for someone else to accept funds from that payment they not only have
to trust you, but also the employer. Sure they could take it as "you said you
would apy me so it is your responsibility to make that happen" but that brings
a whole new level of complexity.

A scheme where you vouch for your payments with your identity can benifit from
being able to follow that chain all the way back to the last confirmed
transaction, although actually implementing this may be too complex to be
worthwhile, especially initially.


Yes. But the issue is how are you going to optmize it? By adding yet more
restrictions and limitations on those who chose to run a node or mining
operation, or by actually fixing the trust issue? We know you can do the
latter, so do not sacrifice Bitcoin's core layer in silly attempts to make
double-spends harder. Fundementally Bitcoin has exactly one way of achieving
consensus, and that is the blockchain.

It must be your right to chose what transactins you chose to mine and chose to
relay. End of story. Bitcoin is not about imposing regulation on those who
choose to use it.


Indeed. Especially for the most popular use of Bitcoin as a payment system:
buying things PayPal won't let you. In that circumstance the only leverage you
have is the protections of the blockchain and the damage you can do to the
other (often anonymous) parties reputation.
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBCAAGBQJRivRcAAoJEEWCsU4mNhiPoJcIAL7T/x5gipsCNn/w3EfhZhKo
iukP0Kc3cni/Kb6gJrOlXufIxDrX8QxEhbIIrypFbyg+xHPK8NzSd13ScKNtLgjM
w2uOI/IkgUh7VLIEZADqLO3TM5S5VDZ/A42yzTIq8MeWxaTBD1JulOc/RbljGu8V
UrF6ptxu2UXTc0eXcor1lHfJRVteTJAAba5Awa1EAHX8f2c/1FhdrnOZwfLVJIfK
/nnUgqGKc8l08knC6NnAlP39zbk/FHiZF/keWIFIzhiyXTnqKnqD096tIx6MpPci
LGafjCoXACpr1XeiSufER/z6WxTvOvCbWRw4MYrbyRkmChqMtc8a7RMEPLXhaMQ=
=Oh/p
-----END PGP SIGNATURE-----


-------------------------------------
cool paper: http://phys.org/news/2013-01-algorithm-message-dissemination-decentralized-networks.html#jCp



-------------------------------------
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256



Peter Todd <pete@petertodd.org> wrote:

Actually, that statement didn't go far enough: rejecting blocks with nVersions that you don't expect is a hard fork.
-----BEGIN PGP SIGNATURE-----
Version: APG v1.0.9

iQFQBAEBCAA6BQJSb544MxxQZXRlciBUb2RkIChsb3cgc2VjdXJpdHkga2V5KSA8
cGV0ZUBwZXRlcnRvZGQub3JnPgAKCRAZnIM7qOfwhfuGCADHB+5WZ3oSRCCYgId+
5c4rxZHjjmXXIVOlXySjoRQ20JUnGbkUqN057VlutYbWaGV7OqR0oQyzh0LGpMdL
BU9hg8XoHbyIvA0WhCfEJvFzkwseN8Ac77UxtV3leBpBkSzjqlMS9QBGU6L5rw2U
uo8Sd7bQaqkadOPode3MMWDtmmqAZaj2dN02w/8C1rRna3SrbYRVYbaVAuN9yREO
99DOGEM2V7ni+eo4sQoxP2jf8vmNzy1EuQH8v1OloPgcpxl/GkLVXzQh4ZfO1ApE
UVKBo93oT34Tce9LwZy+k8XpeCvBRJ/+QwsbAAgdVYKr8KmRcAW4oR2KN7Y0jjq4
44xU
=OaON
-----END PGP SIGNATURE-----



-------------------------------------
On 06/19/2013 02:36 PM, Adam Back wrote:

It's a cool trick but requiring a signature on each multiplier defeats
one of the purposes of a deterministic wallet.  I don't want to have to
explicitly export a whole bunch of signatures from my offline system
just to exercise this address option.  The "observer wallet" should be
able to do anything it needs to on its own, without help from the
offline wallet. 

Unless you mean that there is a one-time signature from the offline
computer that works for all addresses, that can be exported with the
observer wallet...?  If all you want to do is prove that /someone/ owns
that private key, you could send {Sign(MagicString), Multiplier}.   So
it becomes one signature operation *per wallet*, but creating new
wallets would require going back to the offline computer for that
one-time signature.  That's better than the alternative, but it's still
extra bloat for the wallet apps.

Either way, I'm not convinced that these are a problem for the specified
use cases I outlined.   In cases where you have a persistent business
relationship, they need to verify the parent public key exchange
anyway.  After that, the software doesn't technically require the
transmission of the PubKey, it only needs the Name/ID of the party and
the multiplier and it will fetch the PubKey from its data store.  Or it
is transmitted and the payer verifies it's correct.  Computing an
alternate {PubKey', Mult'} that produces the same address and then using
it in a MitM attack doesn't work here if the two parties pre-verified
the public keys. 

In the case that a business is checking whether the cashout address of a
customer is the same as the last time:  if the first payout was not
replaced by an attacker, then the business already has the correct
public key in their DB and a replacement of further payout requests will
fail validation.  If the first payout was replaced... well that could've
been done anyway (with or without this alternate form), and the customer
wouldn't have received their money and the whole process would be
flagged and terminated before further transactions.

-Alan


-------------------------------------
On Wed, Oct 23, 2013 at 10:05:56PM +0200, Martin Sustrik wrote:

What's on the wiki is mostly the work of people who aren't working on
the reference implementation, so no, you can't say that.

-- 
'peter'[:-1]@petertodd.org
0000000000000003c1d48b638b9857cb56b6fe9188a60c481fbc9b738ccb4663
-------------------------------------
on 07/09/2013 10:28 AM Mike Hearn said the following:

the point was just that "if need be" free capacity is available without
having to throw money at it. until there's no need, doesn't matter.

also hackability (and ui) should be irrelevant for the autoupdate
process (which i presume will do all kinds of checksum and sig
verification). and it's likely the autoupdates that will create very
lumpy download demand.



-------------------------------------
On Wed, Jul 31, 2013 at 6:45 PM, Roy Badami <roy@gnomon.org.uk> wrote:

I think we'll want a bitcoin address in there for a long time for
backwards compatibility.

If web browser support for arbitrary MIME types is strong enough (I
haven't tested), then a payment request can be initiated with just an
anchor tag:
  <a href="https://merchant.com/pay.php?3D2a8628fc2fbe"
type="application/bitcoin-paymentrequest">

Doing it that way saves a http round-trip.

--
--
Gavin Andresen


-------------------------------------
On Wednesday, March 13, 2013 6:27:13 PM Mark Friedenbach wrote:

Curiously enough, at least MtGox's custom implementation stuck with the 
canonical blockchain despite 0.8's accidental rule change.


No, if any other client released diverged from the consensus of all 
past/existing clients, we would do the same thing: call it a formerly unknown 
protocol rule, that this new client has a bug implementing, and be done with 
it.

The only reason this particular issue needs special treatment is because the 
implications of the new rule mean that we're up against a hard limit in the 
protocol today rather than 2 years from now.

Luke


-------------------------------------
I want to get some feedback.. I've used distributed version control 
systems for a long time, and the most useful feature is to be able
to merge two different forks.

So what's the equivalent of this for Bitcoin or other crypto-currencies?

Let's suppose that me and my friends get 'islanded' from the rest of
the internet for a week, but we still want to trade bitcoin. It would
work if there are local miners, until we reconnect.

Suppose we have the main chain (Alice), while bob is on a boat, trading
with some friends, but has no network connectivity.

When bob reconnects with Alice, a 'Merge' transaction happens where a 
miner looks at bob's forked blockchain, sees no double-spends, and 
includes BOTH chains.

Now suppose someone on bob's boat has a buggy client, or sent a 
transaction before disconnect that results in a double-spend on the 
merge.

So we have a merge conflict, which generally requires human interaction,
so bob and his friends broadcast a MERGE request with a transaction fee
sufficient to cover reconciling the double-spends, AND incentivize a 
miner to do some extra work to merge.

Thoughts everyone?

-- Troy


-------------------------------------
On 22 May 2013 16:07, Jeff Garzik <jgarzik@exmulti.com> wrote:


Two coin ecosystems could have the same genesis block


-------------------------------------
I submitted the proposal to the mailing list on July 19, 2003.

 
On 2013-10-19, at 3:29 PM, Luke-Jr <luke@dashjr.org> wrote:

-------------------------------------
Heh. People feel rises in sales tax elsewhere too. When VAT rises merchants
all raise their prices, they don't normally swallow it (or if they do, they
make a big fuss over how awesome they are).

The US system is a complete pain in the ass. You never know how much money
you actually need to pay for anything unless you happen to know the local
rate and do the multiplication in your head. There's a reason this system
is not used in big chunks of the world economy.



I would love to know how to do it. If you have an intuitive GUI in mind
please show us so other wallet authors can copy it :)
-------------------------------------
I didnt quite understand the writeup and the references were ambiguous.

But if you are talking about bitcoin/hashcash merged mining for email: it is
something I think should possible.  Of course for email the scale means
bitcoin style flood-fill and direct tiny payments are completely out of the
question, thats why hashcash itself has no communication overhead other than
a header in the mail - its only scalability limit is email itself.

Rivest's PayWord for people who dont know the reference in this context is
the observation that for a low value micro-payment, you dont mind if you
only receive a payment 1 time in k so long as the expected payment is n
after receiving n (eg satoshi sized) payments.  Eg like a penny tip jar so
long as your expected payment is correct long term (win as often as you
lose) you dont mind.  And a fair 100% payout lottery can be fun of itself.

So let say each email client sends in an email header the head of the
bitcoin hash chain, it has seen via other emails, which can be offline
verified back to the genesis hash.  Maybe some clients even have bitcoin
installed and ask the bitcoin client for the hash chain head.  The client
also generates an address on setup, and sends its bitcoin address in a
header.  If you send to a new address you dont know their address, so you
send to eg me (Adam;) as a default, or the bitcoin foundation, or an invalid
address to destroy the coin - the recipient assumes that is not the sender
as those address are in the client.  A sender can under-contribute but makes
no gain.  Under-contributing is fixable if desired (see under-contribute in
amortizable hashcash paper, but using PK decryption with recipients private
key x as its non-interactive b'=D(x,share).) 

Then clients merge mine involving the recipients bitcoin address (or one of
the default addresses).

Even if the merged stamp provdes to be an orphan, even a very old one, its
valid in a hashcash anti-spam sense, meeting the same purpose as destroyed
coin.

Maybe one can put the bitcoin hash in DNS with a 5min TTL and have mail
clients read that to reduce scope for stale mining.

In this way one can merge mine bitcoin & hashcash to the benefit of the
recipient (or some beneficiary trusted not to be paying the proceeds to the
spammer).  And in a way that scales to email scale, and does not involve
installing a bitcoin client in every client, nor mail server.

Adam

On Sat, May 11, 2013 at 12:53:42AM -0400, Peter Todd wrote:







-------------------------------------
On Tue, May 14, 2013 at 09:16:28PM +0200, Melvin Carvalho wrote:

What guarantees do you think a keyserver provides about the keys it
returns?

-- 
'peter'[:-1]@petertodd.org
0000000000000142ad32a203b1627bee8126fa4bcd940b0da3f32bf1b5b07a24
-------------------------------------
I believe a better solution would to use a github clone such as gitlab,
which sits on top of the git repo, and allows for custom code around the
BIP process. Potentially one could even build Bitcoin into such a BIP
system. If somebody wants to support a BIP he donates Bitcoins to that
proposal. Somebody who actually implements the BIP can receive some percent
of the bounty, while some percentage goes to the Bitcoin foundation. Via
such a platform one could create assurance contracts to kickstart BIP
developments or Bitcoin extensions (public infrastructure which is not part
of the core, such as opensourced exchanges).


On Mon, Oct 21, 2013 at 9:47 PM, Luke-Jr <luke@dashjr.org> wrote:

-------------------------------------
Indeed, that has been proposed but it's a dumb idea and I'm very sceptical
it will go anywhere.  Certainly no decision was made. The arguments for it
are based on some quite faulty thinking about economics. Double spend
notifications have been proposed a long time ago, I believe Matt has
indicated some interest in implementing them and that is the right way to
go.
On 20 May 2013 18:57, "Pieter Wuille" <pieter.wuille@gmail.com> wrote:

-------------------------------------
On Fri, Apr 19, 2013 at 06:48:11PM -0700, Jeremy Spilman wrote:

Note that with OP_DEPTH we can remove the small chance of the payee
vanishing and putting the funds in limbo:

    <height + n> OP_DEPTH OP_LESSTHAN
    IF 2 PK1 PK2 CHECKMULTISIG
    ELSE PK1 CHECKSIG
    ENDIF

Though that shows how to implement OP_DEPTH as a true soft-fork we're
probably best off doing it as part of a script v2 using the soft-fork
mechanism I outlined before when talking about fidelity-bonded ledgers.
(best to do MAST (merklized abstract syntax tree) support at the same
time)

-- 
'peter'[:-1]@petertodd.org
-------------------------------------
On Sat, Oct 26, 2013 at 10:25:06AM +1000, Gavin Andresen wrote:

Um... yeah. Note how I said on your original pull-req that I'd be happy
to see it merged once the bugs were fixed (95% of the transactions it
produced had zero fees even with zero priority txins for some reason)
and you added a lower bound on fees in the wallet code as a "do no harm"
measure.

In fact, I think I wasn't being conservative enough given that it
affects relaying of transactions. Instead add both lower and upper
bounds to what the wallet and relaying code uses for 0.9.0 and it'd
probably be safe to merge.  We can get relax those "training wheels" in
0.9.1 or 0.9.2 once we've had some real-world experience with how the
estimation system works in practice, particularly for how it affects
relaying.

-- 
'peter'[:-1]@petertodd.org
00000000000000036253c7a02061121b6a12484278a3c472a22e47a821c28a69
-------------------------------------
Hi!

Gregory, thank you for your time and answers. Just maybe to clarify
where Nick is coming from, there are two previous articles:

http://courses.ischool.berkeley.edu/i290m-ocpp/site/article/nmerrill-assign1.html
http://courses.ischool.berkeley.edu/i290m-ocpp/site/article/nmerrill-assign2.html


Mitar

On Sat, Oct 19, 2013 at 1:40 PM, Gregory Maxwell <gmaxwell@gmail.com> wrote:



-- 
http://mitar.tnode.com/
https://twitter.com/mitar_m


-------------------------------------
Low light shouldn't be an issue for QRcodes generated by phones. They have
backlit screens that should always be bright enough. I can see how it might
be an issue for printed codes.

If your phone has no Bitcoin app installed then being redirected to an
invoice page is pretty useless, you still won't be able to pay the bill no
matter what (where do you get the money from?). If they are just raw HTTP
URLs then it means the effect of scanning a QRcode with a standalone
scanner app is different to scanning it inside the wallet, which is unlike
all other uses of QRcodes I know of. So I'm not really convinced by that UX
yet. Perhaps we can thrash it out in Amsterdam. Right now I'm thinking
QRcodes should always contain bitcoin URIs.


On Wed, Sep 25, 2013 at 4:31 PM, Jeff Garzik <jgarzik@bitpay.com> wrote:

-------------------------------------
The key in the message was used in my last announcement, so that
establishes continuity there.

But regardless, all mails I send are signed automatically by Gmail using
either the gmail.com consumer key (for my posts to this list) or the
google.com corporate key (for my posts to the bitcoinj lists), see
dkim.orgfor more details on this. Whilst this is not signing in the
GPG web of
trust sense, realistically the Gmail DKIM keys are much safer than any key
I could create/maintain, and my ability to sign mail as hearn@google.com is
controlled by hardware second factors and various other rather intense
security systems I can't discuss.

I've considered just not having the additional Bitcoin-key based signatures
at all, but it would help keep continuity in the case that I leave Google
or if there's a DKIM key rotation.



On Wed, Apr 10, 2013 at 10:58 AM, Andy Parkins <andyparkins@gmail.com>wrote:

-------------------------------------
One approach you could use would be to use bitcoin signing on 
a list of the build artifacts together with their SHA256 hashes.

If you have a look at the MultiBit release notes you get the 
overall idea:
https://multibit.org/releases/multibit-0.5.13/release.txt

Currently these aren't machine readable but you can imagine
having a machine readable statement with:
+ a list of the files in the build
+ their SHA256 hashes
+ the above bitcoin signed by multiple signatures e.g. 2 of 3

The client can then download the file, check the signature,
check the hashes and knows which files to download.
The acceptable Bitcoin addresses for signatures would
be a whitelist in the client code.





On Mon, Aug 5, 2013, at 05:47 PM, Alan Reiner wrote:


-- 
https://multibit.org    Money, reinvented


-------------------------------------
I wrote an article intended for a broad/non-developer audience on a few
Bitcoin privacy topics:

- P2P connection encryption
- Address re-use/payment protocol
- CoinJoin and merge avoidance

I don't think there's anything much new here for people who were involved
with the BIP70 design discussions, but it may prove a useful resource when
talking about privacy features in the payment protocol. Specifically the
ability to request multiple outputs and submit multiple transactions that
satisfy them. The article elaborates on how to use that feature to achieve
some useful privacy outcomes.

I also analyze what using SSL for P2P connections would buy us and what it
wouldn't.

https://medium.com/p/7f95a386692f
-------------------------------------
Couple of things I just thought about:

1- Presume server should only sweep with two (or more, see below) revocation certificates being present
2- Need to insert something in the flow so that Alice can verify that the uploaded key is actually Bob's (and perhaps vise-versa, given an extremely dedicated attacker with a fast connection?).

Is there a way to do #2 without creating yet another transaction? Admittedly I am still really puzzled about the accessibility of public keys in Bitcoin!

Please remember that the idea is to have two wallets securely exchange a packet of metadata about a transaction beyond the scope of Bitcoin itself (a name, perhaps a small photo, etc) in order to increase usability. This will be my last post here on the topic except to reply in case anyone else contributes.

-wendell

grabhive.com | twitter.com/grabhive | gpg: 6C0C9411

On Sep 16, 2013, at 4:05 PM, Wendell wrote:




-------------------------------------
I think the one thing that SSL does provide is some protection against ARP
or DNS poisoning to trick the user into downloading from a different site.

The PGP WoT surrounding bitcoin or OS related ISOs be weak - I am not sure
if I could even check it directly myself despite spending a few hours
tracking down keys and checking fingerprints of biz cards of core devs I met
in person, then that is a relevant point.

Adam

On Sun, Dec 08, 2013 at 11:25:24AM -0800, Gregory Maxwell wrote:


-------------------------------------
Embedded consensus systems such as Mastercoin face the risk that the
data they need to embed in the host consensus system will be subject to
censorship. This censorship can take two forms: whitelists and
blacklists. The former we can't do anything about, however the latter
requires someone to identify the data-carrying transactions that are to
be blacklisted.

Embedding data steganographically in transactions is known to be
possible in ways that can-not be detected. Even if P2SH^2 (1) is
implemented data can be hidden in pubkeys in P2SH scriptSigs, either by
using unused pubkeys in CHECKMULTISIG transactions with a simple
transform(2) to turn arbitrary data into valid-looking pubkeys, or with
some ECC math even usable pubkeys can have data hidden in them.(3)

However these methods are unsuitable if the data needs to be provably
made public; without the encryption key the data is securely hidden.
Almost all consensus systems rely on proof-of-publication(4) and even if
the encryption keys are later made public - perhaps by broadcasting them
on a P2P network - we've only shifted the problem to proving that the
keys were released. Of course, if we then publish them via our host
consensus system, *that* act of publishing can itself be censored!

Timelock cryptography offers a solution to this problem. Let S(n, k) be
a sequential-hard strengthening function that takes key k and number of
rounds n, outputting k'. A suitable S() might be the scrypt function.
Let E(d, k) be a symmetric encryption algorithm. Finally let H(m) be a
cryptographic hash function.

To hide data D in a transaction we set k to some random and publicly
known value in the transaction and compute k'=S(n, k) and D'=E(D, k')
Then D' is hidden in the transaction, perhaps in an unused pubkey of a
CHECKMULTISIG scriptPubKey.

Our intended audience can also calculate k' from the public data, and
thus recover D in time ~t, thus we know that after time ~t has elapsed
all participants in the system can reliably come to consensus.

However miners and other parties who may wish to censor D face a
dilemma: If they repeat the calculation for every transaction that may
be hiding data they delay all transactions for all users. In addition
miners have a financial incentive to defect and mine transactions
without checking for hidden data.


Practical Considerations
========================

Efforts should be made to limit the scope of possible transactions as
much as possible to reduce the computation required, e.g. by restricting
the search space to only transactions with scriptPubKeys starting with
some short prefix. This is a balance between computation and censorship
resistance.

Consideration needs to be made as to how the data will be validated as
part of the embedded consensus system, for instance via a checksum or
cryptographic signature.

Participates in the embedded consensus system should share k' keys among
each other to reduce overall effort. This ties back to validation: it
must not be possible to distribute a fake k' undetectably.

Picking n, and thus the time taken, is a balance. Also there should be
some mechanism to update n as technological improvements warrant. Along
those lines this method works best when t can be large and immediate
consensus is not required. A suitable use-case could be a key-value
consensus system for name information where mappings are infrequently
changed.

The source of k should be such that k' can be computed in advance,
however only by the sender. For instance simply using the first txin
hash allows the attacker to compute k' in advance themselves. A better
choice would be the first (real) pubkey in a scriptPubKey, a value we
can both compute in advance, yet is not known publicly.


Censorship resistant voting
===========================

With due care the scheme can be used to allow for censorship-resistant
voting. While previously it was believed that miners would inevitably be
able to censor any voting scheme - with the exception of certain special
cases(5) - provided that the financial incentive to collect fees
outweighs the incentive to not count votes we have strong censorship
resistance with strong consensus in a fixed amount of time.


1) Gregory Maxwell, [Bitcoin-development] To prevent arbitrary data
   storage in txouts â€” The Ultimate Solution,
   https://www.mail-archive.com/bitcoin-development@lists.sourceforge.net/msg01987.html

2) Peter Todd, Re: MasterCoin: New Protocol Layer Starting From â€œThe
   Exodus Addressâ€,
   https://bitcointalk.org/index.php?topic=265488.msg3377058#msg3377058

3) ByteCoin, Untraceable transactions which can contain a secure message
   are inevitable, https://bitcointalk.org/index.php?topic=5965.0

4) Peter Todd, [Bitcoin-development] Disentangling Crypto-Coin Mining:
   Timestamping, Proof-of-Publication, and Validation,
   http://www.mail-archive.com/bitcoin-development@lists.sourceforge.net/msg03307.html

5) John Dillon, Proposal: We should vote on the blocksize limit with proof-of-stake
   voting, https://bitcointalk.org/index.php?topic=230864.0

-- 
'peter'[:-1]@petertodd.org
0000000000000001cdaabe80320d14ab5907997ec6ad12eaaa304941c34fc8bd
-------------------------------------
Merge mining lets Bitcoin miners support or attack an alt-coin without any  
additional cost for their proof-of-work.

Since bitcoin miners have to install software to build and claim blocks in  
the alt-coin, the percentage of bitcoin hashing power reflected toward the  
alt-coin will follow some adoption curve based on convincing bitcoin  
miners to opt-in.

Depending on where you are on that adoption curve or 'participation rate',  
you need [a lot] less than 51% of of total Bitcoin hashing power in order  
to 51% attack the alt-coin.

But there's so much 'dry powder' out there (GPUs), I wonder if *not*  
supporting merge-mining is any better? At least the attacker has to do  
some unique PoW, so you hope it's costing them something. Relatively large  
amounts of hashing can definitely be deployed on target with zero startup  
cost, and perhaps very little runtime cost (botnets).

I think the absolute cost of the PoW is very likely *not* the determining  
factor in preventing a 51% attack on all but one or two blockchains  
currently in existence.

Do I understand correctly, the question here is mostly a matter a game  
theory?

On Mon, 30 Dec 2013 17:14:05 -0800, Luke-Jr <luke@dashjr.org> wrote:




-------------------------------------
On Tue, Jul 23, 2013 at 11:00:24AM +0100, Andy Parkins wrote:

Read my proposal for "Partial UTXO" mode:
http://www.mail-archive.com/bitcoin-development@lists.sourceforge.net/msg02511.html


Actually the really scary thing about partial UTXO mode is miners can
get away without keeping the entire chain provided they don't (often)
try to mine transactions spending UTXO's that they haven't verified
themselves.

They can get away with accepting blocks without checking that the UTXO's
exist, at least until enough miners do so that someone creates an
invalid block and the majority of hashing power never notices. Remember
that only with a complete UTXO set can you know that a UTXO *doesn't*
exist.

We're going to have to force miners to prove they possess the full UTXO
set in the future or the security of Bitcoin will be seriously
threatened.


How do you know they actually are someone else?


Do you think you have SPV or full security in that situation?

Do you know the difference?

-- 
'peter'[:-1]@petertodd.org
0000000000000070f3d118303a611e1f44ea6482a3b59a16056e69af088b1ffa
-------------------------------------
It's expected to be there, yes.


On Mon, May 6, 2013 at 9:56 AM, Addy Yeow <ayeowch@gmail.com> wrote:

-------------------------------------
unfortunately my winter has proven a complicated series of significant life
events - new work, etc - which sees me with little free time to help out.
sorry.


Arklan

----------
As long as there is light, the darkness holds no fear. And yet, even in the
deepest black, there is life. - Arklan Uth Oslin

I want to leave this world the same way I came into it: backwards and on
fire. - Arklan Uth Oslin


On Wed, Apr 24, 2013 at 9:22 AM, Gavin Andresen <gavinandresen@gmail.com>wrote:

-------------------------------------
On 11/05/2013 08:03 PM, Drak wrote:
I don't think that will work but the bit test I suggested won't work either.

Alice can calculate the hash of her blockhash and if the block to mine 
is chosen based on the lowest result she will know the probability Bobs 
block will be used.  This complexity doesn't change anything.  If hers 
is more than 50% likely to be used she should mine the next block 
otherwise its best to work to find a better current block.

But if the block determination takes into account the current difficulty 
we can prevent Alice from knowing if Bobs or any block she mines is more 
likely to win.

Assuming
a = hash of block A
b = hash of block B
difficulty = current difficulty such that A < difficulty and b < difficulty

The following code could be used to determine if the higher or lower 
block should be chosen

uint256 choose_block(uint256 a, uint256 b, uint256 difficulty)
{
   bool choice = false; // false for lower hash, true for greater hash
   uint256 am = (a + d/4) % difficulty;
   uint256 bm = (b + d/4) % difficulty
   if (a + d/4 >= d)
     choice = b > a || b < am || bm > a || bm < am;
   else
     choice = (b > a && b < am) || (bm > a && bm < am);
   return choice ? (a > b ? a : b) : (a > b ? b : a);
}

The basic idea is to find a range over 0 to difficulty starting at A and 
B that is 1/4 of the range of the difficulty.  If the two ranges overlap 
which should be 1/2 of the time pick the greater hash is used otherwise 
the lower hash.

There is likely a cleaner solution but this demonstrates the basic idea.

You could use the hash of the blockhash and just set the difficulty to 
the maximum hash value which would really just end up removing all the 
modulus stuff and make the code simpler.  But that code requires much 
less computation that any cryptographic hash.

I think this is preferable to each node randomly picking a block to mine 
on as the paper suggests.  This should be completely unpredictable but 
deterministic so all the miners should end up working on the same block.


-------------------------------------
On 07/09/2013 08:32 AM, Nick Simpson wrote:


By way of endorsement, at the GNU Radio Project we switched to
CloudFlare's free service tier a few months ago.  We host on AWS EC2 our
own web servers, downloads, and git repositories.  CloudFlare has
reduced our bandwidth bill by about 50%, with very little pain.

-- 
Johnathan Corgan
Corgan Labs - SDR Training and Development Services
http://corganlabs.com

-------------------------------------
On Wed, Mar 13, 2013 at 11:27:13AM -0700, Mark Friedenbach wrote:

The protocol is whatever the network enforces - and that is some mix of versions of the
reference client right now, but doesn't need to remain that way.

I would very much like to have a text book of rules that is authorative, and every client
that follows it would be correct. Unfortunately, that is not how a consensus system works.
All (full) clients validate all rules, and all must independently come to the same
solution. Consensus is of utmost importance, more than some theoretical "correctness".
If we'd have a specification document, and it was discovered that a lot of
nodes on the network were doing something different than the document, those nodes would
be buggy, but it would be the specification that is wrong.

That is what happened: 0.7 and before had a bug, but 0.8 was wrong for not following the
rules of the network (which I hate to say, as I'm responsible for many changes in 0.8).

As said in another thread, the problem in the old versions needs fixing (this would even
be the case if no 0.8 existed at all, and no fork risk existed at all). But let's please
do it in a way we can all agree about, in a controlled fashion.

-- 
Pieter


-------------------------------------
Why does demurrage even still come up? The base rules of Bitcoin will
not be changing in such a fundamental way.

With regards to trying to minimize the size of the UTXO set, this
again feels like a solution in search of a problem. Even with SD
abusing micropayments as messages, it's only a few hundred megabytes
today. That fits in RAM, let alone disk. If one day people do get
concerned about the working set size, miners can independently set
their own policies for what they confirm, for instance maybe they just
bump the priority of any transaction that has fewer outputs than
inputs. An IsStandard() rule now that tries to ban micropayments will
just risk hurting interesting applications for no real benefit. It's
like trying to anticipate and fix problems we might face in 2020.

There are lots of less invasive changes for improving scalability,
like making transaction validation multi-threaded in every case,
transmitting merkle blocks instead of full blocks, moving blocking
disk IO off the main loop so nodes don't go unresponsive when somebody
downloads the chain from them, and finishing the payment protocol work
so there's less incentive to replicate the SD "transactions as
messages" design.


-------------------------------------
Bitcoin-Qt on master does send it now although it doesn't affect anything,
but as old pre-filtering versions will continue to exist, you'll always
have to be able to deserialize version messages without it.

Bitcoin version messages have always had variable length, look at how the
code is written in main.cpp. If you didn't experience issues until now all
it means is that no sufficiently old nodes were talking to yours.

The standard does not say it should appear. Read it again - BIP 37 says
about the new version message field:
If false then broadcast transactions will not be announced until a
filter{load,add,clear} command is received. *If missing or true*, no change
in protocol behaviour occurs.


On Wed, Jun 19, 2013 at 12:33 PM, Turkey Breast <turkeybreast@yahoo.com>wrote:

-------------------------------------
Hi everyone,

I made a post on the BitcoinTalk forums <https://bitcointalk.org/index.php?topic=329229.0> outlining how the Payment Protocol could be extended with optional vCard support to increase the usability of Payment Protocol for user-to-user transactions and improve the user experience in wallets supporting PP.

Ive outlined the concept in as much detail as my feeble brain can handle, drawing on BIP 0070 itself and Mike Hearns Payment Protocol FAQ. I know there is interest in contact exchange functionality from the Hive team, so Im hoping this will begin a discussion on how we can make wallets more friendly in a standard way.

Please read, digest, and let me know if you have any feedback.

Thanks,

Taylor Gerring



-------------------------------------
On Sun, Jun 02, 2013 at 01:35:10PM -0400, Jeff Garzik wrote:

Yeah, and Bitcoin sacrifices are kind of an odd middle ground there.
It's been suggested to make provably unspendable OP_RETURN IsStandard()
only if the txout value is zero, but considering the sacrifice use-case
I'm thinking we should allow people to throw away coins in a
non-UTXO-bloating way if they choose too.


Indeed, just recognize that those disincentives must be implemented in a
way that makes doing the less-harmful thing is to your advantage. For
instance people keep arguing for OP_RETURN to only be allowed as one
txout in a tx, which puts it at a disadvantage relative to just using
unspendable outputs. Similarly because people can play OP_CHECKMULTISIG
games, allow as much data as can be included in that form, 195 bytes.


Of course, you can't block everything:

----- Forwarded message from aitahk2l <aitahk2l@tormail.org> -----

Date: Sun, 02 Jun 2013 02:40:10 +0100
From: aitahk2l <aitahk2l@tormail.org>
To: pete@petertodd.org
Subject: Your timestamper

We spoke a few months back and I sent you some funds to run your
timestamper.

I'm letting you know we're going back to unspendable txout timestamps
for our needs. Your service is great, but I think you have written it
prematurely. Like you said in your recent bitcoin-development post on
sacrifices if the technology enables a use, people will use it. 
Inefficient timestamping is one such use and threatens the blockchain
with unlimited bloat, but from what I hear from Gavin he doesn't see 
decentralization as particularly important.

You really should turn off your OpenTimestamps servers. They mislead
people into a sense of scalability that just isn't there. You'll see 
some of our efforts at 1MBGavinWuiJCF6thGfEriB2WhDD5nhB2a soon;
frankly I think he is the biggest threat Bitcoin faces in the long
term and will back us all into a scalability corner with no good
solutions.

Feel free to forward this message to others.


----- End forwarded message -----

Seems legit - traffic on my timestamper is significantly reduced from
what it was before. Incidentally, I've left the opentimestamps client
deliberately broken for months now to see if anyone used it, and other
than this guy I've had zero bug reports.

-- 
'peter'[:-1]@petertodd.org
0000000000000046da2c6f02bf57f3bdc48a08388e0030fc4490f5fc048516e6
-------------------------------------
On 03/12/2013 12:39 AM, Mike Hearn wrote:
I'm thinking that (assuming 2000 tx/s and UTXO growing 50 GB/year) a 
malicious miner could create 1 GB of unspent outputs and then spam nodes 
with valid transactions. This would not be dangerous, if UTXO were 
smaller and fit on RAM.

Thank you for reading and correcting me :)


-------------------------------------
On 8 December 2013 20:50, Gregory Maxwell <gmaxwell@gmail.com> wrote:


Simple verification relies on being able to answer the email sent to the
person in the whois records, or standard admin/webmaster@ addresses to
prove ownership of the domain. This is a good point to note -
bitcoin.orgshould not get a simple certificate, but one that requires
identify
verification for the person/org who is applying. They are more expensive.



You cannot MITM SSL connections - it will cause a browser warning.
I do not have the means, but it has been demonstrated some people are
performing BGP redirections, daily, and on a massive scale... and it's a
problem, because BGP was designed on implicit trust.




You are right that the CA system is not full-proof, one CA was caught
issuing a bogus certificate on purpose a while back, I forgot the name but
it resulted in CA certificate revokation and the entire company being
blacklisted from Firefox and Google Chrome forever - basically a summary
corporate execution. I personally imagine the CIA or other state actor
could just quietly buy up an already trusted CA and abuse them. But it's
clear, people are watching, and if a CA is caught once, that's the end of
their business forever: Firefox and Google demonstrated that. The strategy
is possibly too expensive and risky to carry off which is maybe why they
don't do it.

What has been noted with all the Snowden leaks, and with the Lavabit case,
the security agencies did not get bogus certificates issued, they still got
court orders, or other deception to get hold of the encryption certificates
of their targets instead of issuing their own so they could listen in.

The CA system is not full proof, but it is what we have. Similar arguments
have been made against the use of identity certificates for bitcoin, but
that hasnt stopped it's inclusion in the bitcoin payment protocol.

Anyway, I take your points, but this is an area I am quite passionate about
so it's important for me to be clear.

Regards,

Drak
-------------------------------------
Not only does the size of the proof grow endlessly as the coin is
passed around, the size of the UTXO set grows endlessly as more and
more of the already spent coins cannot be proven to have been spent
because the proofs are passed out-of-band. I never said the idea was
good, just interesting :)

Thanks,
Caleb


On 05/15/2013 10:45 PM, Gregory Maxwell wrote:



-------------------------------------

Le 31/10/2013 12:18, slush a crit :

even if metadata is only 8 bits ? (that's about 256 hashes)



-------------------------------------
attacker will redirect refunds
to the payment_url (maybe the customer's machine crashes during the HTTPS
handshake)
(1).

I think that's oversimplifying.  (1) is theft, (2) is payment processing.
Reliable payment processing with refund handling is not simple nor free,
but it should be secure. The cost of (2) depends primarily on the failure
rate, which we can only guess at this point, and secondarily on how much
manual intervention is required to recover.

(2) is perhaps more of a problem if wallets broadcast before POST. It's
trading one failure mode (funds sent but not claimed) for another (coins
marked as spent but not). Either way, you fix it by just retrying the POST.
But only with Transmit-After-ACK can the payer's wallet detect the failure
automatically, and even recover automatically (simply unlock the outputs,
or to be sure, spend them back to self).

Since merchants get to choose whether to have a POST url, they get to
decide if the cost of keeping their server up is worth it. I think
eventually there are enough benefits to Transmit-After-ACK that it will
become a supported use case.

Thanks Mike for explaining the threat.

[Aside] I was reading Peter's fidelitybond writeup for his idea on contract
value accounting, and he points to Stephan's post from last September on
payer-encoded metadata (
https://bitcointalk.org/index.php?topic=108423.msg1178438#msg1178438) which
Timo applies here. As a relative newcomer, this is what I am loving most
about Bitcoin.
-------------------------------------
On Mon, Mar 11, 2013 at 12:01 PM, Jorge Timn <jtimonmv@gmail.com> wrote:






Storing an unspent transaction in the block chain costs money because we
can't prune it. However, it would completely destroy confidence in Bitcoin,
as far as I can see. It makes sense economically, but it  isn't feasible if
we want to maintain people's confidence in Bitcoin.

I like Jeff's proposal of letting an alt-coin implement this. If it gets to
the point where Bitcoin can't function without this functionality, it'll be
a lot easier to make the transition, instead of now, when it's not really
needed, and the trust in Bitcoin really isn't that great.

/Rune



-------------------------------------
On 14 November 2013 22:00, Alan Reiner <etotheipi@gmail.com> wrote:


The fed was reduced to 0.0001/kb a while back...

Drak
-------------------------------------
As discussed endlessly data in the UTXO set is more costly, especially
in the long run, than transaction data itself. The fee system is per KB
in a block, and thus doesn't properly capture the long-term costs of
UTXO creation.

It's also been suggested multiple times to make transaction outputs with
a value less than the transaction fee non-standard, either with a fixed
constant or by some sort of measurement.

https://github.com/petertodd/bitcoin/tree/block-uneconomic-utxo-creation

The above patch that implements the latter approach, and thus will not
accept into the mempool any txout whose value is <= the fee per KB paid
by the transaction. That fee is then bounded between MIN_TX_FEE and
COIN_DUST, 0.0005BTC and 0.01BTC respectively. The former due to the
fact that the fee can be zero, and the latter so that delibrate high-fee
creation is still allowed. (provably unspendable txouts can of course be
handled specially later)

By basing the calculation on the fee per KB the transaction itself pays
the limit automatically adjustes as the market for blockchain space
changes, and the value of Bitcoins change.

Since scriptSigs greater than 500 bytes are non-standard the marginal
bytes required to spend a txout is always less than 540 bytes. For
standard transactions the marginal cost is usually just a 80+1 byte
signature, and a 33+1 byte pubkey, or 155 bytes. Thus the choice of the
fee for 1000bytes allows a margin to ensure a net positive return, even
if tx fees become more expensive. In particular I think a reasonable
margin is important to deter users from simply deleting wallets filled
with dust-spam, something which gets reported as happening frequently.
It also protects users who do not understand how Bitcoin works from
thinking that repeated small amounts of coins collected from sites
giving away small amounts will add up to an amount that they can
usefully use, and equally protects the long-term health of the network
from those services.

By basing the threshold for what is considered a too-low output value on
ensuring that spending outputs has a net positive return, rather than
trying to come up with some sort of model of UTXO cost, we make the
logic significantly easier to reason about. In particular, it means that
Bitcoin clients can use an unchanging rule based on fees paid, rather
than some constant subject to change as the economics of UTXO costs
change. Note how the total cost of maintaining the UTXO set is
determined by the number of validating nodes, and what that number will
be in the future heavily debated with a possible range spanning many
orders of magnitude.


Short-term
----------

SatoshiDice will have to change their betting system to have their
"failed bet" messages return enough coins to be economically spendable.
It's notable that Satoshidice seems to have already changed their system
to return what appear to be randomly chosen amounts, likely to get
around the users who have applied custom patches to consider 1 satoshi
output values non-standard. Because this patch does not block
SatoshiDice, nor do I expect it to result in less SatoshiDice traffic, I
expect pool operators to be open to applying it.

Other services such as CoinAd will also have to make changes to either
collect multiple payments together, or use off-chain transactions. I've
spoken with a person who runs one of these sites, CoinAd IIRC, and he
was open to opening an instawallet or easywallet account and using it to
do direct off-chain transactions for users who wanted to be paid
immediately.

Part of the patch includes code that sends change to fees if creating a
change output would produce an uneconomic txout. This will likely
occasionally generate confusion from users, especially as it will only
happen if they try to send almost all of their wallet.


Security
--------

For a non-upgraded client, accepting zero-confirmation transactions
becomes more risky as the change represents yet another way of creating
a transaction that won't be mined. Fortnately the nLockTime problem has
served to warn people yet again about those dangers.


Long-term
---------

If fees required on transactions go up in numerical value, the patch
adapts the minimum output size as required.

If fees go down numerically, the minimum output size is also adjusted as
required. If they go down sufficiently that MIN_TX_FEE requires
changing, only one constant needs to change. In particular, the
MIN_RELAY_TX_FEE blocks relaying small output values with small fees
anyway, and it's set to one fifth of MIN_TX_FEE. Additionally most
miners follow the MIN_TX_FEE default, so using that value ensures that
the logic holds true for the more likely case that fees numerically stay
stable or rise. In any case, Bitcoin will never be a good
microtransaction system.


Ouputs representing other assets; "colored coins" and "smartcoins"
------------------------------------------------------------------

The colored coin ideas being passed around on the forums often used
fixed representations of assets, that is 1 bond unit == 1 satoshi or
similar. Since proving the state of a colored coin to an SPV client
requires providing the full transaction history changing these protocols
to allow a floating numerical ratio Bitcoins to assets is always
possible by allowing for ordinary, non-marked, transaction inputs and
outputs to add or remove coins as required. This has the additional
advantage of making divisibility easy.

If the asset itself is worth less than a tx fee, moving it will still
incur a net loss. Equally if the asset is worth more than a tx fee, the
quickly the burden of requiring an additional tx fee to be locked up by
the asset becomes minor.



Testing Required
----------------

To be written after more consensus. Essentially a UI testing script, and
unittests in wallet_tests.cpp need to be written.

-- 
'peter'[:-1]@petertodd.org
-------------------------------------
On 1 June 2013 21:30, Peter Todd <pete@petertodd.org> wrote:


Sorry if this is a stupid question, but why would someone want to sacrifice
their bitcoins?


-------------------------------------
https://bitcointalk.org/index.php?topic=337294
Since 0.8.x many MacOS X users have been experiencing periodic leveldb data
corruption issues.  While not fatal, it is very time consuming to recover
from this corruption and upsetting that it happens often for some users.
 There have been three commits in Bitcoin that attempted to fix this, one
fsync fix in leveldb, one in util.h, and a leveldb version upgrade to 1.13.
 My guess is that one of these commits fixed other corruption, but there
remains at least one mysterious corruption issue on Mac where leveldb is
corrupted after a clean shutdown of Bitcoin-Qt.  After 5+ months we still
do not know why some users never see corruption while it happens often for
others.

Gavin has pledged 5 BTC, and Litecoin Dev pledges 200 LTC to start this
bounty.  This thread has public addresses for Mac users to donate to
increase the incentive to fix this issue sooner.

To help please contribute detailed bug reports or links to more relevant
background information pertaining to this corruption issue.

https://bitcointalk.org/index.php?topic=320695.0
For testing purposes, please use either Bitcoin git master or Bitcoin 0.8.5
OMG3, both of which contain all of the relevant leveldb fixes.  Testing
without those fixes will not be helpful at this point.

Warren
-------------------------------------
btw with nodes for transport security you might use self-certifying keys. 
Referring to Zooko's triangle, then the key is the node identity.  Similar
to a bitcion address.  So then just another ECDSA key and use emphemeral
ECDH for transport authenticated with the nodes key.

Maybe there can be some value to reputation to a node - eg it can charge a
higher micropayment for its p2p network services, a node with a good
reptuation could charge a higher micropayment for relaying (though bitcoin
itself probably doesnt like micropayments as bloating the transaction log).

Another ZKS era idea I had was to have a gossip protocol for users to find
out what other people think about the trustworthiness and reliability of
nodes.  If that info is distributed via gossip over multiple channels and
network connections over time, and kept in something like a gnutella host
cache (just a cache of random info with some eg random replacement policy)
it becomes very hard for a dishonest node to censor evidence of its low
reputation.

It is best as Gregory said to be able to directly prove, and punish by
block-chain validation, because that is more smart-contract like.  Bisbehave
and nodes wont connect to you or lose somehow.

But what exactly could you prove about a node?  You dont really know if a
node is an originator for a double spend, it could be relay.  And for
privacy and security you cant expect the node to use its coin address
private key.

Hmm: maybe one could use a Brands private credential with offline double
spend detection, with the reputation but not coin address of the node
disclosed, and the nodes coin address embedded in the proof.  Each node
could be is own CA, providing a ZKP.  If the node ever double spends a coin,
it loses its reputation as the coin address is revealed.

btw another old idea was to require proof of the existance of the private
key of a high value coin in the double-spend revealed information.  Then
basically to get a higher good-behaviour bond, the node ties up more coins,
and if a node cheats, the first person to discover this collects the
forfeited good behaviour bond.

Adam

ps I have an opensource openSSL based Brands (& Chaum) credential library at
http://www.cypherspace.org/credlb/ I didnt actually implement the ECDL
version, just the DL version, but that is not so hard, and its on my todo
list.  (There is also a strong RSA assumption version, also not
implemented).

On Mon, May 06, 2013 at 11:01:22AM -0700, Gregory Maxwell wrote:


-------------------------------------
I wonder if you need to take into consideration the fact that there might
be another "bad" pool (in the 1-Q part of the network) running the same
strategy and also holding on to two blocks of their own? Once they find
their third block before you do, then your 2 blocks lead is gone instantly.


--
Jannes Faber
Elevate BV

t: +31 20 636 9977
m: +31 6 5342 9669
j.faber@elevate.nl


On 7 November 2013 04:44, Peter Todd <pete@petertodd.org> wrote:

-------------------------------------
On 03/12/2013 12:19 AM, Mike Hearn wrote:
Isn't there danger of an attack if UTXO is not stored in fast storage?


-------------------------------------
On Wed, Nov 13, 2013 at 01:34:07PM +0100, Michael Gronager wrote:

How did you get those numbers exactly?

Also fee per txn is *not* useful and we really shouldn't quote it so
that newbies reading this stuff get the right understanding.

-- 
'peter'[:-1]@petertodd.org
00000000000000075ed91531e07d2045b5823da050fe373bde7bb363965e44ae
-------------------------------------
Bitcoin version 0.8.0 release candidate 1 is now available from:
  http://sourceforge.net/projects/bitcoin/files/Bitcoin/bitcoin-0.8.0/test

This is a major release designed to improve performance and handle the
increasing volume of transactions on the network.

Please report bugs using the issue tracker at github:
  https://github.com/bitcoin/bitcoin/issues

Release-candidate 1 notes:

The OSX binary reports its version as "0.8.0rc1-1-gba1d080-beta" due to
issue https://github.com/bitcoin/bitcoin/issues/2285 . This will be fixed
before the final 0.8.0 release.

The Windows binaries could not be reproducibly built, due to issue
https://github.com/bitcoin/bitcoin/issues/2288 . This will also be fixed
before the final 0.8.0 release.



How to Upgrade
--------------

If you are running an older version, shut it down. Wait
until it has completely shut down (which might take a few minutes for older
versions), then run the installer (on Windows) or just copy over
/Applications/Bitcoin-Qt (on Mac) or bitcoin-qt (on Linux).

The first time you run after the upgrade a re-indexing process will be
started that will take anywhere from 30 minutes to several hours,
depending on the speed of your machine. If you have enough
memory, running with the -dbcache setting (e.g. -dbcache=1000 )
may make re-indexing faster.

Special notes for release candidate 1:
--------------------------------------

If you helped test pre-release versions, there are two changes that you
should be aware of:

1. Subdirectories in the data directory changed names; to avoid re-indexing
the blockchain, rename:
  mv $DATADIR/blktree $DATADIR/blocks/index
  mv $DATADIR/coins $DATADIR/chainstate

2. The "undo file" format changed; if you see errors at startup during block
validation re-run with the -reindex flag to fix them.

Incompatible Changes
--------------------

This release no longer maintains a full index of historical transaction ids
by default, so looking up an arbitrary transaction using the getrawtransaction
RPC call will not work. If you need that functionality, you must run once
with -txindex=1 -reindex=1 to rebuild block-chain indices (see below for more
details).

Improvements
------------

Mac and Windows binaries are signed with certificates owned by the Bitcoin
Foundation, to be compatible with the new security features in OSX 10.8 and
Windows 8.

LevelDB, a fast, open-source, non-relational database from Google, is
now used to store transaction and block indices.  LevelDB works much better
on machines with slow I/O and is faster in general. Berkeley DB is now only
used for the wallet.dat file (public and private wallet keys and transactions
relevant to you).

Pieter Wuille implemented many optimizations to the way transactions are
verified, so a running, synchronized node uses much less memory and does
much less I/O. He also implemented parallel signature checking, so if you
have a multi-CPU machine all CPUs will be used to verify transactions.

New Features
------------

"Bloom filter" support in the network protocol for sending only
relevant transactions to
lightweight clients.

contrib/verifysfbinaries is a shell-script to verify that the binary downloads
at sourceforge have not been tampered with. If you are able, you can help make
everybody's downloads more secure by running this occasionally to check PGP
signatures against download file checksums.

contrib/spendfrom is a python-language command-line utility that demonstrates
how to use the "raw transactions" JSON-RPC api to send coins received
from particular
addresses (also known as "coin control").

New/changed settings (command-line or bitcoin.conf file)
--------------------------------------------------------

dbcache : now controls LevelDB memory usage. Running with (for
example) -dbcache=1000
will use a gigabyte of memory and might make the initial blockchain
download faster.

par : controls how many threads to use to validate transactions.
Defaults to the number
of CPUs on your machine, use -par=1 to limit to a single CPU.

txindex : maintains an extra index of old, spent transaction ids so
they will be found
by the getrawtransaction JSON-RPC method.

reindex : rebuild block and transaction indices from the downloaded block data.

New JSON-RPC API Features
-------------------------

lockunspent / listlockunspent allow locking transaction outputs for a
period of time so
they will not be spent by other processes that might be accessing the
same wallet.

addnode / getaddednodeinfo methods, to connect to specific peers
without restarting.

importprivkey now takes an optional boolean parameter (default true)
to control whether
or not to rescan the blockchain for transactions after importing a new
private key.

Important Bug Fixes
-------------------

Privacy leak: the position of the "change" output in most transactions
was not being
properly randomized, making network analysis of the transaction graph
to identify
users' wallets easier.

Zero-confirmation transaction vulnerability: accepting
zero-confirmation transactions
(transactions that have not yet been included in a block) from
somebody you do not
trust is still not recommended, because there will always be ways for
attackers to
double-spend zero-confirmation transactions. However, this release
includes a bug
fix that makes it a little bit more difficult for attackers to double-spend a
certain type ("lockTime in the future") of zero-confirmation transaction.

Dependency Changes
------------------

Qt 4.8.3 (compiling against older versions of Qt 4 should continue to work)


Thanks to everybody who contributed to this release:
----------------------------------------------------

Alexander Kjeldaas
Andrey Alekseenko
Arnav Singh
Christian von Roques
Eric Lombrozo
Forrest Voight
Gavin Andresen
Gregory Maxwell
Jeff Garzik
Luke Dashjr
Matt Corallo
Mike Cassano
Mike Hearn
Peter Todd
Philip Kaufmann
Pieter Wuille
Richard Schwab
Robert Backhaus
Rune K. Svendsen
Sanjay Ghemawat
Sergio Demian Lerner
Wladimir J. van der Laan
burger2
default
fanquake
grimd34th
justmoon
redshark1802
tucenaber
xanatos


-------------------------------------
It has been previously(1) proposed that hashcash using the same PoW
function as the Bitcoin block hashing algorithm be used to create
hashcash whose value is denominated in Bitcoins. This poses two problems
however: widespread use of such hashcash would harm overall network
security and determining the value of the hashcash requires knowing the
revenue miners can gain from transaction fees at a given block height -
a non-computable function. However, with some modifications we can
extend the idea to directly denominate the hashcash in Bitcoins at the
cost of a small increase in proof size.

Recall that the fundemental problem is the need to do some work to make
digest D have value V, resulting in a proof that can be given to a third
party. We want V to be denominated in Bitcoins, and we want the actual
economic cost to create P to be as close as possible to the face-value
V. Finally should computing P result in a valid Bitcoin block header,
the creator of the proof should have a strong incentive to publish their
header to the P2P network and extend the current best chain.


# Proof structure

Lets look at the elements of the proof from the block header to the
digest.


## PoW Block Header

This must be a valid block header. It is particularly important to
ensure that the header can be linked to the actual blockchain, although
the header itself does not need to be a part of the chain, and hence the
block hash does not need to meet the difficulty requirements.


### Previous Block Headers

The proof may optionally include one or more previous block headers in
the event that the PoW block header's previous block is an orphan.
Unlike the PoW block header, these block headers MUST meet the
difficulty requirements although an implementation MAY skip actually
checking the difficulty if a difficulty retarget has not happened or the
PoW is timestamped. (see below)


## Partial Transaction and Merkle Path

The partial transaction consists of a SHA256 midstate followed by
exactly one transaction output. The merkle path to the PoW block header
MUST prove the transaction was the coinbase transaction and not any
other transaction.


## Transaction Output

The last transaction output must have a scriptPubKey consisting of
exactly one PUSHDATA op which pushes H(D | N) to the stack. Its value,
V', is the basis for determining the value of the proof of work. V' must
satisfy V' < k*Vi(h) where Vi is the inflation reward for the PoW block
height and k < 1 For a number of reasons, including making sure there
are strong incentives for broadcasting succesful PoW solutions, the
value of k should be chosen fairly conservatively; the author suggests k
= 1/10 as a ballpark figure. Finally N is some fixed value specific to
hashcash of this form to ensure the txout proof can-not be reused.

Vi can also be calculated as the median of the last n "anyone-can-spend"
outputs seen in coinbases when the value of the inflation reward falls
low enough that using the inflation reward is impractical.


## Timestamp

If the proof-of-work is used after a difficulty retarget the PoW needs
to be timestamped in the block chain with a merkle path leading to a
valid block header. The difficulty used for calculating the value of the
PoW then becomes the minimum of the difficulties of the PoW previous
block and the timestamp.


# Determining the actual value of the PoW

The proof proves that work was done to find a valid block header. That
block header, had it met the difficulty threshhold, could have created a
valid block worth at least the inflationary reward Vi(h) to the miner.

The coinbase transaction output and merkle path shows that were such a
block found, the miner would have then given away V' to whomever managed
to create a transaction spending it when the coinbase matured. The
coinbase takes 100 block to mature, so the chance of any one miner
collecting it is proportional to the hashing power they control.(*)

*) As with fidelity bonds we make the assumption that no party controls
more than 50% of the hashing power - the assumption underlying Bitcoin's
security anyway. If this assumption is proven incorrect or
insufficiently strong, possibly due to a cartel of miners banding
together to create low-cost PoW's, the output can use the provably
unspendable/prunable OP_RETURN <digest> scriptPubKey instead with a
non-zero value.

With P(block hash, target), the expected probability of a valid PoW
being found given the work required to create the block hash with the
given difficulty target, we can finally calculate the value of the PoW
in terms of expected cost: V = P(hash, target) * V'


# Pool implementation and 51% attack security

Because doing the work required to create coinbase txout hashcash is
sufficient to also create a valid block a pool can safely rent out
hashing power to create hashcash of this form on demand without making
it possible to rent large amounts of hashing power directly on short
notice. (though some extensions to GetBlockTemplate for hashers
verifying it may be required)

Because the anyone-can-spend txout is the basis for the value of the
hashcash the value remains computable even if transaction fees become a
larger proportion of the block reward in the future.

Unlike announce-commit sacrificies(2) proofs with very small values can
be easily created; the pool operator can make a trade-off between the
profit varience - remember that a block header with a valid PoW
represents a loss - and latency by adjusting the proof of work
difficulty and V'.

As an aside, note how the mechanism of a anyone-can-spend txout in a
coinbase can replace the announce portion of an announce-commit
sacrifice; a coinbase transaction is the only case where a single merkle
path proves that the transaction output was possible to spend in a
subsequent block, but was not yet spent; also an argument for allowing
coinbase transaction inputs.


# Application: Paying for additional flood-fill bandwidth

Additional messaging applications built on top of the Bitcoin P2P
network would be useful, yet there needs to be some general mechanism to
make DoS attacks expensive enough that they are impractical. For
instance a useful P2P network feature would be a mechanism to propose
trust-free coin mixes transaction outputs, propose specific txout sets,
and finally a mechanism to broadcast valid ANYONECANPAY signatures so
the inputs and outputs can become a valid transaction. By separating the
txout and signature broadcasts, who is paying for what output is made
very difficult to determine.

Of course such a mechanism will likely come under attack by those trying
to combat anonymity. However with the coinbase txout hashcash mechanism
those attackers are forced to either contribute to the security of the
Bitcoin network or incur much higher opporuntity costs for conducting
their attack than honest nodes pay. (remember how the choice of k = 10
makes for a large ratio of maximum V' value to Vi(h) inflation reward)

To reduce amortized proof size one proof can be used for multiple
payments with Rivest PayWords and similar techniques.


# PowPay - Off-chain, anonymous, probabalistic payments

By setting the special txout to a scriptPubKey spendable by the
recipient we can prove to a third party that work was done that with
probability P(hash,target) could have resulted in a txout spendable by
them of value V' Thus the expected value of the payment is V = P(h,t)*V'
The recipient needs to make the proof non-reusable, either by recording
all proofs submitted, or by requiring a nonce in the scriptPubKey: (*)

    <nonce> DROP {additional ops}

*) Note the implications for the IsStandardInput() test.

Because the recipient has no way of knowing how the sender paid to have
the hashing done on their behalf the source of the funds is unknown to
them. Additionally the payment can be of any amount less than a full
block reward, and the time varient between actual payments can be
reduced to, in theory, as little as the block interval itself with 100%
miner participation.


## Maximum Payment amount

Unlike coinbase txout hashcash the maximum value of a PowPay transaction
is strictly limited by the inflation reward; the trick of calculating
actual cost by prior sacrifices doesn't work because no honest sacrifice
is involved. In any case it is desirable for the mechanism to account
for a large percentage of total transaction value.

The issue is that should a valid block be found either the miner must
still have a strong incentive to broadcast that block that can be proven
to the recipient, or the miner must not be the one who controls that
decision.

The latter option is possible by inverting the relationship: now the
recipient constructs the block, and the sender simply arranges for a
valid PoW to be created - essentially the recipient acts as a mining
pool with an extremely high minimum work, and the sender provides
hashing power. With the 1MB blocksize the cost to operate the full
validating node required is low and attacks on block propagation are
difficult to successfully pull off.


### Supporting PowPay volume in excess of inflation reward + tx fees

To support overall PowPay volumes that are in excess of the inflation
reward and transaction fees the sender can provide the recipient with
signed transaction inputs subject to the constraint that only blocks
with PoW's generated by the sender can be used to spend them. For
instance a nonce in a well-known place can be provided by the sender and
included in a modified block header. By modifying the block hashing
algorithm so that PoW-withholding is not possible - a significantly more
serious problem in this application - the sender still is forced to send
all potential solutions to the recipient, including possible winning
ones. Provided that attacking block propagation is difficult the sender
can't prevent the reciver from spending their transaction inputs.


## Scalability

PowPay can provide much greater scalability than Bitcoin itself, in
terms of payments per second, however it is still limited in terms of
actual fund transfers to recipients per second. A naive implementation
would give a actual transfer every ten minutes maximum, and a highly
sophisticated solution 7/second. (albeit probably requiring a hardfork
to solve PoW withholding and/or use of third parties)

At the same time the proofs required become large with an increased
blocksize, and in the case of the inverted "recipient builds blocks"
mode the recipients either incur large costs running full nodes, or
greatly disrupt transaction flow for on-chain users by mining blocks
with no transactions in them at all. (remember that a recipient who
trusts someone else to construct the blocks for them is trusting that
third-party to do so correctly)

The latter is especially problematic because as the blocksize is
increased a higher percentage of the cost of mining goes to the overhead
required to run a validating node, rather than hashing, which has the
perverse effect of decreasing the cost of mining blocks with no
transactions in them at all. (or transactions that the miner knows have
not been revealed to other miners)

The analysis of this strange mixed bag of incentives is highly complex.


# Paying for mining

TxOut HashCash and PayPow both require the sender to somehow get someone
to mine on their behalf. The exact nature of these relationships will
vary and are beyond the scope of this paper.


# Eliminating PoW withholding

While the above examples have used economic incentives possible within
the existing Bitcoin system a structural incentive is possible as well.
A nonce N is chosen by the party paying for the PoW, such as a pool or
PowPay recipient, and H(n) is included in the block header.(*) The PoW
function is then modified to consider the PoW valid if the sum of the
expected hashes required to find H(B) and H(B | n) exceeds the current
difficulty target.

*) Note how the block header can be extended, while remaining fairly compatible
with existing ASIC mining hardware, by taking advantage of the fact that
ASIC's use the SHA256 midstate at a starting point for their PoW
calculations.(3)




1) "Re: [Bitcoin-development] Discovery/addr packets (was: Service bits
for pruned nodes)" - 2013-06-06 - Peter Todd <pete@petertodd.org> -
bitcoin-development email list

2) "Purchasing fidelity bonds by provably throwing away bitcoins" -
https://bitcointalk.org/index.php?topic=134827.0 - Peter Todd

3) "Re: 32 vs 64-bit timestamp fields" - 2013-06-09 - John Dillon
<john.dillon892@gmail.com> - bitcoin-development email list

-- 
'peter'[:-1]@petertodd.org
0000000000000039e49118426bbe6739360d35116e920d6502dcacd8e51bc74c
-------------------------------------
On Thursday, June 06, 2013 7:59:16 PM Andreas M. Antonopoulos wrote:

This doesn't work like you might think: first of all, the fees today are 
greatly subsidized - the actual cost to store data in the blockchain is much 
higher than most storage solutions. Secondly, only the miner receives the 
fees, not the majority of nodes which have to bear the burden of the data.
That is, the fee system is setup as an antispam/deterrant, not as payment for 
storage.


Not the same thing at all; nobody is forced to store/relay video/voice/images 
without reimbursement. On the other hand, any full Bitcoin node is required to 
at least download the entire blockchain once. And the network as a whole 
suffers if nodes decide to start not-storing parts of the blockchain they 
don't want to deal with.


This is how merged mining solves the problem. A single extra hash in the 
coinbase can link the bitcoin blockchain up with unlimited other data.


See above.



-------------------------------------
Looking at the proposed native crypto browser support (should arrive in the
next year)

http://www.w3.org/TR/WebCryptoAPI/#EcKeyGenParams-dictionary

We see:

enum NamedCurve {
  // NIST recommended curve P-256, also known as secp256r1.
  "P-256",
  // NIST recommended curve P-384, also known as secp384r1.
  "P-384",
  // NIST recommended curve P-521, also known as secp521r1.
  "P-521"
};

I wonder if we might be able to get bitcoin's curve in there

For more background on Koblitz curve used by bitcoin see:

https://bitcointalk.org/?topic=2699.0
-------------------------------------
On Thu, Apr 18, 2013 at 06:07:23AM +0000, John Dillon wrote:

FWIW Gavin has spent quite a bit of time and effort ensuring that
Bitcoin is resistent to DoS attacks, as well as spearheading a move
towards better testing. The latter in particular is helpful against
chain-forking bugs, so better testing is very much a security issue. He
also spearheaded P2SH, and the current efforts to get a payment protocol
implemented. I'm less convinced about his stance against attackers that
pose a threat to the system as a whole, but it's not fair to accuse him
of not taking security seriously.


You should clarify if you want this patch to compute fees recursively or
not, IE, should the patch include fees paid by child transactions in how
it computes the total fee the transaction pays. Doing this is
non-trivial, although Luke-Jr has written a patch to do this without
replacement: https://github.com/bitcoin/bitcoin/pull/1647

Also, clarify if you want unit-tests and similar things included in the
implementation.

-- 
'peter'[:-1]@petertodd.org
-------------------------------------
On Sat, Mar 02, 2013 at 04:09:38PM -0500, Gavin Andresen wrote:

Would be nice to have a secure page at bitcoin.org, though, rathar
than having to go to github - certs from somewhere like Namecheap
should cost you next to nothing.  For those of us too lazy (not
paranoid enough) to bother with GPG, a (secure) page on bitoin.org
with the MD5 hashes of the binaries would be awesome...

roy


-------------------------------------
Providing people with a great user experience is something that Hive Wallet is enthusiastic about, so this is stuff were thinking about constantly. For example, how do you alert the user to abnormal activity (i.e. sending too much on accident[1])? The removal of extraneous UI and functionality that can be automated is a priority, which is why we (to date) still dont have a Preferences dialog. Smart defaults should be an important aspect of design decisions.

Thinking about stripping UI away as much as possible, consider what was done with dat.wallet[2]: no wallet file whatsoever and it doesn't even reveal the address except when explicitly necessary. For privacys sake, the intent should be to detect the use of an address and automatically rotate it away from the user. This minimal interaction results in maximum benefit.

Or take a look at the new Bitstamp app Im writing for Hive[3]. How do you cram an entire trading API into a mobile-like window? Smart use of space and making intelligent event-driven decisions is often overlooked. In the linked screenshot, imagine the user actually clicks the deposit button. A send bitcoins" dialog is pre-populated with the deposit address and the requested amount. Copying and pasting addresses is error-prone and not user-friendly in the least.

I would urge all software developers to think about UX when developing applications. What can be automated? What can we make a best guess about? In the case of fees, we will hopefully have more control over them in the coming months, but in the meantime, consider what your application tries to accomplish and how it can do that without getting in the way too much. Software should enable the user, not encumber them.

Lastly, Ill leave everyone with an approach were considering once floating fees are feasible[4], something Mike Hearn asked about in a previous thread.

[1] https://github.com/hivewallet/hive-osx/issues/107
[2] https://github.com/darkwallet/dat.wallet
[3] https://github.com/tgerring/hiveapp-bitstamptrader
[4] https://github.com/hivewallet/hive-osx/issues/148


Taylor


On Dec 16, 2013, at 5:37 AM, Wladimir <laanwj@gmail.com> wrote:


-------------------------------------
On Wednesday, March 13, 2013 6:01:02 PM Michael Gronager wrote:

While 0.7 and earlier do have issues, they also define the Bitcoin protocol. 
0.8's failure to comply with the protocol is an issue.



-------------------------------------
On Sat, Mar 23, 2013 at 1:09 PM, Luke-Jr <luke@dashjr.org> wrote:

slush, BTC Guild, ozcoin too I think, several others.

-- 
Jeff Garzik
exMULTI, Inc.
jgarzik@exmulti.com


-------------------------------------
On Thu, Nov 14, 2013 at 04:07:58PM -0600, Allen Piscitello wrote:

Why not just using SI prefixes, as God intended.

MBTC mega 10^6 
kBTC kilo 10^3
-    -    10^0
mBTC milli 10^-3 
uBTC micro 10^-6
nBTC nano  10^-9 (at all possible?)


-------------------------------------
On 22/10/13 09:56, Gregory Maxwell wrote:

In fact, yes.

In the end it boils down to saying something like: "Bitcoin is a unique 
global distributed application and thus all implementations MUST support 
the version of the protocol currently in use, irrespective of whether it 
have been documented and/or published. This RFC is meant only for 
informational purposes and is a snapshot of the protocol as to Oct 22nd 
2013."

That being said, I understand the idea of not publishing the spec so 
that everyone is forced to work with live data.


Heh. Haven't seen that one.

Martin




-------------------------------------
On 3/12/2013 5:18 AM, Jorge Timn wrote:
It was reported that not all 0.7 died from the BDB error either. This 
will likely take a post-mortem to determine exactly what build 
environments and versions are incompatible, by feeding each the bloated 
block (hopefully there are lots of snapshots of the bad chain being the 
best height for testing; I forgot to get one).


-------------------------------------
On Thursday, December 05, 2013 1:37:10 PM Wladimir wrote:

I think this would stifle active BIP draft editing. We're already having a 
hard time getting some developers to write BIPs for their proposals - I don't 
think we should be putting up bigger hurdles.

Luke


-------------------------------------
Current rough timeline proposed for 0.9 was end-of-January, IIRC.

On Mon, Dec 2, 2013 at 9:44 AM, Mike Hearn <mike@plan99.net> wrote:



-- 
Jeff Garzik
Bitcoin core developer and open source evangelist
BitPay, Inc.      https://bitpay.com/


-------------------------------------
I paid the new anti-spam deposit and updated the BIP 37 page to the latest
version of the protocol, then marked it as accepted. High fives all round,
but especially to Matt for doing the heavy lifting on this feature.


On Wed, Feb 6, 2013 at 5:45 PM, Gregory Maxwell <gmaxwell@gmail.com> wrote:

-------------------------------------
I find it interesting that this is a "linux packaging letter".  How much
of this applies to pkgsrc, FreeBSD ports, OpenBSD ports, and other
non-Linux packaging systems (pkgsrc supports Linux as on of 20 operating
systems, but is not a "Linux packaging system")?

Is the repeatable build infrastructure portable (to any reasonable
mostly-POSIX-compliant system, with gcc or clang)?  I have the vague
impression it's Ubuntu only, but I am very unclear on this point.  How
does this repeatableness interact with building for multiple operating
systems and cpu types (say 20 OS, with typically 3 versions of the OS
for each, with 1-20 cpu types per OS, for a cross-product of perhaps 200
combinations)?

Requiring precise library depdendencies is quite awkward.  Certainly
requiring new enough to avoid known bugs is understandable, but that
should be caught at configure time and fail.  Synchronous updates of
multiple packages is difficult, and runs into A wants only n of C, while
B wants only m.  So if you are talking about running regression tests
with the set of versions of a dependency that are considered reasonable,
and there's therefore a solution to the multiple-package constraint
problem, that seems ok.

It seems like a bug that the package will build on BE systems and then
fail tests.   If it's known not to be ok, it seems that absent some
configure-time flag the build should fail.

Asking people not to patch should mean willingnesss to make accomodation
in the master sources for build issues for multiple packaging systems.
I haven't gotten around to packaging this for pkgsrc - so far I only
have the energy to lurk (due to too many things on the todo list).  But
I often find that some changes are needed.  If you're willing (in
theory) to add in configure flags to control build behavior (in a way
that you can audit and decide is safe), that's great, and of course we
can discuss an actual situation when one gets figured out.

Greg





-------------------------------------
On Tue, Jul 30, 2013 at 02:01:39PM +0200, Bazyli Zygan wrote:

There was a good reply to those concerns last time the issue came up:

    Tor does not act as a particularly effective man in the middle for nodes
    that support connections to hidden services because while your
    connections to standard Bitcoin nodes go through your exit node, the
    routing path for each hidden service peer is independent. Having said
    that we should offer modes that send your self-generated transactions
    out via Tor, while still maintaining non-Tor connections.

    Anyway Sybil attacks aren't all that interesting if you are the one
    sending the funds, and receivers are reasonably well protected simply
    because generating false confirmations is extremely expensive and very
    difficult to do quickly. After all, you always make the assumption that
    nearly all hashing power in existence is honest when you talk about
    replace-by-fee among other things, and that assumption naturally leads
    to the conclusion that generating false confirmations with a sybil
    attack would take more than long enough that the user would be
    suspicious that something was wrong long before being defrauded.

    I'd be surprised if anyone has ever bothered with a false confirmation
    sybil attack. I wouldn't be the slightest bit surprised if the NSA is
    recording all the Bitcoin traffic they can for future analysis to find
    true transaction origins. Which reminds me, again, we need node-to-node
    connections to be encrypted to at least protect against network-wide
    passive sniffiing.

    Regarding usage I would be interested to hear from those running Bitcoin
    nodes advertising themselves as hidden services.
    -http://www.mail-archive.com/bitcoin-development@lists.sourceforge.net/msg02438.html

tl;dr: Users should be using Tor to preserve their privacy and the MITM
risks are minimal to anyone using Bitcoin correctly. (don't trust
zero-conf transactions, they are not secure!)


Yeah, he had the idea of adding .onion addresses of seed nodes
along-side the DNS seeds table; that would give an end-to-end MITM-proof
channel to a trusted seed who can in turn give an honest view of the
network.

Ideally those .onion addresses would be of nodes run by the same people
as running the existing seeds so that it was clear who was being trusted
- I'll write a patch to do this soon with a .onion testnet seed first.
(I run one of the testnet DNSSEED seeds and have a small grant from the
foundation to do so)

Bitcoin relays .onion addresses over the P2P network, so once you are
connected you can gain additional peers with addresses that are MITM
resistant. Currently there isn't any equivalent to the (weak) anti-sybil
properties of IP address range diversity for .onion's, but in the future
we'll eventually add node identities and some way to make creating lots
of fake identities for a sybil attack expensive.

-- 
'peter'[:-1]@petertodd.org
00000000000000321cb1ef9de9c4a6c470c7f88c4b85bcee3a63121e31096fef
-------------------------------------
https://bitcointalk.org/?topic=205878

This encoding is designed so that it could replace Base58Check in new data, 
with the following goals in mind:
- Impossible(?) to manipulate without completely changing it
- Clearly identifiable prefix, regardless of data size
- Cheaper to process (simpler and faster code; it's a power-of-two radix)
- Fixed length string for fixed length data
- More unambiguous (removal of chars 'isuvzSVZ')
- Compatible with using seven-segment displays
- Altcoin friendly (16 bit namespace, which can be read without decoding)

Since there are fewer digits and more identifying/signature characters, 
addresses are longer. This should be less of a problem since ordinary users 
will hopefully be using addresses less common as the payment protocol becomes 
more popular.

Example Python code (including tests) is attached.
I can write up a formal BIP if this seems useful.

For example:

160 bits of data, such as current addresses:
    2nc111dhAPE2aUdYAOF88JhLn5jEjbULy4eFe9tyFYFE8
An ordinary P2SH destination, incorporating Greg's "require the hash mid-image 
to be relayed" concept (256 bits of data):
    2bc511A95e74P13dPb6b5t7yrh12EhC363ayH98n1cFbr3rAHdA49nCcC1G3P71j
The same key in Namecoin:
    2nc5119ttL35HPhc3Hh6aHe2tOhF6rdFtAOE1ahFLt9Ecabhcn5FLea5Le71P56C
The example "puzzle" script from the wiki (arbitrary scripting):
    2bc311d126acCyAnHAjabeUtOHcr7F811j4UYE6ECtOcbcGGn4O9chAt7O7y2LU9ty9cnG4
An alternative for BIP32 extended public keys (560 bits):
    2bc911AcchHheAGFnn9LC6FdF7bOc99APJtcEc46U655JheH6LCr3Y333eFEOtPJ9rj22rEcchHheAGFnn9LC6FdF7bOc99APJtcEc46U655JheH6LCr3YJCtPYea
An alternative for BIP32 extended private keys (552 bits):
    2bcb11O77GHdP53FH7Jh44OdEh3rLd4eFr2h7c8rGeErELG18yCy9O7L9LednyHJa5hyeAP77GHdP53FH7Jh44OdEh3rLd4eFr2h7c8rGeErELG18yCyGG5drPF1
-------------------------------------
I'm very much in favor of double-spend propagation across the network.

Most of the arguments about replace-based-on-fee /
child-pays-burn-coins / etc are orthogonal.

Letting a merchant know ASAP that their customer is trying to cheat
them is, in my opinion, strictly better than what we have now.

-- 
--
Gavin Andresen


-------------------------------------
On Mon, Dec 9, 2013 at 12:42 PM, Drak <drak@zikula.org> wrote:

Yes.

-- 
Jeff Garzik
Bitcoin core developer and open source evangelist
BitPay, Inc.      https://bitpay.com/


-------------------------------------
I'm not even sure I'd say the upgrade "went wrong". The problem if
anything is the upgrade didn't happen fast enough. If we had run out
of block space a few months from now, or if miners/merchants/exchanges
had upgraded faster, it'd have made more sense to just roll forward
and tolerate the loss of the older clients.

This really reinforces the importance of keeping nodes up to date.

On Tue, Mar 12, 2013 at 12:44 PM, Pieter Wuille <pieter.wuille@gmail.com> wrote:


-------------------------------------

IME most CAs verify by emailing hostmaster/webaster@ or one of the
contacts in the WHOIS.  But you're right, still subject to a MitM.
Still better than nothing though.

I would have suggested an EV cert, but that's more expensive (and
still far from foolproof)


Also helps protect against DNS spoofing attacks, but yes, you're
right.  I should be checking GPG sigs but I'm lazy :-)

roy


-------------------------------------
We're open to changes in the wordlist. We'll accept pull request
replacing potentially offensive words by another more neutral, which
also fits all other requirements.

Putting the wordlist together is really hard job and we spent few
sleepless nights on that. By the way, words "murder, black, people"
are contained also in Electrum wordlist and nobody complained yet :-).

slush

On 9/11/13, Gregory Maxwell <gmaxwell@gmail.com> wrote:


-------------------------------------
On 1 April 2013 09:59, Melvin Carvalho <melvincarvalho@gmail.com> wrote:


Hi All

Sorry for the delay on this.  I've made a very simple start, and am hosting
the vocabulary at.

https://w3id.org/cc

Having chatted on IRC, I'm not only going to model bitcion, but all crypto
currencies in time, starting first with bitcoin.  There's only one use case
currently support, which is a way to tell the semantic web that a link is a
bitcoin address (I know you can already introspect on the bitcoin: link but
introspection requires out of band knowledge).  More explanation below:

*Use Case
*

As a publisher Alice would like to link her web page content (or app) to a
bitcoin address, so that donations can be received by those that have
enjoyed her work.

*Model
*
It's only a slight overhead to model all crypto currencies so perhaps the
model will be something like

URI -> crypto-currency-address -> bitcoin-address

*Implementation
*
The folks at w3id.org have kindly offered to user their permanent
identifier switchboard, then we redirect to a locked down vocabulary.

As an implementer you simply need to add a single rel= tag to your markup.

*Example Usage*

In a web page:

<*meta* rel="https://w3id.org/cc#bitcoin<https://w3id.org/cc#bitcoin-address>"
href="bitcoin:1234...." />

In an html5 app:

<a rel="https://w3id.org/cc#bitcoin <https://w3id.org/cc#bitcoin-address>"
href="bitcoin:1234...."></a>

*Note: you an provide context for an individual concept in HTML5 (as
opposed to the webpage itself), such as an app, a project, a person, but
using the @about tag.
*

For litecoins (coming soon)

<a rel="https://w3id.org/cc#litecoin <https://w3id.org/cc#litecoin-address>"
href="...."></a>


*Next Steps

*
It's just a small step to start with, can allow all sorts of entities to
start accepting bitcoin in a way that complies with the W3C best
practices.  I'll be improving and extending this over time, feedback or
help is welcome!
-------------------------------------
Bitcoin p2p seeding requirements hav some ToR similarities, and we went
through the same security considerations with Zero-Knowledge systems freedom
network.  Though bitcoins attacker profile and motivation is different - so
the defense maybe even more demanding.  At least you have no shortage of
nodes and perhaps merchant interest and general good-will to lean on.

At ZKS I proposed we should fix the exit node issue (exit sees where you go
often in the clear) with an apache mod so the freedom aip tunnel (ToR tunnel
equiv) could terminate right on the web site.  (ZKS freedom network is long
dead but some of the ideas I think made it into ToR, eg I hope my end2end
forward anonymity idea that is implemented in Zach Brown's cebolla.)

Anyway I'd have about DNS being of limited value: bitcoins primary
vulnerability IMO (so far) is network attacks to induce network splits,
local lower difficulty to a point that a local and artificially isolated
area of the network can be fooled into accepting an orphan branch as the
one-true block chain, maybe even from node first install time.

(btw I notice most of the binaries and tar balls are not signed, nor served
from SSL - at least for linux).

Therefore as it applies to discover, you want to be able to discover peers
through as many network routes, and even steganographic protocols as
possible.  eg if a popular web server (say apache, or an apache module) put
a steganographic peer discover relay from its own network area, even for a
small bitcoin fee, that would help a lot.  (Steganographic in the SSL sense
would just mean that the peer seed request to /btcseed.cgi would not be
distinguishable to someone highly sophisticated on the inside of the router
all the peers traffic is routed through.  Eg you could easily do this with a
special magic header that overwrites something else or deletes some
unnecessary header so that the request at least is a standard size, and pad
the response to the same size as the site index.html or whatever).  If the
user picks a few SSL sites and cross checks (more for high value) a subset
of peers available on all and uses them as his seed that seems like a better
direction.

In that way an attacker cant control the network without denying service to
popular SSL sites, which would be a warning sign to users, or having at his
disposal a SSL sub-CA cert (like happened with diginotar and gmail).  You
may be able to pin CAs for popular sites.  Obviously to the extent you're
using SSL you want to generally use EDH for forward-secrecy.  And not RC4 :)

Probably anysite that accepts bitcoin payment will be happy to run such a
mod-bitcoin.


With ToR, it has a similar bootstrap problem to bitcoin.  So while that may
help it is also passing the buck, not necessarily solving the problem.  And
as I said I think its possible bitcoin has a higher assurance need in that
the attackers motivated my $$ might put more effort in than the odd
dictatorship trying to pay lip service to preventing people reading pages on
a blacklist.


Given the vulnerability of DNS to poisoning I would not trust it too much. 
I know its just a bootstrap, but ideally you dont want to bootstrap from a
known publicly vulnerable protocol - it invites DNS poison net splits
against new users.


Also to the extent that users local clock is under his control (with
unuthentcated NTP?) he should also treat sudden dramatic changes in luck
(deviations from 10min interval) as suspicious.  

Unfortunately at present because of the first past the post nature of the
bitcoin lottery, reduced variance hashcash cannot be used, so its hard to
infer too much even from quite significant luck changes.

Adam

On Mon, May 06, 2013 at 06:47:22PM +0200, Mike Hearn wrote:


-------------------------------------
Determinstic ECDSA signature aka k=H(d,m) insead of k=random, with signature
(r,s) calculated r=[kG].x, s=k^-1(H(m)+rd) with public key Q=dG and
verificaton relation [H(m)s^-1G+rs^-1Q].x=?r is cool and should be done. 
Otherwise RNG issues like EC_DRBG or even leaked partial bits like the RNG
bias in the original DSA spec that Bleichenbacher pointed out and then they
corrected.

On Wed, Oct 09, 2013 at 09:10:09PM -0700, Jeremy Spilman wrote:

But k=random and k=H(d,m) create compatible signatures - or were you eaning
to cross check the two implementations with fuzz tester on lots of messages?

btw about malleability:

Mike Hearn <mike@plan99.net> wrote:

other than the ASN.1 related parsing ambiguity, if any (openSSL asn.1
parsing code is evil and shold not be used), the (r,s) vs (r,-s) ambiguity
can be plugged as discussed (eg define -s as invalid).  But that is ECDSA
specific, and signature malleability and its impact is a generic problem. 
Its probably a non-requirement of a signature scheme in terms of the
analysis effort put in by cryptanalysts that the signature itself be
non-malleable, eg there are some encryption schemes which are publicly
reblindable, like Elgamal.  By plugging the (r,s), (r,-s) specific case as a
DSA specific work-around there may be other malleability even in DSA, unless
someone has a clear proof that there is not.

And we may want to add ECS (schnorr) because it's simpler and allows more
flexibility and efficiency (eg native n of n multisig at the storage cost of
1 signature vs n with ECDSA, and k of n threshold signature at the cost of 1
sig (but some threshold secret share setup up front).  The relying party
doesnt need to know how many multi-sigs there are there is a single public
key.

So I was thinking a more generic / robust way to fix this would be to change
the txid from H(sig,inputs,outputs,script) to H(pubkey,inputs,outputs,script)
or something like that in effect so that the malleability of the signature
mechanism doesnt affect the security of conditional payments.

Adam


-------------------------------------
Hi Mike,

It seems to me there is some confusion about this. Taylor's talking about a standard way to pass around data; the end user would never be exposed to something like a "vCard". That vCard's existence itself would in fact be very temporary.

-wendell

grabhive.com | twitter.com/hivewallet | gpg: 6C0C9411

On Nov 10, 2013, at 7:08 PM, Mike Hearn wrote:




-------------------------------------
BTW, on the "make qrcodes more scannable" front -- is it too late to change
BIP 72 so the new param is just "r" instead of "request"? Every byte helps
when it comes to qrcodes ...


On Tue, Aug 20, 2013 at 12:05 PM, Mike Hearn <mike@plan99.net> wrote:

-------------------------------------
On 7 May 2013 12:18, Melvin Carvalho <melvincarvalho@gmail.com> wrote:


Hi All

I enuired about this and got the following reply, from the chair of the
crypto group:

[[
Just email public-webcrypto-comments@w3.org. It's a public list. Do
definitely mention your use-cases!

I think there's issues of whether NSS etc. already support it. I think the
answer here is "no" but David can clarify. The goal is not to get browser
vendors to write new crypto code, but to expose the crypto code that
already exists.

We still have an open issue about whether "experimental" registry for
identifiers for say, new curves that aren't in the core spec, will be
maintained. So, maybe if browsers don't support it today, it's always
possible they might want to support it tomorrow given Bitcoin's growth.
]]

Please let me know if anyone has a use case for ecdsa in the browser let me
know.

Or if anyone would like to write to the public list that's fine

Otherwise I'll just fire off a mail and see what they come back with ...
-------------------------------------
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256

On Sun, Jul 28, 2013 at 1:20 AM, Peter Todd <pete@petertodd.org> wrote:

<snip>


You missed a 'CAT' opcode here.


<snip>


I think you should disclose whether or not you have any ties to the pulp and
paper business... By my calculations the production of a single OTP table would
consume roughly half of all the forest biomass on this planet.


ROTFL!

Your idea is better than you realize, you are just too paranoid for your own
good. The thing is the attacker isn't going to be someone paying you funds over
your minimum spending limit, which means the size of the table deriving which
H(nonce) is selected for a given txid:vout can be significantly smaller. For
instance if you want to have 256 total payments before a 50:50 chance of any
pair using the same nonce, you only need a table with ~2^16 elements or with 20
byte hashes just a megabyte of data. It is the 16 level merkle proofs that are
the problem, 16*21=336 bytes of data in the scriptSig. Then again, that's only
4.5x the size of a single signature, not unreasonable.

Also your nested IF statements, while a lovely and hilarious use of MAST, can
be replaced by simply creating the merkle tree over the tuples [i,H(nonce_i)]
and proving that the nonce_i you provided matched the precommitted tree. Now
you only need to provide one merkle proof, not two.

But don't let me discourage you, rarely do I see elaborate jokes that also meet
the criteria to be a least publishable unit. :)
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBCAAGBQJR9WzMAAoJEEWCsU4mNhiP8wIIAJTESdZiIyrfmrJIQad19He0
nPUB1UGdrcRyYBKfk2bxmIgeTppEneISerAzFpfsZk/R1vLSp2zuFvFLMvaTqF0a
nof9dR4ztp753P6O9nLBIK1gcoOagg/FL61Cd1mQzoTjznGioEgk1mCo/Qjb8h9E
I43De70j575bvUkq8RQgijctIt463bM7vfdBC6qtgSziL/xrLUDQEJ6Mhqz3rnmX
+A2+MPHd/aGnRIcBuN6DFQTMXpjXG2y1CIM45e2gPL5x/vSIXqJoJs9tgGyzuFLG
rR34GCsifUKxJyvswG5ue9rNuo5mDkri2jIFx8SlqhfT/b8iWU8JIieoZYGuMiA=
=uhmy
-----END PGP SIGNATURE-----


-------------------------------------
This is all FAQ territory, and has been covered on the forums for years.

Balance-at-point-in-time is not completely trust-free, as it is a
dataset that must be bootstrapped into trust by... an earlier dataset.
 Continue this logic and you have a... chain.

There is plenty of on-going discussion on UTXO snapshotting -- UTXO
lockin for each block, or something.  This is /somewhat/ like
balance-at-point-in-time, but no one pretends it is trust-free.

The /only/ way to have a completely trust-free solution is to be able
to verify all data from genesis through $now. However, it is not
necessary for all bitcoin wallets to download and verify all those
gigabytes of data; that is what SPV mode is for.

      Jeff



On Sat, Sep 7, 2013 at 11:56 PM,  <rob.golding@astutium.com> wrote:



-- 
Jeff Garzik
Senior Software Engineer and open source evangelist
BitPay, Inc.      https://bitpay.com/


-------------------------------------
On Tue, Feb 12, 2013 at 10:11 AM, Peter Todd <pete@petertodd.org> wrote:


First: I really like the fidelity bond concept, and want to see it happen.

RE: OP_RETURN : I've got a knee-jerk opposition to the OP_RETURN opcode,
because it was the cause of the nastiest bug ever Bitcoin history. So I'd
be more comfortable using either OP_FALSE or OP_INVALIDOPCODE for the
"provably unspendable" transaction.


RE: anyone-can-spend transactions:  Thinking aloud... I wonder if we might
inadvertently cause "spend storms" on the network; if suddenly there are 11
BTC sitting in an anybody-can-spend txout, I could imagine EVERYBODY on the
network trying to race each other to spend it (maybe assuming that there
are a few miners on old versions of the software who are too dumb to claim
it for themselves).


-- 
--
Gavin Andresen
-------------------------------------
Hi all,

We've been having a heated discussion on HD wallet import strategies on bitcointalk and I was wondering what the people on bitcoin-dev had to say about the subject. 

So I have a few questions and would love to hear your thoughts on them:

1) What information do you consider absolutely essential when importing an HD wallet root key?
2) If you already have an HD wallet import function, can you give a rough description of how it works?
3) Do you think it would be wise to set up some sort of guidelines to ensure that different HD wallet implementations will be able to import each others HD wallet root keys?
4) Anything else on the subject you consider important?

Thanks in advance,

Jean-Paul

-------------------------------------
My draft is as follows.

Gregory Maxwell: Can you assign a BIP # for this? The next number, 38,
is on the wiki as "Passphrase-protected private key" by Mike Caldwell,
although it isn't in the list so I don't know if that is official or
not.



BIP: ?
Title: NODE_BLOOM service bit
Author: Peter Todd <pete@petertodd.org>
Type: Standards Track (draft)
Created: 17-08-2013

Abstract
========

This BIP extends BIP 37, Connection Bloom filtering, by defining a service bit
to allow peers to advertise that they support bloom filters explicitly.


Motivation
==========

BIP 37 did not specify a service bit for the bloom filter service, thus
implicitly assuming that all nodes that serve peers data support it. There are
however cases where a node may want to provide data, such as mempool
transactions and blocks, but do not want to or have not implemented bloom
filtering. Additionally it is good practice for nodes to be given options as to
the granularity of the services they are providing the public - a full-node
operator may be able to donate only a small amount of bandwidth and may want
those efforts to be used by other full-node operators.


Specification
=============

The following protocol bit is added:

    NODE_BLOOM = (1 << 1)

In addition the protocol version is increased from 70001 to 70002 in the
reference implementation. Nodes that support bloom filters should set that
protocol bit. Otherwise it should remain unset.

NODE_BLOOM is distinct from NODE_NETWORK, and it is legal to advertise
NODE_BLOOM but not NODE_NETWORK.

If a node does not support bloom filters but receives a "filterload",
"filteradd", or "filterclear" message from a peer the node should disconnect
that peer immediately.

While outside the scope of this BIP it is suggested that DNS seeds and other
peer discovery mechanisms support the ability to specify the services required;
current implementations simply check only that NODE_NETWORK is set.


Design rational
===============

A service bit was chosen as applying a bloom filter is a service.

The increase in protocol version is for backwards compatibility. Nodes that
require the bloom filter service can set NODE_BLOOM for peers advertising a
protocol version < 70002, allowing the rest of the implementation to be
unchanged. Nodes with implementations that do not know of the NODE_BLOOM bit
will be disconnected immediately as though the connection failed for some
reason, and thus will not have incoming bandwidth wasted by that peer and can
easily connect to another peer.

Supporting NODE_BLOOM but not NODE_NETWORK allows for situations where a node
may have data that its peers may be interested in, but is not a full node and
thus does not have block data in general. For instance an SPV node that
receives a full, unfiltered, block from a peer may want to let its SPV peers
know about the existence of that block and provide them that data if requested.
Those peers in turn may only be interested in knowing about the block if it
matches a specific bloom filter. Note how in this example DoS attacks are made
prohibitively expensive by the work required to create a valid block header.


Reference Implementation
========================

https://github.com/bitcoin/bitcoin/pull/2900


Copyright
=========

This document is placed in the public domain.

-- 
'peter'[:-1]@petertodd.org
-------------------------------------

I was wondering, would it be possible to create an area where proposals like your NODE_BLOOM and BIP 38 could live? 

On 2013-10-20, at 11:25 PM, Peter Todd <pete@petertodd.org> wrote:


-------------------------------------
Indeed.  You can hardcode a "distributor" public key in the software,
and client software will only trust signed data from that key.  Of
course, the private key for that data is not kept on the server
distributing the signed checksums.  Ideally it would be kept offline,
and the couple-times-per-year that you actually execute an upgrade, you
sign the new checksums offline and upload the signed checksum to the
distribution server.  Then even if the server is compromised, the
client-side software will not accept a bogus checksum because it won't
bear the right signature.

If you do this, it would be good to also have some kind of revocation
process that can be used in the event of the offline key being
compromised.  You won't be able to "switch" keys, as that would defeat
the purpose (the attacker who compromises the offline key could just
issue a replacement with his own).  Instead, it would be an irreversible
broadcast that would force clients to start rejecting updates from that
key.  If the key is compromised (and find out), you broadcast the
revocation and the users will stop auto-updating, and be given a warning
that they should manually upgrade the software through trusted
channels.  It's not failproof, but it's a decent way to minimize damage
if you discover compromise early enough.

-Alan






On 08/05/2013 11:54 AM, Daniel F wrote:



-------------------------------------
you mixed up BitMail with BitMessage, this is different:
http://bitmail.sf.net

2013/8/13 The Doctor <drwho@virtadpt.net>

-------------------------------------
Hey everyone,

I have noticed that there was a recent change to BIP 0038 (Password-Protected Private Key) on the Wiki, which is a proposal I wrote in late 2012.  Gregory, it looks to me as though you have made this change, and I'm hoping for your help here.  The change suggests that the number was never assigned, and that there has been no discussion regarding the proposal on this list.

I had this number assigned by Amir Taaki in November of 2012, consistent with what I understood the procedure to be at the time by reading BIP 0001 on the Wiki.

First off, I want to confirm that when I send to the list, that there isn't a technical reason it's not getting to everybody.  I believe I most recently mentioned BIP 38 to this list on August 17, 2013. (EDIT: seems my prior messages, including an earlier revision of this message, have not made it to the list)

Secondly, in the case that it is deemed that this has never been properly submitted, discussed, or pushed forward, I'd like to propose that this happen, and request help with the formalities where I'm lacking.

I believe BIP 38 is a valuable proposal that is seeing real-world use.  BIP 38 allows people to create private keys (including paper wallets) protected by a password, and also allows one party to select the password for paper wallets to be created by another party.

Real-world use includes a working implementation at BitAddress.org, one at Bit2Factor.org, implementation by Mycelium, and others.  Also, others are informally using it as a sort of abbreviated escrow scheme where a buyer and seller agree on the buyer maintaining control over the release of funds.  In short, it would be terribly confusing to reassign the number BIP 38 after already having had an established meaning for the better part of the year, particularly on what appears to be procedural grounds.

Mike

-------------------------------------
http://bitmail.sourceforge.net/


   - Secure P2P Email from Friend to Friend without relying on a central
   server.
   - Key- / Repleo-Exchange.
   - Full decentral Email-Network using the Echo Protocol.
   - Store Email for Offline-Friends in the P2P Network.
   - Chat and Instant Messaging is build in. Define & Add your friends.
   - Strong e2e Multi-Encryption (PGP-kind/AES over SSL: using
libgcrypt<http://www.gnu.org/software/libgcrypt/>).

   - Libspoton Integration.
   - Additional Security Layer with the GB-Feature for Emails.
   - Preventing Data Retention (VDS). WoT-less.
   - HTTP & HTTPS Connections.
   - Open Source. BSD License.

anyone with a Server? Key?
-------------------------------------
Yeah, what I meant is, it'd be useful to know the average amount of time
that the app was holding connections open for.


On Wed, Jul 17, 2013 at 4:32 PM, Andreas Schildbach
<andreas@schildbach.de>wrote:

-------------------------------------
On 19 December 2013 13:17, Peter Todd <pete@petertodd.org> wrote:



Can you add a part about SHOULD/MUST warn users if the fee is unusually
high to avoid sob-stories of people sending 20BTC fees with for the
0.002BTC sandwich.

Sourcecode MUST be PGP signed on a regular basis. Releases MUST be

"SHOULD be cryptographically signed" I assume.



Once could make efforts to publish (maybe even as signed commits in the git
repo etc the current valid certificate fingerprints and which CA signed
it). This would go some way to exposing
MITM either by CA or in workplaces where browsers are loaded with bogus CAs
for the purpose
of deep packet inspection.



According to RFC 2119 <http://www.ietf.org/rfc/rfc2119.txt> language, you
might be better using the word RECOMMENDED or MAY over SHOULD here.

Additionally, at the beginning of the spec I would put :

"The key words "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT",
"SHOULD", "SHOULD NOT", "RECOMMENDED", "MAY", and "OPTIONAL" in this
document are to be interpreted as described in RFC
2119<http://www.ietf.org/rfc/rfc2119.txt>
."

Regards

Drak
-------------------------------------

I fully agree that someone *must* be assigned to the task, otherwise
it's better keeping current hosting.

Perhaps that was implicit, but I can take this responsibility so long as
I can be replaced if required for any reason. On this regard, I agree
that the Foundation funding / owning / securing the server
infrastructure is a much better long term strategy.

This said, I also agree that it is a better idea to keep the domain and
website content independently owned and managed, for the reasons stated
by Gregory Maxwell.

If there isn't a good consensus on one of the two options I suggested, I
vote we don't lose more time on this question and keep focus with bigger
priorities.


-------------------------------------
Would not an SPV bitcoind transfer all control on validation rules to miner?

A majority coalition of miner (pool operator) might even decide to change block reward
rules if the rest of the network only verifies POW.

Regards,

Tams Blummer
Founder, CEO

http://bitsofproof.com

-------------------------------------
On Thu, Jun 27, 2013 at 10:10 AM, Jim <jim618@fastmail.co.uk> wrote:

Being able to promote a fast SPV desktop wallet would be great!

I went through an cycle of testing on multibit after I saw some
complaints when it went up on the page before without at lot of
discussion. There were a number of issues with it at the time, in
particular the frequent deadlocksâ€” though Mike was saying that those
should be fixed.

I see some of the the other things that were concerning for me at the
time are still uncorrected though, e.g. no proxy support (so users
can't follow our recommended best practices of using it with Tor),
that it reuses addresses (esp for change), that it doesn't clearly
distinguish confirmation level. It also make repeated https
connections to 141.101.113.245? (I'm not seeing the IP in the source,
and it doesn't have a useful reverse dns entry, so I can't tell what
its for).  Is there any timeframe for changing any of this stuff?


-------------------------------------
On Sun, Dec 8, 2013 at 8:03 PM, Mike Hearn <mike@plan99.net> wrote:

I registered bitcointalk.org originally, then passed along control.
It is likely that the two domains are /not/ registered and controlled
in the same way.

The handling of bitcointalk.org was quite disappointing.  Even after
"control" passed from me to Sirius, he did not bother to change the
registrar credentials for months afterward, despite repeated urging.

-- 
Jeff Garzik
Bitcoin core developer and open source evangelist
BitPay, Inc.      https://bitpay.com/


-------------------------------------
No, you don't get it, and it's been explained clearly to you twice.  Take
it to bitcointalk, this does not belong on this list.  Your cure is worse
than the disease.


On Wed, Dec 25, 2013 at 12:53 AM, Ryan Carboni <ryan.jc.pc@gmail.com> wrote:

-------------------------------------

demurrage of any kind will never, ever happen, just give up on that idea.

The negative publicity of "the bitcoin developers are destroying YOUR
coins!" would be devastating.

-- 
--
Gavin Andresen


-------------------------------------
Do you think we're at the point where wallets have to be able to "actively  
bid" the fee using replacement due to block contention?

I think a fee estimation API is just a data point. Depending on the  
properties of the estimator, and how that's presented in the UI, it could  
serve to either increase or decrease the need for recovery.

Like you said, we already have "fee estimation" in the form of "user,  
please estimate the fee!" Now we want to make fee estimation "better", and  
one key aspect of better fee estimation is decreasing the need for  
recovery. Techniques like signing multiple transactions with different fee  
levels should become less useful the better you are at estimating the fee.

What I find interesting is that fee estimation can look at the size and  
type of the transaction, the age of the inputs, the number of inputs  
versus outputs, amount of the outputs, factor in [assumptions about] what  
fee policies miners are actually using, and after all that, look at the  
actual competing transactions on the blockchain and try to figure out how  
many of those are even real.

For example, if you just look at fee-per-KB of mempool versus fee-per-KB  
of recently mined transactions, without taking into account input age,  
number of inputs vs outputs, output amounts... all the other things miner  
might have used to discriminate between transactions, then I don't think  
you'll end up with a better fee estimator.

Contention might bump you out of a few blocks, but if the basis for  
calculating the fee is fundamentally compatible with the relay policies  
and the transaction-inclusion policies being run by large mining pools,  
the transaction isn't dead, it's just pending.

On Fri, 25 Oct 2013 09:13:23 -0700, Peter Todd <pete@petertodd.org> wrote:




-------------------------------------
On 8 December 2013 21:01, Luke-Jr <luke@dashjr.org> wrote:



It's not just about trust, there is the robustness factor: what if he
becomes sick, unavailable, hit by a bus? Others need the ability to pickup
and run with it. The control over the domain (including ability to renew
registration, alter nameservers) needs to be with more than one person.
That's why I suggest using the same people who have control over the
software project at sf,github.
-------------------------------------
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Hi John,

Thanks for the feedback - comments below:


Well, my work from last week and now is a model. A model enabling you to
easily calculate the minimum fee and as a miner which transaction to
include to not shoot yourselves in the foot risking to create an
orphaned block.

The assumption that there is a linearity between block size and latency
is shown pretty well in the paper by Decker et. al (see last weeks
post). What I add this week is mainly more up to date numbers and a
formula dependent only of data that is easy to measure. (fork rate and
block size).


Probably not - but the are at least a minimum - in case they are higher,
the fee should go up further.


Another way to measure latency is to setup a node that only listens but
do not relay data. By measuring the propagation of blocks of different
size as well as transactions, you can get a propagation distribution and
from that an average. However, the relevant propagation time is the one
between the pools/(single miners). Which you cannot assess using this
scheme - however, it would be nice to compare it to the orphan block scheme.


Indeed, and nice... But note that it is never of benefit for the miner
to include a transaction with a fee of less than ~0.0004BTC - unless it
is linked to another transaction that pay an extra fee.

There have been a lot of assumptions on the fee size and generally it
has been linked to the bitcoin exchange rate. This analysis shows that
this is wrong. Also it shows that the scalability of bitcoin is directly
linked to the network and node latency (with the current latency it will
never beneficial for miners to include more than ~30k transactions in a
block or ~70 pr second resulting in ~10MB blocks).
However, halving the latency will double the capacity, down to the
minimum which is governed by the speed of light.


-----BEGIN PGP SIGNATURE-----
Version: GnuPG/MacGPG2 v2.0.22 (Darwin)
Comment: GPGTools - http://gpgtools.org
Comment: Using GnuPG with Thunderbird - http://www.enigmail.net/

iQEcBAEBAgAGBQJSg+H7AAoJEKpww0VFxdGRn+gIAIgju90DED5r//USqKvkQsYI
JDj0tLBLMg9BPXOOt3eJ+NX4YE4lW+QkwqDd/swuJxLmj0l9BQKgt1lTb/f0P/cY
GdE14gh5EYlvNzY1h0TGKcMe8NTWXU0/tC+Clpy4sqBHPXW/eF/77sLQUnFRrLKi
sT48aHOOFUdBLdlyylUzzevh/FFVLidkKqV031tv52+BFHcTFd4kRPwZXgBSs9YH
U66MkJ4ytAqeOfJue9n7Qn4kJF9kNIhRpqTrtapqu8jglLfuYlJ3s5fwaw9FxQdR
+On4IWeXzURQ6tcVRCovCq/2lxRKIbYGlW7HGVASjRmm68/+8YUAfFsYFl6DIgA=
=9tbL
-----END PGP SIGNATURE-----


-------------------------------------
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Also somewhat related, I have been looking for some time now to
abstract out the UTXO and block databases so that a variety of
key/value stores could be used as a backend, configured by a command
line parameter. In particular, it would be interesting for some server
applications to support HyperDex, which is basically a distributed,
fault-tolerant version of LevelDB:

http://hyperdex.org/

By the same mechanism you could just as easily support a Sophia backend.

Mark


On 9/17/13 4:00 AM, Mike Hearn wrote:
LIMITED TIME SALE - Full Year of Microsoft Training For Just $49.99!
-----BEGIN PGP SIGNATURE-----
Version: GnuPG/MacGPG2 v2.0.19 (Darwin)
Comment: GPGTools - http://gpgtools.org
Comment: Using GnuPG with Thunderbird - http://www.enigmail.net/

iQIcBAEBAgAGBQJSOIymAAoJEAdzVfsmodw4H48QALC+ae4wRLEg3lrg9sgayfOn
ukLM079PXgEbARFPt6WxkLnNGYzEbb7IzT0uvaKH4VIW/rrORy9VqNPmliF+834h
XygUwfAzU04K/oLyCsdWZcOugj2P8aufNeA6whLS5IijDLtHb3Ueu4ORNcfLBGqp
KKfqPj0QHseusiLJ9f3IW+LrdM1vAoT1jryTngpQy2i+qFFDM6CN3THCq4adJvjr
AnYlfLoJSZ0/obz/krwLv6vP1BbwxXzv5CfD0Q2bdoEV/EgWDP3Bd5tUzUCjj53/
qMmhaACoVlarohh64s3JNSDSkHDFSbHFt65ZgNQbNY1wmSeyilQcd8FGWOF/WRzW
Z/pl2IdhoCm3t86xSggRGivj/EVeBJlD36i7ohpDbVWFPsf6B4e5M6xSdso/2WBp
fr55TwehCaGE+UHa0gITkE/si1txvY4gti0bLNvwFDEcZ3qsXRsz4CyLlZLMBbPX
4aRNGyqv2yJ2AivkEyNOUugo1Q8RKEKZWfWWDecI53DHdebzKX1zu9GLJwlGJqGw
Qzm7Tdb7S8J/D6IIHf4Xq2LDhQ2fnPylmGSmtuVFEMxeDhmdbNqKSr3kqlWQf3T8
Oa8bm6kUQFJ+11jLEkVEGZJC4e42+faQBxR+CsqvVsTEezDCP1dE7D3QV8ry9YBc
DwXt3299Q03B5LoxpWTq
=KseH
-----END PGP SIGNATURE-----


-------------------------------------




________________________________
 From: "bitcoin-development-request@lists.sourceforge.net" <bitcoin-development-request@lists.sourceforge.net>
To: bitcoin-development@lists.sourceforge.net 
Sent: Wednesday, October 23, 2013 3:38 AM
Subject: Bitcoin-development Digest, Vol 29, Issue 20
 

Send Bitcoin-development mailing list submissions to
Â Â Â  bitcoin-development@lists.sourceforge.net
When replying, please edit your Subject line so it is more specific
than "Re: Contents of Bitcoin-development digest..."
Today's Topics:
Â   2. Re: Revisiting the BIPS process, a proposal (Peter Todd)
----------------------------------------------------------------------
....

On Tue, Oct 22, 2013 at 09:34:57AM +0200, Martin Sustrik wrote:

Writing such RFCs is dangerous due to the consensus nature of Bitcoin -
it makes people think the standard is the RFC, rather than the code.

I hear one of the better intros to Bitcoin is the Khan academy videos,
but I've never watched them myself. Once you understand how it works,
start reading source code - the Bitcoin codebase is actually really
simple and readable. However remember that the implications of that
codebase are anything but simple; there's lots of reasons to think
Satoshi himself didn't understand Bitcoin all that well, even by the
time he left the project.

-- 
'peter'[:-1]@petertodd.org
000000000000000f155e7a648e84a83589048ae1cacb0c60bfce2437553b6af4
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 685 bytes
Desc: Digital signature

------------------------------
I feel that I must respond to the statements that 
1.
the Bitcoin codebase is actually really
simple and readable. 

2.
However remember that the implications of that
codebase are anything but simple; there's lots of reasons to think
Satoshi himself didn't understand Bitcoin all that well, even by the
time he left the project.

On point one: if it was/is so readable, why hasn't it been documented better, if at all? 
Why haven't the obscure names of important items been globally searched and replaced?
Why are there still mixed formatting "styles" still in the code. I think it is the fear that C++ 
is so brittle, that one change may bring the whole house of cards down.
I feel that it is the language (C++) that is hindering the expression of ideas in the code.
This goes to your point two about Satoshi's understanding. I think just the opposite:
that he knew what he wanted but that C++ hindered him in expressing and implementing it.
I think that if anything, C++ was what Satoshi "didn't understand all that well".

But then who does understand C++, really? See
https://groups.google.com/forum/#!msg/comp.lang.lisp/7xCvdzijzgU/4xCFzLc3d5EJ 
and the quote:
Whenever I solve a difficult problem with C++, I feel like Iâ€™ve won a bar fight. â€” Michael Fogus

I don't think readability is attainable easily in C++. It requires intentionally writing so that 
others may understand your code. How many programmers have ever done that? And this 
is like swimming upstream in C++, where things are designed to be hidden! 

Ron
-------------------------------------
We've been toying with the idea of a 'dead' button, one that issues a bunch
of pre-generated txs sending stuff out to a previously secured 'backup' set
of addresses (we don't think in terms of wallets, just keypairs).

In this scenario, you have a long-term storage address (or set of them),
and if you need to hit the panic button, previously signed transactions
send value over to your emergency storage.

If you've mucked around sending / receiving with your long-term storage,
you'd only catch some BTC, not necessarily all, but what's nice is the
panic transaction leaking has lower security requirements than your private
keys -- worst case it's out, and you've got to deal with stuff in emergency
storage, as opposed to losing all your coins.

You could pair this with a server that checks if 'safe' addresses have
'unauthorized' transactions showing up on the blockchain, and you'd have a
reasonable automated security layer. Maybe. :)

I'm interested in thoughts on this approach as well.

Jorge -- I respectfully disagree with you, there are a number of enterprise
scenarios where your method is not appropriate.
-------------------------------------
I would like to know what are your thoughts on moving bitcoin.org on a
dedicated server with a SSL certificate?

I am considering the idea more seriously, but I'd like some feedback
before taking steps.

Savann


-------------------------------------
I disagree.  There's a real perception and usability issue with the
current interface combined with the current price.  People are
intimidated by the current system, even though the price really reflects
Bitcoin starting to spread its wings (maybe prematurely, bubble-style,
but the price will have to get to this point eventually if Bitcoin will
thrive at the target scale). 

Bitcoin's learning curve is hard enough already.   As silly as it
sounds, feeling "insecure" because you only 0.00032 BTC, and then using
too many zeroes when paying for your smoothie are problems that can
really turn people off.  You say "Let the market sort it out". 
Sometimes the market needs direction and consistency.  Without us doing
anything, we just end up with fragmentation and confusion. 

I'd much prefer we reach a consensus on a path forward and push that
path hard.  Because there's always resistance to change, and confusion
along the way.  The easier and more consistent we can make it, the
smoother it will be.  We want to avoid:

"Hey, I'll sell it to you for 382 microbes." 
"What is a microbe?  Is that the same as a XBT?"
"I don't know, my wallet uses NBC."
"Well how much BTC is it? Okay, just send me 0.00038200 BTC"
"Four zeros after the decimal?"
"Yeah... oh wait you just sent me 10x"
...

Again it sounds silly, but this is a real usability issue.

On 11/14/2013 07:37 PM, Daniel F wrote:



-------------------------------------
Hi all,

We're thinking about ways of automatically exchanging contact details between wallets, in order to encourage the proliferation of identifiable names and photos rather than long and hard-to-verify addresses.

The simplest version goes like this:

2 BTC Bitcoin is sent to someone, and a data lookup hash is inserted into the transaction. When it arrives on the other end, it is indeed looked up, and instead of being presented with a dialogue that says "you received 2 BTC from 13Y94z43Nbbb6wevRyk82CeDoYQ5S28zmA", it's "You received 2 BTC from Frank Jones" including a nice photo.

Now. We can simply delete this data in reference to the transaction ID after it happens (or delete it after a time), but is there any more decentralized way to do it? I would prefer us to run no dedicated servers that would ever put us in a position of being coerced into giving data, or otherwise altering our system to store it.

Any thoughts about this?

-wendell

grabhive.com | twitter.com/grabhive | gpg: 6C0C9411

-------------------------------------
Please do not post about this on bitcoin-development again. It's off topic
and you were already asked to stop.


On Wed, Sep 4, 2013 at 11:35 PM, Randolph D. <rdohm321@gmail.com> wrote:

-------------------------------------
bitcoinj-0.10 release notes:

   - We now require Bloom-capable (0.8+) peers by default and will
   disconnect from older nodes. This avoids accidental bandwidth saturation on
   mobile devices.

Given the user-security concern that Peter brings up, reconsideration of
this new default behavior in SPV clients may be warranted.



On Fri, Aug 16, 2013 at 4:15 AM, Peter Todd <pete@petertodd.org> wrote:

-------------------------------------
On Mon, Nov 4, 2013 at 8:39 PM, Peter Todd <pete@petertodd.org> wrote:

Likewise, I did too and am also not very tolerant with "trusted" or
"centeralized" things in general.

An authenticated miner announced set of nodes is _far_ from a cure
all, as any attack they stop can be recovered by adding "and dos
attacks the public miner announced nodes" to the attack's
requirements... but we build security with layers.

Bitcoin's security is only improved when we can weave the network
tighter and make partitioning it more difficult.


-------------------------------------
On 14 November 2013 22:32, Drak <drak@zikula.org> wrote:


Hrm. Freudian slip... you know what I mean *fee, not fed.... :-)

.... so in response to those saying the fees are $0.20, actually it's more
like $0.042 at current prices.

Drak
-------------------------------------

It was fixed by Satoshi long ago, back when we used CVS I think.

The problem was how scripts were executed. They were concatenated together
and then run as a single unit. The now obsolete OP_CODESEPARATOR was put
between them to control what was hashed and what wasn't.

The obvious problem with that arrangement being that scriptSig ran first
(it has to, to push the signatures onto the stack), so nothing stopped you
setting a scriptSig to OP_RETURN and making the script evaluate to true,
always. A pretty amazing oversight given the thought and care that went
into Bitcoin generally, and its robustness since then.

The fix was to move to the current system whereby the two scripts are
executed independently but sharing a stack, and it's only the return value
of the scriptPubKey that matters.

The scripting system always struck me as a rather late addition to the
design. Satoshi admitted as much when he said that he added it after
encountering an explosion of special cases as he designed various types of
contracts. The fact that there's an obvious bug in CHECKMULTISIG is more
evidence of this part being a general rush job, along with Satoshis
willingness to disable much of its functionality later with the IsStandard
checks. Also the design of CHECKSIG is an obvious retrofit, it would have
made far more sense to decompose it, and we never found a use case for 99%
of the opcodes despite having successfully designed (redesigned?) all the
contract types he ever mentioned.
-------------------------------------
One of the primary upcoming priorities for bitcoinâ€™s infrastructure, beyond the bloom filter, will be the continued modularization of the system.
Here at the Bitcoin Grant, we would like to jump start this development with a financial incentive and initiate an ongoing conversation on how we can work together towards developing a smarter, more efficient system of tomorrow, today.
Up for grabs: 500 bitcoins or $500,000; whichever is greater.
Taking on a project of this scope is a highly intensive, technical undertaking and we believe excellent developers should be compensated as such, especially when it comes to open source projects.
One of the main goals will be to separate the wallet from the node, as we have already done with mining. This way, the wallet, which will only hold private keys and create transactions, would pass transactions directly to a relay node, based on the bloom filter. Meanwhile, the block node will maintain the block chain and validate and relay new blocks.
Such developments would significantly strengthen the system. Modularization would make cancer attacks less likely and increase the node count, which, currently, is fairly low.
This is by no means is a feature request, merely ideas as to initiate a discussion. We welcome any feedback or suggestions. And of course, let us know if you would like to contribute to this project by submiting a grant proposal.
http://bitcoingrant.org http://bitcoingrant.org/&lang=en
-------------------------------------
On Tue, Nov 05, 2013 at 11:56:53AM -0500, Ittay wrote:

<snip>


Credit goes to Gregory Maxwell for pointing this out, but the random
choice solution does in fact introduce a vulnerability in that it
creates incentives for pools over a certain size to withhold blocks
rather than immediately broadcasting all blocks found.

The problem is that when the pool eventually choses to reveal the block
they mined, 50% of the hashing power switches, thus splitting the
network. Like the original attack this can be to their benefit. For
pools over a certain size this strategy is profitable even without
investing in a low-latency network; Maxwell or someone else can chime in
with the details for deriving that threshold.

I won't get a chance to for a few hours, but someone should do the
analysis on a deterministic switching scheme.

-- 
'peter'[:-1]@petertodd.org
0000000000000005e25ca9b9fe62bdd6e8a2b4527ad61753dd2113c268bec707
-------------------------------------
On Wed, May 15, 2013 at 07:19:06AM -0400, Peter Todd wrote:

Protocol voting is a vote per user policy preference, not a CPU vote, which
is the point.  Current bitcoin protocol is vulnerable to hard to prove
arbitrary policies being imposable by a quorum of > 50% miners.  The blind
commitment proposal fixes that, so even an 99% quorum cant easily impose
policies, which leaves the weaker protocol vote attack as the remaining
avenue of attack.  That is a significant qualitative improvement.

The feasibility of protocol voting attacks is an open question, but you
might want to consider the seeming unstoppability of p2p protocols for a
hint.

Adam


-------------------------------------
On Mon, Dec 9, 2013 at 6:55 AM, Drak <drak@zikula.org> wrote:

It has not been released. It's queued for announcement. We were
waiting for another independant gitian build before sending out the
announcement.


-------------------------------------

Oh, it did? When was that? I must have missed this excitement :)

Any idea how much load it had?

Perhaps I wasn't clear on the point I was making Drak's threat model

Well, that depends. If you watch Applebaums talk he is pushing TLS pretty
hard, and saying that based on the access to the source docs some of their
MITM attacks can't beat TLS. It appears that they have the capability to do
bulk MITM and rewrite of downloads as Drak says but *not* when TLS is
present, that would force more targeted attacks. So to me that implies that
TLS does raise the bar and is worth doing.

However if we can't find a server that won't melt under the load, then
that'd be an issue. We could consider hosting downloads on AppEngine or
something else that can handle both high load and TLS.
-------------------------------------
How many downloads/day do we see currently? I think you said it's on the
order of a few thousand, so nowhere near 30k I'd guess. Anyway I can mirror
it if we need to.

The JavaFX packager is supposed to delete parts of the JVM that aren't
used. Is the 30-40mb figure based on using that tool or something else?
Note that you don't need to use the JFX widget toolkit to use the bundler
tool.

We could also invest in a copy of JET, which does native compilation down
to self contained Windows binaries. It might create smaller bundles. But,
it's a proprietary tool and I don't know how reproducible its outputs are.

For the auto update, is there an existing auto update framework that we can
modify to support threshold signed updates? I'm sure such a thing must
exist. The updates would download in the background and then the app can
just ask the user to restart it once the update is locally available, as
Chrome does.



On Tue, Jul 9, 2013 at 12:56 PM, Jim <jim618@fastmail.co.uk> wrote:

-------------------------------------
Pieter,

I was re-reading BIP0032, and checking some of the equations... It seems
to me that there is something wrong (or I have missed something).

As I see it there can only be one HMAC function, used for both private
and public derivation - I assume that:
[1]  CKD((k_par, c_par), i) -> (k_i, c_i)
[2]  CKD'((K_par, c_par), i) -> (K_i, c_i)

Where K_par = k_par*G, will result in K_i = k_i*G (and identical c_i's
in both expressions).

Now following your formulas for [1]:
  k_i = I_L + k_par (mod n)
where I_L = {HMACSHA512(c_par, 0x00||k_par||i)}_L (denoting left
256bits). Further c_i = I_R.
This gives a K_i = k_i*G = I_L*G + k_par(mod n)*G

Now follow the formula for [2]:
  K_i = (I_L+k_par)*G = I_L*G + K_par
This is not the same as above, however, if we remove the (mod n) we are
getting closer, but still the value of I_L are different in the two
equations as: HMACSHA512(c_par, 0x00||k_par||i) <> HMAXSHA512(c_par,
X(k_par*G)||i).

We can, however, fix things if we change private child key derivation to:

To define CDK((k_par, c_par), i) -> (k_i, c_i):
* (no difference in deriving public or private):
	I = HMACSHA512(c_par, X(k_par*G)||i)
* Split I into I_L, I_R (256bits each)
* k_i = k_par + I_L
* c_i = I_R
* and, if using public derivation, we use K_i = (k_par + I_L)*G

Now for pure public derivation (i.e. we don't know the private key):
To define CDK'((K_par, c_par), i) -> (K_i, c_i):
* I = HMACSHA512(c_par, X(K_par)||i)
* Split I into I_L and I_R
* K_i = K_par + I_L*G (= k_par*G + I_L*G = (k_par+I_L)*G = k_i*G)
* c_i = I_R

Now we have the right properties, but it required quite some changes,
also note that c_i are now equal in both private and public derivation.

Comments ?


Sincerely,

Michael


-------------------------------------
Names clearly solve a different problem than that, but we still use them,
so they must be solving _some_ problem :p  In this case they're a unique
identifier humans can remember after a bit of use and easily communicate to
each other with little room for error.  Securely mapping them to public
keys would make key verification simpler.  Simpler than checking a much
larger key fingerprint, at least.  Like I said, it's probably a niche
product ;)

I used to remember dozens of phone numbers before my phone did it for me,
but maybe I was just weird.


On Thu, Oct 3, 2013 at 9:22 AM, Mike Hearn <mike@plan99.net> wrote:

-------------------------------------
Sorry I don't have time to reply more in depth, but I wanted to say to
Jeremy (especially) and Peter I'm very impressed to see such a good
design be created so fast that does not depend on replacement at all.
This is a great example of how often the right approach to a problem
is to accept that the easy solution will not work, and find a way to
overcome the issue, rather than trying to paper over the easy
solution's problems with insecure design. I'm reminded of Peter's work
on fidelity bonded banking to overcome Bitcoin's scalability problem,
although that needs to become real, and soon, so we can find all the
flaws in it that will only become apparent when the idea is
implemented for real.

Jeremy: There does not seem to be a PGP key listed for your email
address. Is that correct?

On Sat, Apr 20, 2013 at 8:51 PM, Jeremy Spilman
<jeremy.spilman@gmail.com> wrote:


-------------------------------------
Ryan Carboni wrote:

Need is an awfully big word.  One thing we are certain of is that some 
guy telling us all that we are wrong is nowhere near the "need" level.
Don't take this the wrong way, but things like this make it very hard 
for us to take you seriously.

Please read up on how the system works, then read up on why we reject 
the argument from authority, then if you still have something to say, 
please do so in a proper venue.  One option for this discussion is the 
bitcointalk.org forums, where you will find literally dozens of threads 
proposing the exact same thing you are proposing.

This mailing list is NOT for political discussion.
-------------------------------------
On Tue, Dec 3, 2013 at 12:07 PM, Gavin Andresen <gavinandresen@gmail.com>wrote:


Wouldn't the idea be that the user always sees 10mBTC no matter what, but
the receiver may receive less if the user decides to pay with a huge
transaction?

It may be acceptable that receivers don't always receive exactly what they
requested, at least for person-to-business transactions.  For
person-to-person transactions of course any fee at all is confusing because
you intuitively expect that if you send 1 mBTC, then 1 mBTC will arrive the
other end. I wonder if we'll end up in a world where buying things from
shops involves paying fees, and (more occasional?) person-to-person
transactions tend to be free and people just understand that the money
isn't going to be spendable for a while. Or alternatively that wallets let
you override the safeguards on spending unconfirmed coins when the user is
sure that they trust the sender.
-------------------------------------
On 11 June 2013 17:29, Luke-Jr <luke@dashjr.org> wrote:


I think this statement may need to be justified.



Got it.



Does this mean that people should not be investing in "vanity addresses"?


-------------------------------------
Hey list,

Currently the bitcoin-qt application's XDG desktop integration on some
desktop environments requests that it be placed under the "Office" menu
category.[1] This is a rather broad category and I would like to suggest
that this be refined further into "Finance", given that XDG's menu
specification allows for this.[2]

I believe the line in question in bitcoin-qt.desktop should be as
follows:

        Categories=Office;Finance;

I would have provided this trivial patch myself, but my knowledge of Git
is rather weak and I apologize.

Respectfully,

[1] <https://github.com/bitcoin/bitcoin/blob/master/contrib/debian/bitcoin-qt.desktop>
[2] <http://standards.freedesktop.org/menu-spec/latest/apas02.html>

-- 
Kip Warner -- Software Engineer
OpenPGP encrypted/signed mail preferred
http://www.thevertigo.com
-------------------------------------
On Mon, Nov 04, 2013 at 12:10:38PM +0100, Adam Back wrote:

There's been a number of uses found for tx-replacement beyond simply
modifying fees. In additition, allowing for the value of a specificly
designated change address to be changed after the fact is not compatible
with current zero-conf-using implementations; they don't know to treat a
txout as special so allowing its value to be reduced would allow for a
zeroconf attack.

Anyway, if you look at the code that actually implements the
replacement, it's extremely simple already. I see no reason to make it
less general; transaction relaying rules are not part of consensus.

-- 
'peter'[:-1]@petertodd.org
000000000000000a6dd96c551eca7299463e4e523462798a006535f412b519c7
-------------------------------------
I don't think choosing the block with the lowest hash is the best 
option.  The good and bad miners have an equal probability of finding a 
lower hash.  But after Alice finds a block she can easily determine the 
probability that someone else will find a lower hash value that meets 
the difficulty requirement.  This can be used to judge if its best to 
start working on the next block or work on finding a lower value hash to 
increase the chance her block is used.

Its better if the block is chosen in a way that doesn't let Alice know 
the probability her block will be chosen.  One simple possibility is to 
start at the least significant bit of the hash and whichever has a 1 is 
chosen and if both bits are the same the next bit is used.

This should be pseudo random and not give Alice any knowledge ahead of 
time if her block will be chosen.  This would prevent the network hash 
power from being split between two branches unlike each node choosing a 
random block.

Quinn

On 11/05/2013 05:51 PM, colj@Safe-mail.net wrote:



-------------------------------------
On Tue, Apr 30, 2013 at 3:27 PM, Andy Parkins <andyparkins@gmail.com> wrote:

Hardly.  The storage format is bitcoin protocol wire format, plus a
tiny header.  It is supported in multiple applications already, and is
the most efficient storage format for bitcoin protocol blocks.



You don't have to create anything on the fly, if you store blocks in
their native P2P wire protocol format.


This is a whole new client interface.  It's fun to dream this up, but
it is far outside the scope of an efficient HTTP protocol that
downloads blocks.

Your proposal is closer to a full P2P rewrite over HTTP (or a proxy thereof).

-- 
Jeff Garzik
exMULTI, Inc.
jgarzik@exmulti.com


-------------------------------------
Abe is able to do what you want.

https://github.com/jtobey/bitcoin-abe
https://bitcointalk.org/index.php?topic=22785.0

With kind regards,

Jouke Hofman
Bitonic.nl



On 06/06/2013 02:53 AM, Marko Otbalkana wrote:



-------------------------------------
On Sat, Feb 09, 2013 at 03:33:25PM +0100, Timo Hanke wrote:

In what way are you not solving the same problem as DNS? I don't mean
the Luke-Jr's (quite correct) technical point about key-value maps, I
mean the human problem that I have these unique numbers that I can't
memorize, and I have some non-unique names that I can.

By creating Yet Another Totally Different System you are just creating
another way that users can be confused into thinking some name snatched
up by some scammers in some little-used PKI system is who they are
supposed to be communicating with. Fortunately your PKI system isn't
actually used and probably never will be, so it's not a big deal yet,
but ultimately you are adding to the problem.

Go work on namecoin and make it more usable. Then add some PKI to it
using the *same* domain names so when I see a PKI certificate for "foo"
I know it must be the same "foo" website I just visited and the same
"foo@foo" I just emailed.


Alt-chains don't have to be based on mining you know. Your proof-of-work
can be replaced by proof-of-sacrifice, specifically Bitcoins. A
particularly nice scheme is to use transaction fees and Bitcoin block
height. Specifically every block in your alt-chain will have a merkle
path to a transaction in a Bitcoin block. Of course there can be more
than one such block, so you introduce a tie-breaker rule: the
transaction with the highest mining fee wins.

The reason why this is nice is because it becomes really easy to be sure
that a better chain won't turn up after the fact - make sure the
transaction linking the alt-chain to the Bitcoin block has the highest
fee in the block. Thus if you want to, say, register a domain name, do
so in the alt-chain, then "mine" the block by creating a suitable
transaction. Make sure it's the biggest fee, wait a few confirmations,
and you're good to go with the same level of security as Bitcoin proper.

Because the rule is that a merkle *path* exists, multiple alt-chains can
use this mechanism at the same time, with the exact same security
guarantee re: max fees. (note that you're chain needs to store copies of
the txin's for the tx sacrificing the fee, transactions by themselves do
not prove fees) Multiple parties can also colaborate to create the
transaction, each providing, and signing for, an input for their portion
of the total fee.


There is the problem that miners get to keep the fee, thus they can
create these special proof-of-sacrifice transactions at low cost, and
potentially make it difficult to get a block mined, or to be sure a
block won't be undone later. This problem can be solved with my
"two-step sacrifice" protocol.(1) Essentially you create a transaction
that is invalid until some time in the future and sacrifices Bitcoins to
mining fees, then create a second transaction that includes the first
one as data. You publish the second in the block chain, proving the
whole world had an opportunity to mine it. Eventually the first is in
fact mined, thus sacrificing Bitcoins to a miner you have no control
over. For a alt-chain you would consider the sacrifice to be a "balance"
and then spend that balance as required in later blocks in a way that is
guaranteed to be public so you can still check the security guarantee of
knowing your tx had the max fee. For instance with the contract protocol
I describe in (1), shave off what ever percentage of the original
sacrifice, linking the merkle-root of the merkel tree of alt-chains at
the same time. Anyone can still monitor the set of all two-step
sacrifices and associated contract movements and check that their one in
a block was the largest possible. Finally if you want to be nice, modify
the contract value rules so only the successful max contract value tx
has it's balance decreased.

1) https://github.com/petertodd/trustbits/blob/master/fidelitybond.md

Actually, you know gmaxwell, the above would be a great way to run the
alt-chain I'm probably going to need for the fraud proofs in Trustbits.
Although it does have the minor problem of being ludicrously complex...


The blockchain grows at a maximum rate of 55GiB/year. Do you think your
users will all want to have that available just to validate some PKI
certificates?

-- 
'peter'[:-1]@petertodd.org
-------------------------------------
Some really nice efforts out there to map and analyze the bitcoin P2P  
network.

The current protocol apparently recommends returning up to 2500 addresses  
 from 'getaddr'. I'm not sure how much clients are expected to probe the  
address space in order to select 'far-apart' peers, or how much such an  
process would even attempt to achieve.

How much does it matter if the ability to discover the entire network of  
peers is fast or slow? There are probably pros and cons to both.

Is there any thought to how existing bitcoin node relations, and the ease  
at which peers can be discovered, becomes a service in itself, or even  
possibly a vulnerability?

Are there any past instances of applications hijacking or interfacing with  
the exiting p2p messages, or abusing 'getaddr' functionality? Are there  
any guidelines on this, or should there be?



-------------------------------------
On Thu, Oct 24, 2013 at 9:32 PM, Jorge Timn <jtimon@monetize.io> wrote:


Well, I would say more "retype" than "remember". I really don't think that
common user will memorize it. But of course, it is still an option.



No, I dont' think it is stupid! Actually it was my concern as well.
Unfortunately I don't think it is "politically correct" to include all
bitches, assholes and motherfuckers in end user product :-).




Well, bip39 can have more dictionaries and *maybe* swearword dictionary
would gain some popularity ;).

slush
-------------------------------------
Im inclined to agree, as this was discussed on multiple occasions and seems to fix a lot of the address re-use problems. With hot topics like coin validation, I think its important to highlight the privacy that generating fresh addresses from public extended keys grants us.

Also thinking about implications regarding non-merchant use of Payment Protocol, encouraging the exchange of extended public keys instead of a single address could be a boon for Payment Protocol to actually be useful for users. Initially, the idea was that the merchant would generate a new address from an extended key and include that in the Payment Request. How do we handle pushing the extended public key down to the wallet itself? Do we just shoehorn the exchange of keys into the Payment Protocol itself via a special tag or would this require more substantive change? Services could develop to facilitate the exchange (acting as a sort of PP gateway) or wallet software might be able to directly communicate, perhaps by exchanging PGP-encrypted files in Payment Protocol format via Bluetooth, AirDrop, email, BitMessage, or whatever future communications channel comes into being. 

Thanks again to Peter for putting together a consolidated list of topics!

Taylor



On Dec 19, 2013, at 2:40 PM, caedes <caedes@sindominio.net> wrote:


-------------------------------------
On Mon, Oct 14, 2013 at 2:08 PM, Adam Back <adam@cypherspace.org> wrote:

Quite a neat idea...



FWIW, litecoin devs are open to having litecoin be a bit of a staging
area for new bitcoin features.  Obviously there is some self-interest
there -- "we have new cool stuff first!" -- nevertheless, it is a live
test that could demonstrate problems with new features before they
land in bitcoin-stable.

-- 
Jeff Garzik
Senior Software Engineer and open source evangelist
BitPay, Inc.      https://bitpay.com/


-------------------------------------
On Wed, Jul 17, 2013 at 2:37 PM, Tamas Blummer <tamas@bitsofproof.com>wrote:


Which is why it's still vital that any "important" node in the economy uses
full validation.

A majority miner coalition could change the block reward and award
themselves money which SPV clients would accept, however, the moment
somebody tried to cash that money out via an exchange, or use it to
purchase something from an online shop, or just see if it propagated across
the P2P network effectively, they'd notice something had gone wrong. Of
course it'd be in the news long before this happened ....

SPV is really meant for nodes that go away and come back a lot, i.e. end
user wallets. If you're a merchant it'd be dumb to run one unless you're on
such a tight budget that your server resembles a powerful tablet.
-------------------------------------
On Thu, Jun 20, 2013 at 3:13 AM, Addy Yeow <ayeowch@gmail.com> wrote:

That works until another field is added in the same manner.

Implementations are expected to follow the standard logic of

if (more data)
   parse field X
if (more data)
   parse field X+1
if (more data)
   parse field X+2
etc.

Ugly or not, there is no point in changing now.  Updating the version
message to a radically different design, for simply cleanliness
reasons, is not sufficient cause to migrate the entire bitcoin
universe to a new and different version/feature negotiation setup.

--
Jeff Garzik
Senior Software Engineer and open source evangelist
BitPay, Inc.      https://bitpay.com/


-------------------------------------
-----BEGIN PGP MESSAGE-----
Version: GnuPG v1.4.11 (GNU/Linux)
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=6OvE
-----END PGP MESSAGE-----


-------------------------------------
Following the discussion on the recent mining sybil trick, I reread the
article on block propagation by Decker et al.* and decided to use it for
doing a proper estimate of transaction fee size and optimal block size.

The propagation of a block depends on and is roughly proportional to its
size. Further, the slower a block propagates the higher the risk of a
fork, so as a miner you are basically juggling the risk of a fork
(meaning you loose your bounty) vs the opportunity for including more
transactions and hence also get those fees.

This alone will dictate the minimal transaction fee as well as the
optimal block size!

Lets try to put it into equations. For the purpose of this initial study
lets simplify the work by Decker et al. Roughly, we can say that the
average propagation time for a block is t_propagate, and the average
time between blocks is t_blocks. Those are roughly 10sec and 600sec
respectively. The risk of someone else mining a block before your block
propagates is roughly**:

P_fork = t_propagate/t_blocks (~1/60)

Also note that propagation time is a function of block size, S:

t_propagate = t_0 + alpha*S

where Decker et al have determined alpha to 80ms/kb. We also define the
fee size pr kilobyte, f, so

E_fee = f*S

Given these equations the expected average earning is:

E = P_hashrate*(1 - P_fork)*(E_bounty + E_fees)

And inserting:

E  = P_hashrate*[1 - (t_0 + alpha*S)/t_block]*(E_bounty + f*S)

We would like to choose the fee so the more transactions we include the
more we earn. I.e. dE/dS > 0:

dE/dS = P_hashrate*{[(t_block - t_0)*f - alpha*E_bounty]/t_block -
2*alpha*f/t_block*S}

Which gives:

 f > alpha*E_bounty/(t_block-t_0) ~ alpha*E_bounty/t_block

or f > 80*25/600000 = 0.0033 or assuming a standard transaction size of
0.227kb:

f_tx > 0.00076.

Note that this number is 8 times higher than the current transaction
fee! So the current optimal block size is an empty block i.e. without
other transactions than the coinbase! (miners don't listen now...)

Lets see what you loose by e.g. including 1000 transactions:

E(1000) = P_hashrate*24.34XBT

Which is a loss of 2.6% compared to not including transactions at all!

So there are two ways forward from here. 1) raise the minimum fee, and
2) make transactions smaller. We cannot make transactions much smaller,
but we can utilize that most of them have already been broadcasted
verified and validated and then just include their hash in the block***.
This changes the relevant size for a transaction from 0.227kb to
0.032kb. Which makes f_tx = 0.00011. We are almost there!

Now assume that we implement this change and raise the minimum fee to
0.00015, what is then the optimal block size (dE/dS = 0) ?

 S = 1/2 * (t_block/alpha - E_bounty/f)

Which gives 1083kb for a bounty of 25 and 2417kb for a bounty of 12.5.
Optimal size in case of no bounty or an infinite fee is 3750MB.

Final conclusions is that the fee currently is too small and that there
is no need to keep a maximum block size, the fork probability will
automatically provide an incentive to not let block grows into infinity.

*)
http://www.tik.ee.ethz.ch/file/49318d3f56c1d525aabf7fda78b23fc0/P2P2013_041.pdf
**) The calculations should be done using the proper integrals and
simulations, but I will leave that for academia ;)
***) A nice side effect from switching to broadcasting transactions in
blocks as only their hash is that it decouples fee size from transaction
size!


-------------------------------------
On Sat, Oct 19, 2013 at 9:38 AM, Mitar <mmitar@gmail.com> wrote:

Hopefully Nick will show up someplace and offer some specific pointers
to where we failed him.

The only interaction I can find from him on IRC is in #bitcoin, rather
than #bitcoin-dev:

--- Day changed Mon Sep 16 2013
11:45 < csmpls> Hi, I'm interested in contributing to the official
bitcoin project. Is there a mailing list I can join?
11:46 < neo2> csmpls, contributing how?
11:47 < csmpls> neo2 - probably start by approaching a low priority
issue like this one https://github.com/bitcoin/bitcoin/issues/2545
11:48 < michagogo> csmpls: There *is* a mailing list
11:48 < michagogo> ;;google bitcoin-dev mailing list
11:48 <@gribble> SourceForge.net: Bitcoin: bitcoin-development:
<http://sourceforge.net/mailarchive/forum.php?forum_name=bitcoin-development>;
Bitcoin-development Info
11:48 < csmpls> Great, thanks.
11:48 < michagogo> I don't know how active it is, though
11:49 < michagogo> There's also the #bitcoin-dev channel

I got involved with Bitcoin without previously interacting with other
contributors (AFAIK) and maybe things have changed in ways invisibly
to me. But I don't think so. Michagogo, who was answering there, is a
newer participant and I don't think anyone knows him from anywhere.
Certainly if things have become less welcome to new participants that
would be bad.

I can point out a number of other recent contributors who, as far as I
can tell, just showed up and stared contributing.  But I don't think
that the existence of exceptions is sufficiently strong evidence that
there isn't a problem.

The specific complaints I can extract from that article are:

"I wasn't even allowed to edit the wiki"

I'm confused about this, if he's referring to en.bitcoin.it.  Editing
it is open to anyone who is willing to pay the 0.01
(https://en.bitcoin.it/wiki/BitcoinPayment) anti-spam fee. This isn't
a policy set by the bitcoin development community, though I'm not sure
that its a terrible one. I've both paid it on behalf of other users
and made edits on behalf of people who didn't want to go to it.  At
least relative to some policy which requires actual approval the
payment antispam is at least open to anyone with Bitcoin.

"My IRC questions about issues on the github page were never answered"

Without a nick I'm unable to find more than the above, unfortunately.
So I don't yet know what we need to improve there.

"#bitcoin-dev would rather talk about conspiracies, or about
destroying other cryptocurrencies"

I've been pretty aggressive about punting out offtopic conversation
from #bitcoin-dev lately. Enough that I worried that my actions would
be the inspiration for this complaint. Much of the time discussion
like that is brought in and primarily continued by people who are not
active in the development community at all, but deflecting it to other
challenge without creating a hostile environment (or one that merely
feels hostile to new people) is hard.  Nicks comments themselves may
be a useful thing for me to show to people in the future on that
point.

"Bitcoiners are a bunch of paranoid, anti-authoritarian nutjobs"

I actually don't think that this stereotype accurately reflects the
development community. (In fact, I personally enjoy the great sport of
being called a statist by some of these aformentioned jutjobs, but
none of them are developers). On his other article Nick also asserts
"Most contributors hide their identities", but this is factually
untrue as far as I can tell. (In that same article he writes,
"Bitcoin's core code is written in Typescript, which is compiled into
C++"â€¦)

"I looked at the many items sitting in pull request purgatory"

Many of the long standing pull requests are actually created by people
with direct commit access.  We use a model which has a relatively long
pipeline, a fact which I think is justified by the safety
criticialness of the software and our current shortages of active
review. Hopefully long term motion towards increased codebase
modularity will allow faster merging of "safe" changes.

But I suspect there will always be a backlog, at least of "unsafe" changes.

Which brings me to,

"I didn't even know what I had to do"

Above all, I think the most important takeaway from this is that we
need to have better introductory materials.

One obvious place to put them would be
http://bitcoin.org/en/development  but the IRC question makes me
believe that Nick hadn't actually found that page, it's a little
buried.


-------------------------------------
On 8 December 2013 12:37, Luke-Jr <luke@dashjr.org> wrote:



Malicious actors with root access to the server is another issue entirely.
Sure it's a problem, but it is not an argument not to have a properly
signed SSL certificate.

With out one, the exploit can be performed on routers to redirect traffic
through a third party alter the content of the site (like the links on
bitcoin.org to various wallet projects) and then onto the correct
destination. SSL at least mitigates that. For example it would be trivial
to impersonate Electrum's site or whatever, "change" the link on the fly
that appears on the trusted source bitcoin.org via BGP redirection. Now
users will be directed to the scammers site which could be identical except
for domain name and of course malicious binaries.

BGP redirection is a reality and can be exploited without much
expense/effort. MITM is a real world threat, not some theoretical
possibility - reports show it's happening on an unprecedented scale. SSL is
essential - that's a no-brainer. Sure other measures are important, but
without SSL there is almost no point to any of the other options.

SSL is so considered so important that the *HTTP 2.0 spec might be SSL
only*according to recent discussions at the W3C (
http://lists.w3.org/Archives/Public/ietf-http-wg/2013OctDec/0625.html).

Drak
-------------------------------------


When the log messages don't accurately describe the contents of the diff,
it's just misinformation and noise. Everyone starts out by wanting a neat
collection of easy to understand and review commits, but in practice it's
extremely hard to always get it.

I know how to make squashed commits, thanks. I've done LOTS of code review
in my life. I'm making a point here as one of the few people who goes
through large pull requests and reviews them line by line. It's hard,
partly because github sucks, and partly because reviewing lots of small
commits sucks.

There's nothing that makes a single large commit harder to review. It's the
same amount of code or strictly less, given the tendency for later commits
to change earlier ones. You can easily search the entire change whilst
reviewing. There are lots of things that make it easier.

FWIW inside Google the code review process is one-commit-one-review.
-------------------------------------
I think this is a very interesting idea. As Bitcoiners, we often stuff
things into the 'alt chain' bucket in our heads; I wonder if this idea
works better as a curing period, essentially an extended version of the
current 100 block wait for mined coins.

An alternate setup comes to mind; I can imagine this working as a sort of
gift economy; people pay real BTC for merge-mined "beta BTC" as a way to
support development. There is no doubt a more elegant and practical
solution that might have different economic and crypto characteristics.



On Sun, May 19, 2013 at 6:23 AM, Adam Back <adam@cypherspace.org> wrote:




-- 
Are you coming to Bitcoin2013 <http://bitcoin2013.com> in San Jose In May?
------------------------------

[image: CoinLab Logo]PETER VESSENES
CEO

*peter@coinlab.com * /  206.486.6856  / SKYPE: vessenes
71 COLUMBIA ST / SUITE 300  /  SEATTLE, WA 98104
-------------------------------------
On 9 December 2013 13:52, Roy Badami <roy@gnomon.org.uk> wrote:


It was released and it's all over bitcointalk/reddit
-------------------------------------
As I said, there's no benefit. Even if we do that on the C++ side, you
still have to handle connections from bitcoinj clients which will send the
field with the old version number. You can't assume they'll all be updated
simultaneously, even though both the Android app and MultiBit do have
update notifications these days and eventually old versions will presumably
disappear.

Re: flexibility. Let's say version V+1 adds a complicated new set of data
to some messages. Not every client wants or needs the feature enabled by
them.

Now version V+2 adds a simple extension to a basic message that everyone
wants/needs.

To get the latter feature, all clients now have to support the first
feature as well because the version number is monotonic.

OK, we can use a service bit to handle these cases, if we anticipate that
not all clients will want the first feature. But then again, we can also
use the presence of the additional data as the ground truth instead of
duplicating that fact. I don't really mind either way. It just seems that
parsing always requires you to be able to handle truncated messages anyway
(without asserting or crashing), because a bogus client can always send you
partial data. So I don't see what effort is saved.



On Thu, Jun 20, 2013 at 12:52 PM, Pieter Wuille <pieter.wuille@gmail.com>wrote:

-------------------------------------
On Tue, Dec 17, 2013 at 02:48:14PM -0800, Gregory Maxwell wrote:

Now maybe this is a fatal flaw with Bitcoin's hard upper limit for number
of coins, but any miners that with good faith tried to support an islanded
bitcoin network now have generate transactions that get clobbered when
the network reconnects.

I can imagine a way to do this with some freicoin-like demurrage, which
would only impact new coinbase based on the percentage of the hashing
power that was on the other side of the fork. So if you are with the
95% of hashing power, you keep 95% of the new coins when the other 5%
shows back up from being islanded.

And this is also way more complicated than what I had first imagined
to do securely and reliably.


-------------------------------------
On Thu, Nov 14, 2013 at 5:27 PM, Drak <drak@zikula.org> wrote:

While the sentiment is appreciated, it seems important to gently push
back a bit, and remind:

This is a decentralized currency, and we should avoid centralizing
decisions.  This is something that impacts the community at large, and
deserves input and discussion at every level.

I would suggest posting on all possible forums "proposal: switch to
uBTC, labelled as ISO prefers (XBT?)" and see what sort of discussion
is generated.  If the support is broad, it will be plain from the
responses if there is a consensus.  Perhaps everyone will agree it is
the best course, and we can make an easy change.

But we need less "core dev fiat" not more :)

-- 
Jeff Garzik
Senior Software Engineer and open source evangelist
BitPay, Inc.      https://bitpay.com/


-------------------------------------

RAM is used as a database cache.

But regardless, what kind of attack are you thinking of? Using up all
available disk seeks by sending a node a lot of fake transactions that
connect to unspent outputs, but have invalid transactions? You'll get
yourself disconnected and the IP banned even with todays code.

It's much easier to hose a node by just asking it to send you the
block chain. Watch your own node when something is syncing the chain
from it. Ping times go through the roof because there's only one
network thread. If you're worried about DoS attacks on Bitcoin, it'd
be better to fix that first.


-------------------------------------
Hello Mike,

You can see the three nodes from nogleg on
https://blockchain.info/hub-nodes. They also relay the most to
blockchain.info.

Arthur

On 21/11/13 14:55, Addy Yeow wrote:



-------------------------------------
On Sun, Oct 20, 2013 at 11:40:26PM -0700, Jean-Paul Kogelman wrote:

Sure, I think Jeff mentioned the idea of a specific drafts/ directory
within the repository. (could also do a rejected/)

Less of an issue in some ways when it's all in git - just point people
to your bips fork.

-- 
'peter'[:-1]@petertodd.org
00000000000000099eaa116fac83a2b0e097cae3391c794990e128c8e162d91a
-------------------------------------
I was just looking at:

https://bitcointalk.org/index.php?topic=4571.0

I'm just curious if there is a possible attack vector here based on the
fact that git uses the relatively week SHA1

Could a seemingly innocuous pull request generate another file with a
backdoor/nonce combination that slips under the radar?

Apologies if this has come up before ...
-------------------------------------
On Thu, May 09, 2013 at 01:19:13PM +0200, Adam Back wrote:

The patch makes the concept of a 0-confirm double-spend obsolete
basically. The model is rather than having some vague, insecure, easily
broken, de-facto no-replacement rule it replaces it with something very
easy to reason about: you are bidding for blockchain space, and you can
adjust your bid after the fact.

The reality is zero-conf double-spends aren't that big of a problem
because the vast majority of payments have other mechanisms they can use
instead of relying on the defacto behavior of dozens of major miners and
nodes.

Long story short, we're better off if we don't give people a false sense
of security.


A node has no idea which transaction output is change and which one
isn't; if nodes could distinguish change from payment your privacy would
be badly violated.

By allowing simple replacement without further rules the fee adjustment
process can go on as long as required, without you running out of
additional transaction inputs and without causing the transaction to get
bigger and bigger each time.

It also allows more interesting use cases, like adding additional
outputs to a transaction after the fact as more payees become known, or
if two unrelated parties decide to combine their transactions to save on
blockchain space and preserve their privacy.

Eventually the P2P protocol can have delta compression support, so the
network bandwidth required to merge two transactions into one will be
minimal.

-- 
'peter'[:-1]@petertodd.org
000000000000014c26728a13e351b4dd7a32e99e28d43a960b5ac5f98696ae5b
-------------------------------------
On Sat, Oct 26, 2013 at 1:31 PM, Gregory Maxwell <gmaxwell@gmail.com> wrote:


This would give us an fully supported option which is completely CA

I think a tiny number of people would use it, so from a purely engineering
priority perspective my initial reaction is "not worth it."

However, as a demonstration of the flexibility of the payment protocol and
because it is a really nifty idea that will give lots of people warm
fuzzies I think you should do it and we should pull it.

-- 
--
Gavin Andresen
-------------------------------------
Fair enough, though people still manage okay with phone numbers.  And a
decentralized naming system seems to come at great cost - with namecoin you
need the whole blockchain to resolve names without trust.  Strip out a bell
and whistle - meaningfulness and transferability of names - and you get a
simple, rudimentary (spam killing!) system that scales on any device.  I'll
only argue that it seems to be Good Enough *for the types of people who
might care about decentralized names*.  Probably a very small set :)


On Thu, Oct 3, 2013 at 8:00 AM, Mike Hearn <mike@plan99.net> wrote:

-------------------------------------
On Mon, Sep 30, 2013 at 11:01 PM, Warren Togami Jr. <wtogami@gmail.com> wrote:

No, this is not correct at all.  RPC keepalive was present in 0.7.0,
possibly earlier.

Come on, it took a 30 second 'git checkout' session to verify this.



I was about to flame you with a "WTF is this fiction?" but it seems
true: 21eb5ada introduces this.

Unfortunately, it does so erroneously, introducing clearly buggy
behavior that did not exist with the thread-per-connection code that
provided keep-alive before commit 21eb5ada.

In my opinion, 21eb5ada half-changed the RPC code from
thread-per-connection to a worker-group model, without considering all
the consequences.

-- 
Jeff Garzik
Senior Software Engineer and open source evangelist
BitPay, Inc.      https://bitpay.com/


-------------------------------------
SourceForge has a horrible UI and blocks some countries. It also exposes us
to a large and potentially hackable mirror network. Whilst we're not
bandwidth constrained on our own servers, let's try and keep using them.


On Tue, Jul 9, 2013 at 4:06 PM, Jeff Garzik <jgarzik@bitpay.com> wrote:

-------------------------------------
On Fri, Apr 5, 2013 at 10:24 AM, Adam Ritter <aritter@gmail.com> wrote:
[...]

I prefer to call them system tests.

We use a system called blocktester that Matt Corallo wrote,
https://code.google.com/r/bluemattme-bitcoinj/source/browse/core/src/test/java/com/google/bitcoin/core/FullBlockTestGenerator.java?name=fullverif&r=874c5904b12d1fcec5b556429cf208f63cd4e1bc

It's based on BitcoinJ and works by simulating a peer against a
slightly instrumented copy of Bitcoin(d/-qt) (modified to avoid
computationally expensive mining).  The tests simulates many
complicated network scenarios and tests the boundaries of many
(hopefully all) the particular rules of the blockchain validation
protocol.  We can use these tests to compare different versions of the
reference software to each other and to bitcoinj (or other full node
implementations) as well as comparing them to our abstract
understanding of what we believe the rules of the protocol to be.

These tests are run as part of the automated tests on every proposed
patch to the reference software. Via a robot called pulltester which
comments on github requests and produces logs like this:
http://jenkins.bluematt.me/pull-tester/92a129980fb9b506da6c7f876aa8adb405c88e17/.
Pulltester also performs automatic code coverage measurements.

Additionally, we run a public secondary test bitcoin network called
'testnet', which can be accessed by anyone by starting the reference
software with testnet=1.  Testnet operates the same as the production
network except it allows mining low difficulty blocks to prevent it
going for long times without blocks, and some of the protective
relaying rules against "non standard" transaction types are disabled.

Most of this testing work has been centered around validating the
blockchain behavior because thats what has serious systemic risk.
Measuring the json rpc behavior is strictly less interesting, though
interesting too.


-------------------------------------
The conversations that spawned from this paper have been fascinating to 
read, but I have a problem with the conclusions. To quote the paper:

"The Bitcoin ecosystem is open to manipulation, and potential takeover, 
by miners seeking to maximize their rewards. This paper presented 
Selfish-Mine, a mining strategy that enables pools of colluding miners
that adopt it to earn revenues in excess of their mining power. Higher 
revenues can lead new rational miners to join sel
sh miner pools, 
leading to a collapse of the decentralized currency."

Please explain to me why any rational miner would collude to earn 
slightly higher short term profits at the expense of then wiping out the 
value of all their bitcoins in the long term.

Also, if you felt that this vulnerability is an immediate danger to the 
Bitcoin network, why publish the vulnerability publicly rather than 
first disclosing it privately to the core developers? Apologies if you 
did disclose it privately in the past; I've seen no mention of it.
--
Jameson Lopp
Software Engineer
Bronto Software

On 11/05/2013 01:58 PM, Jeff Garzik wrote:


-------------------------------------
On Mon, Oct 28, 2013 at 2:26 AM, Andreas Schildbach
<andreas@schildbach.de> wrote:

I do not believe we should do that:  It would be a non-trivial
increase the protocol bandwidth requirements.


-------------------------------------

If users want to pay with a huge transaction then it seems to me the user
should cover that cost. Allowing users to pay merchants with 100K
transactions full of dust and expecting them to eat the cost seems like a
great way to enable bleed-the-merchant-dry attacks.


RE: hiding or showing fees:  I pointed out to Peter that there doesn't have
to be One True Answer.  Let wallets experiment with either hiding or
exposing fees, and may the best user experience win.

-- 
--
Gavin Andresen
-------------------------------------
On Thu, Oct 10, 2013 at 10:29 AM, Mike Hearn <mike@plan99.net> wrote:

The current idea is to provide a compile-time flag to enable it, which
at the same time disables the wallet and mining RPCs. In that state,
it should be safe enough to provide test builds.


I'm pretty sure that libsecp256k1 supports every signature that
OpenSSL supports, so that direction is likely covered. The other
direction - the fact that libsecp256k1 potentially supports more than
OpenSSL - is only a problem if a majority of the hash power would be
running on it. However, with canonical encodings enforced by recent
relaying nodes, I hope that by then we're able to schedule a softfork
and require them inside blocks.

Apart from that, there is of course the issue that there may be actual
exploitable mistakes in the crypto code. There are unit tests,
including ones that create signatures with libsecp256k1 and verify
them using OpenSSL and the other way around, but errors are certainly
more likely to occur in edge cases that you don't hit with randomized
tests. The only way to catch those is review I suppose. I certainly
welcome people looking at it - even if just to get comments like "Can
you add an explanation for why this works?".

-- 
Pieter


-------------------------------------
I took a brief look at the code - it's looking very reasonable. You can
replace any construct like

try {
  Thread.sleep(1000);
} catch (InterruptedException e) {
  throw new RuntimeException(e);
}

which is quite verbose, just with
Uninterruptibles.sleepUninterruptably(1000, TimeUnit.MILLISECONDS); (and of
course static imports help too)

I think for this concept to take off, you'd need a website and to recruit
someone to help you market it. Pool operators won't reach out to you.

I still find it perhaps more elegant to just boost the connectivity of the
existing network with bitcoind changes, but this can help for now.



On Thu, Nov 7, 2013 at 12:35 AM, Matt Corallo <bitcoin-list@bluematt.me>wrote:

-------------------------------------
Ryan,

Maybe you could test out your ideas somewhere like bitcointalk.org and/or provide some more technical substance before engaging with this forum.

Developers tend to prefer dealing with numbers known to be either 1 or 0, not a variable set of possible values depending on non-technical factors ...

Gavin
------------------------------------------------------------------------------
Rapidly troubleshoot problems before they affect your business. Most IT 
organizations don't have a clear picture of how application performance 
affects their revenue. With AppDynamics, you get 100% visibility into your 
Java,.NET, & PHP application. Start your 15-day FREE TRIAL of AppDynamics Pro!
http://pubads.g.doubleclick.net/gampad/clk?id=84349831&iu=/4140/ostg.clktrk_______________________________________________
Bitcoin-development mailing list
Bitcoin-development@lists.sourceforge.net
https://lists.sourceforge.net/lists/listinfo/bitcoin-development
-------------------------------------
These tests are run on each pull requests and on each new commit to
master.  They arent very complete, but they do test a lot of block
acceptance rules.

https://github.com/TheBlueMatt/test-scripts

Matt

On Fri, 2013-04-05 at 12:24 -0500, Adam Ritter wrote:




-------------------------------------
That is true, but someone is already running it as a service on the blockchain itself. See:

https://www.proofofexistence.com/

You can imagine similar  services cropping up for things like torrents, sending btc tweets, etc. While I am not saying these things are particularly refined ideas in and of themselves, people should have an opportunity to play with them, and better testnet. 

Sent from my iPhone

On Jun 15, 2013, at 3:57 AM, "Luke-Jr" <luke@dashjr.org> wrote:

-------------------------------------
On Fri, Dec 20, 2013 at 8:49 AM, Chris Evans <aaxiomfinity@gmail.com> wrote:


You can help me and diapolo a lot by testing his pull request to add a few
options to the options dialog (and improve the dialog in general),

https://github.com/bitcoin/bitcoin/pull/3347

It doesn't add the RPC settings though. As Mark says, it's dangerous to
make it too easy to shoot yourself in the foot.

Wladimir
-------------------------------------
On Tue, Apr 2, 2013 at 11:41 PM, Wladimir <laanwj@gmail.com> wrote:

Correct, that rules out github, AFAICS.

Though, honestly, when I ACK that means I read the code, which is more
important than the author really.  github seems fine for that still,
though I do wonder if there is a race possible,

* sneak uploads innocent branch sneak/bitcoin.git #innocent
* sneak creates pull req
* just before I click "pull", sneak rebases the branch to something evil

-- 
Jeff Garzik
exMULTI, Inc.
jgarzik@exmulti.com


-------------------------------------

Not all end-user clients are always-on though


-------------------------------------
On Fri, Aug 16, 2013 at 4:59 PM, Peter Todd <pete@petertodd.org> wrote:


Not sure - it could be investigated. I think UPNP is an entirely
userspace-implementable protocol, so in theory it could be done by a
userspace library (even libminiupnp - java is not a requirement on android)



I suspect you mean "I think lots of people do that". I'm not so sure. We
could potentially run an experiment in the Android app to measure how many
users are in a position to contribute back, but just because you have wifi
doesn't mean you can reconfigure it using UPnP. That helps a lot in home
networks, but at the office it doesn't help.

I'm wary of a ton of work being put in to achieve not very much here.
Satoshi's original vision was always that millions of users were supported
by 100,000 or so nodes. I don't think that's unreasonable over the long
term.

Besides, prioritisation isn't very hard. Nodes can just hand clients a
signed timestamp which they remember. When re-connecting, the signed
timestamp is handed back to the node and it gives priority to those with
old timestamps. No state is required on the node side. Signing and checking
can be passed onto the general ECDSA thread pool that works its way through
pending signature operations, they'd be prioritised lower than checking
blocks/broadcasts.
-------------------------------------
Is the number representing the count for the client nodes?

I was curious of the count myself earlier this week and started to
traverse down the network using getaddr message starting from seed
nodes and found upward to 57k nodes running protocol >= 70001 with
timestamp no older than 24 hours.

On Thu, May 16, 2013 at 8:48 PM,  <bitcoingrant@gmx.com> wrote:


-------------------------------------
Here's my draft. I don't claim this to be "official", but I think this
should represent the consensus we've come to at the DarkWallet
Hackathon; I'm writing it up as an email in part to preserve a record of
that consensus.


* General Principles

We believe in decentralization, user-defined privacy, education as
opposed to "magic", and security based on openness rather than just
trust. We consider users who are individuals as well as the needs of
businesses such as merchants and exchanges. We recognize that often the
more people who use privacy protection technologies such as CoinJoin,
the better protected we all are.


* Privacy

Bitcoin inherently makes the flow of money visible, however it does not
require that flow to have real-world identities attached, or even for
that matter, pseudonyms. We see this as an unfortunate flaw in the
Bitcoin protocol that is to be corrected; the Satoshi whitepaper itself
included one such correction by outlining how avoiding address re-use
helped preserve privacy.


** Threat model

We assume a worst-case sophisticated state-level attacker with the goal
of deanonymizing and otherwise subverting Bitcoin users. Such an
attacker can be assumed to control up to 100% of the Bitcoin relay
network as well as have the ability to wiretap up to 100% of the
node-to-node traffic. (for nodes that they do not control) Such
attackers are however constrained by politics and budget. We assume they
use their ability to conduct MITM attacks sparingly - for instance by
subverting certificate authorities - due to the risk of detection. (note
how such attackers may be more willing to use detectable attacks in the
future now that their activities are public knowledge) We also assume
that while their budgets for individual targets may be very large, the
equally large number of targets required for en-mass survailance leads
to relatively low budgets per target. In particular note how the 51%
assumption assumes that the overall "economic value" of Bitcoin to its
participants is greater than the attacker's budget by some margin.


** Address re-use

Wallet software SHALL avoid address re-use. New addresses will be used
for all change and users will be encouraged through the user-interface
and other measures to use new addresses for every payment to the wallet.


** CoinJoin

With CoinJoin the more users that make use of it, the larger the
anonymity set and the better protected user privacy is. Thus we
encourage wallet software to agressively make trade-offs between
absolute privacy and usability; compromise is not a dirty word.

Wallet software SHALL implement basic two-party mix functionality and
MAY implement more sophisticated CoinJoin functionality such as n-party
mixes. CoinJoin SHALL be the default way that all transactions are sent.
Wallet authors are cautioned that more sophisticated functionality may
be more secure in theory, but if users do not use it the functionality
is wasted; focus on the general case first and only then try to improve.


*** Two-Party Mixes

The most basic form of CoinJoin is for two parties to author a
transaction. A key distinction between a 2 party mix and an n-party mix
is that in the two party case both parties automatically learn the
other's inputs and outputs by simple elimination; sophisticated
cryptographic blinding protocols are useless. To an external attacker
each transaction doubles the size of the anonymity set: the coins may
have come from one party or the other and the attacker has no way of
knowing which. (modulo value analysis, which will be discussed later)


*** n-party Mixes and Blinding

If two parties can jointly author a transaction, n parties can too.
Without special effort this has the disadvantage of revealing the input
to output mapping to all parties. Various cryptographic blinding schemes
have been proposed to fix this problem, either with multi-party
computational techniques, or by making use of multiple communication
channels along with a robust anti-DoS scheme. In either case, for now we
reject such schemes as complex and inconvenient and prioritize robust
two-party mixing. However we do take the existance of such schemes into
account; note how a n-party mix can act as a single party in a two-party
mix scheme.


*** Four-stage two-party mix protocol

<on the wiki>


*** Defeating value analysis

Attackers can make good guesses at the mapping of inputs to outputs
based on value. For instance with two inputs of 3 and 5, and fours
outputs of 1.4, 1.6, 2.4 and 2.6 the attacker can easily map inputs to
outputs based on what values match up, in this case 3 split into 1.6 and
1.4, and 5 split into 2.4 and 2.6


**** Value Matching

Not all CoinJoin users need their transactions to have specific output
amounts; some users simply need to move money from one place to another
but do not need a specific amount moved or at a specific time. These
users can assist users with more stringent requirements by matching the
input or output values they request. As a general principle wallets
SHOULD make these anonymity optimizations possible by allowing users to
schedule transactions to complete by a specific time and/or allow users
to specify that they do not wish the transaction to happen unless
CoinJoin is used.

With four-stage two-party mixes the Alice, who advertised a desire to do
a transaction first, can easily do ths by picking the transaction output
amounts only after Bob replies with his desired inputs and outputs, and
picking those amounts so they match Bob's. (or some combination of Bob's
outputs)


**** Merge Avoidance

Merge avoidance is the practice of avoiding the merging of multiple
transaction inputs into a single new transaction output, thus implying a
common relationship between those inputs. The most primitive form of
merge avoidance is to create multiple individual transactions, each
moving single transaction input to an output. (or perhaps some small
number) This is of course inefficient, and appears to have only been
proposed as a means to still allow for coin blacklists to function while
preserving some financial privacy.

Combined with CoinJoin however merge avoidance becomes much more
powerful. For instance even in its most simple form multiple parties can
combine their merge-avoiding transaction sets, giving even transactions
without actual counterparties a useful measure of plausible deniability.

In addition the underlyng features that make merge-avoidance possible -
the ability of a recipient to designate they are willing to receive
payments made to multiple addresses - synergisticly make very
sophisticated value matching strategies possible.


***** Cut-thru payments

Related to merge avoidance the idea of a cut-thru payment is that if an
intermediary is both a debitor and a creditor, with sophisticated
payment protocols they can request incoming payments to directly pay
outgoing liabilities, skipping them as an intermediary. While premature
to implement this feature now, it is worth thinking about for the future.


** Tor

While Tor isn't perfect there is real-world evidence - specifically the
Snowden leaks - that it works well enough to be considered a worthy
adversary by state-level attackers. Wallets MUST suppoort the basic
proxy options that allow the Tor proxy - or some other similar
technology - to be used for privacy enhancement and SHOULD make use of
Tor-specific features such as hidden services.


* Decentralization

** Fees

In a decentralized system distinguishing DoS attackers from legitimate
users is at best difficult, at worst impossible. Wallets that do not
provide users with the ability to set fees, both when a transaction is
created initially and after initial broadcast, do their users a
disservice by taking away a vital method of responding to an attack:
outspending the attacker.

Wallets MUST give users the ability to set the fee per KB they are
willing to pay for their transactions. Wallets SHOULD allow users to
change that fee after the fact via transction replacement. Wallets MAY
additionally implement fee estimation techniques, such as watching what
transactions in the mempool are finally mined, or using estimates
provided by miners. However it must be recognized that such data is
inherently unreliable, and this may become a problem in practice in the
future; giving users robust ways to alter fees after the fact will make
lying about fee data - perhaps to push fees upwards - less advantageous.

Note that the current direction of the Bitcoin Foundation maintained
reference implementation is weakly towards a pure estimation scheme;
deployment of full nodes supporting replacement and support from miners
is a precondition to doing things correctly.


*** Fees and privacy

Where there is a trade-off between fees and privacy - such as with merge
avoidance strategies - users should be given options to specify how much
extra they are willing to pay for extra privacy. Wallets SHOULD default
to being willing to pay some extra, perhaps 25% more over the basic fee.


** SPV, full nodes and partial nodes

Wallet software SHOULD whenever possible blur the distinctions between
full UTXO set nodes, SPV nodes, and partial UTXO set nodes. In addition
to those three basic categories there is also the question of whether or
not a node stores archival blockchain data, something that all three
categories of nodes can participate in.

Instead how a node contributes back to the health of the network should
be a function of what resources it has available to it. Of course in
some cases, like a phone wallet, that won't be very much, but for
desktop or business usage the resources available can be significant in
both bandwidth and storage capacity.


*** Relaying data

**** Blocks and blockheaders

Any node can safely relay blocks and block headers, where "safely" is
defined as SPV-level security. Our threat model implies that we don't
trust random peers on the network, thus we are not relying on them for
block validity; as a SPV node we are relying on miners to do validity
checking for us. In short feel free to relay data that you yourself
would trust.


**** Transactions

Remember that relaying transactions has a DoS-attack risk; the Bitcoin
model relies entirely on mining fees and/or priority as the limited
resource to prevent DoS attacks. Thus at present nodes SHOULD NOT relay
transactions if they do not have an up-to-date copy of the relevant
parts of the UTXO set spent by the transaction. (relaying transactions
spending only inputs in a partial UTXO set is acceptable):


**** Block-header diversity

Wallet software MUST make it possible to get block-header information
from a diverse set of sources. These sources SHOULD comprise more than
just peers on a single P2P network. Remember that it is acceptable to
use even centralized sources in addition to decentralized ones for
blockheader data - knowing that a miner did the work required to create
a block header is always valuable information. (for reasonable amounts
of work) For instance the author's block headers over twitter project -
while an April Fools joke - is equally a perfectly reasonable backup
source of blockheader data.


** Updating wallets from blockchain data

In an ideal world wallets wouldn't need to sync their state with
blockchain data at all: pervasive use of payment protocols would have
senders send txout proofs directly to recipients. But that's not the
case. Instead wallet implementations sync themselves from the
blockchain, and when bandwidth limited this becomes a tradeoff between
bandwidth and privacy: your transactions hide in the anonymity set of
the false positives matched by the filter.


*** Bloom filters

The current implementation for SPV nodes is to simply give peers a bloom
filter; the false-positives make the anonymity set. For n peers this has
O(n) cost when a new block comes in; Bloom filters are cheap to test
against and this system works reasonably well.

However, for archival blockchain data bloom filters are seriously
flawed: every block has to be read from disk in full, the bloom filter
matched, and some (potentially very small!) subset sent to the peer. n
peers. The result is high IO load on the node relative to the client,
enabling easy DoS attacks.

Wallet software SHOULD NOT implement only Bloom filters, however using
them when availalbe is acceptable. Note how the Bloom filter design has
at best O(n^2) scaling ruling it out for large-blocksize future
scenarios.


*** Prefix filters

TXO or UTXO data can be easily indexed by in radix trees with log2(k)
lookup cost per query. We can take advantage of the fact that the query
keys need not be provided in full by only providing partial keys.
Because scriptPubKeys are randomly distributed a prefix n bits long has
an anonymity set of roughly 1/2^n * # of transactions in total.

Wallet software SHOULD implement prefix filters and SHOULD use them in
preference to bloom filters whenever available. Wallet software that
currently uses full-key filtering - e.g. Electrum - MUST be upgraded to
support prefix filters in the future.

Wallet software MUST NOT assume that matching anyting other than
H(scriptPubkey) is possible. This applies to bloom filter matches as
well.

In the future miners may commit to either the TXO set in conjunction
with per-block lookup trees, or possibly the full UTXO set. In either
case many of the leading designs may be implemented with only
H(scriptPubKey) lookup capability for reasons of scalability.


* Security

Bitcoin wallet software is unprecedented in how they provide attackers
targets that are highly profitable to attack and highly liquid. (note
the irony here!) A succesfull attack that injects malicious theft
routines into either sourcecode or binaries can steal thousands of
Bitcoins in one go, and the attacks target is you and your team.
Following basic good practices for robust code is a start, but it's far
from enough.


** Source-code integrity

Sourcecode MUST be maintained using a revision control system that
provides strong integrity guarantees; git is recommended.

Sourcecode MUST be PGP signed on a regular basis. Releases MUST be
signed - in git this is accomplished by signing the release tag.
Individual commits SHOULD be signed, particularly if source-code used in
day-to-day development is kept on an untrusted server, e.g. github.
Recovering from a server compromise is made significantly easier if
every commit is securely signed.


** Binary integrity

All things being equal it is better to use an interpreted language
rather than a compiled one; auditing the former is significantly easier
than the latter. Similarly, all things being equal, do not distribute
binaries of your software - have end-users compile binaries themselves.

Of course all things are not equal, and frequently compiled languages
and distributing binaries is the correct choice. If that is the case
deterministic build systems MUST be used when possible; if using them is
not possible take great care with the process by which binaries are
created and try to create long-term plans to move to a deterministic
build system in the future.


** PGP

Developers of wallet software MUST make use of PGP and participate in
the web-of-trust. Developers MUST advertise their PGP fingerprint
widely, for instance on personal websites, forum profiles, business
cards etc. simultaneously. Multiple paths by which someone can find a
fingerprint claimed to be of some developer make subterfuge easier to
detect and more costly to carry out. When possible it is highly
recommended to attach these advertisements to real-world, physical,
actions. For instance the author has included his PGP fingerprint in
highly public, videotaped, talks he has given at conferences. He has
also created a videotaped statement of his PGP key that was timestamped
in the Bitcoin blockchain. While it certainly is possible for such
artifacts to be faked, doing so convincingly is expensive, labour
intensive, and error prone.

Developers SHOULD sign as much communication as practical. Sourcecode is
one form; your emails to development lists and between each other are
another. Signing both leaves a large body of widely distributed work,
all tied to your identity. (it's highly unfortunate that nearly all
publicly available mail archives do not make mail accessible to the
public in such a way as to allow verification of PGP signatures; often
even inline signatures are broken for various reasons)


*** Increasing adoption of PGP

Keep in mind that end-users very rarely verify PGP fingerprints at all,
let alone correctly - the above advice with regard to PGP is currently
mostly useful in allowing *other developers* the tools they need to
verify the integrity of your code. For instance, in the event of a
suspected compromise consistantly signed code allows anyone competent in
the use of PGP to quickly evaluate the situation, and if warrented,
inform less sophisticated users through traditional measures such as the
media.

While this is somewhat out of scope for this document the "DarkWallet
effort" should include work to make PGP more user-friendly and a better
experience. But that does *not* have to mean "making PGP easier for
grama", right now "making PGP easier for Joe Wallet Developer" is a
laudable goal. For instance understanding and using the web-of-trust
sucks right now. How can we make that experience better for a user who
understands the basics of cryptography?


** SSL/Certificate authorties

While certificate authorities are notoriously bad at the job they are
supposed to be doing the CA system is still better than nothing - use it
where appropriate. For instance if you have a website advertising your
software, use https rather than http.


** Multi-factor spend authorization, AKA multisig wallets

<mainly discussed at the conference in terms of multiple individuals
controlling funds, which is out of scope for this document>

Assuming any individual device is uncompromised is risky; wallet
software SHOULD support some form of multi-factor protection of some or
all wallet funds. Note that this is a weak "should"; mainly we want to
ensure that users have options to keep large quantities of funds secure;
accepting higher risks for smaller quantities is an acceptable
trade-off.

FIXME: go into more detail.


*** P2SH

Wallet software MUST support paying funds to P2SH addresses.


** Payment Integrity

Multi-factor wallets protect your funds from being spent without your
knowledge, but they provide no assurance about where those funds went; a
Bitcoin address is not an identity. A payment protocol, such as BIP70,
is needed.

Wallet software SHOULD support BIP70. Yes, there are (justified)
concerns about its current dependence on the certificate authority
system, but those concerns should be addressed by a combination of
fixing that system, and extending BIP70 with different and better
identity verification options.

However, remember that in the absense of multi-factor wallets the "know
who you are paying" protections of BIP70 are actually pretty much
useless; malware that defeats the payment protocol locally is not much
different than malware that silently rewrites Bitcoin addresses. There
are other motivations for the BIP70 version of the payment protocol, but
whether or not they are actually interesting for users is an open
question; it was not designed by user-experience experts. Thus wallet
authors should consider supporting a low priority for now.


-- 
'peter'[:-1]@petertodd.org
000000000000000f9102d27cfd61ea9e8bb324593593ca3ce6ba53153ff251b3
-------------------------------------



You might want to look at http://www.monotone.ca/, it does a good job
of integrating crypto and review primitives into the workflow.
It also has some reliable network distribution models (netsync) that work
well over things like Tor, in case a new developer (or old Satoshi) doesn't
wish to be in the public light.

http://www.monotone.ca/monotone.html

Once you have the crypto, it always boils down to human risk factors,
rogue, password, cracks, etc which are harder.


-------------------------------------
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 11/14/13 3:01 PM, Luke-Jr wrote:

"key id" (thanks sipa).

I know it's a more technical term, but that is rather the point. It
was a fundamental error to call hashed-pubkeys "addresses" as people
either associate this with "account" or physical addresses, which also
rarely change.

Security and privacy guarantees of the system are defeated when key
pairs are reused. We should ideally adopt terminology that lead people
to associations of ephemeral, temporary use. "key id" is at least
neutral in this regard. Can anyone think of something better?

Mark

-----BEGIN PGP SIGNATURE-----
Version: GnuPG/MacGPG2 v2.0.19 (Darwin)
Comment: GPGTools - http://gpgtools.org
Comment: Using GnuPG with Thunderbird - http://www.enigmail.net/

iQIcBAEBAgAGBQJShVieAAoJEAdzVfsmodw4TlkP/i2cZm9NolReIsv6WBNQUGZ6
0VJveOcsOmEXj3ixSyzPRitFl52EOfU+LZaM3liwFPczuIOXZUXOLAJqakxGGsFa
cWwvZjrBk13aTR+4dXZ6OWcCNmTfm6+st2+v1MpQcXlHD8J1WtrdrzKr3fNSntir
yHbNmF6hPfgLr64m52BhUVrxBg9eiIFDI6VCzmUgk+paNmIxs9dgx7POnz1/hQb3
2FGfNt2J81t4F78mpzjtKx+vHRyHpIKJ2+3mjzcQ7IBkhBgPYnp69TwBSGXbg7l9
6yV0P7DGjWepO5+s96GCjbScYpmZO0gx0ZTn/eamfxh20XuX2fZBEVNd1KnhX4Xq
D4UwylGNa5FteRgURtVN5Xdb82jB2qhhr/IkGSgKds24zhHzgvBgvLJBgwtQHwil
M/y2DMC70WVEXf0Fz96L1kNYUA6062/ZNlwITRWxkUUJprF+xyN3R+BVWMggBMnR
Vjht74MZMkJyYlPQr8BRbYdhgMwv6dh0v5T4M6ck6MjKYj/GLsnEfHyY2d/BNg8c
2nkcBC8Dtv9KoFOk6STS1n7R4ooqepmdsRNPBZUzKvv/NN1B1A8jeluLiN9hSzl1
ubDF/34LJTji8bP9jfDBEND94xdaKjTl+2ISweRttBOOVqCtQlzCQ4udiT7vAntb
AYYMBYmYO/A926T+K6Lp
=kFj9
-----END PGP SIGNATURE-----


-------------------------------------
Well its a bit more hopeful than that :)

On Tue, May 07, 2013 at 11:17:17AM +0200, Mike Hearn wrote:

If they are PGP signatures, they can check the PGP WoT; its not that
hopeless some us eg have our keys in Ross Anderson's PGP Global Trust
Register, a PGP and CA key fingerprint book.  

http://www.cl.cam.ac.uk/research/security/Trust-Register/index.html

Probably most of the CA keys expired, but many of the PGP keys didnt.  So to
the extent that those people take PGP WoT seriously, and the main developers
names and email addresses are known and scattered around hundreds of web
mailing list archives etc there is some trust anchor.


And even without a PGP WoT connection, if the website had SSL enabled, they
can trust the binaries its sending to the extent that it is securely
maintained, and to the limit of the CA security weakest link (modulo sub-CA
malfeasance, and all the certification domain ownership laxness you or
someone mentioned in another mail).  That there are limitations in it doesnt
mean you should not avail of the (moderately crummy) state of the art!

And that is tied back to the domain itself hwich is very mnemonic and
referenced widely in print, tv, websites etc.


I guess its the least of the concerns but I believe Damgards is better. 
Another possibility is threshold DSA (which is built using Damgards Paillier
additively homomorphic cryptosystem extension) and discrete log schemes are
easier to setup with zero-trust.  Other simpler discrete log signatures ie
Schnorr are much easier to work with (threshold DSA is a mite complicated),
but NIST tweaked Schnorr to create DSA, and the rest is history.  The trust
n-1 of n is good enough for signatures because anyway that is above the
assurance of the signature.


Well before I tried the download I had downloaded and compiled a few
versions from git.  But to get a stable and experience the non-programmer
view I did first try "yum install bitcoin" and then "yum whatprovides bitcoin"
on fedora 18 with +rpmfusion and there appeared to be no package!

I didnt find the signature on the source either or I would've checked.


Other ways you could get usefully get assurance of the source is multiple
people signing the release, with an asserted meaning being - I checked the
patches that went into this and I see nothing malicious.  It might help if
one or more of the signer were pseudonymous even (eg Satoshi if willing)
because you cant coerce legally, nor physically a pseudonymous person
because you cant find them.  Its a lot of pressure on open secure coding
process when there is $1bil value protected by the integrity of the code. 
(It seems the most likely avenue to bypass that maybe simply the attacker to
just become a committer and slip the 0-day past the review process.  There
were in the past modest-impact and plausible looking mistakes in PGP
discovered after sometime.)

Adam


-------------------------------------
On Thursday, November 14, 2013 11:45:51 AM Melvin Carvalho wrote:

There's already a dropdown display option...


-------------------------------------

Disagree. Unless I'm misunderstanding what they propose, their suggested
change would mean anyone could broadcast a newly discovered block at any
point and have a 50% chance of being the winner. That is a fundamental
change to the dynamics of how Bitcoin works that would require careful
thought and study.

Also, their solution doesn't really address the problem they bring up, it
just changes the size of the threshold required.

Fundamentally, their attack is a sybil attack. It doesn't work if they
can't delay or block a pools competitors because mostly their block will
come in second place and they'll lose the race. Thus the solution should be
a solution to sybil attacks.
-------------------------------------
On Sun, Jun 2, 2013 at 5:45 PM, Adam Back <adam@cypherspace.org> wrote:


I'm one of the people experimenting in this area.  I've long argued
that a zero-output transaction should be permitted -- 100% miner fee
-- as an elegant proof of sacrifice.  Unfortunately that requires a
hard fork.  Also, for most people, it seems likely that a change
transaction would be generated.  That, then, would generate an
already-standard transaction, where inputs > outputs.

-- 
Jeff Garzik
Senior Software Engineer and open source evangelist
BitPay, Inc.      https://bitpay.com/


-------------------------------------
On Sunday, December 08, 2013 10:00:35 AM Drak wrote:

I'm not aware of any rational basis for trusting GitHub more than SourceForge. 
At least SourceForge is transparent and releases their source code.

Luke


-------------------------------------
On 31 July 2013 13:33, Gavin Andresen <gavinandresen@gmail.com> wrote:


Unless I'm mistaken you cant generally set the "Accept" header on a browser
via a standard href ... one of those annoying quirks


-------------------------------------

Nope, ahh well, I agree that the use of UTXOs in the Satoshi client today by no means a directed towards a DHT, though it does help speeding up validation (db lookup to check if an output is indeed unspent).

However, an alternative way to bootstrap and validate transactions exist, needing only the UTXOs and not the rest of the blockchain history: An authenticated data structure storing the UTXOs in a DHT. 

/M





-------------------------------------
On Thu, Jan 10, 2013 at 10:59 PM, Matt Corallo <bitcoin-list@bluematt.me> wrote:

0.8rc1 will probably happen when the core ultraprune/leveldb stuff is stable.

-- 
Jeff Garzik
exMULTI, Inc.
jgarzik@exmulti.com


-------------------------------------
On Fri, May 03, 2013 at 05:02:26PM +0200, Mike Hearn wrote:

Hmm, on second thought you're probably right for the standard case where
it's really P2P. On the other hand it kinda limits us in the future if
seeds have high-bandwidth nodes they can just point clients too, but
maybe just assuming the DNS seed might need high bandwidth as well is
acceptable.

I dunno, given how badly behaved a lot of ISP dns servers are re:
caching, maybe we're better off keeping it simple.

-- 
'peter'[:-1]@petertodd.org
000000000000013bfdf35da40a40c35ccd75e09652ae541d94d26130a695f757
-------------------------------------
Hello,

This concept, 'ABIS protocol,' has been many years in the making and is
presented here as a basic concept.  It is sent to you for you review and
possible consideration.  There will be further additions in the near
future.  Looking forward to your reply and any contributions you may
provide.

Cheers

https://github.com/ABISprotocol/ABIS#abis




-------------------------------------



If there is a situation where wallets are supposed to constantly monitor
the tx propagation and recreate their transactions with different fees,
this would make a lot of usecases inconvenient.
half-offline bluetooth transactions, users with unstable connections,
battery power lost, etc, etc. - and last but not least power concerns on
hardware wallets on the bitcoincard (tx signing drains a significant amount
of power and should therefore only be done once)

-Andreas


-------------------------------------
On Tue, Sep 17, 2013 at 11:22 PM, Ron <rdwnj@yahoo.com> wrote:



My understanding is that XBT is a proposed standard, and hasn't been
approved by ISO yet.  Did that change?
-------------------------------------
On Wed, Jul 24, 2013 at 10:42 AM, Peter Todd <pete@petertodd.org> wrote:


The are a range of workable values.  Ideally, there would first need to be
agreement on the general principle.

Distributing headers with 1/64 of the standard POW means that a header
would be broadcast approximately once every 9 seconds (assuming a 10 minute
block time).  This was picked because sending 80 byte headers every 9
seconds shouldn't represent much load on the network.

The second magic number is how much credit to give for mini-headers.
Setting it at 1/16 means that the headers will be worth around 4 times as
much as a block (since there would be around 63 low POW headers for each
full POW one).

This creates an incentive for miners to take headers into account.  If all
the headers were worth less than a full block, then a fork which was losing
would suddenly be winning if a block is found.  A fork will only become the
main chain due to a new block, if it is within 16 mini-confirms.

Miners don't have to mine against the absolute best fork, but they do need
to make sure they stay within 16 of the best one (so if they find a block,
that block would be considered part of the main chain).  Some hysteresis
might be helpful.  The rule could be to only switch unless the current fork
is losing by at least 4 mini-confirms.

In most cases, this won't be a problem, since orphans don't happen that
often anyway.

Since it isn't a chain, this doesn't give the full benefits of a 9 second
block, but it should bring things to consensus faster.  6 full confirms
would be much more secure against random and hostile reversals.

It doesn't have the risks of 9 second blocks in causing network collapse,
since it isn't a chain, the headers are short, and there is no
confirmations of the required (other than checking the hash).

Each "mini" confirms adds to the strength of leaf blocks of the tree.  If
there is a tie, and 20% of the network is mining one block and 80% is
mining the other, the mining power of the network will be split until the
next block arrives.

With mini confirms, the entire network is aware of the 2 blocks (since the
headers would be forwarded) and the mini-confirms would show which one has
majority hashing power.

The least risk option would be to make them purely advisory.  The proposal
takes it further than that.

The proposal means that if the network is split 80/20, then miners should
stick with the 80% fork, even if the 20% fork wins the race for the next
block.

Winning a few rounds is easier than wining many rounds worth of
mini-confirms.

The key is that as long as the honest miners stay on the main chain, they
will eventually overwhelm any rewrite attack with less than 50% of the
mining power.  This is a system to agree on what is the main chain in the
face of a re-write attack.



The (sub) proposal is that headers would still be broadcast.  The blocks
would not be forwarded.

If a header extends the header tree, meets full POW and is "near" the end
of the chain, then it is broadcast.  This means that all nodes will have
the entire header tree, including orphans.

The full blocks would only be sent if they extend the main chain.

Second, if a header builds on a header that is in the header tree, then it
is broadcast, even if it doesn't meet full POW (only 1/64 required).  This
gives information on which fork is getting the most power.

It gives information about potential "consensus loss" forks, where a
significant number of miners are following an alternative chain.

In fact, this is probably worth doing as an initial step.

A warning could be displayed on the client if a fork is getting more than
15% of the hashing power.
-------------------------------------
On Tue, Nov 19, 2013 at 6:06 PM, Peter Todd <pete@petertodd.org> wrote:


Ok cool, I forked it into https://github.com/bitcoin/bips



Agreed, I had no idea github could do that too.

Wladimir
-------------------------------------
On Tue, Dec 03, 2013 at 12:57:23PM +0100, Taylor Gerring wrote:

Indeed.

Transparency on fees is going to be good from a marketing point of view
as well: fact is, Bitcoin transations have fees involved, and if we're
up-front and honest about those fees and what they are and why, we
demystify the system and give people the confidence to tell others about
the cost-advantages of Bitcoin, and at the same time, combat fud about
fees with accurate and honest information.

-- 
'peter'[:-1]@petertodd.org
000000000000000f9102d27cfd61ea9e8bb324593593ca3ce6ba53153ff251b3
-------------------------------------
On Thu, Dec 19, 2013 at 05:47:52PM -0800, Mark Friedenbach wrote:

Could you expand more on how prefix trees could be used for
time-stamping and merged mining?



I'd be inclined to leave the unicode out of the code examples as many
editors and shells still don't copy-and-paste it nicely. Using it in BIP
documents themselves is fine and often has advantages re: typesetting,
but using it in crypto examples like this just makes it harder to
reproduce the results by hand unnecessarily.

-- 
'peter'[:-1]@petertodd.org
0000000000000002d7a0c56ae2c5b2b3322d5017cfef847455d4d86a6bc12280
-------------------------------------
URL: https://github.com/jgarzik/txtool

txtool is a command line tool written in node.js that interfaces with
Bitcoin-Qt/bitcoind, to automate or assist in building interesting,
unusual, complicated or just plain odd transactions.  The goal is to
demonstrate advanced bitcoin features, and make it easier for users to
experiment.  The intended audience has a basic awareness of how
bitcoin transactions look and work.

The theory of operation and full list of commands may be reviewed at
https://github.com/jgarzik/txtool/blob/master/README

Initially, two working examples are presented:
* Easy multi-signature transaction building:
https://github.com/jgarzik/txtool/blob/master/examples/multisig.txt
(similar to gmaxwell's P2SH multisig example)
* Passing around transactions (possibly multi-signature) for signing:
https://github.com/jgarzik/txtool/blob/master/examples/tx-signing.txt

Further examples such as decentralized crowdfunding and atomic coin
swapping* will be demonstrated soon.


* https://bitcointalk.org/index.php?topic=112007.msg1212356#msg1212356

-- 
Jeff Garzik
Senior Software Engineer and open source evangelist
BitPay, Inc.      https://bitpay.com/


-------------------------------------
On Tue, Jul 23, 2013 at 4:01 PM, Mike Hearn <mike@plan99.net> wrote:

Hi Mike,
Debian's bitcoin is maintained on an open and archived mailing list
and git repo:
Debian Bitcoin Packaging Team <pkg-bitcoin-devel@lists.alioth.debian.org>

If there is a problem or question, getting an answer should be really
easy. It would be good to include them in the discussion there (I
CC:ed the list). If the upstream developers have a consensus that
distribution packaging is not in the best interest of the project,
then I personally would defer to their judgement and request removal.
I'm leaving this open for other opinions from the Debian side.

That said, let me summarize the arguments and see if we can figure out
a permanent solution:

1) It appears that the consensus of upstream developers is that any
distributed binary should only be linked against libraries that the
bitcoin developers have tested and audited since any compatibility bug
is a risk to both the user and the network.

Response: Is there a way to "certify" the Debian libraries? Debian
bitcoind/bitcoin-qt runs the compile test during all architectures.
MIPS has been failing recently, but no one has looked into it yet.
Perhaps it's not worth developers efforts yet, but at some point the
technology should reach a point it can be redistributed.


2) Bitcoin is new technology, so any patches have the ability of
harming both the network and user.

Response: I, and I'm sure everyone else working on it, totally agrees.
All patches are public [1], you can see that the patches are only to
the build system (except for one adding a debug message). Is there a
specific patch or bug that is problematic? This seems to be
reiterating (1) above: don't patch the build system to use libraries
that were not audited by the developers.



The two solutions are: (1) no one besides the upstream developers
compiles and distributes binaries, ever, or (2) upstream comes up with
a system where someone besides them can compile working binaries for
distribution. Most likely the best solution is to do (1) until
upstream sets up a system to allow (2).

I'm curious as to other's opinions.
Thanks,
Scott


[1] http://anonscm.debian.org/gitweb/?p=collab-maint/bitcoin.git;a=tree;f=debian/patches;h=ba576f9f3ddad47a2f85dcbfb7a0b3482834f19f;hb=HEAD


-------------------------------------
On Friday, June 14, 2013 8:06:54 PM Peter Todd wrote:

Share rate is relevant to more than user information - it also affects the 
variance of reward/payout. I disagree with claiming shares are found when 
they're not sent to the pool - this makes auditing and troubleshooting more 
difficult; for example, see the GUIMiner bug where it reports shares despite 
misinterpreting the pool's target and submitting nothing at all (this happens 
when the pool uses pdiff 1).


I don't understand the first two questions here at all.

Luke


-------------------------------------
FWIW, Litecoin 0.8.x entirely removed the internal miner and we warned
people that getwork will be removed in the next major version.  Pooler's
CPU minerd which supports both sha256d and scrypt recently grew stratum
support.  Perhaps he could be convinced to add GBT support too, which would
help this goal of completely removing the internal miner and getwork.

Warren


On Mon, Aug 19, 2013 at 10:23 AM, Gregory Maxwell <gmaxwell@gmail.com>wrote:

-------------------------------------
RE: replace BIPs on the wiki with links to github documents: agreed.

Wladimir or Gregory: can one of you update BIP 0001 to describe the Proper
Process for creating/editing a BIP? It doesn't mention the github repo at
all right now.

-- 
--
Gavin Andresen
-------------------------------------

On Dec 3, 2013, at 2:20 PM, Mike Hearn <mike@plan99.net> wrote:


Most of what you mentioned is entirely culture-dependant. In the majority of North America, sales tax is calculated at the point of sale on top of the advertised price. When my local government increases sales taxes, we feel it BECAUSE we see it. Expose information in a digestible way. Just because you dont instinctively know how to implement a UI for varying sender fees doesnt mean that other wallets dont.

Leave the fee structure alone. Instead, lets concentrate on how to calculate an accurate assessment of what a reasonable fee is for reliable service and let the software shake out the rest.

Taylor

-------------------------------------
It seems so much easier to just allow bitcoin testnet to be used more widely for larger scale bitcoin staging. People can assign value as they wish to testnet bitcoins but at their own risk/peril. This incremental amount of value though would allow for testing of larger ideas, ideas that perhaps might not be appropriate in their nascent stages to apply for bitcoin. 

Have your seen 'proof of existence'? It's basically a bitcoin notary service that proves a document existed before it gets inserted into the blockchain. While a good idea- you could argue that it's blockchain spam as well- especially if one were to adapt it to high volumes in the future for notarizing permanently things like tweets (for example) or combining it with something like colored coins. These are great ideas, but maybe better suited to a proto bitcoin without needing to fashion a brand new coin. 

Sent from my iPhone

On Jun 14, 2013, at 11:25 PM, Andreas Petersson <andreas@petersson.at> wrote:



-------------------------------------
Not at all - ACK from me, fwiw. Any attempt at a double spend should be
shouted from the housetops.

What Miners should do with that is still up for debate, it seems. My
opinion is that they should hold on and attempt to confirm the first,
letting it go only if a conflicting transaction is mined elsewhere. (Let
your Yes mean Yes...) But I understand the contrary arguments.


On 21 May 2013 17:04, Gregory Maxwell <gmaxwell@gmail.com> wrote:

-------------------------------------
Maybe it's because the arguments being presented are nonsensical and
irrelevant to the current Bitcoin network topology, composed of a small
number of mining pools, not solo miners? Furthermore I think people would
realize that their mining pool has gone "off the reservation" so to speak.


On Mon, Dec 23, 2013 at 8:05 PM, Allen Piscitello <
allen.piscitello@gmail.com> wrote:

-------------------------------------
It is simpler than that; simple numbers.  Bitcoin is volatile right
now, not for fundamental architecture reasons, but for reasons why
many other small issues are volatile.  Low liquidity and a small issue
implies that a single big player can easily the move the market.
Further, it is volatile because common financial tools available
elsewhere -- shorting, futures/options, etc. -- are not widely and
easily available.

None of these factors are special or specific to bitcoin.  See
http://garzikrants.blogspot.com/2013/11/solution-to-bitcoin-volatility.html

However, this is getting WAY off-topic for a development mailing list.

Ryan successfully trolled the list.  Let's not further feed the trolls.


On Tue, Dec 10, 2013 at 7:07 PM, Baz <bk@thinkloop.com> wrote:



-- 
Jeff Garzik
Bitcoin core developer and open source evangelist
BitPay, Inc.      https://bitpay.com/


-------------------------------------
See this BIP. I'm not sure if this is a bug or what, but it would be good if messages always had a fixed number of fields per protocol version.

https://en.bitcoin.it/wiki/BIP_0060#Code_Updates

This BIP details everything that needs to be done and proposes a protocol upgrade.
-------------------------------------
On Mon, Dec 2, 2013 at 9:33 AM, Mike Hearn <mike@plan99.net> wrote:

<vendor hat: on>

BitPay noticed this detail last week.  We were noticing that some
transactions were not even reaching our bitcoind border routers (edge
nodes), due to low/no fees.  That led to a long discussion of all
things fee-related.  SPV fees are a big issue.  Getting
child-pays-for-parent in some form out to miners is another.  Getting
a smart, dynamic fee market Gavin mentions is a big need.

-- 
Jeff Garzik
Bitcoin core developer and open source evangelist
BitPay, Inc.      https://bitpay.com/


-------------------------------------
On Tue, Apr 09, 2013 at 11:03:01PM -0400, Peter Todd wrote:

Oh, and while we're at it, long-term (hard-fork) it'd be good to change
the tx hash algorithm to extend the merkle tree into the txouts/txins
itself, which means that to prove a given txout exists you only need to
provide it, rather than the full tx.

Currently pruning can't prune a whole tx until every output is spent.
Make that change and we can prune tx's bit by bit, and still be able to
serve nodes requesting proof of their UTXO without making life difficult
for anyone trying to spent old UTXO's. The idea is also part of UTXO
proof stuff anyway.

-- 
'peter'[:-1]@petertodd.org
-------------------------------------
On 07/23/2013 11:37 AM, Pieter Wuille wrote:


I certainly don't want to push ideas that won't work for whatever
reason. So I fully respect whatever you decide regarding that feature.
Personally I have never felt any need for being able to sweep paper
wallets, I am more or less just relaying the need of users.

Let me just say this:

Sweeping paper wallets is a common feature request. People switch to
centralized services just for getting that.

It is my understanding that for the usecase, an address-indexed UXTO is
enough. So you probably don't need to worry about script-indexed for now.

Security issues could be mitigated by applying trust to the REST server,
e.g. because its your own or the one of your apps vendor. Of course,
link-level security would be needed for this (e.g. SSL).

Paper wallets that include the necessary additional information is
something I have been thinking about. I see some issues:

- Paper wallets are already quite widespread. You still won't be able to
sweep those.
- Some people like to "top up" a paper wallet or even just sweep a
portion of it. That would not be possible, and in some cases even lead
to loss of coins because of the "involuntary fee" you described.
- Does the necessary info fit into a QR code?




-------------------------------------
Not sure if this is the right place, but since a few wallet authors
congregate here I though it might be the best place.

It seems every once in a while you see stories of people accidentally
paying huge fees. Today I read about a man who paid a 20.14BTC fee for a
0.05 BTC transaction[1], oops. There was another recently where someone
paid a fee of about 200BTC which fortunately the pool operator refunded.

It just occurs to me this kind of sad story could be averted if wallets
implemented a confirmation box if the fee amount seems crazy - for example,
if it's >10x what the default fee should be, or if it's greater than x% of
the sending amount. "the fee seems unusually high, are you really sure you
want to pay X in fees?"

I realise the exact details of this might need to be fleshed out given we
want flexible fees, but it should be pretty simple to agree with what looks
like an unusually large fee according to the going rate.

Drak

[1]
http://www.reddit.com/r/Bitcoin/comments/1syu3h/i_lost_all_my_bitcoins_in_an_erroneous/
-------------------------------------
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 02.11.2013 19:08, Jeff Garzik wrote:

Well in the view of an average internet browser, it is not a solved
problem neither does this identity protocol solve it.

But Mike is correct, this is a wrong place to discuss about it.

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)
Comment: Using GnuPG with Thunderbird - http://www.enigmail.net/

iEYEARECAAYFAlJ1M30ACgkQvafo1Ths1SxypQCgor9LQTyKnlr0gByMPPJRQF6U
LpIAnRMj/udBSDJOK+2JP0hhiG1Bk81d
=tcpx
-----END PGP SIGNATURE-----


-------------------------------------
On 9 December 2013 15:07, Gregory Maxwell <gmaxwell@gmail.com> wrote:


Why would it be made available for download at sourceforge.net if it's not
actually released? The files are available here:
http://sourceforge.net/projects/bitcoin/files/Bitcoin/bitcoin-0.8.6/ and
people watch the sf rss feeds etc...
Seems to me like there needs to be a better release workflow. As far as the
world is concerned, they are downloading the 0.8.6 and there is a lot of
community buzz about it already.
IMO, to avoid that, no files should be placed online unless they are the
official release.

Drak
-------------------------------------
As part of the process of moving to BitPay, I'll be switching to
jgarzik@bitpay.com as a PGP identity, with brand new signing keys.

Here is a message, signed by jgarzik@exmulti.com's key (the one listed
on bitcoin.org), proving they are the same person.

http://yyz.us/jgarzik-now-at-bitpay.txt
http://yyz.us/jgarzik-bitpay-pubkey.txt

If a couple people would run through this and verify that "I am me", I
would appreciate it.  A sig check and IRC ack would be great.  Thanks!
 bitcoin.org will be updated after this.

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1


Jeff Garzik's business identity and PGP information is:

pub  2048R/7ADCA079 2013-05-23 Jeff Garzik <jgarzik@bitpay.com>
	 Fingerprint=3710 4081 6275 9FC5 A429  6536 E7A5 8E33 7ADC A079

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.12 (GNU/Linux)

iQIVAwUBUZ4ykNodwg8tvwyoAQImAg//WdYc4RpZDtLUGWGMXr4Jnme9gjLdmFr4
em1McXk7faHls/qbQOlKdi46mTm4E/RZ6SLE7wMQkPD5RD0ukx3zkkFznbAuBuw2
/wCmNP2Tt/PZI2x3e9gfdBL0WxVfDTczZtMEMhz0ovMm3MtfZ8Xv9GtK3go+4LXa
eX4OguGVsuh/iJ1fSgr9ObZM1RSC7d7niXDw7oK8St6+G9z/4JiAs7jSpG1/jkw1
hNqSwxXSL/N5rbccPNvR91jWL7s63MQbrjYSWADxJQ81vLwV6JbyANyc6HnkfrPY
s0LmqtGqO3qa3xikhde8Iw0urejgyLSSJXcYLak+3TgRZqXmqJWhCW5bwRmathht
Y7Aev1g5oUsrX1KfvSwc76U13C8lqCzi2ICmUt1r2nMDR74hi8rxsxlY/axqZ2nJ
v2wROiD1ecxBx6rWeSi6K6cl3Oa7jUMkAk0avlw8Ozg/cXDmWqDzqyrLVZNFlDni
FeoAbgoJ6AnKULVyMLjwHQqx4Dg7tFGFiVefkiNMsXijwhXE2IxiEK52yvBN1M06
UWwmwBIqFnUnCHN98UGbI4yT9favE2eqKAChvQo4TowaycCw5wNtI1zCkb+Uw40j
0l3TMCkrqIPJ+1EeQKusewgHk/knpeXuqDFei/04b2TILo1RaQLwwQMyZMILozki
81Zs1bizUuU=
=a02R
-----END PGP SIGNATURE-----


-------------------------------------
You are welcome to optimise P2P addr broadcasts or develop better bootstrap
mechanisms.


On Sun, May 5, 2013 at 3:12 PM, John Dillon
<john.dillon892@googlemail.com>wrote:

-------------------------------------
Busy with pre-conference stuff, not following details of this conversation...

... but it sounds a lot like the "guy fawkes" protocol Zooko was thinking about a year or so ago.

-------------------------------------
On Tue, Sep 17, 2013 at 4:00 AM, Mike Hearn <mike@plan99.net> wrote:

I'd looked at the hyperleveldb, but their performance graphs made it
seem like it would be slower for the actual database sizes we're using
today.

Is there a competitor that specializes in being more robust to corruption? :(


-------------------------------------
Could anyone point me to work/project(s) related to storing the block chain
in a database, like PostgreSQL, MySQL? How about any tools that can read
the block chain from the Satoshi client and convert it into different
formats?

Thanks,
-Marko
-------------------------------------
Reserving my judgement until I've though about it more (design by committee
scares me, and this voting sounds expensive), I think the SPV-verifiable
moving median can be done by binning the space of block size limits, and
for each node in the UTXO tree, a value for each bin is stored which is the
sum of the corresponding bins of each of the children.  The childless nodes
- which correspond to the individual UTXOs - increment the appropriate bin
of their parents according to the rules you mentioned.  The bin values in
the root node of the UTXO tree would then be added to those, weighted
appropriately, of the previous N blocks.

The hash of a node would be that of the bin values, concatenated with the
child nodes' hashes.  In this way, any step of the calculation of the
median would produce a localized error in the UTXO tree that's easily
verified.

The number of bins would have to be kept relatively small in order to keep
this from adding too much data to the UTXO tree branches though.


On Mon, Jun 10, 2013 at 2:30 AM, Peter Todd <pete@petertodd.org> wrote:

-------------------------------------
Did some tests with a varient of attack... In short it's fairly easy to
saturate a node's disk IO bandwidth and when that happens the node
quickly falls behind in consensus, not to mention becomes useless to
it's peers. Note that the particular varient I tried is different, and
less efficient in bandwidth, than others discussed privately.

Bandwidth required to, for example, take out a Amazon EC2 m1.small is
about 1KiB/second, and results in it getting multiple blocks behind in
consensus, or a delay on the order of minutes to tens of minutes. I had
similar results attacking a p2pool node I own that has a harddrive and
4GiB of ram - of course my orphan rate went to 100%

It'd be interesting to repeat the attack by distributing it from
multiple peers rather than from a single source. At that point the
attack could be made indistinguishable from a bunch of SPV wallets
rescanning the chain for old transactions.

In any case given that SPV peers don't contribute back to the network
they should obviously be heavily deprioritized and served only with
whatever resources a node has spare. The more interesting question is
how do you make it possible for SPV nodes to gain priority over an
attacker? It has to be some kind of limited resource - schemes that rely
on things like prioritizing long-lived identities fail against patient
attackers - time doesn't make an identity expensive if the identity is
free in the first place. Similarly summing up the fees paid by
transactions relayed from that peer also fail, because an attacker can
easily broadcast the same transaction to multiple peers at once - it's
not a limited resource. Bandwidth is limited, but orders of magnitude
cheaper for the attacker than a Android wallet on a dataplan.

-- 
'peter'[:-1]@petertodd.org
-------------------------------------
This may be a semantic issue. I meant that it's not a hard-fork of the
bitcoin protocol, which I'm taking to mean the way in which we all
*expected* every version of the Satoshi client to behave: the rules which
we have documented informally on the wiki, this mailing list, and in code
comments, etc. I'm just trying to prevent protocol-creep.

Luke-Jr is suggesting that we add-to/modify the bitcoin protocol rules
which all verifying implementations must adhere to. I'm suggesting that we
instead change the old codebase to do what we expected it to do all along
(what 0.8 does and what every other verifying implementation does), and
through miner collusion buy ourselves enough time for people to update
their own installations.

I know there's people here who will jump in saying that the bitcoin
protocol is the behavior of the Satoshi client, period. But which Satoshi
client? 0.7 or 0.8? How do you resolve that without being arbitrary? And
regardless, we are moving very quickly towards a multi-client future. This
problem is very clearly a *bug* in the old codebase. So let's be forward
thinking and do what we would do in any other situation: fix the bug,
responsibly notify people and give them time to react, then move on. Let's
not codify the bug in the protocol.

Mark



On Wed, Mar 13, 2013 at 10:58 AM, Pieter Wuille <pieter.wuille@gmail.com>wrote:

-------------------------------------
We could also say that if protocol part (https://) is missing, it's implied
automatically. So just:

bitcoin:1abc........?r=bob.com/r/aZgR

I think that's about as small as possible without re-using the pubkey as a
token in the url.


On Wed, Sep 25, 2013 at 1:35 AM, Gavin Andresen <gavinandresen@gmail.com>wrote:

-------------------------------------
On Mon, Dec 09, 2013 at 02:55:02PM +0000, Drak wrote:

Oh, I see - so it was.  It wasn't announced here though - is there
some other list I need to be on, too?  It would be nice if
announcements like this were posted to a mailing list as well as
bitcointalk.org (is there a bitcoin-announce list that I missed?  If
not, maybe there should be)

roy



-------------------------------------
Hello dear list

I have an application that wants to keep up with new blocks as they come
in. For that I can use the -blocknotify option with bitcoind, which will
execute my application for each new block.

The problem is that my app isn't necessarily quick enough to finish its
work before a new block comes in and the app is executed again. This means
the that bitcoind might keep executing my application even though the
previous instance hasn't finished, and that's fairly inefficient
resource-wise, as many instances of the application will be running
simultaneously.

I've discussed this with wumpus on bitcoin-dev, and we figured out a
solution that might be better. It could replace -blocknotify or we could
put it in a new function called -batchblocknotify

The idea is that when bitcoind is executed with the -batchblocknotify
option, and it's missing a lot of blocks, upon the first incoming block,
the command specified by -batchblocknotify is executed, and if additional
blocks come in while this command is still running, we add the block hashes
to a list instead of executing the command again. When the previous command
finishes, we execute it again and pass two parameters to it: 1. the first
block hash in the list of queued blocks, and 2. the number of blocks that
have come in while the last command was executing.

This prevents bitcoind from "fork bombing" the system, and allows the
command to handle incoming blocks in batches.

Would this make sense as an approach?

I've been looking at the code and I'm not sure how to implement it.

As far as I can see, I need to pass an object - whose state is retained
between calls - to the thread function (runCommand) that runs the command,
which contains a variable that keeps track of whether a previously executed
command is still running, and that contains a list of block hashes that
haven't been processed. And I'm not sure how to do this.

The runCommand thread is started in SetBestChain() in
main.cpp. SetBestChain() is executed by ConnectBestBlock() in main.cpp.
ConnectBestBlock() is executed by CBlock::AddToBlockIndex() in main.cpp.
CBlock::AddToBlockIndex() is executed by CBlock::AcceptBlock() in main.cpp.
CBlock::AcceptBlock() is executed by ProcessBlock() in main.cpp.
ProcessBlock() is executed by ProcessMessage() in main.cpp. And so on, and
so forth.

What's the right way to create an object that can be passed to the
runCommand thread, whose state is retained, so it can hold information
about whether the -batchblocknotify command is still executing, and contain
a list of blocks that are waiting to be passed to the -batchblocknotify
command?

I assume I shouldn't add a new parameter to the ProcessMessage() function,
which passes it to ProcessBlock(), which passes it to AcceptBlock() which
passes it to AddToBlockIndex()... and so on.

Would it be appropriate to store this object inside the CValidationState
class that is passed to SetBestChain()?

I'm not quite so how to go about this.

/Rune
-------------------------------------
On Wed, Sep 25, 2013 at 01:35:48PM +0200, Melvin Carvalho wrote:

...until the Bitcoin payment protocol showed up and let anyone with the
ability to MITM https turn that ability into untraceable cash.

I won't be at all surprised if one of the most valuable things to come
out of the payment protocol using the SSL PKI infrastructure is to give
us a good understanding of exactly how it's broken, and to give everyone
involved good reasons to fix it.

Even if the flaws of SSL PKI were exploited as a way to harm bitcoin by
governments and other large players - and SSL PKI remained unfixed - I'd
much rather have that solid evidence that it was broken than not.

-- 
'peter'[:-1]@petertodd.org
-------------------------------------
For those interested in these things the multibit.org server
is a dedicated server hosted by the German company
http://www.server4you.net. 

It is physically located in the delightful city of Strasbourg, 
just on the French side of the French German border.



On Tue, Jul 9, 2013, at 03:28 PM, Mike Hearn wrote:


-- 
https://multibit.org    Money, reinvented


-------------------------------------
On Mon, May 06, 2013 at 08:32:22PM +0200, Adam Back wrote:

re: double-spends - punishing relay nodes and miners for them is a very
bad idea. Ultimately it is the blockchain by which Bitcoin comes to
consensus about what transactions belong in the blockchain - to punish
double-spends implies a second consensus mechanism. Anyway it's
unnecessary: you can hold the actual spender accountable for
double-spends and punish them directly rather than adding a lot of
complexity and dangerous assumptions about propagation to the Bitcoin
core network.


Some useful things you can hold relay nodes accountable for without a
lot of complexity:

1) Having a reasonably correct view of the best block. Make the node
sign a statement including a block hash sequence (the last 3-6 blocks)
and what it believes the current time is.

2) Accurate knowledge of the blockchain. Sign a statement claiming that
what block hash is for a given chain height. Note that due to reg-orgs
this is actually a different statement than #1 and nodes should be
careful what they are claiming.

3) Accurate knowledge of the UTXO set. Sign a statement claiming that
a given txid:vout for the current best block hash is in or not in the
UTXO set.

4) Accurate bloom filtering; same idea as #3

5) Make the node identity expensive to obtain. For instance, construct
PoW's including the node pubkey somehow, or purchase fidelity bonds for
the node's identity. Makes sybil attacks more difficult, among other
things.

5) Provide useful propagation/mining services. Sign a txid and
timestamp/blockhash-sequence, and hold the node accountable for how long
it takes the txid to make it into the blockchain. Useful especially for
miners offering the service of mining your transaction.



Be careful not to mix up the concept of a relay node with someone
posessing Bitcoins. Node's don't spend coins, people/wallets do.


That stuff is cool, but we should focus first on simple efforts, like
SSL transport, that do not require complex cryptography to obtain an
improvement in security.

Of course, not to say long-term research is bad, but that's just not
going into the Bitcoin reference client in the near future.

-- 
'peter'[:-1]@petertodd.org
0000000000000124d42390b0db4c125f6be87835c49dc88f1bdeba527b77abc2
-------------------------------------
Pull request https://github.com/bitcoin/bitcoin/pull/2905 proposes to
remove "getwork" RPC from bitcoind: https://en.bitcoin.it/wiki/Getwork

On mainnet, almost everybody uses a pool (and therefore, not "getwork"
directly to bitcoind).  Those few who solo mine use a pool server to
talk to bitcoind via "getblocktemplate" or other means.  Tests show
that attempts to solo mine on mainnet via "getwork" lead to delays and
problems.

On testnet, getwork has a better chance of continuing to work.
Nevertheless, the same tools (open source pool servers or p2pool) are
available for testnet, obviating the continued need to support
getwork.

However, at one time, getwork to bitcoind was widely used.  I wanted
to poke the audience, to gauge response to removing "getwork."  If a
driving use case remains of which we're unaware, speak up, please.  We
don't want to break anybody needlessly.

-- 
Jeff Garzik
Senior Software Engineer and open source evangelist
BitPay, Inc.      https://bitpay.com/


-------------------------------------
On Thursday, June 06, 2013 8:16:40 PM Andreas M. Antonopoulos wrote:

Because payments are the only thing everyone using Bitcoin has agreed to use 
the blockchain for. Furthermore, there is no *reason* to store non-payments in 
the blockchain. If there was in fact such a use case, things might be arguable 
- but there isn't any I'm aware of.


The issue is using other peoples' resources for something they did not agree 
to use it for. The fees aren't merely "not enough", they were never *intended* 
to be "cost of storage". They are "cost of security" and "prevent spamming".


The concepts behind Bitcoin are applicable to future innovation, but this can 
all be accomplished without spamming Bitcoin itself.


Non-payments are quite possible without the Bitcoin blockchain itself. If 
you're worried that not enough people will store the alternative-non-payment 
data, then you are essentially saying that voluntary participation is not 
enough and that forced storage is your solution. I don't think this is what 
you intend...


The Bitcoin blockchain protocol has 95 bytes per block reserved for miners to 
put extra data. Currently, this is used for extranonces, political or other 
short messages (such as in the Genesis block), miner "signatures", and also, 
as I mentioned, merged mining. Merged mining works by tying a non-
transactional merkle tree to the blockchain. The block coinbase stores the 
hash of the top of this merkle tree, so any data within the merkle tree can 
prove it is associated to the block. The merged mining merkle tree then stores 
hashes of multiple other data sets: for example, a Namecoin block can be 
referenced in a merged mining merkle tree, to use the Bitcoin block's proof-
of-work for itself (so, miners can mine both Bitcoin and Namecoin using the 
same hashing effort). You could also add other non-transactional blocks to the 
merged mining merkle tree, for generic timestamping or really anything at all.

Luke


-------------------------------------

This is already the case and always has been.




If you're volunteering to store and serve the chain no matter what it
contains, indefinitely, then you're free to have a no blacklists policy and
serve up data transactions for no cost. Otherwise, other people will do
whatever they want.
-------------------------------------
Thank you for setting me straight. Please forgive my ignorance.


On Mon, Aug 19, 2013 at 3:14 PM, Pieter Wuille <pieter.wuille@gmail.com>wrote:




-- 
*MONEY IS OVER!*
                                IF YOU WANT IT<http://www.zeitgeistmovie.com/>
=====================================================
The causes of my servitude can be traced to the tyranny of money.
-Serj Tankian
-------------------------------------
Thanks, Mike!

   "PaymentRequest messages larger than 50,000 bytes should be rejected by

Yes, fixed.




I don't like putting "this is what we think will happen in the future"
types of statements in specifications, so I'm inclined to leave that out.



Added:

"Resistance from man-in-the-middle attacks that replace a merchant's
bitcoin address with an attacker's address before a transaction is
authorized with a hardware wallet."

Perhaps note in the BIP that the merchant should not assume the

Added:

"Note that malicious clients may modify the merchant_data, so should be
authenticated in some way (for example, signed with a merchant-only key)."



done.



Added:

"payment | Copy of the Payment message that triggered this PaymentACK.
Clients may ignore this if they implement another way of associating
Payments with PaymentACKs."



Modified that section to say:

"...followed by additional certificates, with each subsequent certificate
being the one used to certify the previous one, up to a trusted root
authority. The recipient must verify the certificate chain according to
[RFC5280] and reject the PaymentRequest if any validation failure occurs.

Trusted root certificates may be obtained from the operating system; if
validation is done on a device without an operating system, the Mozilla
root store<http://www.mozilla.org/projects/security/certs/included/index.html>
is
recommended."

-- 
--
Gavin Andresen
-------------------------------------
Perhaps there should be two different sections on the web page.

Nerds  / Non-Nerds

With different recommendations for which clients to use.


On Thu, Jun 27, 2013 at 2:56 PM, Jeff Garzik <jgarzik@bitpay.com> wrote:




-- 
Alex Kravets <http://www.linkedin.com/in/akravets>       def redPill = '
Scala <http://www.scala-lang.org/>
[[ brutal honesty <http://goo.gl/vwydt> is the best policy ]]
-------------------------------------
On Thu, Jun 27, 2013 at 12:03 PM, Arthur Gervais
<arthur.gervais@inf.ethz.ch> wrote:

Certainly.  Though given current P2P network node version
distributions, it is increasing difficult to relay the older version
of transaction, and will only become more so in the future.

It also remains the case that merchants who accept zero confirmation
transactions are likely already aware of the risk level, and make a
business decision.  One can see tiny digital downloads often at zero
confirmation, but rarely a Porsche or house or bitcoin exchange
deposit.

-- 
Jeff Garzik
Senior Software Engineer and open source evangelist
BitPay, Inc.      https://bitpay.com/


-------------------------------------
Mike, Pieter,

My writeup outlines a framework for good approximation to a minimal fee
as well as the optimal block size. The model has basically just one
parameter, the propagation time - if that goes down, so can the fee.
(Well there is another parameter too, the time btw blocks, which
currently with the current hash acceleration is more like 400 than 600).

Also seconding Mike, that, yes, it would be tremendously useful to track
propagation times and other things on the network to help us all decide
the proper settings.

Finally, it would be great if someone from academia would grab the ball
and do the full probabilistic analysis based on my outline.

Michael

On 7/11/13, 16:22 , Mike Hearn wrote:



-------------------------------------
Chris,

First, an important point: addresses are not wallet ids. They are single-use 
destinations for a single transaction. It isn't intended that anyone should 
remember them, just that they should send them electronically (or with eg, QR-
Codes). Bitcoin does not (yet?) have a person/wallet identity system, but 
there are other mechanisms for this already (eg, PGP).

With regard to your idea, I believe it is satisfied by the new Payment 
Protocol that Gavin has been working on. You will be able to publish a URI for 
a website which people can reuse to pay you more than once.

Luke


On Friday, August 02, 2013 8:40:27 PM Chris Evans wrote:


-------------------------------------
On Sat, Jun 1, 2013 at 11:29 AM, Wladimir <laanwj@gmail.com> wrote:

I hadn't seen this, thanks! I've integrated zmq myself for block
notifications in bitcoin and the alt coins I use it on my bitparking
merge mining pool. I would love to see something official. I'll try
out the patch in the pull request.

Chris.
-- 
http://www.bluishcoder.co.nz


-------------------------------------
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256

On Thu, May 9, 2013 at 1:13 AM, Pieter Wuille <pieter.wuille@gmail.com> wrote:

Doesn't most mining hardware at the ASCI level start with a SHA256 midstate
given that the nonce is at the end?  Adding further information to the block
should be possible at the beginning of the block without major changes to the
mining hardware.


I feel somewhat uncomfortable about the "after-the-fact" auditing possible in
this scenario. Besides the timestamping provided by the block headers appears
to be useful in some payment protocols, not to mention in general.
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBCAAGBQJRivnmAAoJEEWCsU
4mNhiPUIYH/AlxK4DHvIdq0khNH0nfK65E
F1ZyYZTGLNHKqrJLCU2kc7zteGadQuccmFsYpmViIr14tzpU7xMImUHpj7fEHO3R
S/1zy59rx2+VYcevYdwMDTywanjeForRpli93Hz570GfwfG/D7VPejfLo6iq5dOt
EG5m3Z8F7wNzWBmfBYBHKLrNBJe6iw0qJ2nNiHXcELt6gaqG3C9wI9NAPtQWQKjB
57h7yTnFCRmjA3HDdCe2s0FVJgRP5cJqz3e62qZrY/BRmw/Vrx8ExuX1LJFqUx3k
5tg+BxXH4DJbNIojuq9lLl5lWxKOI1iSJJuCAixo/6s/manLFggJv7KtYgzhhjI=
=BxDb
-----END PGP SIGNATURE-----


-------------------------------------
On Fri, Oct 4, 2013 at 2:22 AM, Gavin Andresen <gavinandresen@gmail.com> wrote:

It's all still working around a problem unchanged since Satoshi wrote
it:  the HTTP server code paths use blocking I/O.

Amusingly, we do this through an async I/O library, which helps
facilitate SSL, but all our connections and operations are blocking.

That's why RPC was multi-threaded in part:  to work around the ugly
blocking nature of the code.  At least with multiple threads, one
thread will not stall another even if the network stalls (or a
software bug triggers a stall etc.)

Hopefully I can dive into the code and make is truly async I/O.  It
takes some work, and I'm happy if someone else steals the task, but
that's what really needs to be done.

I tried the multi-threaded approach, writing an entire boost::asio
skeleton JSON-RPC HTTP server: https://github.com/jgarzik/rpcsrv
This is working, tested code that uses boost::asio properly.  It's
also quite a bit of LOC, and a bit messy to boot (four LOC per boost
async action and incomprehensible compiler errors in return for proper
async+MT).

A single thread with async I/O is likely sufficient for even heavy
uses of RPC -- since today it all goes through a big lock anyway.

-- 
Jeff Garzik
Senior Software Engineer and open source evangelist
BitPay, Inc.      https://bitpay.com/


-------------------------------------
I did some very rough initial performance tests.

Syncing from a local peer gives me about 50 blocks per second in the
later parts of the chain (post SD), which is about a 10-20x speedup
over what I could do before. This is on a MacBook Pro. But at those
points it's clearly bottlenecked by bitcoind which has saturated its
CPU core. This makes sense - the filtering is much more server than
client intensive because every transaction in every block has to be
loaded and checked.

I think filtering can be fairly well parallelized on the server side.
So the current 10-20x speedup could potentially be larger if the
server becomes more efficient at scanning and filtering blocks. It's
still a very nice win for now, especially bandwidth wise. And if Matt
makes the mempool command filtered it solves a common usability
problem as well.

Once we get this code in, merged and rolled out I think what we need
for bloom v2 is clear:

 - Multi-thread the filtering process in bitcoind so transactions can
be checked in parallel. A 4-core server would then get 4x faster at
filtering blocks and assuming it's not too busy doing other stuff we
could maybe sync at more like 200 blocks per second, which is cool ...
more than a days worth of history for each second of syncing.

 - Make the client smarter so the FP rate is adapted during the sync
process. An FP rate that makes sense post-SD results in no false
positives pre-SD, more or less.

 - Make the client shard its wallet keys over multiple peers, for
better privacy.

 - Make the client suck down filtered blocks in parallel from multiple
peers, for better speed.

As it seems the bottleneck for chain sync is now CPU time, the latter
point may be the most important from a practical perspective.

On Fri, Jan 11, 2013 at 6:02 AM, Jeff Garzik <jgarzik@exmulti.com> wrote:


-------------------------------------
On Sat, Jul 13, 2013 at 11:51:14AM +0200, Jorge Timn wrote:

Without a bitcoin peg on the creation cost of zerocoins, it is hard for a
new alt-coin to have a stable value.  Bitcoin itself is volatile enough.

Generally the available compute for mining is what it is, adding more
alt-coins just dillutes the compute available for a given coin.  (Modulo
different mining functions like scrypt vs hashcash there is some
non-overlapping available compute because different hardware is more
efficient, or even cost-effective at all).

Merge mining is less desirable for the alt-coin - its mining is essentially
free, on top of bitcoin mining.  Cost free is maybe a weaker starting point
bootstrapping digital scarcity based market price.

I think that serves to explain why bitcoin sacrifice as a mining method is a
simple and stable cost starting point for an alt-coin.  


Bitcoin sacrifice related applications do not require code changes to
bitcoin itself, which avoids the discussion about fairness of which alt-coin
is supported, and about sacrifice-based pegging being added or not.

I dont think it necessarily hurts investors in bitcoins as it just creates
some deflation in the supply of bitcoin.


You can sacrifice bitcoins as a way to mine zerocoins without having the
bitcoin network validate zerocoin.  For all bitcoin clients care the
sacrifice could be useless.

Bi-directional sacrifice is more tricky.  ie being allowed to re-create
previously destroyed bitcoins, based on the sacrifice of zerocoin.  That
would have other coin validation requirements.

But I am not sure 1:1 is necessarily far from the right price - the price is
arbitrary for a divisible token, so 1:1 is as good as any.  And the price
equality depends on the extra functionality or value from the
characteristics of the other coin.  The only thing I can see is zerocoin is
more cpu expensive to validate, the coins are bigger, but provide more
payment privacy (and so less taint).  Removing taint may mean that zercoins
should be worth more.  However if any tainted bitcoins can be converted to
zerocoin via sacrifice at 1:1, maybe the taint issue goes away - any coins
that are tainted to the point of value-loss will be converted to zerocoin,
and consequently the price to convert back should also be 1:1?


p2p transfer is a good idea.

Adam


-------------------------------------
On Monday, March 11, 2013 7:27:51 PM Rune K. Svendsen wrote:

Please use GitHub pull requests (or at least publish a git repository) rather 
than mailing patches..

I'd suggest two commits for this:
1. Move the recommended fee outside the translatable string (bonus points to 
format it using the user's preferred unit)
2. Change the recommended fee in one place

Whether the recommended fee *should* be changed or not, I have no opinion on.
Eligius uses a lower minimum fee, but I believe most pools/miners will treat 
anything under 0.01 BTC as if it were no fee at all...

Luke


-------------------------------------
I prefer to leverage the signing of the (.) root in the DNS tree. The
amount of effort in signing the root holds more weight than building a CA
off the bitcoin blockchain.

If you want to associate identifiers for payment addresses I suggest
putting those in DNSSEC signed records in the DNS.

For routing around x.509 CAs I suggest participating in the DANE working
group in the IETF.

-rick


On Fri, Feb 8, 2013 at 2:03 AM, Timo Hanke <timo.hanke@web.de> wrote:

-------------------------------------
On Mon, Dec 16, 2013 at 12:31 PM, Pieter Wuille <pieter.wuille@gmail.com>wrote:


Jim seems to be planning some parallel development to what I'm doing, but
HD wallets and stopping address re-use is the current feature I'm working
on for bitcoinj. Only code review and merging takes higher priority at the
moment. So I think we might be able to stop re-using addresses at least on
devices with sufficient memory some time in Q1
-------------------------------------
I was just reviewing the integration work to integrate the Payment
Protocol into our products. Is there any notion of a standardized
invoice serialisation? If i pay for two Burgers and one Club Mate, how
would my Bitcoin Wallet be able to know that? Right now, i would simply
put that into "memo" and come up with my own serialisation mechanism.

Second, is there a way to communicate acceptance levels of TX
(unconfirmed, 1 conf, 6 conf) maybe using several PaymentACK?

-Andreas




-------------------------------------
This has been asked very recently:

http://sourceforge.net/mailarchive/forum.php?forum_name=bitcoin-development

And a thousand times on bitcointalk.


On 12/10/13, Jameson Lopp <jameson.lopp@gmail.com> wrote:


-- 
Jorge TimÃ³n

http://freico.in/


-------------------------------------
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 08/13/2013 04:46 PM, Randolph D. wrote:

Oops!  My bad.

- -- 
The Doctor [412/724/301/703] [ZS]
Developer, Project Byzantium: http://project-byzantium.org/

PGP: 0x807B17C1 / 7960 1CDC 85C9 0B63 8D9F  DD89 3BD8 FF2B 807B 17C1
WWW: https://drwho.virtadpt.net/

"This time we're using four times the Kevlar."

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.20 (GNU/Linux)
Comment: Using GnuPG with Thunderbird - http://www.enigmail.net/

iEYEARECAAYFAlILuDcACgkQO9j/K4B7F8HDBQCfR0F9SmCBCuFN1cAg/FExzicj
wfMAn0Fob9raimlp0/JQLi9y9hOyIwpG
=0vIZ
-----END PGP SIGNATURE-----


-------------------------------------
On Thu, Aug 1, 2013 at 9:30 AM, E willbefull <ewillbefull@gmail.com> wrote:

P2SH addresses already support all exotic transactions.


Do you mean assemble the PaymentRequest message?  Because the payment
transaction will always be created by the customer's wallet software.

IF PaymentRequests take over the world and we get 100% wallet software
support, then I'd be happy to write another BIP that says that a
bitcoin: URI can be just bitcoin:?request=http...

-- 
--
Gavin Andresen


-------------------------------------

I'm thinking about a use case I hope will become common next year -
pastebin style hosting sites for payment requests. Like, if I as a regular
end user wish to use the payment protocol, I could just upload a (possibly
signed) payment request to:

payr.com/a62gahZ

or whatever, and then payr.com can take care of incrementing the iteration
count on each download of my file. That's why it's useful for it to be
unsigned.



Absolutely. The two use cases can both be supported. You could give
iteration ranges, for instance, if you want to specify expiry in terms of
number of payments rather than time.
-------------------------------------

This must be a new use of the word "abuse" I haven't come across before :)

At any rate, some of these assumptions are incorrect. Botnets of
compromised web servers are quite common, and asymmetry in node resources
is obviously biased against the kinds of devices people increasingly have
(phones, tablets) where extremely limited memory bandwidth is common and
apps routinely have just 16 or 32mb of memory to do everything including
the GUI.

A good anti-DoS strategy looks much the same as a good load shedding
strategy. There's little reason to treat them separately. Perhaps instead
of talking about DoS we should instead talk about what happens if Bitcoin
suddenly gets too popular. Now there are suddenly lots of good users all
wanting to use the network, and not enough nodes to support them all. What
do we do?

Some rules seem obvious - try to prioritise existing users over new users,
old coins over new coins (dPriority already does this) etc. If you run out
of TCP sockets prefer to disconnect recent connections (probably new users)
to long lived connections (probably high powered backbone peers). If you
run out of disk seeks prefer processing new blocks to serving old parts of
the chain, etc.
-------------------------------------
Hello, 


Has everyone seen 

http://www.coindesk.com/bitcoin-gaining-market-based-legitimacy-xbt/ 


Bitcoin has its own ISO currency code.

Ron



________________________________
-------------------------------------
On Mon, Jul 29, 2013 at 10:01 PM, Randolph D. <rdohm321@gmail.com> wrote:

Keep safe everyone:

A number of apparent sock accounts has been posting about what appears
to be the same software under the name "goldbug" for a couple days
now:

e.g.
https://lists.torproject.org/pipermail/tor-talk/2013-July/029107.html
https://lists.torproject.org/pipermail/tor-talk/2013-July/029125.html
http://lists.gnupg.org/pipermail/gnupg-users/2013-July/047137.html


-------------------------------------
On Fri, Oct 04, 2013 at 12:30:07PM +0200, Mike Hearn wrote:

When I'm reviewing multiple commit pull-requests and want to see every
change made, I always either click on the "Files Changed" tab on github,
which collapses every commit into a single diff, or do the equivalent
with git log.

Why doesn't that work for you?


One advantage of using github is that they're an independent third
party; we should think carefully about the risks of furthering the
impression that Bitcoin development is a closed process by moving the
code review it to a server that we control with explicit review groups.

Given that Review Board appears to remain cryptographically unverifiable
there may also be disadvantages in operating it ourselves in that if the
review server does get compromised we *don't* have a third-party to
blame. In addition GitHub is a third-party with a very valuable
reputation to uphold and full-time staff - they're doing a better job of
keeping their servers secure and running then we ever could.

-- 
'peter'[:-1]@petertodd.org
-------------------------------------
(cross-post from bitcointalk.org)

Hello all,

as some may know, Bitcoin uses DER-encoded signatures in its transactions.
However, OpenSSL (which is used to verify them) accepts more than just the
strict DER specification (it allows negative numbers, extra zero padding,
extra bytes at the end, and perhaps more). As we don't like the de-facto
specification of the Bitcoin block validity rules to depend on OpenSSL,
we're trying to introduce a rule to make such non-standard signatures
invalid. Obviously, that can't be done as long as any significant amount of
clients on the network is creating these.

I've monitored all transactions the past weeks (1.4M transactions), and it
seems 9641 of them contain at least one non-standard signature. See
https://bitcointalk.org/index.php?topic=169620.0 for a list of the top
addresses that had coins used as inputs in such transactions. If you
recognize any of these addresses, or have an idea of who owns them or what
software they are using, please let me know.

Thanks!

-- 
Pieter
-------------------------------------
The current BitCoin implementation is subject to relatively easy double 
spend attack for 0 confirmation payments.  Yet 0 confirmation payments 
are needed for typical in person transactions like most purchases at a 
local business.

Notably, it is easy to transmit two transactions from the same output at 
the same time to different sets of nodes on the network by using two 
instances of bitcoind with same wallet file and a spend on each daemon 
initiated by RPC by some easy to implement code.  If the first attempt 
to pay the merchant doesn't go through because they received the "wrong" 
transaction it could be quickly followed up with another initiated spend 
from a different output switching which daemon sends the transaction the 
merchant is expecting.  This means an unsophisticated attacker can 
reliably get away with this attack and it would be worth while for small 
transactions.  Given this, I would be reluctant to trust 0 confirmation 
transactions at all though I think many do in practice.  Someone could 
write and publish a special daemon to execute this attack further 
reducing the cost.

Right now a node will drop any second spend of the same output in the 
memory pool.  After the first transaction has propagated through the 
network issuing a second double spend transaction isn't likely to be 
seen by a significant number of miners as most nodes especially non 
miner nodes will drop this transaction.  Today, it is necessary to 
transmit both transactions on the network nearly simultaneously to 
reliably get away with this simple attack.  If in this case, the 
receiving end is quickly notified of the double spend this attack 
becomes more more difficult to get away with.

If the second transaction is relayed instead of being dropped to notify 
the receiving party of the double spend, most miners will receive both 
transactions and it is possible that some or even many of the miners 
would replace the first transaction with the second if it has a higher 
fee as it would be in their short term interest. This can happen some 
time after the first transaction has propagated through the network so 
the receiving end wouldn't get a timely notification of the double 
spend.  Depending on the choices of the miners, this approach to double 
spend notification could exacerbate the very problem it was attempting 
to fix compared to the current implementation.  While miners might 
continue to drop the second spends, the easy availability of the second 
spends would increase the short term reward for changing this policy.

This problem can be fixed if instead of sending the second transaction a 
new double spend message is sent with proof of the double spend but not 
the complete transactions.  This would allow the receiving end to be 
quickly notified of a double spend while in no way increase the chance 
over the current implementation that a double spend would be successful.

The proof of the double spend would include the scriptSig (input) from 
the original transactions and the hashes from the "simplified" 
transaction used by OP_CHECKSIG of the scriptPubKey (output) but not the 
entire transaction.  This is the hash computed by the SignatureHash 
function in script.cpp.   The double spend notification message should 
contain proofs of both signed transaction spending the same output 
ordered by hash to produce a canonical proof for a specific two 
transactions.  To reduce DOS potential, the proof should not be relayed 
unless one of the original transactions has been received to ensure 
there is some commitment to the block chain and different double spend 
proofs of the same output should not be relayed.  The forwarding of 
transactions should remain exactly the same as it is now where the 
second transaction is dropped but a double spend message is transmitted 
if appropriate.

The existing block chain needs to be checked to make sure the proof of 
double spend couldn't have been derived from the block chain and a 
single spend in the memory pool.  This could happen if there was already 
an identical transaction in the block chain.  This would typically only 
happen if someone was paying someone else the same amount they had 
before and neither side changed addresses.  In this case double spend 
detection wouldn't be reliable as it could be generated by anyone, but 
both the sending and receiving client could detect this situation and 
warn the user.

It would still be possible for an attacker to send the second 
transaction directly to powerful miners but this is a distinctly less 
viable attack than the current double spend attack.

I would expect this double spend notification implementation to make 
double spends more costly than they are worth for most cases today that 
0 confirmation acceptance is needed.  That said over time this provision 
might become less effective.  As the reward for each block mined 
decreases, transactions fees will become a more significant part of the 
mining reward accordingly increasing the incentive to replace 
transactions with higher fees.  Today most BitCoin participants have a 
high expectation of significant future appreciation of BitCoins and 
recognize anything that brings into question the integrity of the system 
is likely to reduce that future value so they have a long term self 
interest to keep up the impression of integrity.  As BitCoin becomes 
more establish this incentive will decrease.

On the other hand, non mining nodes have no incentive to replace by 
fee.  The continued increased capital costs of mining would likely 
increase the proportion of non mining nodes typically run by those with 
an incentive to assure integrity of the network such as merchants.  But 
increasing transaction volume is likely to increase node costs which 
would push out non mining nodes with lower incentive more than mining 
nodes.  Accordingly increasing block size would have a tendency to 
reduce the effectiveness of double spend notification.  The primary 
point is there are multiple counteracting forces that make predicting 
the future effectiveness of double spend notification uncertain.

I don't believe this necessary warrants conceding that we can not 
provide any protection from non trusted 0 confirmations transaction as a 
replace by fee implementation would do.  But it would still be important 
to work towards more robust solutions notably various forms of 3rd party 
trust.  This could be tamper resistant devices trusted to not duplicate 
spends, 3rd party certificates with proof the transaction was spent by 
the holder of the certificate or multi signature transactions on the 
block chain that must be signed by a trusted 3rd party to spend.  I 
would expect it would take significantly longer for the companies and 
technologies to be built to implement this on a wide scale than adding 
double spend proof messages to the current implementation.  In addition, 
there will likely always be some use cases where a 3rd party 
(centralization) is not viable.

Should a BIP and pull request implementing a double spend notification 
as described be accepted?

- Quinn




-------------------------------------
Only slightly related to this...
What's the reason why BerkleyDB is maintained for the wallet?
I think it would be a good thing to get rid of the libdb4.8++-dev
dependency that makes bitcoind harder to compile on debian and ubuntu.
Unless, of course, there's a reason I am missing...


On 9/17/13, Mike Hearn <mike@plan99.net> wrote:


-- 
Jorge Timn

http://freico.in/


-------------------------------------
On Sun, Dec 29, 2013 at 11:53:19AM -0700, Evan Duffield wrote:

I would strongly suggest that if you have not done so already you hire
someone competent to do an analysis of whether or not your idea makes
sense at all; that you are using merge-mining is a red-flag because
without majority, or at least near-majority, hashing power an attacker
can 51% attack your altcoin at negligible cost by re-using existing
hashing power. If you are starting a timestamping service that may be an
exception, but how to turn a profit doing so is non-obvious.


I would offer that consulting myself, but it would likely be a conflict
of interest with my employers. I'd be happy to speak informally in
private, but am explicitly unwilling to agree to any
non-compete/non-disclosure terms.

-- 
'peter'[:-1]@petertodd.org
000000000000000f9102d27cfd61ea9e8bb324593593ca3ce6ba53153ff251b3
-------------------------------------
For people who are interested in such technologies, I recommend looking at
Pond:

https://pond.imperialviolet.org/

It is written by Adam Langley, so it comes with some serious credentials
behind it. It provides asynchronous email-like messaging that's forward
secure, resistant to traffic analysis and the whole thing runs over Tor.
Messages are stored for a week and are strictly limited in size. There's no
spam because nobody has an address - instead you have to grant someone the
ability to message you by giving them a small file. So, not really intended
as an email competitor convenience wise, but it has many interesting ideas
and a reasonable GUI.

As a testament to the seriousness with which Pond takes forward security,
it can use the NVRAM in a TPM chip to reliably destroy keys for data that
an SSD device might have otherwise made un-erasable.

The main downside - it's written in Go :)


On Tue, Jul 30, 2013 at 8:50 AM, Gregory Maxwell <gmaxwell@gmail.com> wrote:

-------------------------------------
While it's good to save space, I'm at the moment not convinced that
taking a de-route via an URL is a good idea to begin with.

The main problem is trust. If you scan a QR code from a foreign phone,
you trust that that phone is owned by the one you want to send money to.
By adding the HTTP request that trust is voided.

As soon as there is a BIP70 implementation, I will begin playing with
putting the payment request directly into the QR code.


On 09/25/2013 11:27 AM, Mike Hearn wrote:




-------------------------------------
Yeah, if anyone wants to make the letter more digestable please do propose
an alternative, although by this point it's probably not worth it as people
have already signed.

FWIW, Gregory is right that my original draft was much more brusque. The
pain in the packaging relationship travels both ways. I have in the past
wasted a lot of time due to bogus packaging applied by non-expert packagers
that broke things. In fact the project I was a part of adopted a policy of
automatically closing bug reports from people who were using distributor
packages (any distro) because the quality was so inconsistent and so many
subtle bugs were introduced.

If packagers hear upstreams cry about packaging a lot, I think you should
keep an open mind that some of them probably know what they're talking
about. We really shouldn't have to beg and cajole here. Saying "we have our
reasons and we want you to stop" should be enough.




On Wed, Jul 24, 2013 at 5:19 AM, Gregory Maxwell <gmaxwell@gmail.com> wrote:

-------------------------------------
Hi

I'd like to introduce MacWallet.
A tiny and integrated thin client wallet app based on bitcoinj.

Main focus of the app:
-> Small and integrated wallet app for Mac OSX.
-> Low memory and cpu footprint, can be run in background without pain
-> Use Mac OSX keychain as wallet store (by default encrypted with your login credentials)
-> Simple UI. Use status menu (a.k.a global menu) as main UI entry point

Currently, MacWallet app is in early development stage.

Screenshots:
https://github.com/MacWallet/MacWallet/blob/master/SCREENSHOTS.md

Check the bitcointalk post:
https://bitcointalk.org/index.php?topic=307200.0

Github:
https://github.com/MacWallet/MacWallet

</jonas>
-------------------------------------
Can this be combined with the ideas on deterministic signing to show  
matching signatures with OpenSSL's implementation?

Not sure if that's worth much, since we would just be testing needles in a  
very large haystack, but better than nothing?

On Wed, 09 Oct 2013 20:50:30 -0700, Warren Togami Jr. <wtogami@gmail.com>  
wrote:

-------------------------------------
our estimates: ~8000
----- Original Message -----
From: Addy Yeow
Sent: 05/16/13 06:27 AM
To: bitcoingrant@gmx.com
Subject: Re: [Bitcoin-development] Modularizing Bitcoin

-------------------------------------
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 12/13/2013 09:26 AM, Mike Hearn wrote:

Or alternatively, the user-signed payment request without iteration
count is enclosed within a payr.com-signed envelope that contains the
iteration count. Having fields completely unsigned by anybody leaves
me a little nervous.

Mark
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.14 (GNU/Linux)
Comment: GPGTools - http://gpgtools.org
Comment: Using GnuPG with Thunderbird - http://www.enigmail.net/

iQIcBAEBAgAGBQJSq12pAAoJEAdzVfsmodw4MC4QAI9cjmQXz8AVawwr1htFc6b+
DVAAs1Y4hzbChPeeJCmy13m8a/BuXqc6G0WEWGSzIIa1or3IXCd01JQ2a5waD0IC
uOjlIMD0tTT7yxwxRjxPc2df82s82traGJC2caOMYjrN4T5VPtj7erB2poNyvOF+
p0lmj+duxUZ8IoyDaih5mgNKzIVujfX7o3lPoOMDdIi6Q1LF9SZ9XbUAxHCpCLfw
ieqVIm8zqtH0NprZ7/JLbqstl1iq5jCPKbORc+9qQWESZH1hFAeS29/ptjnRR8y6
HqrpDP236vSlrLDW4dLcW9UiQP42tSTwrLCgud08VqeKapSlMX8fjukLyNlTD7h5
GtPHEo1/j+LmpMfwsXA2OotUIVQBeFfEoi7PwV/Jd+SRVqC6zCTPky1lfg0P7JXA
7qD9m3u/Ey0+nk888zzff8N7AfBe7GaqFuUByXIyHh6dkcr0xUHBU4afiadFpNhg
8dTvmP4yqY0g05uz/Cq/ZqrSb5y/yPqsysuruAjWG2GT0M8rFM9oYepVHpUJr01K
QOHY6qSoqyX/KDCkZgpTMZFDq9gvyPyMFuCQbdecNcCeMPV5kiwPyqqH4rHliJ8I
gsXW44re5GfdL90nCOTboYFf2CFEn+66zyJ5vBskKSyDRDcU3t5YyCtrDzXdtJMu
MjVeMFRluY700zLBajw0
=+MjP
-----END PGP SIGNATURE-----


-------------------------------------
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On Wed, Apr 17, 2013 at 9:48 AM, Mike Hearn <mike@plan99.net> wrote:

Please don't say Gavin agrees with you. This reminds me of discussing
security in the early days of the internet when the general assumption
that everyone played nice was still correct.

We're seeing huge, expensive, DoS attacks against mining pools,
exchanges, information sites, stores etc. Bitcoin has enemies. Peter
Todd is 100% correct, tx replacement is another form of zero
confirmation transaction and all that has to happen is some subset of
mining power start doing replace by tx fee for it to have no security
while with your proposed implementation opening up a DoS attack
vector.

You also see the DoS attack vector as unimportant and suggest to
handle it as a prioritization problem. "real world experience
indicates that people don't pointlessly mount attacks over and over
again if there's nothing to be gained by doing so." <- of course there
is something to be gained, shutting down a service dependent on tx
replacement, as seen by all the DoS attacks we are seeing. If I were
deciding if my service should use tx replacement and I understood that
it could be trivially shut down, I sure wouldn't be happy I could
"just warn users not to take advantage of the feature whilst the flood
is in progress"

Gavin do you actually agree with Mike on this stuff like he implies?
Because if you do, I think people should know. Myself I wouldn't want
to be contributing to your salary as a foundation member if you don't
take Bitcoin security seriously.


The rapidly-adjusted payments stuff on the Contracts page of the wiki
is broken in multiple ways:

1. (known) Requires DoS vulnerable infrastructure.
2. (known) TX mutability
3. (unknown?) Just doesn't work. Step 5 is to check that T2 is signed
correctly by the access point, and if so, sign T1 and T2. But the
signature of T2 includes the txid of T1 and that isn't known until T1
is fully signed.

That #3 has not been noticed before shows that for all this hot air
no-one has ever bothered making an implementation of the idea. So
Mike, why are you happy to make testnet vulnerable to an unusually
easy DoS attack for an idea you haven't even tried on your own private
testnet with replacement enabled?


Anyway, with Peter Todd's much saner tx-replacement-by-fee the
following can be done:

1. Create a new public key PK1

2. Request a public key PK2 from the access point.

2. Create TX1 with two inputs and two outputs. Both parties sign it
and broadcast it.

access point input -> 2 PK1 PK2 checkmultisig, value = input #1 - fee
you input -> 2 PK1 PK2 checkmultisig, value == input #2 - fee

3. Create TX2.

TX1 #1 -> pay to access point PK2
TX1 #2 -> pay to yourself PK1 (change)

Set TX2 nLockTime to some time in the future.

4. Set the initial value's of TX2 out #1 and out #2 to the value the
access point and you committed in TX1. Both parties sign with
SIGHASH_SINGLE. (which means both parties are signing for both inputs)

5. Update TX2 as required and sign both inputs. The access point
doesn't need to sign TX2 or give the updated copy of TX2 to the other
party. The TX is not broadcast when updated (like the earlier contract
proposal) although doing so harms no-one.

When the session ends with both parties online, do the following:

1. You sign a version of TX2 with the final output values and nLockTime=0

2. If the final output values are acceptable to the access point, they
sign the other half of the 2-of-2 inputs and broadcast. (with whatever
fees required)

If the buyer quits the session abruptly:

1. Access point signs the last (most funds) version of TX2 given to
them, waits until the nLockTime expires, and broadcasts. This also
gets their TX1 input back.

If the access point quits abruptly they can do the above when they go
back online. The buyer has the first, signed, version of TX2 and at
worst can broadcast it eventually to get their deposit back.

Attacks:

After TX1 is signed and broadcast both parties are in on the contract
together, so the funds can't move without the consent of the other.
Both parties can block the movement of the other's deposit, but they
lose their deposit too. With tx mutability there is a small window of
time for a technical mistake, but that should be very, very rare.

You can broadcast an earlier version of the transaction where you pay
less than you were supposed too. However if you do this, the access
point can broadcast a new version of the transaction, splicing
together your signature on the correct output value, with your
signature on an earlier version of the access point's output, thus
paying miners a higher fee than the transaction you broadcast.
Rational miners will chose the latter version rather than your one.
This bidding process can continue until you are out the full amount
you were supposed to pay, with the whole payment going to fees, so why
bother? With nLockTime you don't have a better chance of mining the
transaction than any other miner.

I apologize if the above has already been discussed. I only looked at
the wiki and source code and don't waste too much time reading the
endless bitcointalk forums. The wiki should be updated with these
ideas as they are developed by people and vetted.


Strict replacement by fee should be written so it can be tested
properly and people in the Bitcoin ecosystem use proper security
practices with regard to unconfirmed transactions. I'm willing to
pledge $500USD to anyone who implements it. That is write the core
functionality that does replacement by fee, and a simple 'undo' RPC
command. I would do it myself but my programming is rusty.
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJRb4vZAAoJEEWCsU4mNhiPRNoH/jGcGw2NBUcIh0/HT70nnwU+
deaXcdYp9RhDlSf0VGvPwwEAnjWBFc+pYVC+vtL4XEvWR+5PC7FcOrRrv/+sTDPs
YwPkCIwvXJizFe5pAhXOde4EdibXU0WXTLonMNUeZkwhxUfrczURm2tgmJlNE7nA
3PBun4c4r7EcdRHuh9SiK0C4RgB5w63t/qyFVUfqwhyKYiS55K/2t2mVLLxcPWkY
8nxlYlese5eZZJBTfiePtPOqTd43DHOkN+4Iu5XXQIH7v2QHf50DMqgI3iVLVe08
c2i9GutwX+2MevSMe/S57952BCjBq4zF0nBpaAfIFCVHDDZ6bDbgA7fUjDtLVds=
=1Tc0
-----END PGP SIGNATURE-----


-------------------------------------
I'm working on a project that requires users to exchange public keys (for
multisig transactions).

It seems that hex encoding is usually used to display public keys (i.e. in
bitaddress and brainwallet), which results in longer strings and lacks the
4-bytes verification.

A standard way to encode public keys as base58-check addresses would make
it easier and safer to display and exchange public keys. All that is really
needed is deciding on a prefix byte.

Perhaps we can use 0x37/0x38, which results in the letter P (for "Public")?
It seems like those bytes aren't used for anything yet.

Thanks,
Nadav
-------------------------------------
You are ignoring the gambler's ruin. We do not operate on an infinite 
timeline.  If you find a big pool willing to try this, please give me 
enough advance warning to get my popcorn ready.

Peter Todd wrote:

-------------------------------------
In the design of Bitcoin mining serves two fundemental purposes:
proof-of-publication and order consensus.  Bitcoin's design entangles
these fundemental purposes with other goals, such as validation and
initial coin distribution. This leads to a design that is fundementally
unscalable, albeit effective on a small scale. Here we show how these
purposes do not need to be entangled together, and how by disentangling
them we can achieve better scalability and validation of the system as a
whole.

Let's first look at what role each of those purposes plays:

* Proof-of-publication

The fundemental problem Bitcoin solves is the double-spend problem.
Alice has some Bitcoins, and she wants to give them to Bob. She does
this by signing a digital message, a transaction, authorizing her coins
to be assigned to Bob. However, Bob has no way of knowing if Alice has
signed a conflicting digital message assigning her coins to Charlie
instead.

Bitcoin solves this problem by providing a way for Alice and Bob to
agree on a common place where *all* transactions will be published, the
blockchain. Because the definition of a valid transaction is that it has
been published in the blockchain, Bob can examine the contents of it,
and be confident that no conflicting transaction exists.


* Order consensus

Due to the constraints of physics no decentralized system can provide
instantaneous and reliable proof of publication; for a non-ideal
proof-of-publication system to be useful to solve the double-spend
problem we need to come to a consensus about the order in which data was
published. Once an order has been established, subsequent
double-spending transactions can be declared invalid.

Note that time itself isn't directly required, only the order of
transactions needs to be agreed upon.


* Why validation is an optional optimization

Given only proof-of-publication, and a consensus on the order of
transactions, can we make a succesful crypto-coin system? Surprisingly,
the answere is yes!

Suppose the rules of Bitcoin allowed blocks to contain invalid
transactions, in fact, suppose miners did no verification what-so-ever
of the contents of the blocks they mined. Could Bob still be confident
in the coins he received? Absolutely. There is consensus that the
transaction sending coins to Bob's came first and all prior transactions
can be verified as valid by checking the entire blockchain. In Bitcoin
all full nodes do this and Bitcoin could succesfully operate on that
model.

What can't be supported in this model is SPV clients: the existance of a
transaction in a block tells you nothing about its validity, so no
compact proof can be made.

Real-world examples of this issue can be found in the parasitic
consensus system Mastercoin, and to a lesser extent Colored Coins: the
former uses Bitcoin as a proof-of-publication, applying it's own
independent set of rules to that published data. The latter tracks the
transfer of assets in a way that takes advantage of the Bitcoin
validation rules, but any given txout can only be proven to represent a
particular asset with a full chain of transfers back to the asset
genesis. It's notable that proponents of colored coins have proposed
that rules to validate colored coins be added to Bitcoin to make such
lengthy proofs not required.(1)


* What is the minimum domain for anti-double-spend proof-of-publication?

Answer: a single txout.

So what do we mean by "domain" here? In the existing Bitcoin system,
modulo validation, what Alice has proven to Bob is that an entire
transaction has been published. But that's not actually what Bob wants
to know: he only wants to be sure that no transaction inputs, that is
the CTxIn data structure containing a valid scriptSig and reference to a
previous output, have been published that spend outputs of the
transaction he is accepting from Alice. Put more simply, he doesn't care
where a double-spending transaction sends the money, he only cares that
it exists at all.

Suppose the blockchain consisted of blocks that only contained
information on the transaction outputs spent by that block; essentially
a block is a list of CTxIn's. We also, add a third field to the existing
CTxIn structure, hashTx, which commits to the rest of the transaction
spending that txout.

If we sort the CTxIn's in each block by the hash of the *transaction
output being spent* and commit to them with a merkle tree, Bob can now
determine if Alice's transaction is valid by checking the blockchain for
blocks that contain a conflicting spend of any of the inputs to that
transaction. For each block the proof that the block does not contain a
given spend is log2(n) in size.

Put another way, Bob needs proof that some data, a valid CTxIn spending
some CTxOut, has never been published before. He only cares about that
particular CTxOut, so the "publication domain" he is interested in is
that single CTxOut. (note that we are considering a CTxIn as valid if
its scriptSig satisfies the prevout's scriptPubKey; the rest of the
transaction may be invalid for other reasons)

Conversely a transaction is only considered to be valid if all CTxIn's
in that transaction have been succesfully committed to the blockchain
proper; there must be proof that every CTxIn has been published.

Note the parallels to the authors TXO commitments proposal: where TXO
commitments commit to the outputs of every transaction in each block,
here we are committing to the inputs of all transactions.


* Transaction validation

Miners still are doing almost no validation in this scheme, other than
the fact that a block is only valid if the data in it follows some
order. Bob still needs to examine the chain of of all transactions to
determine if Alice's payment was valid. However, the information he
needs to do this is greatly diminished: log(n) * m per txout in that
history, with n as the average number of spends in a block, and m the
number of blocks each txout was in existance for.

Of course, a practical implementation of this concept will have to rely
heavily on direct transfer of proof data from payor to payee.


** Privacy

The increased validation effort required on the part of Bob has an
important privacy advantage: whole transactions need never appear in the
blockchain at all. By incorporating a simple nonce into every
transaction blinding the miners have no way of linking CTxIn's to
CTxOut's. This achieves the end goal of Adam Back's blind symmetric
commitments(3) but by leaving data out of the blockchain entirely rather
than blinding it.


* The incentive to share blockchain data

What is the incentive for miners have in the Bitcoin system to share
their blocks? Why not just share the block header? Of course, the
incentive is that unless they share their block data, all other miners
in the system won't build upon their blocks because they have no idea if
they are valid or not.

But here there is no such thing as an invalid block! Blocks are just
arbitrary data with no specific meaning; whether or not the data is
valid in some sense is of no importance to the miner.

We can re-introduce this incentive by using a proof-of-work scheme that
has the requirement of posession of blockchain data. For instance we
could make the underlying computation be simply H(header + all previous
blocks) - without the entire blockchain you would be unable to mine, or
even validate the work done.

Of course this is impractical for a number of reasons. But it's
important to recognize that this simple scheme doesn't make any
compromises about the continual availability of blockchain data, and
thus the ability for users to validate history. Any lesser scheme will
be a trade-off between that guarantee and other objectives.


** Full TxIn set commitments

Since we have to require miners to posess blockchain data, we might as
well make a simple optimization: rather than commit to the CTxIn's in a
single block, commit to multiple blocks.

First, let's require that every CTxIn present in a block be have a valid
scriptSig for the corresponding scriptPubKey. To do this we need for
CTxIn's to commit to the H(txout) they are spending, and include the
CTxOut itself alongside the CTxIn in the block. Our hash commitments are
now chained as follows:

    CTxIn -> CTxOut -> <merkle path> -> CTransaction -> <merkle path> -> CTxIn

Now that we have valid and invalid CTxIn's, we might as well state that
only one valid CTxIn is allowed for a given CTxOut per block; proof that
a transaction is valid now doesn't have to take into account the problem
of an *invalid* CTxIn that you need to prove is invalid and thus can be
ignored. This validation is stateless, requiring only local data, and
still provides for strong privacy.(a) A fraud proof in this scheme is
simply the CTxIn and CTxOut and merkle path, and the code required to
evaluate it is the same code required to evaluate the data in a block.

a) Remember the mention of a per transaction nonce? It can be used
   between the CTxOut and the rest of the CTransaction so that even if
   every CTxIn and CTxOut is known, the actual transactions can't be
   derived.

Now that we have a definition of a valid CTxIn, we can naturally extend
this to define the set of all valid *oldest* CTxIn's. That is for any
given CTxOut, we include the first valid CTxIn found in any block in
this set. This is analogous to the concept of the UTXO set, except that
items can only ever be added to the TxIn set.

As with UTXO commitments we can commit to the state of the TxIn set
using a merkelized radix tree whose tip is committed to by the block
header.

Of course because a block can manipulate the contents of this set in an
invalid way, we've strongly reintroduced the notion of an invalid block,
we've re-introduced the incentive to share blockchain data, and we've
re-introduced the requirement to have the full set of blockchain data to
mine.


*** Mining with incomplete blockchain data

Or have we? This requirement isn't particularly strong as all: if other
miners are usually honest we'll get away with just trusting them to mine
only valid blocks. Meanwhile the TxIn set in merkelized radix tree form
can have items added to it with only the subset of internal nodes
modified by your additions. A miner can easily produce blocks only
containing CTxIn's spending CTxOuts from a subset of the possible
values. Multiple such miners can even co-operate to produce blocks, with
each handling a specific subset, as multiple radix trees are easily
composed.(b)

Note that Bitcoin is even worse in this regard: you don't need any
previous blockchain data at all to create a new block. For instance the
authors proof-of-tx-propagation concept(5) has the serious flaw that
unscrupulous miners can use the proof that other miners are mining
certain transactions as a way to avoid doing any validation themselves.


*** The deletion problem

What happens if a copy of some of the txin set can't be found? With
Bitcoin this isn't an issue in theory - the miners are supposed to never
extend blocks they haven't verified in full and they are supposed to
distribute blocks freely. Not necessarily a perfect assumption(6) but it
mostly holds true.

With any type of sharded blockchain, it is easy to see that assumption
may not hold true. Now rather than a 51% attack in terms of total
hashing power, you could have a "local" attack on some portion of the
commitment set. On the other hand, with the right set of incentives, the
existance of such an attack can be made to imply actual consent by those
owning the coins involved, e.g. through proof-of-stake combined with the
proof-of-work. (perhaps better described as proof-of-consent with
proof-of-work)


1) OP_CHECKCOLORVERIFY: soft-fork for native color coin support,
   https://bitcointalk.org/index.php?topic=253385.0,
   jl2012

2) Merkle tree of open transactions for lite mode?
   https://bitcointalk.org/index.php?topic=21995.0,
   Gregory Maxwell

3) Ultimate blockchain compression w/ trust-free lite nodes
   https://bitcointalk.org/index.php?topic=88208.0
   Alan C. Reiner

4) blind symmetric commitment for stronger byzantine voting resilience,
   http://www.mail-archive.com/bitcoin-development@lists.sourceforge.net/msg02184.html,
   Adam Back

5) Near-block broadcasts for proof of tx propagation,
   http://www.mail-archive.com/bitcoin-development@lists.sourceforge.net/msg02868.html,
   Peter Todd

6) Perverse incentives to withhold blocks
   http://www.mail-archive.com/bitcoin-development@lists.sourceforge.net/msg03200.html
   Peter Todd

-- 
'peter'[:-1]@petertodd.org
0000000000000009f9403506c42540415272f68232a986e8f529d994bc917c1e
-------------------------------------
On Saturday, March 23, 2013 6:21:32 PM Jeff Garzik wrote:

Transaction selection and everything else bitcoind does, is irrelevant to BIP 
34. It is incompatible with getblocktemplate for coinbase-creating software to 
produce v2 blocks without implementing BIP 34 themselves, even if the upstream 
GBT server specifies it.


-------------------------------------
On Tue, Dec 3, 2013 at 11:59 AM, DÃ¢niel Fraga <fragabr@gmail.com> wrote:

I actually think this is part of a larger and somewhat subtle UX problem
with bitcoin-qt â€“ and, to be totally fair, a whole bunch of other wallet
programs.

I think the issue is that bitcoin-qt should have a document-oriented
approach to wallets. It should make you select a location to store your
wallet, just like a word processor, when you create a new wallet. It could
open the most recent wallet when you run the program, or allow you to open
a wallet by double-clicking it directly in the OS.

I think this would solve this particular issue nicely, just double click
the wallet file. Also, the menu item can just be labeled "Open Wallet". It
might also prevent those kind of heartbreaking posts which read something
like, "I just wiped my hard drive and reinstalled bitcoin-qt, where are my
coins?" People don't have the expectation that if they get Word on a new PC
that their documents will somehow magically be available, I think in part
because Word forces you to deal with the documents and the save location
yourself.

I know that this would bring with it a host of other considerations: Can
multiple wallets be open at the same time? What happens if a wallet file is
moved while it's open? What happens when there are two versions of the same
wallet? Will users understand that they need to backup their wallets
periodically?

But, I think it would be a big enough usability win that it should be
considered. Also, if at the same time bitcoin-qt were to adopt BIP 32 style
deterministically derived private keys from a single seed, a bunch of the
issues above would also go away: There are never two versions of the same
wallet, since they're the same seed, and periodic backups are unnecessary.
-------------------------------------
On Tue, Oct 1, 2013 at 6:58 PM, slush <slush@centrum.cz> wrote:


getinfo does a bunch of stuff; with 0.9 you will be able to use
getbestblockhash instead.




If you just want to see if bitcoind is responding to RPC requests, then
'help getinfo' would do the trick without acquiring any locks.

RE: running into the maximum-of-4-keepalive-requests : simple workaround is
to run with -rpcthreads=11 (or however many keepalive connections you need
to support).  I agree that the rpc code should be smarter; making the last
rpc thread ignore keepalive and always disconnecting should be a fairly
simple patch, and "patches welcome."

-- 
--
Gavin Andresen
-------------------------------------
Currently the most compact way (proof-size) to sacrifice Bitcoins that
does not involve making them unspendable is to create a anyone-can-spend
output as the last txout in the coinbase of a block:

scriptPubKey: <data> OP_TRUE

The proof is then the SHA256 midstate, the txout, and the merkle path to
the block header. However this mechanism needs miner support, and it is
not possible to pay for such a sacrifice securely, or create an
assurance contract to create one.

A anyone-can-spend in a regular txout is another option, but there is no
way to prevent a miner from including a transaction spending that txout
in the same block. Once that happens, there is no way to prove the miner
didn't create both, thus invalidating the sacrifice. The announce-commit
protocol solves that problem, but at the cost of a much larger proof,
especially if multiple parties want to get together to pay the cost of
the sacrifice. (the proof must include the entire tx used to make the
sacrifice)

However if we add a rule where txouts ending in OP_TRUE are unspendable
for 100 blocks, similar to coinbases, we fix these problems. The rule
can be done as a soft-fork with 95% support in the same way the
blockheight rule was implemented. Along with that change
anyone-can-spend outputs should be make IsStandard() so they will be
relayed.

The alternative is sacrifices to unspendable outputs, which is very
undesirable compared to sending the money to miners to further
strengthen the security of the network.

We should always make it easy for people to write code that does what is
best for Bitcoin.

-- 
'peter'[:-1]@petertodd.org
00000000000000ce3427502ee6a254fed27e1cd21a656a335cd2ada79b7b5293
-------------------------------------
JavaScript is turing complete so of course it can be done. The real
question you're asking is, can it be done in a web app? I think the answer
is I think "no" because web apps aren't allowed to make raw TCP socket
connections.

Now there may be a way around that by using browser-specific things like
extensions or "installable apps" which give your code greater access
permissions. This approach means you essentially use Chrome as your app
platform instead of a JVM, the assumption presumably being that more users
have Chrome than a JVM. The flip side is that users who don't would
probably balk at the idea of installing an entire browser in order to run a
wallet app, whereas a JVM can be bundled and the resulting app acts like
any other. I don't know of a convenient way to "statically link" Chrome
into a regular-looking application.

I personally wouldn't find such a design compelling. Whilst Java isn't
exactly a great language, JavaScript is significantly worse in virtually
all aspects. I don't understand why anyone would want to use JavaScript
outside the browser - you get less safety, less performance, fewer
features, less mature tools and so on. If the end result is an installable
app like any other, all you did is cripple yourself vs the competition
that's using languages/platforms designed for it.



On Fri, Aug 9, 2013 at 1:32 PM, Wendell <w@grabhive.com> wrote:

-------------------------------------
Thanks guys, it sounds great.
Testing the JSON-RPC is/was not the main goal, just an interface for testing.
I didn't know that the bitcoinj implementation is getting close to a
full implementation..it sounds interesting, as it's much easier to
understand and work with. I'll look at the test cases.

Thanks very much,
Adam


On Fri, Apr 5, 2013 at 12:42 PM, Gregory Maxwell <gmaxwell@gmail.com> wrote:


-------------------------------------
On Sat, Mar 23, 2013 at 1:43 PM, Luke-Jr <luke@dashjr.org> wrote:

Sure, that is largely the pool server layer.  But it is misleading to
imply that bitcoind is nowhere in the stack.

-- 
Jeff Garzik
exMULTI, Inc.
jgarzik@exmulti.com


-------------------------------------
Mike Hearn had a rather cool idea about watermarking images with Bitcoin addresses in order to facilitate auto-magically linking social networking profiles: apparently even without API access, reasonably large user images are available publicly via the major services (Facebook, Twitter).

Since this process would necessarily be somewhat manual and would of course be "undone" anytime the user changed his/her profile image, it is probably not a solution for everyone. But it seems that this could be a helpful way to at least _begin_ organizing Bitcoin around people and organizations in a way that is broadly familiar.

I haven't been able to get this to work myself, but Blockchain.info seems to offer sending 'coin via Facebook:
https://blockchain.info/wallet/send-via

There is also the very cute Bitcoins With Friends:
https://bitcoinswithfriends.com/

Most of the other apps that I have seen at one point or another have vanished. I recall reading that Facebook was not particularly friendly to them, hence the present interest in more subversive (?) ways of making those connections.

Again, I am not 100% sure that this is the correct place for it, but I'm opening this thread to other such ideas in case anyone else wants to discuss it. Our motivation is making Bitcoin easier to use, and we suspect that even imperfect social network support will move us closer to that goal.

-wendell

grabhive.com | twitter.com/grabhive | gpg: 6C0C9411



-------------------------------------
on 07/09/2013 06:56 AM Jim said the following:

You could host your downloads on sourceforge and achieve virtually
unlimited capacity.


-------------------------------------

We're planning to support payment protocol in Trezor as well, if it counts.
I think it's a missing piece in absolute security of hardware wallets.

slush
-------------------------------------
Interesting. I think the original BitDNS discussion was more interesting
that what currently is happening with namecoin, see
https://bitcointalk.org/index.php?topic=1790.0

Satoshi said there: "1) IP records don't need to be in the chain, just do
registrar function not DNS.  And CA problem solved, neat."

Besides, ICANN is currently selling out the global public namespace - not
that anybody really cares about such measly topics as the ownership of
global namespaces. And so some guy on the Cayman Islands is now the largest
holder of TLD's.

On Tue, Dec 31, 2013 at 2:48 PM, Gregory Maxwell <gmaxwell@gmail.com> wrote:

-------------------------------------
On Thu, Jun 27, 2013 at 1:10 PM, Jim <jim618@fastmail.co.uk> wrote:

This is definitely a great discussion to have.  Here are some initial,
unprioritized thoughts.  As an engineer, there is never a clear
answer, but a balance of costs and benefits.

Arguments in favor of moving away from Bitcoin-Qt/bitcoind for wallet services:
* Bitcoin-Qt is admittedly a very simple wallet.  I see it's core
strengths more as a "P2P router" for the public blockchain data.
* Wallet feature innovation moves more slowly than
Armory/bitcoinj/blockchain.info.
* Requires the full blockchain, which is resource-intensive versus SPV.

Arguments in favor of retaining Bitcoin-Qt/bitcoind default:
* More field experience, code review and testing on desktop than others
* Very real possibility of an overall net reduction of full nodes on P2P network

Arguments in favor of multibit default:
* Good user interface, perhaps more friendly for entry level users as
you describe
* Based on bitcoinj, which has field experience and a very large
installed base thanks to Bitcoin Wallet/Schildbach

Arguments against multibit default:
* Less testing, field experience on desktop

I'm sure others can come up with a few more.

-- 
Jeff Garzik
Senior Software Engineer and open source evangelist
BitPay, Inc.      https://bitpay.com/


-------------------------------------
On Tue, Dec 03, 2013 at 12:29:03PM +0100, Mike Hearn wrote:

Person-to-person payments are an *excellent* argument for keeping fees
visible to end-users; people will pay other people commonly in Bitcoin
and they will be very confused if those transactions act weirdly
differently than payments to merchants.


NAK on unconfirmed overrides - if something goes wrong even by accident
it just makes fixing the problem much harder and less intuitive.

-- 
'peter'[:-1]@petertodd.org
000000000000000f9102d27cfd61ea9e8bb324593593ca3ce6ba53153ff251b3
-------------------------------------
  Hello, All!

I'm trying to setup pushpool + bitcoind.  However, when I connect to
pushpool with cpuminer I receive this error:

    [2013-04-21 12:47:47] json_rpc_call failed, retry after 30 seconds
    [2013-04-21 12:48:17] JSON-RPC call failed: {
       "code": -2,
       "message": "upstream RPC error"
    }
    [2013-04-21 12:48:17] json_rpc_call failed, retry after 30 seconds



I see this error in the **pushpool server log**:
    root@ip-10-28-79-184:/usr/local/sbin# ./pushpoold --debug=2 --stderr --
 foreground --config=/usr/local/sbin/server.json
    [2013-04-21 13:26:28.319949] Debug output enabled
    [2013-04-21 13:26:28.333064] Forcing local hostname to localhost
    [2013-04-21 13:26:28.456350] Listening on host :: port 8336
    [2013-04-21 13:26:28.456477] Listening on host 10.28.79.184 port 8334
    [2013-04-21 13:26:28.485367] initialized
    JSON protocol request:
    {"method": "getwork", "params": [], "id":1}

    About to connect() to 127.0.0.1 port 8332 (#0)
       Trying 127.0.0.1... * TCP_NODELAY set
     connected
     Connected to 127.0.0.1 (127.0.0.1) port 8332 (#0)
     Server auth using Basic with user 'username'
     POST / HTTP/1.1
    Authorization: Basic dXNlcm5hbWV2YXN5YTpwYXNzd29yZHZhc3lhMTQ=
    Host: 127.0.0.1:8332
    Accept: */*
    Accept-Encoding: deflate, gzip
    Content-type: application/json
    Content-Length: 45

     The requested URL returned error: 500
     Closing connection #0
    [2013-04-21 13:26:31.743119] HTTP request failed: The requested URL
returned error: 500



**bitcoind config:**

    testnet=0
    server=1
    rpcuser=username
    rpcpassword=password
    rpctimeout=30
    rpcallowip=*
    rpcport=8332
    rpcconnect=127.0.0.1
    gen=0
    keypool=256
    paytxfee=0.00




**pushpool config:**

    {
        "listen": [
            {
                "port": 8336
            },
            {
                "host" : "server_ip",
                "port" : 8334,
                "protocol" : "http-json"
            }
        ],
        "database": {
            "engine": "mysql",
            "host": "localhost",
            "port": 3306,
            "name": "bitcoin",
            "username": "mysql_username",
            "password": "mysql_password",
            "sharelog": true,
            "stmt.pwdb": "SELECT `password` FROM `pool_worker` WHERE
`username` = ?",
            "stmt.sharelog" :  "INSERT INTO shares (rem_host, username,
our_result, upstream_result, reason, solution) VALUES (?, ?, ?, ?, ?, ?)"
        },

    "pid": "/tmp/pushpool/pushpoold.pid",
    "forcehost": "localhost",
        "log.requests": "/tmp/pushpool/request.log",
        "log.shares": "/tmp/pushpool/shares.log",
        "auth.cred_cache.expire": 75,
        "rpc.url": "http:// 127.0.0.1:8332/",
        "rpc.user": "username",
        "rpc.pass": "password",
        "rpc.target.rewrite": true
    }



I have tried to change ports, and even rebooted the server,  nothing helps.
If you need pore information, i will show.
   Thanks.

-- 
 ,
  

            mailto: agsmorodin@gmail.com
-------------------------------------
On Sun, Dec 8, 2013 at 1:07 PM, Drak <drak@zikula.org> wrote:

Godaddy and many other CA's are verified from nothing other than a
http fetch, no email involved.

As I said, I'm willing to demonstrate if you have a domain.


You can, once you've obtained a certificate.


As I warned before, you're making my reconsider my position about the
downloads being SSL. If people are so convinced that SSL provides
protection it does not that even with an explanation and and an offer
to demonstrate then perhaps providing SSL will reduce people's
security.

... the _only_ reason I don't yet hold that position now is that I
know objectively that almost no one tests the signatures.

On Sun, Dec 8, 2013 at 1:11 PM, Drak <drak@zikula.org> wrote:

My understanding is that the domain is already controlled by more than
one person. You're not the first person to think of these things. :)


-------------------------------------
On Wed, May 15, 2013 at 07:45:34PM -0700, Gregory Maxwell wrote:

I believe the coin size and verification cost is linear not quadratic, but
maybe it depends on the parameter you're measuing in.  The coin size is
linear with the number of committed (uncompacted) spends.  You can view
reveals as committed compaction.  For efficiency a recipient of a committed
coin may as well compact and spend in one transaction so no new messages are
created.

Btw I believe if one were concerned about the committed coin size, I can see
a small tweak that would keep the size of the committed coins small eg
256-bit regardless of number of spends (no longer grows), and let the block
store the encrytped & MACed commitment.  Then compaction is no longer a
concern.  However I think that is SPV -> SPV client unfriendly.  (A full
client -> SPV client should still be workable as the full client could
alternatively send the client the MACed data and key, rather than have him
look at it from his block history.)  (Crypto sketch below).

However I am not sure multi-spend committed coin size is really a concern
because to the extent people hold long commitments without revealing to the
network for the long term, that is a bandwidth saving to the network.

Overall about privacy it would be typically temporary, though the peers have
the technical means to react and defend themselves by using longer committed
chains if dishonest mining is detected on a significant scale.


That was the seed idea.  The more aggressive "spend lots of times in
committed form" is just a technical threat that will keep dishonest mining
in check.  By definition the coin is already irrevocably spent before the
reveal (without the threat of having the dishonest miners endlessly redoing
their own deeply burried work).  The only person who could be punished by
policy by >50% dishonest miner (retroactively) is the recipient, not the
spender, and the punishment is very muted: all he can do is prevent coin
compaction.  If the committed coins are small, compact doesnt even hurt the
committed coin user, just network itself.  Therefore a dishonest miner is
wasting his time his dishonesty cant enforce his dishonest policy.

To store the commitments in the block chain replace:


with:

(blind-sender, auth-tag, encrypted-tx-commit)

	blind-sender = SHA1( SHA256( 1, pub ) )
	auth = HMAC-SHA256-128( K, encrypted-tx-commit )
	encrypted-tx-commit = AES( K, tx-commit )   (*)
	K = SHA-256( pub )

then a reveal is just to send the recipient the public key (32 bytes)
per hop, still linear but ~3x smaller.

I suggested fixed size committed coin spends, that also you can do but with
public key crypto needed probably, and so dropping to the verification
efficiency of standard transactions.  Sketch 2:

(blind-sender, auth-tag, encrypted-tx-commit)

(pub key P = xG, G = base point)

	blind-sender = cP (public key EC multiplied by constant c)
	sig = ECDSA( cx, encrypted-tx-commit )
	encrypted-tx-commit = AES( K, tx-commit )
	K = random

as K is random, knowledge of P if stored unencrypted does not allow
committed spend-to-junk.  To reveal to a recipient just send them P and K at
each hop.  (Same K each time, anyone on the committed coin spend chain can
already chose to reveal at any time so no loss of security.)

You dont need to verify a second signature inside the tx-commit because you
already signed the encrypted-tx which binds to it (encryption with out MAC
is malleable but you cant change it at all without invalidating the
encryption).  Just need to check the input tx in the tx-commit has P as its
recipient.  P does not even need to go into tx-commit as its already bound
by cP and signature security (cant create a signature with someone elses
key).  So I think the commited coins of this form are the same size and
verification cost for the network.  And small and fixed size to spend
offline.  (32+32=64 bytes fixed).

Adam

(*) You should not as a principle re-use keys across algorithms, I omitted a
second key for simplicity.  Really K1 = SHA256( 1||pub ), K2 = SHA256(
2||pub ) encrypted-tx-commit = AES( K1, tx-commit ), auth = HMAC( K2,
encrypted-tx-committ ).  Or more simply a combined authenticated mode like
CCM or GCM and a single key managed by the mode.


-------------------------------------
Agreed, this looks good to me.
-------------------------------------
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256


Peter claims on IRC that he is writing a paper of some kind on this topic. I
suggest he submit it to that crypto-currency thing the foundation is
sponsoring. Given the Nov 24th deadline, I also suggest at least making part of
it public ASAP so some peer review can be done. It would be a shame for a
simple math error to cause embarassment later.



Are you sure about that? You are assuming linearity where none may exist.



Are those stats accurate? Have any pool operators at least confirmed that the
orphaned blocks that blockchain.info reports match their own records?

My gut feeling is to relay all orphaned blocks. We know that with a high
investment and sybil attack as blockchain.info has done you can have better
awareness of orphaned blocks than someone without those resources. If having
that awareness is ever a profitable thing we have both created an incentive to
sybil attack the network and we have linked profitability to high up-front
capital investments.

On those grounds alone I will argue that we should relay all orphans to even
the playing field. If there is a circumstance where we do not want the attacker
to have that knowledge we have failed anyway, as blockchain.info's sybil attack
on the network clearly shows.



With relayed orphans you could even have P2Pool enforce an optimal tx inclusion
policy based on a statistical model by including proof of those orphans into
the P2Pool share chain. P2Pool needs to take fees into account soon, but simply
asking for blocks with the highest total fees or even highest fee/kb appears to
be incomplete according to what your and Peter's analysis is suggesting.

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBCAAGBQJSg9pfAAoJEEWCsU4mNhiP5mcH/jKd2Rpl9gEJ7WhTndS5gYJ9
Ep151NyD/iKpAA4E/d9QVYalo8595LCqnrXnV6wuvuiifB6EJD5WBJq3MAMyaJLA
agl920ygY98slhDmFhnwlU9lkJVim5FoUkZgE7lQ5dr0MIhvoLQiF2Ywky49Izf0
IqL+nyW83AQweSalvktA+XGkDfGDV/EnJN7SdNqKDNtE7E9NeMl61NNOWNndsYy6
uT4PF2YB7rh8wGyHXMTC4Z192pfW4S4s60ZAflG/sTtWCcEwWi+5V/RIu0o5Hmog
RFpEPvc6d6ykdqtPfTRADMGkT2wC1yXsgeos9oFFVVuVSj8EqHb2db0B+psHRBk=
=76Qs
-----END PGP SIGNATURE-----


-------------------------------------
Woo, huzzah :-)

Now the BIP draft is available and we know it all hangs together, I'm
hoping to (re)start implementation work in bitcoinj in the next month or
two. I'm currently trying to figure out which is more important,
deterministic wallets or payment protocol, but I think right now the
payment protocol would be easier to do and would benefit more from a second
implementation. HD wallets have already been shown interoperable.

Comments on BIP 70:

   "PaymentRequest messages larger than 50,000 bytes should be rejected by
the merchant's server, to mitigate denial-of-service attacks."

Do you mean "users wallet" here?

You could note in the motivation section two more motivations:

1) That the protocol can be a foundation on which other features are built
2) That it is required to assist hardware wallets when there is a virus on
the system

Perhaps note in the BIP that the merchant should not assume the
merchant_data field is trustworthy - malicious buyers could rewrite it as
they see fit. Point out that a good way to use this is to serialize server
state, signed by a merchant-only key, in the same way one might use an HTTP
cookie.

   "PaymentDetails.payment_url must be secure against man-in-the-middle
attacks that might alter Payment.refund_to (if using HTTP, it must be
TLS-protected).

This says "must", but what should a client do here if the payment URL is
not HTTPS? I suggest weakening this to "should", as sometimes TLS is
redundant (e.g. if you're sending to a Tor hidden service).

The PaymentACK message contains a copy of Payment, but the BIP doesn't say
what to do with it. I assume this means a client is free to ignore it and
rely on TCP state to figure out the payment/ack connection instead? It may
be worth noting that explicitly.

In the certificates section, you could observe that "validation" means
"verification that it correctly chains to a trusted root authority, where
trusted roots may be obtained from the operating system. If there is no
operating system, the Mozilla root store is recommended".

All the rest LGTM.
[edit<https://en.bitcoin.it/w/index.php?title=BIP_0070&action=edit&section=7>
]


On Wed, Jul 31, 2013 at 8:28 AM, Gavin Andresen <gavinandresen@gmail.com>wrote:

-------------------------------------
On Sun, Nov 17, 2013 at 12:49:04AM +0100, Pavol Rusnak wrote:

No, this question of mine was regardless of any cryptomagic or neat
tricks like Thomas' suggestion. It has nothing do with auditing the
entropy. It was just a backup question.

I recently had an experience where I thought coins were lost because the
secrets I had didn't match the public keys that I thought they'd match.
secrets, before sending any coins to the pubkeys in the wallet. I will
never again generate a wallet, backup the secrets, and hope the secrets
indeed match the pubkeys.. without testing that. My question was how
Trezor allows me to verify my backup.

All this makes me think if having one device generating and displaying
the secret, and making a backing from the display, is the right way to
go. Since you would need a second device to verify your backup is sane,
you could have two devices to start with. One is your hardware wallet
and it only imports secrets (restores backups). The other is an entropy
generator and it only generates secrets.

Best regards,
Timo

p.s. The question about auditing entropy would only apply to the generator,
not the wallet. Is it yet documented how Trezor proves that external
entropy was used? 

-- 
Timo Hanke
PGP 1EFF 69BC 6FB7 8744 14DB  631D 1BB5 D6E3 AB96 7DA8


-------------------------------------
For a long time the only block explorer for testnet has been the original
blockexplorer.com, which is unfortunately often broken / behind / slow and
not really maintained any more.

There is now a new one, here:

https://www.biteasy.com/testnet/blocks

There's also a REST/JSON API for it.

Please note one curiosity of this block explorer is that the coinbase tx
doesn't necessarily come first in the listing (it's sorted by "time
received", see).

Other interesting thing to note: this site is built using bitcoinj. The
author can be contacted on IRC sometimes using the nick damethos.
-------------------------------------
On Mon, Jul 29, 2013 at 1:17 AM, Luke-Jr <luke@dashjr.org> wrote:

Indeed.  Current designs are all based around pattern matching a
script template.  Satoshi even described lightweight clients as
needing no script engine at all, only the ability to match patterns.

-- 
Jeff Garzik
Senior Software Engineer and open source evangelist
BitPay, Inc.      https://bitpay.com/


-------------------------------------
For tx reject, should there be a code for "unknown version"? That is,
tx.nVersion > bestKnownVersion == reject? In that case 0x40 would become
"non-standard transaction type". I think "unknown transaction type" is a
bit vague. Or do we want new tx messages to always be backwards compatible?

0x42 and 0x43 seems a bit similar to me. The sender knows what fee was paid
(presumably). If free transactions and fee-paying transactions end up
having a unified ranking applied, then distinguishing between them in the
reject message won't make much sense.

For block 0x11 again shall there be a separate code for "block is from the
future"? We don't want to lose the nVersion field to people just using it
for nonsense, so does it make sense to reject blocks that claim to be v2 or
v3?




On Tue, Oct 29, 2013 at 6:37 AM, Gavin Andresen <gavinandresen@gmail.com>wrote:

-------------------------------------

That's true, but we can extend the DNS seeding protocol a little bit - you
could query <current-chain-height>.dnsseed.whatever.com and the DNS server
then only returns nodes it knows matches your requirement.

This might complicate existing seeds a bit, and it's a bit of a hack, but
protocol-wise it's still possible. Of course if you want to add more
dimensions it gets uglier fast.
-------------------------------------
I'm not sure where you got the idea that Bitcoin-development was ideal for hiring scamcoin developers, but it's not. Most of the people on this list are smart enough to realize posts like this are dumb ideas backed by greedy "entrepreneurs" who don't understand the system they're trying to improve 99.9% of the time.


Evan Duffield <eduffield82@gmail.com> wrote:
-------------------------------------
On Sat, Feb 09, 2013 at 07:01:48PM +0000, Luke-Jr wrote:

It's not about technical differences, but about the different use or
purpose, which can result in different security demands. I argue that
DNS has a lower demand in this respect than payment ids have. So DNS
data can be in a chain with a hashrate lower than bitcoin's hashrate but
payment ids _for_ bitcoin have to be in a chain with equal hashrate.


Ok, true. This does the trick. If few miners merge-mine then the new
chain just becomes slower. But is this still an alt-chain? It is not
independently verifiable anymore, like the alt-chains described in the
wiki are. Instead, you need to refer to the bitcoin's chain to see if
the target is correct. Not sure if I got you right on this. But it seems
to be essentially a more efficient version of what I proposed, rather
than a true alt-chain.

I suppose you suggest to place the master header hash into the coinbase.
A drawback may be that it puts miners at a great advantage over regular
users. This could (but doesn't have to) become relevant depending on
your counter-measures against excessive alias registration. I think
Peter addressed this (below). 

On Fri, Feb 08, 2013 at 06:01:08AM -0500, Peter Todd wrote:

This was not intended to be a prototype and will certainly not be
maintained. It is a demo to be run on the testnet to get a feel of how
the user interface (RPC) and the "work flow" could look like, starting
from the creation of a certificate all the way to paying to a
customer-derived payment addresses (pay-to-contract) when the merchant's
base address is defined in the certificate. There's an appeal to be able
to issue
./bitcoind sendtoalias foo deadbeef 10
and being sure that 10 BTC go, e.g., to a unique P2SH multisig address
that is derived for order number 'deadbeef' from the two pubkeys that
foo defined in his certificate. And having the certificate verification
happen automatically in the background. The demo is in the reference
client a) to simulate this feel, b) because it was the fastest way to
code it. Apart from that, it could have just as well been separate, and
an UTXO query-RPC would certainly be nice.  

Another reason for this demo was the fun of devising a certificate that
can handle all this. 

BTW, I'm sure that some form of certificate handling will find its way
directly into the reference client. The user will want to trust only one
piece of software running on one piece of dedicated hardware. 

On Mon, Feb 11, 2013 at 06:21:03AM -0500, Peter Todd wrote:

What exactly is the problem, the "little-used"? Otherwise it's the same
as it is now, you pick up an interesting domain name on the street, type
it in, and start communicating with who you think it is, and maybe even
pay them. The EV that centralized PKI offers prevents only some attacks,
and may even create a false sense of security.


No. I outlined above why I think namecoin is unsuitable (but Luke's
suggestion for a new alt-chain may be). BTW, if you want to link aliases
of some "bitcoin PKI" and "domain names", they should not correspond
bijectively to each other. The "bitcoin alias" corresponds to a payment
base address, which I see as a more universal identifier than a domain
name. First, bitcoin alias foo can have several domains foo.com,
foo.co.uk, etc. but still only one "bitcoin certificate". This can be
achieved by either writing the domain names directly into the
certificate, or better, by having the "bitcoin certificate" sign an SSL
sub-certificate and tell your browser to ask bitcoind to verify it.
Second, a bitcoin alias can be meaningful without any domain names, e.g.
it can be a certificate for all vending machines of a certain seller,
with who you interact directly, say NFC. To summarize, I would either
not link bitcoin aliases with domain names, or put SSL certificates
"below" bitcoin certificates in the verification chain.

Also BTW, it is the beauty of the pay-to-contract principle that
authenticated communication is not even required. This means that if you
know you have the correct "bitcoin certificate" stored with your
bitcoind and you pay to it, then it doesn't matter if you ordered on a
wrong or fake website. The worst-case scenario is that you have to call
in via another channel and re-submit your order, but funds are never
lost.


Yes, I already read your discussing of sacrifice-methods after your
first reply and found it interesting.. The problem I see is to
dynamically (and automatically) adjust the minimum sacrifice amount. A
strict limit on the number of registrations like namecoin has is not
desirable. A constant sacrifice, as you mentioned earlier, is also
undesirable. A good measure could be the average transaction fee taken
over several blocks. Maybe the minimum sacrifice should be a constant
times that. 


Actually yes. They are also willing to do that to verify their payments,
so why not for the certificate? But true, this was the reason why I
thought of putting it in the UTXO. To enable some future dedicated
"hardware wallet" to keep only the UTXO and to verify against it. Where
would you store you alt-chain block header hashes? UTXO? 

BTW, suppose you avoid any squatting (there would certainly be ways to
do that). Then with my original proposal of one transaction per
registration you would grow the UTXO by O(n), n is the number of users.
Each user would create a small constant number of aliases. This number
will certainly be dwarfed by the number of unspend outputs that each
user keeps anyway as a result of their regular transactions. So it would
not present a problem for the UTXO. Actually, anything above the dust
threshold should not be a problem, or the system is misdesigned.  But of
course the alt-chain header hashes would only take O(1), much better.

Timo



-------------------------------------
Hi list,

Can someone explain why do we have 32-bit and 64-bit timestamp fields
instead of all being 64-bit?

https://en.bitcoin.it/wiki/Protocol_specification

Cheers,
Addy


-------------------------------------
The HTTP status code system seems to work well enough, and seems to give 
the best of both worlds.  A 3 digit numeric code that is 
machine-readable, and a freeform text note for humans.

The clever part about that system was in realizing that the numeric 
codes didn't need to account for every possible error. They just need to 
give the other node the most useful information, like "try that again 
later, I'm having a temporary problem" vs. "That is just plain wrong and 
it will still be wrong next time too, so don't bother to retry".

We can leave it to the humans to puzzle out the meaning of "403: values 
of txid gives rise to dom!"

Gavin wrote:



-------------------------------------
On Tue, Jul 23, 2013 at 6:26 PM, Luke-Jr <luke@dashjr.org> wrote:

The above is a key point, lukejr addressed it well "I think it is
likely all this additional work/delays will be considered unacceptable
to your library/security teams, thus using the bundled/embedded
LevelDB is probably the best solution."


To be clear, bitcoind/bitcoin-qt is only built on little endian machines
https://buildd.debian.org/status/package.php?p=bitcoin


The only current modification is to use system leveldb instead of the
packaged leveldb. (There is also a patch porting libmemenv.a to
several other architectures, but that is only used in test suites - so
it shouldn't pose a risk to users).


Ironically, debian (in general) doesn't trust upstream security
maintenance of third part libraries - that's why they typically get
dropped in favor of use system libraries.

In this case, upstream doesn't trust (rightfully) that some future
debian security team bug fix to a stable library won't be tested
properly against bitcoin, causing problems for users (since bitcoin
might expect buggy library behavior).


I'm not the original packager or maintainer - I just came across the
package in really bad shape and helped bring it to something
reasonable and have done the most recent uploads (since 0.8, I
believe). Since updated libraries could pose a security risk because
bitcoin may expect buggy behavior, I think that is a good argument for
debian to use the included library. However, I'm just a recent helper
- I still want to hear what people who have been doing this for longer
think.

~Scott


-------------------------------------
On Tue, Mar 12, 2013 at 2:10 AM, Mike Hearn <mike@plan99.net> wrote:

Locks are only mostly related to block size, once I heard what was
happening I was unsurprised the max sized test blocks hadn't triggered
it.

until nodes start dying en-masse.

Scaremongering much? Egads.

On Tue, Mar 12, 2013 at 5:27 AM, Michael Gronager <gronager@ceptacle.com> wrote:

And ... if you aren't aware that you're making a change ???


-------------------------------------
On Mon, Oct 21, 2013 at 4:30 PM, Jeff Garzik <jgarzik@bitpay.com> wrote:


Are we going to move ahead with this?

If so, I'm volunteering to create the repository and import the current
BIPs from the wiki there (and convert from wiki markup to markdown where
necessary).

2) Time passes.  Software for BIP drafts is developed, tested,

Personally I think it is useful to have a number as soon as a BIP can be
implemented, even if still in draft status; it gives something to refer to
when mentioning a certain improvement proposal (in commit messages and such
it could be called BIP xxx Draft).
I don't think we are at risk of running out of numbers to assign any time
soon.

Wladimir
-------------------------------------


I guess these days most Facebook/G+/Twitter users are logged in from their
smartphone , so you'd implement it as a mobile app that gets API access via
the standard mobile frameworks. The UI flows for this are highly optimised
and very slick. Once you have API access to read/write the users profile
picture, your app can just wake up from time to time and check if the users
profile picture has changed. If it did, download the highest resolution
available, rewatermark and reupload.

The main sticking point I can see is that the user might end up losing
comments or likes on their primary photo, which would upset some people,
and they might end up with duplicates if the old one was not erased. The
Facebook API docs are notoriously poor - it's unclear to me whether an app
can edit a photo after it was uploaded, or whether it can only create new
ones (deleting photos requires whitelisting by Facebook).

To read the users watermarked address requires no API access or account,
though.

Probably you wouldn't want to watermark an actual Bitcoin address or key.
The capacity of social network photos to carry stegod data is very low due
to the incredibly high compression they go through. More likely you'd
encode a very short URL which contains a payment request and then users
would rotate their key from time to time at the hosting site.
-------------------------------------
Very cool, thanks Matt.

I was actually thinking this morning, maybe we should require all nodes to
go through the inv/getdata dance. Otherwise it's possible to improve your
chances at racing a block by mining a block, waiting to see a block inv
from another node, then blasting out your block while other nodes are still
waiting on their getdatas.


On Wed, Nov 6, 2013 at 6:50 AM, Matt Corallo <bitcoin-list@bluematt.me>wrote:

-------------------------------------
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Dear Bitcoin developers,

We would like to report a vulnerability which might lead, under some
assumptions, to a double-spending attack in a fast payment scenario.
The vulnerability has been introduced due to signature encoding
incompatibilities between versions 0.8.2 (or 0.8.3) and earlier
Bitcoin versions.

Please find at the following link a detailed description of this
vulnerability:
ftp://ftp.inf.ethz.ch/pub/publications/tech-reports/7xx/789.pdf

We contacted and informed Gavin earlier about this problem.

With best regards,
Arthur Gervais
-----BEGIN PGP SIGNATURE-----
Version: GnuPG/MacGPG2 v2.0.18 (Darwin)
Comment: GPGTools - http://gpgtools.org

iQEcBAEBAgAGBQJRzBKLAAoJEI2AYXeasI8/eNYH/2b45o8JPjuiOXeE0MgiYO4g
HgGorNBvH3hLlSZkGh/7GxeGWi3tiEq8DKAgqFd8p+1Ay4YVHK86jJMBxAc8lzpx
TqS6Szrhlx7slamMGhjeem4BJ2RmfVqSRQjidYxwdee8bMQRVH5DiBzndpZwCeHa
AvlP8ojTUFozOJs5PvjEqE+sDKDe5nDC96uiZyMROK8neoiLZpJzV3+ScTUjLCeB
zg34wttX80WKpkXJFvq88FTIvO5E42NGP3APnt2J/HZcey4Mi9UIhLt+/TJ7Z07l
HuxFlzyXdCgRkJWvU13yn8bUP0cbeoox6Cwn7rDAIisVLn4KB9XPThPjfJbKEkg=
=Y6bs
-----END PGP SIGNATURE-----


-------------------------------------
On Wed, Mar 13, 2013 at 02:27:01PM -0700, Gregory Maxwell wrote:

Still, it would have meant that all 0.8 users would have immediatley
been told that something was wrong.  I don't know to what extent it
was luck that this was dealt with as promptly and efficiently as it
was, but to the extent that luck was involved, a slew of 0.8 users
shouting in various places "wtf is going on" couldn't but help in
reducing the element of luck if something similar were to happen again.

roy




-------------------------------------
Bitcoin-Qt/bitcoind version 0.8.1 is available from:
  https://sourceforge.net/projects/bitcoin/files/Bitcoin/bitcoin-0.8.1/

This is a maintenance release that adds a new network rule to avoid a
chain-forking incompatibility with versions 0.7.2 and earlier.

Source code for this release is in a 0.8.1 tree branched directly from
the 0.8.0 release:
  https://github.com/bitcoin/bitcoin/tree/0.8.1

-- 
--
Gavin Andresen
Chief Scientist, Bitcoin Foundation
https://www.bitcoinfoundation.org/


-------------------------------------
On Mon, Oct 21, 2013 at 11:36 AM, Melvin Carvalho
<melvincarvalho@gmail.com> wrote:

Indeed. The BIP analogs that immediately come to mind would be the
enhancement proposal processes for Python, XMPP, and BitTorrent:

http://www.python.org/dev/peps/
http://xmpp.org/xmpp-protocols/xmpp-extensions/
http://www.bittorrent.org/beps/bep_0000.html

-- 
Arto Bendiken | @bendiken | http://ar.to


-------------------------------------


It's done that way because it was originally registered by Satoshi. It's
now controlled by Sirius, who doesn't really take part in the project
anymore.

I bring this up because of the recent bitcointalk fiasco. AFAIK the domains
are registered and controlled in the same way. It's likely that the current
registrar isn't very secure.
-------------------------------------
On Sat, Mar 09, 2013 at 11:31:55PM -0500, Peter Todd wrote:

There's been a lot of discussion about this issue, and many people have
asked that Bitcoin not arbitrarily block interesting potential uses of
provably unspendable txouts for data applications, and similarly
spendable txouts representing assets. I've changed my hardline position
and now think we should support all that stuff. However, there is one
remaining class of txout not yet talked about, unspendable but not
provably so txouts. For instance we could make the following a standard
transaction type:

scriptPubKey: OP_HASH160 <20 byte digest> OP_EQUALVERIFY <data>
scriptSig: <data>

Of course, usually the 20 byte digest would be picked randomly, but it
might not be, and thus all validating nodes will always have a copy of
the data. With the 10KB limit on script sizes you can fit 9974 bytes of
data per transaction output with very little waste.

A good application is timestamping, with the advantage over
coinbase/merkle tree systems in that you don't have to wait until your
timestamp confirms, or even store the timestamp at all. Another
application, quite possible with large block sizes and hence cheap or
free transactions, is secure data backups. In particular such a service,
perhaps called Google Chain Storage, can offer the unique guarantee that
you can know you're data is secure by simply performing a successful
Bitcoin transaction.

-- 
'peter'[:-1]@petertodd.org
-------------------------------------
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256

On Fri, Jun 28, 2013 at 9:05 AM, Mike Hearn <mike@plan99.net> wrote:

Tor does not act as a particularly effective man in the middle for nodes
that support connections to hidden services because while your
connections to standard Bitcoin nodes go through your exit node, the
routing path for each hidden service peer is independent. Having said
that we should offer modes that send your self-generated transactions
out via Tor, while still maintaining non-Tor connections.

Anyway Sybil attacks aren't all that interesting if you are the one
sending the funds, and receivers are reasonably well protected simply
because generating false confirmations is extremely expensive and very
difficult to do quickly. After all, you always make the assumption that
nearly all hashing power in existence is honest when you talk about
replace-by-fee among other things, and that assumption naturally leads
to the conclusion that generating false confirmations with a sybil
attack would take more than long enough that the user would be
suspicious that something was wrong long before being defrauded.

I'd be surprised if anyone has ever bothered with a false confirmation
sybil attack. I wouldn't be the slightest bit surprised if the NSA is
recording all the Bitcoin traffic they can for future analysis to find
true transaction origins. Which reminds me, again, we need node-to-node
connections to be encrypted to at least protect against network-wide
passive sniffiing.

Regarding usage I would be interested to hear from those running Bitcoin
nodes advertising themselves as hidden services.


For what it is worth I ran a double-spend generator a month or so ago
against the replace-by-fee node that Peter setup and I found that a
small number of the double-spends did in fact appear to be mined under
replace-by-fee rules.

Specifically the generator would create a transaction from confirmed
inputs, wait 60-180 seconds (randomized) to allow for full propagation,
and then create a double-spend if the transaction hadn't already been
mined. The transactions were randomized to look like normal traffic,
including occasional bets to Satoshidice and similar for fun. (for the
record the script had no way of knowing if a bet won and would happily
attempt to double-spend wins) Fees for the replacement were power-law
distributed IIRC, with some occasionally set to be quite hefty.

Though possibly just an artifact of unusually slow transaction
propagation it appeared that about 0.25% of hashing power was following
replace-by-fee rules. (not including transactions involving gambling, I
know Eligius and perhaps others block such transactions from their
mempools making double-spends easy to accomplish by including
Satoshidice outputs)

I'm actually surprised by that figure myself given Peter Todd and I
haven't made a serious attempt yet to get miners to use replace-by-fee
rules. An interesting experiment would be to advertise that money is
being given away by such a tx generator in the mining forum, although I
would prefer to see solid mempool support for the "scorched-earth"
double-spend countermeasure first; Peter sounds like he has some great
ideas there, although as usual I am seeing very little in the way of
code. :)
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBCAAGBQJRzWCOAAoJEEWCsU4mNhiPwhgH/ic/OJMCYwdIuEM2ArSAEQRY
l5bqafMYMcC/KE9xqZ1HVkLJ9Zg57MQ8VZw95WOsmRgNA0v1xIoCyREjI84QkCIq
R/hOgS97eJc+XXnPBVoB4Jadq5LQ6jNpJo7cmiLJjCEmE6rTxLZBBT4P3eQw8oIn
WAd7X7utP7/QAkjhaWB9FsfWT8QZseqpSPv8WucRftsRCABurzuD+eSfpRqYwk2z
XBD0zO+EyAtu6hB3dRAFhqnhVfEcOLJCtXpm76WO574H4AZ/8EN+HozLJSUtylCq
j1NZnpj/6pdFh2v5Pid4HEMEvuNNX60u6iXGJ560PUsdKmOh+LEhUBLKd9acJTw=
=QtjI
-----END PGP SIGNATURE-----


-------------------------------------
On Sun, Dec 1, 2013 at 1:19 AM, Wladimir <laanwj@gmail.com> wrote:

Did as you suggested, removed both setFocus() calls that happen after Send
is clicked

http://pastebin.com/j4adDpsM
Now it crashes in something else within qt.

I'm trying other things...

Warren
-------------------------------------
Chrome has whitelisted bitcoin: URIs for web apps, and Firefox it turns out
doesn't use whitelisting at all, so it already works there.

https://chromiumcodereview.appspot.com/14531004

I'm hoping this means web wallet developers won't be put off from
supporting the payment protocol (that risk is the reason I started this
work).

The next step is to file bugs against WebKit (for Safari/iOS/misc other
platforms), and IE, though I don't know if Microsoft uses open bug trackers
much.



On Wed, Apr 24, 2013 at 6:37 PM, Gregory Maxwell <gmaxwell@gmail.com> wrote:

-------------------------------------
I just added a requirement to the BIP 72 (bitcoin: URI payment protocol)
spec:

Wallets must include an Accept HTTP header in HTTP requests:

Accept: application/bitcoin-paymentrequest

... and submitted a pull request so the reference implementation follows
the spec.

Thanks to Stephen/Jeff at BitPay for the suggestion. I'll make a similar
change to BIP 70 and require wallets set Accept:
application/bitcoin-paymentrequestack when sending the Payment and
expecting a PaymentACK message in return.

-- 
--
Gavin Andresen
-------------------------------------
I like the UUID-as-path idea. That resolves the problem of how to share the
alt-chain merkle tree quite nicely.

On Mon, Nov 4, 2013 at 7:16 PM, Peter Todd <pete@petertodd.org> wrote:


The Merkle branch doesn't get stored indefinitely though, whereas the
coinbase hash does. The data stored in the coinbase [output] can always
just be the 256-bit root hash truncated to less.

I doubt the additional bytes make much difference really, so the additional
complexity may not be worth it. But it wouldn't be an issue to do.
-------------------------------------
On Fri, Aug 9, 2013 at 1:58 PM, Wendell <w@grabhive.com> wrote:

Well, "wally" is just a demo application, a command line client to
prove a technology.

The main development is in places like "node-libcoin", where a wallet
platform is being developed.  While maintaining a strong commitment to
the blockchain engine side of bitcoind, BitPay has enterprise wallet
needs that do not necessarily mesh well with the standard bitcoind
wallet.  Multi-sig, P2SH and other advanced features are key to the
future use of bitcoin in large enterprises.  Managers, CEOs and other
functionaries at a corporation may each have their own wallets /
keyrings, and cooperate to sign large value, high security bitcoin
multi-sig transactions, for example.

-- 
Jeff Garzik
Senior Software Engineer and open source evangelist
BitPay, Inc.      https://bitpay.com/


-------------------------------------
I think it's worth noting that quite a large portion of Linux users
probably get the mainline Bitcoin client from the packages. I think Bitcoin
package maintainers are doing mostly a pretty good job :)


On 6 May 2013 18:13, Gregory Maxwell <gmaxwell@gmail.com> wrote:

-------------------------------------
Categories that make sense to me:
1) protocol related problems
1.a) failed to deserialize transaction
2) core principle violations
2.a) script evaluation fail (only owner is allowed to spend)
2.b) outputs larger than inputs (no creation of new money)
2.c) outputs not found/already spent (no double spending)
3) policy rules
3.a) not standard
3.b) ...

-- 
Pieter
 On Oct 27, 2013 11:54 PM, "Gavin Andresen" <gavinandresen@gmail.com> wrote:

-------------------------------------
Mike asked what non-0.9 code I'm working on; the three things on the top of
my list are:

1) Smarter fee handling on the client side, instead of hard-coded fees. I
was busy today generating scatter-plots and histograms of transaction fees
versus priorities to get some insight into what miner policies look like
right now.

2) "First double-spend" relaying and alerting, to better support low-value
in-person transactions.  Related:
*Have *a *Snack*, Pay with
*Bitcoins*<http://www.tik.ee.ethz.ch/file/848064fa2e80f88a57aef43d7d5956c6/P2P2013_093.pdf>


3) Work on 2-3 whitepapers on why we need to increase or remove the 1MB
block size limit, how we can do it safely, and go through all of the
arguments that have been made against it and explain why they're wrong.

-- 
--
Gavin Andresen
-------------------------------------

slush wrote :

I was wrong, and I fully acknowledge it.

My concern was that adding extra information would make the mnemonic 
longer than 12 words.
In addition, you proposed to allocate these extra bits for a checksum, 
not for metadata.
However, a checksum does not really add any information, because 
Electrum checks the existence of a wallet directly from the blockchain.
So, my feeling at that time was that adding extra bits would increase 
the risks (a longer seed is harder to memorize, increases the 
probability of mistakes, etc), and did not bring any real benefit.

However, you showed since then how to solve this by using a slightly 
longer dictionary, and I do like your solution, I find it absolutely 
brilliant.
In addition, I realize now that metadata (ie a "version number") is 
crucially needed, for the reasons mentioned in my previous post.


BIP32 gives a lot of freedom to wallet developers: it does not specify 
which branches of the HD tree shall be used for which purpose.

However, if you want to recover a wallet from its mnemonic (a 
requirement for Electrum), then you need to know which branches to explore.
In Electrum 1.9 I had to make some choices about branch allocation. 
However, the decisions that I made are certainly not final, so it is 
important to be able to change them in the future. Thus, this metadata 
needs to be added to the mnemonic.



The solution I propose is very different from BIP39, and it does not 
require to predefine a dictionary.
My proposal is actually somewhat similar to Pieter Wuille's proposal, 
which I discovered after his recent post.
( https://bitcointalk.org/index.php?topic=102349.0 )


No, there are not so many words that are frequent enough.
Overlapping will be an issue, especially if we go for a 4096 words 
dictionary.



You are right, this encoding is not symmetric.
Bi-directionality has never been a requirement for Electrum. May I ask 
why you need bi-directionality in Trezor?
(the only reason I can think of is if you want to export a bip32 branch 
into another wallet, but this would create a very long mnemonic string)


it makes it possible to hash a utf8 string, and to retrieve the metadata 
from the hash.
Thus we don't need to spend ages arguing about the best choice of a 
dictionary, and to set it in stone.




-------------------------------------
On Wed, Oct 23, 2013 at 09:38:31AM +0200, Martin Sustrik wrote:

The reference implementation is the specification - the "specification"
on the wiki is best thought of as a set of Coles Notes on the real
specification. If you don't already understand that and the nuance of
that statement you should assume the protocol is fixed in stone and
doesn't evolve at all; that statement is not quite true, but it's very
close to the truth.


I gotta get around to writing a "Developers" section for the FAQ
explaining this stuff....

-- 
'peter'[:-1]@petertodd.org
0000000000000007362b283ac07839aba795dbfb3c5c4e831d80df9cf3bea2d5
-------------------------------------


Thanks for the explanation. Here is how I understand how it works, 
please correct me if I'm wrong:

The user's computer picks a random number a, the Trezor picks a random 
number b.
Trezor adds a and b in the secp256k1 group, and this creates a master 
private key k.
Trezor sends the corresponding master public key K to the computer.
Thus, the computer can check that K was derived from a, without knowing b.
This also allows the computer to check that any bitcoin address derived 
from K is derived from a, without leaking b. (and reciprocally)

However, it seems to me that this property will work only with bip32 
public derivations; if a private derivation is used, don't you need to 
know k?



-------------------------------------
This sounds similar to the "bitcoin2" branch I created a while back - 
basically a "next"-like branch, but for hardforking changes that refused to 
run without the -testnet option. There's so much non-hardforking code that can 
be written/tested, at this point, that I think it was and maybe is premature 
to be writing hardforking code outside of necessity. But perhaps if you want 
to play around, it might be a good starting point (it can probably merge up to 
latest master, and trivial to rebase if not).

On Sunday, May 19, 2013 1:23:59 PM Adam Back wrote:


-------------------------------------
On Thu, Apr 25, 2013 at 09:07:07PM -0400, Gavin Andresen wrote:

How does the current protocol protect the refund address? Protecting the
payee against a compromised webserver may be out of scope for now, due
to the lack of a suitable PKI, as Mike Hearn explained. But signing the
refund address is a more immediate issue. There is no obvious key that
the payer can use to sign the refund address. However, this can be
solved right now with marginal changes to the protocol, like this:

- Payee creates his PaymentDetails message with an explicit pubkey in
  output.script, not an address.
- If payment_url is not specified then payer pays as before (he cannot
  sign his refund address) 
- If payment_url is specified then payer hashes his Payment message
  (with transactions zeroed out) and pays to h*pubkey, where h is the
  computed hash; then submits his Payment message.
- Upon receiving the Payment message, payee computes the same hash and
  can pick his funds from h*pubkey. 

As long as it is trivial to reconstruct the Payment message this is
completely safe. But probably this isn't the case in general. So the
drawback is that the payer has to backup the Payment message before
submitting it or before broadcasting the transaction, in order to keep a
proof. If the payer trusted the payee then it would suffice to wait for
an ACK before broadcasting. Because of the backup issue, refund address
signing should probably be an option that the payer can choose after
reading a backup warning.



-------------------------------------
I suspect what you saw is mining nodes restarting and clearing their
mempools out rather than an explicit policy of replace by fee.

On Fri, Jun 28, 2013 at 12:09 PM, John Dillon
<john.dillon892@googlemail.com> wrote:


-------------------------------------
Thanks Chris.

Yep, looks like an honest-ish user managed to accidentally get one tx into
one chain and another into the other.

I think I'd cautiously say that if OKPay gets their cash back, or freezes
his balance nobody is out BTC for last night, (instead just time and
effort).

I'm doing a little FUD-fighting right now, but will try and pick up a bit
more if necessary tonight after my flight lands. I think this is mostly
over the heads of a lot of our typical media contacts, though.

Peter


On Tue, Mar 12, 2013 at 12:53 PM, Christian Decker <
decker.christian@gmail.com> wrote:




-- 
------------------------------

[image: CoinLab Logo]PETER VESSENES
CEO

*peter@coinlab.com * /  206.486.6856  / SKYPE: vessenes
811 FIRST AVENUE  /  SUITE 480  /  SEATTLE, WA 98104
-------------------------------------

The "mempool" command allows nodes to request the contents of a peers
memory pool, yes.

It is currently used by SPV clients to find transactions that were
broadcast before they were started up (but not yet confirmed).




0.9 has code to save the mempool to disk.



Er, you mean, distinguishing features beyond the nodes IP address?

The contents of the mempool may vary depending on when the node was started
and what it saw at what times. I guess it's distinguishing in a way, but
not in any important way. Nodes are not intended to be completely
indistinguishable, just indistinguishable enough that it doesn't matter
which you connect to.




I don't think so, unless there are quirks to do with sendrawtransaction
RPCs or strangely crafted wallet spends. Normally if a tx is in the mempool
it will be relayed.



I don't know of any such place, but I'm sure people have compiled tables
somewhere.
-------------------------------------
Payment protocol is locked down for v1 already. But did you read it? It
doesn't use addresses anywhere. Payments are specified in terms of a list
of outputs which can contain any script. Of course it could be a
pay-to-address script, but pay-to-address uses more bytes in the chain and
there isn't any typeability benefit.

The multiplication trick for deterministic keys is a nice one and worth
doing, but it has to be a v2 feature by this point. It's more important to
get v1 widely implemented and deployed first.


On Fri, Aug 9, 2013 at 7:57 PM, Alan Reiner <etotheipi@gmail.com> wrote:

-------------------------------------
On 6 June 2013 02:19, Peter Vessenes <peter@coinlab.com> wrote:


Also see satoshi's comments on this, though it may be restating what others
have said:

https://bitcointalk.org/index.php?topic=750.0

"Here's an outline of the kind of escrow transaction that's possible in
software.  This is not implemented and I probably won't have time to
implement it soon, but just to let you know what's possible.

The basic escrow: The buyer commits a payment to escrow. The seller
receives a transaction with the money in escrow, but he can't spend it
until the buyer unlocks it. The buyer can release the payment at any time
after that, which could be never. This does not allow the buyer to take the
money back, but it does give him the option to burn the money out of spite
by never releasing it. The seller has the option to release the money back
to the buyer.

While this system does not guarantee the parties against loss, it takes the
profit out of cheating.

If the seller doesn't send the goods, he doesn't get paid. The buyer would
still be out the money, but at least the seller has no monetary motivation
to stiff him.

The buyer can't benefit by failing to pay. He can't get the escrow money
back. He can't fail to pay due to lack of funds. The seller can see that
the funds are committed to his key and can't be sent to anyone else.

Now, an economist would say that a fraudulent seller could start
negotiating, such as "release the money and I'll give you half of it back",
but at that point, there would be so little trust and so much spite that
negotiation is unlikely. Why on earth would the fraudster keep his word and
send you half if he's already breaking his word to steal it? I think for
modest amounts, almost everyone would refuse on principle alone."


-------------------------------------
BTW, check out the blockchain torrent, as one way of offloading some
of the download bandwidth used from the P2P network:

     Bitcoin blockchain data torrent
     https://bitcointalk.org/index.php?topic=145386.0

-- 
Jeff Garzik
exMULTI, Inc.
jgarzik@exmulti.com


-------------------------------------
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256

On Thu, May 9, 2013 at 1:57 AM, Peter Todd <pete@petertodd.org> wrote:

I actually just meant how Pieter Wuille was talking about a blocktime accurate
to only within 18 hours. :) But it is a nice writeup!

In any case, for many things simple relative ordering is enough rather than
absolute time.


Nope. The attacker can make the timestamp on the block they mine as little as
the minimum from GetMedianTimePast(), and adding two hours to that number could
easily be well before true time.

What you probably need to do is some sort of median time calculation for the
blocks around your timestamp. The proof becomes probabalistic based on the % of
hashing power the attacker controls and in turn depends on if the time they
created their timestamp was of their own choosing.

IE, if you just want to create an inaccurate timestamp, but don't care when,
you can just mine blocks and wait until you get lucky. If you need to create an
inaccurate timestamp *now* the problem is much harder.

But all this analysis can be developed later, and data timestamped now. :)


Oh, right, yes, that is a much more simple idea and far less prone to bugs.

Many SPV clients wouldn't even need upgrades if they don't acturally validate
the blocks they receive and just look for the biggest PoW.


Yes


Anyway, you are being distracted from what we were talking about before, get
back to work!
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBCAAGBQJRiwrGAAoJEEWCsU4mNhiPvYAH/3kjlg5diWeyYUJlKPKRpygQ
XAU8a2D3h9bABacmmhx5yW3AmtV0QqLgKlB76t41JB4O6Jer5FT8tBBwPnjDijtI
KrBWwPqNhVZiyTSDZQTF6BR1a0DDCZVtOXlpOTj6NL1+hy7NYTYsqxAVzS8QgZUH
RXt7QTYGrrmMbmm75NdWhK59mbv22UEaDHfDW0qqgSzdb7f1EQv1fou3MfKScQSd
7OsGU3k5PM+KQ/FGBy+r+07GY5yj85YMooGky0MCjtkOiU/qr+pxfs1uT2R8/512
TyZxzn1vtgWUEGOUeMCml+bgjUOvOgcIvAarzZmyLyAAY15S/LT8MvAr2RUjAfY=
=UDyE
-----END PGP SIGNATURE-----


-------------------------------------
Is there any consideration given to the fact that bitcoin can operate as a
platform for many other services, if it is able to be neutral to payload,
as long as the fee is paid for the transaction size?

Unless I have misunderstood this discussion, it seems to me that this is a
bit like saying in 1990 "IP Is only for email, the majority of users want
email, we shouldn't allow video, voice or images". Ooops, there goes the
web.

Is it possible to solve this by solving the issue of provably un-spendable
outputs without foreclosing on the possibility of other types of
transaction payloads (ie, not money), that would open the possibility for a
myriad of layered apps above? For example, hashes of content that is
external to bitcoin, that people want to pay to have timestamped in the
blockchain, as provably unspendable outputs.

The social compact is to accept transaction for fee. I think it is a major
mistake to make decisions that discriminate on the content of the
transaction, saying that some uses are not appropriate. If the fee is paid
and it covers the size of the transaction, why would it matter if it is not
a payment?

I could be totally misreading this thread, too, so please allow me some
slack if I have!




On Thu, Jun 6, 2013 at 12:14 PM, Luke-Jr <luke@dashjr.org> wrote:

-------------------------------------
On Sat, May 25, 2013 at 7:46 AM, Zooko Wilcox-OHearn <
zooko@leastauthority.com> wrote:


I'm sure he means rule changes with economical impact, such as miner block
reward, total number of bitcoins, block speed. Mostly non-interesting from
a technical view point, but the only changes most altcoins seem to be
making... In any case, these are set in stone and cannot ever be changed
for bitcoin or all hell will break loose.

See also https://en.bitcoin.it/wiki/Hardfork_Wishlist.

Wladimir
-------------------------------------
On Thu, Jun 20, 2013 at 09:36:40AM +0200, Mike Hearn wrote:

Actually, that is not the same issue. What is being argued for here is that
the version in the version message itself should indicate which fields are
present, so a parser doesn't need to look at the length of the message. That
seems like a minor but very reasonable request to me, and it's trivial to do.
That doesn't mean that you may receive versions higher than what you know of,
and thus messages with fields you don't know about. That doesn't matter, you
can just ignore them.

I see no problem with raising the protocol version number to indicate
"all fields up to fRelayTxes are required, if the announced nVersion is above N".
In fact, I believe (though haven't checked) all previous additions to the version
message were accompanied with a protocol version (then: client version) increase
as well.

-- 
Pieter



-------------------------------------
A great presentation on advances in crypto

http://www.slideshare.net/astamos/bh-slides
-------------------------------------
On Thu, Sep 5, 2013 at 12:04 PM, Wendell <w@grabhive.com> wrote:


Well, it's a bit complicated and needs some software development to do
well. The best way to fund a complex project would be to raise the money
using an assurance contr.... oh wait ;)



It could be automatic in the sense that users don't need to know it's
happening, but look at it this way. Gavin believes the future of computing
is mobile and tablets. I don't know about that, but let's assume for the
sake of argument he turns out to be right. These devices are expected to
have much longer battery life than laptops. Apps that spin up in the
background and use battery+radio can easily be seen as "abusive" by end
users. In fact, if you look in the Bitcoin Wallet section of the forum,
you'll see a giant argument by users of the Android app who are upset
because the app sometimes runs in the background *just to keep up with the
chain*! That's not even donating resources, it's just trying to ensure it
doesn't fall behind, and this enrages some users because it can have a
small but non-zero battery/bandwidth usage impact.

Given the number of complaints generated by just having the app sync
automatically, imagine what would happen if we started relaying blocks!

Generally the ethos and modus operandi of desktops is different to laptops
which is in turn different to mobiles/tablets. Things you can get away with
on more powerful machines that expect to be plugged in all the time are
verboten on more modern devices.

Now that said, I can easily see Bitcoin enthusiasts buying some kind of
cheap embedded device, maybe Raspberry Pi based, and plugging it into a
wall in order to donate to the network. That way it doesn't affect their
primary devices responsiveness or storage or battery life.
-------------------------------------

I'll go ahead and use 0.8.x since it will be just transactions and queries.

I'm guessing this will all be fixed in a couple weeks and that ASIC and FPGA
miners will have their softcode updated, as will the pure softminers (GPU).


-------------------------------------
The TPM is a piece of secure* hardware that provides various cryptographic
services to the host system. It is important to understand that it is not a
crypto accelerator. It is a place to store keys and small pieces of data
(like hashes, counters) where it's difficult for someone to extract them
even if they have physical access.

The TPM is designed to support trusted computing, a rather splendid set of
extensions to the x86 architecture that let you do remote attestation,
software sealing and other things. Or at least it would be splendid if it
had been really finished off and pushed to completion by the designers.
Unfortunately due to various political issues it exists in a
quasi-finished, semi-broken state which only experts can use. Without a
doubt you have never run any software in a TC environment.

As part of that role, the TPM provides some permanent storage in the form
of NVRAM. Because the TPM is designed to be as cheap as possible, it has a
limited number of write cycles. Normally you're meant to store Intel TXT
launch control policies and sealed keys there, but Pond uses it in a
different way by storing keys there that it encrypts local data with. By
erasing the key in the TPM chips memory area, the data on disk is
effectively destroyed too.

This is useful because modern "disks" are often SSD drives, or physical
metal disks that use log structured file systems. Because flash memory has
a limited number of write cycles per cell, internally SSDs have firmware
that remap writes from logical addresses to different physical addresses,
the goal is to avoid wearing down the drive and extend its useful life.
Normally it doesn't matter, but if you want to delete data such that it's
really really gone, it obviously poses a problem. Using TPM NVRAM solves
it, albiet, at a high usability cost.



*note: actual tamper resistance of real-world TPM chips is not something
that seems to have been studied much


On Tue, Jul 30, 2013 at 1:27 PM, Wendell <w@grabhive.com> wrote:

-------------------------------------
On Wed, Jul 31, 2013 at 05:30:46PM -0600, E willbefull wrote:

Also:

* There may be a desire to minimize the URL length when used in a QR code

* Some applications might specifically require some of the features of
the payment protocol - e.g. it may be a requirement that a print-media
QR code cannot be used after a cut-off date, or a vendor may have a
specific requirement not to accept payments without a refund address

There are pros and cons, but it's not clear to me that the benefits of
enforced backward compatibility outweigh the benefits of allowing
application designers to innovate as they see fit.

roy




-------------------------------------
On Tuesday 23 July 2013 11:17:28 Peter Todd wrote:

Very interesting.  I love the idea of the UTXO set being tied to a block.


You're right.  That is scary.


You don't.  You can't invalidate the lie if all you have access to is lies.  
But if you have access to just one honest node; that will reveal the liars.  
I'm not claiming that headers-only nodes can ever be made as secure as a full 
node.  Just _more_ secure than they are now; and potentially able to act as 
one of those honest nodes.


There is absolutely no need to get condescendingly shirty.  I thought this was 
a friendly list; and we were having a discussion.  If you don't want to 
respond to posts -- don't.  I also didn't realise I had to pass an exam before 
I was allowed to speak.

Yes: I know the difference between SPV and full security.  SPV is headers only 
and so has no way to verify that the transaction outputs references as inputs 
to any new as-yet-unverified transaction are valid.  Instead it relies on 
having some way of proving it's in the chain; and then looking for the number 
of blocks built on top of it as "verification".  "Full security" (which is 
itself a very poor name), is obviously just checking that every output 
referenced in the inputs is unspent; that necessarily requires full blocks.

The difference in security being that in SPV there is no way to know if the 
referenced Unspent TransaXtion Output really is unspent -- it might have been 
spent elsewhere then referenced again in this new transaction.

My suggestion was that we want to be able to fetch a block by transaction; and 
that simple nodes can all, in aggregate offer contribution to the network 
rather than just being parasitical on the full nodes.   When I ask for a block 
that contains a transaction, and I do that repeatedly, I have part of the 
block chain.  If lots of simple nodes are doing that, then the whole chain 
should be available if there are enough of them.  They would then gain the 
ability to do transaction-forwarding in some cases.  This is only possible if 
a few extra facilities are added to the protocol.  One of which is the new 
feature I suggested: block-given-transaction.  It's not enough on its own, but 
if you also add in the ability for a node to tell another about the output 
transactions (basically, what block spends it), _then_ the simple nodes are 
able to become much more secure -- not 100% of course, they're still not full 
nodes, because they have no way of knowing if they are being lied to when they 
are told (this transaction is unspent), but all it takes is one honest node to 
point them at the truth, and the lie is then exposed.

That facility is just a drain on full nodes for the most part; except if you 
start encouraging it whole-sale.  The simple node would keep cache both the 
incoming and outgoing transactions (or rather the blocks that contain them) 
for addresses to which they are paying attention.  That gives them a cache 
that contains more than just their minimal set; and then they are able to do 
just a little bit of verifying on their own.  With enough nodes of this sort, 
the verification load is reduced.

Perhaps all that effort is not worth it for the tiny reduction.  Perhaps it's 
not true that that contribution of verification adds nothing.  I can live with 
those objections.  But "do I know the difference" as a reposte?  Not so much.

Anyway; going by your post on partial UTXO's; you're well ahead of the game, 
and I'm not suggesting anything that hasn't already been thought of, and 
thought of better.  I'm not sure why you took umbridge at my idea, when it 
seems like I'm just a few steps behind what you've already thought of.  Not 
everything is an attack you know?



Andy

-- 
Dr Andy Parkins
andyparkins@gmail.com


-------------------------------------
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 07/05/13 14:16, Adam Back wrote:

[...]


"sendfrom" in the RPC interface. Difficult to use (I would like to be
able to use source key, in addition of source "accounts") and easy to
make mistakes. But doable.

Would be nice to have an "advanced" GUI option to chooce source
account/key.

- -- 
Jess Cea Avin                         _/_/      _/_/_/        _/_/_/
jcea@jcea.es - http://www.jcea.es/     _/_/    _/_/  _/_/    _/_/  _/_/
Twitter: @jcea                        _/_/    _/_/          _/_/_/_/_/
jabber / xmpp:jcea@jabber.org  _/_/  _/_/    _/_/          _/_/  _/_/
"Things are not so easy"      _/_/  _/_/    _/_/  _/_/    _/_/  _/_/
"My name is Dump, Core Dump"   _/_/_/        _/_/_/      _/_/  _/_/
"El amor es poner tu felicidad en la felicidad de otro" - Leibniz
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.10 (GNU/Linux)
Comment: Using GnuPG with Thunderbird - http://www.enigmail.net/

iQCVAwUBUY0R5plgi5GaxT1NAQLJ6AQAkWozxNWJdMYbIBKFTxsPErmv3LChAsYm
bzVIb8ufwV45X0QT3maxz6A/u3yr4wGxu53Vs29dJkM5rgO5JU7akuPs3qvg3ffh
h593zmqyVimfpXxBppff4vocpKTCJ+1ocB5MydGjgGoH2hJ8dwZNQRHYnMwqCjDf
2ONQu7nT0pQ=
=zZVh
-----END PGP SIGNATURE-----


-------------------------------------
Since the payment request is available from a location defined in the URI,
I think it would be appropriate to attach the PaymentACK once payment 
accepted by Merchant.

This would make the request and receipt available for later review.

Regards,

Tams Blummer
Founder, CEO

http://bitsofproof.com

-------------------------------------
Bitcoinj already has such chain id's and we use standard Java style reverse
DNS names: org.bitcoin.main, etc. If we want a more global naming system
that seems like a good compromise between uniqueness and readability.
On 20 May 2013 19:45, "Jeff Garzik" <jgarzik@exmulti.com> wrote:

-------------------------------------
Here's the plan for the 0.8.1 release:

A new CheckBlock() rule, in effect until 15 May, that ensure only
blocks compatible with old releases are accepted into the main chain
(only blocks that touch 4,500 or fewer distinct txids are allowed).

A limit of 500k to blocks created, also in effect until 15 May.

Alerts will be sent to pre-0.8 releases over the next two months,
telling people to either upgrade or create a DB_CONFIG file so they
can handle large blocks.

Code is : https://github.com/bitcoin/bitcoin/pull/2373

I chose May 15 arbitrarily; two months seems like a reasonable 'quick'
amount of time to give people to upgrade/workaround.

The fix was written to be trivial to port to previous versions, and to
be as simple as possible.

Some of the exact details may still change before the 0.8.1 release
(e.g. it might not be exactly 4,500 distinct txids).

Schedule:

0.8.1 binaries late tomorrow or Monday.  An expires-after-24-hours
Alert sent on Tuesday to everybody running pre-0.8, pointing to
http://bitcoin.org/may15.html

Another 24-hour Alert sent on April 15, reminding everybody again they
will need to upgrade or workaround.

A final Alert that never expires sent on May 8th.

After May 15, miners will be free to create blocks up to 1MB, and
anybody running old versions who ignored the alerts may be left
behind.

-- 
--
Gavin Andresen


-------------------------------------
On 3 December 2013 10:45, Mike Hearn <mike@plan99.net> wrote:


I respectfully disagree. Senders need their funds to be received. The
incentive is right there. Miners want mining fees. So if you want to pay
for something, you need to make sure payment arrives. Senders know that if
they exclude the fee it might not arrive at all. Miners increasingly ignore
no or low fees. So those two agents together ensure there is a fee more
than not. If what you said was true, we would hardly see fees being paid at
all, but on the contrary we see lots of fees, and much higher than the
minimum 0.0001/kb rate that is currently required.

Merchants will just include ridiculous fees - there are some exchanges that
do it already - MtGox being the famous example requires a 0.001 fee 10x
higher than the network rate - the CEO does it because he says "it's
better". That's not a fee going to MtGox, that is the miner fee and they
have no plans to reduce it.

Typically vendor software may not get updated and or lag behind with fat
fees never decreasing or decreasing way too slowly - it's just not fluid or
dynamic enough when it rests with the vendor.

However, receivers do want a fee attached,

No - receivers want to be paid. If they are not paid they wont dispatch the
goods or service. Neither party is happy in that circumstance. The
incentive that the payment confirms is there naturally.



Miners cant lie about fees accepted because that's part of the transaction.
When Alice sends funds to Bob it includes the fee information and that is
included in the block. There is no way to fake it. The average fee paid is
provable - so there is no need to query nodes at all, you simply look at
the blockchain. You dont even need to write it into the blockchain since it
can be calculated from the blockchain, it would just make it simpler.

Drak
-------------------------------------
Git makes it easy to fork peoples work off and create long series of
commits that achieve some useful goal. That's great for many things.
Unfortunately, code review is not one of those things.

I'd like to make a small request - when submitting large, complex pieces of
work for review, please either submit it as one giant squashed change, or
be an absolute fascist about keeping commits logically clean and separated.
It really sucks to review things in sequence and then discover that some
code you spent some time thinking about or puzzling out got
deleted/rewritten/changed in a later commit. It also can make it harder to
review things when later code uses new APIs or behaviour changes introduced
in earlier commits - you have to either keep it all in your head, do lots
of tab switching, or do a squash yourself (in which case every reviewer
would have to manually do that).

On a related note, github seems to have lost the plot with regards to code
review - they are spending their time adding 3D renderers to their diff
viewer but not making basic improvements other tools had for years.

So, I'd like to suggest the idea of using Review Board:

http://www.reviewboard.org/

It's an open source, dedicated code review tool used by lots of big name
companies for their internal work. It has git[hub] integration and a lot of
very neat features, like the ability to attach screenshots to reviews. Also
more basic ones, like side by side diffs. Branches can be and often are
submitted to the system as single reviews.

The company behind it (disclosure - written and run by a long time friend
of mine) offers hosting plans, but we could also host it on a Foundation
server instead.
-------------------------------------
On Wed, Jul 31, 2013 at 06:11:10PM -0400, Peter Todd wrote:

By request,

Zip archive:
https://s3.amazonaws.com/peter.todd/litecoin-v0.8.3.7-audit-report.zip

The individual files:
https://s3.amazonaws.com/peter.todd/litecoin-v0.8.3.7-audit-report/report.txt.asc
https://s3.amazonaws.com/peter.todd/litecoin-v0.8.3.7-audit-report/40809aed-1b5cb086.diff
https://s3.amazonaws.com/peter.todd/litecoin-v0.8.3.7-audit-report/litecoin-0.8.3.x-code-audit-agreement.txt.asc

report.txt.asc SHA256 hash:
24832b4b8411f3fbcc98b96bdfaaf90f4aeac39a7fbfb491bff5a76d23859dbd

-- 
'peter'[:-1]@petertodd.org
-------------------------------------

Would it make sense to use either fixed length strings or maybe even enums?

On Oct 25, 2013, at 05:34 PM, Gavin Andresen <gavinandresen@gmail.com> wrote:
Mike Hearn has been lobbying for an "error" message in the Bitcoin p2p protocol for years (at least since the "ban peers if they send us garbage" denial-of-service mitigation code was pull-requested). This came up again with my proposed "smartfee" changes, which would drop low-priority or low-fee transactions.
-------------------------------------
Hello,

Were a startup looking for 1 or 2 really good C++ programmer that is
familiar with the bitcoin internals to help with a for-profit startup.

We will be able to provide more information about the project after signing
a non-compete/non-disclosure agreement. Our coin will be one of the truly
unique coins that are not just a clone of the original Bitcoin code. In
short the project will be a merge-mined altcoin that will provide a very
useful service to the whole crypto-coin ecosystem.

If you have added any features to Bitcoin or related technologies this is a
definite bonus. Please include information about the work youre done in
the space.

We have detailed plans on how to implement it and the roles we are looking
to fill. If interested please email eduffield82@gmail.com with a
description of your work experience and well vett the applications and
share our plans to see if youre interested.

Thanks,

Evan & Kyle
Hawk Financial Group, LLC
-------------------------------------
Thanks a lot! I will run these patches on some nodes tomorrow to see if
it works.

On 22-11-13 21:49, Jeff Garzik wrote:



-------------------------------------
Sorry about that.
Maybe more important, what's wrong with bitcoin and zerocoin being
different currencies with an exchange rate completely decided by the
market instead of trying to force 1:1 ???


On 7/13/13, Jorge Timn <jtimon@monetize.io> wrote:


-- 
Jorge Timn

http://freico.in/


-------------------------------------
Trying something new... a [simple] patch sent to the list, for
discussion.  Seems unlikely to be controversial.  github access is
temporarily disabled, so this is the best pull request avenue for the
moment.

-- 
Jeff Garzik
Bitcoin core developer and open source evangelist
BitPay, Inc.      https://bitpay.com/diff --git a/node_modules/bitpay/bitcoinRPC.js b/node_modules/bitpay/bitcoinRPC.js
index bd410ac..e6edf81 100644
--- a/node_modules/bitpay/bitcoinRPC.js
+++ b/node_modules/bitpay/bitcoinRPC.js
@@ -68,6 +68,18 @@ function spec(b) {
     RPC.call(this, 'gettransaction',  [txid], callback);
   };
 
+  BitcoinRPC.prototype.getRawTransaction = function(txid, callback) {
+    RPC.call(this, 'getrawtransaction',  [txid], callback);
+  };
+
+  BitcoinRPC.prototype.signRawTransaction = function(hexstr, callback) {
+    RPC.call(this, 'signrawtransaction',  [hexstr], callback);
+  };
+
+  BitcoinRPC.prototype.sendRawTransaction = function(hexstr, callback) {
+    RPC.call(this, 'sendrawtransaction',  [hexstr], callback);
+  };
+
   BitcoinRPC.prototype.sendToAddress = function(address, amount, callback) {
     RPC.call(this, 'sendtoaddress', [address, amount], callback);
   };
diff --git a/node_modules/txtool/txtool b/node_modules/txtool/txtool
new file mode 100755
index 0000000..b50dc77
--- /dev/null
+++ b/node_modules/txtool/txtool
@@ -0,0 +1,124 @@
+#!/usr/bin/env node
+
+var fs = require('fs');
+var Util = require('bitcoin/lib/ext/util');
+var BitcoinRPC = require('bitpay/bitcoinRPC').default();
+var bitcoinRPC = undefined;
+var Transaction = required('bitcoin/lib/model/transaction').class();
+
+var argv = require('optimist')
+	.usage('Transaction tool.\nUsage: $0 [options]')
+	.demand(['c'])
+	.alias('f', 'file')
+	.describe('f', 'Transaction source file (raw, serialized, hex encoded)')
+	.alias('x', 'txid')
+	.describe('x', 'Transaction id (switches TX source to RPC)')
+	.alias('c', 'cmd')
+	.describe('c', 'JSON command file')
+	.alias('h', 'host')
+	.describe('h', 'bitcoind RPC hostname or IP address')
+	.alias('p', 'port')
+	.describe('p', 'bitcoind RPC port')
+	.alias('U', 'user')
+	.describe('U', 'bitcoind RPC username')
+	.alias('P', 'pass')
+	.describe('P', 'bitcoind RPC password')
+	.argv
+;
+
+function setupRPC(host, port, user, pass) {
+	var opts = {};
+	opts.host = host;
+	opts.port = port;
+	opts.user = user;
+	opts.pass = pass;
+	bitcoinRPC = new BitcoinRPC(opts);
+}
+
+function loadTxRPC(txid) {
+	var hexstr = bitcoinRPC.getRawTransaction(txid);
+
+	var data = new Buffer(hexstr, 'hex');
+	var tx = new Transaction(data);
+	return tx;
+}
+
+function loadTxfile(filename) {
+	var hexfile = fs.readFilesync(filename, 'utf8');
+
+	var data = new Buffer(hexfile.trim(), 'hex');
+	var tx = new Transaction(data);
+	return tx;
+}
+
+function loadCmdFile(filename) {
+	var data = JSON.parse(fs.readFileSync(filename)).result;
+	return data;
+}
+
+// how many copies of this can one codebase bear?
+function transactionDesc(tx) {
+  var outDescriptions = [];
+  var outs = tx.outs;
+  for(var i=0; i<outs.length; i++) {
+    var txout = outs[i];
+    var script = txout.getScript();
+    var type = script.getOutType();
+    var amount = (txout.getValue() / 1e8).round(8);
+    if(type == 'Address') {
+      outDescriptions.push({
+        type: type,
+        amount: amount,
+        address: Util.pubKeyHashToAddress(script.simpleOutHash())
+      });
+    } else {
+      outDescriptions.push({
+        type: type,
+        amount: amount
+      });
+    }
+  }
+  return {
+    txid: Util.formatHashFull(tx.getHash()),
+    outs: outDescriptions
+  }
+};
+
+function CmdShow(tx) {
+	console.log(inspect(transactionDesc(tx), false, 10));
+}
+
+function CmdSign(tx) {
+	var txHex = Util.encodeHex(tx.serialize());
+	var retHex = bitcoinRPC.signRawTransaction(txHex);
+	console.log(retHex);
+}
+
+function CmdSend(tx) {
+	var txHex = Util.encodeHex(tx.serialize());
+	bitcoinRPC.sendRawTransaction(txHex);
+}
+
+function ExecCmdData(tx, cmdData) {
+	for (var i = 0; i < cmdData.length; i++) {
+		var obj = cmdData[i];
+		if (obj.cmd == "show") {
+			CmdShow(tx);
+		}
+		else if (obj.cmd == "sign") {
+			CmdSign(tx);
+		}
+		else if (obj.cmd == "send") {
+			CmdSend(tx);
+		}
+	}
+}
+
+if (argv.host) {
+	setupRPC(host, port, user, pass);
+}
+var tx = argv.txid ? loadTxRPC(argv.txid) :
+		     loadTxFile(argv.file);
+var cmdData = loadCmdFile(argv.cmd);
+ExecCmdData(tx, cmdData);
+
-------------------------------------
On 6 June 2013 23:48, Luke-Jr <luke@dashjr.org> wrote:


Two quotes satoshi:

"Piling every proof-of-work quorum system in the world into one dataset
doesn't scale."

and

"I like Hal Finney's idea for user-friendly timestamping.  Convert the hash
of a file to a bitcoin address and send 0.01 to it"

This leads me to believe, that while bitcoin should not be over used as a
time stamp server, there could be a balance reached for casual time stamp
recording as part of satoshi's concept.

What we call "spam" is to a degree subjective, and I think not always
obvious, tho in some cases it clearly is.


-------------------------------------
I just posted the following to bitcointalk.

https://bitcointalk.org/index.php?topic=221164.0


Right now between two to four running the largest pools control Bitcoin
in the short term. That's a lot of hashing power in the hands of very,
very few people. In addition pools have little incentive to run secure
operations, and many pools have been hacked with their funds stolen.
Those hacks could just have easily been used to attack the network
itself.

This needs to change.

Pooled-solo mining is a concept Gregory Maxwell, Luke Dashjr and I were
discussing at the conference two weeks ago. (credit goes to Greg and
Luke; I was mostly just listening) Basically the idea is that miners
with mining equipment run a local Bitcoin node and use that node to
construct the blocks they mine - the same as if they were solo mining.
The pools job is then to only track shares and organize payouts.

If the pool gets hacked the worst that can happen is miners are ripped
off, rather than Bitcoin itself being attacked. With pooled-solo mining
even a pool with a majority of hashing power wouldn't be able to do much
harm to Bitcoin. (depending on the implementation they may be able to
blacklist specific transactions - the pool needs to know what
transactions are in the share to credit fees properly)

Tech-wise Luke created getblocktemplate last year as a means to audit
mining pools. I'm sure Greg and Luke can explain the nitty gritty
details better than I can, but essentially the plan is to take
getblocktemplate and extend it as required for pooled-solo mining. This
will include pool and miner software initially, and later improvements
to GUIs and what not to make the whole process easier.


With the success of my recent video project I also want to make this
Keep Bitcoin Free's next project, specifically funding a developer
(likely Luke) to make this happen. Additionally once software is written
and easily usable a good follow-up would be a video and other media to
promote the idea to miners. No guarantees we'll be able to come up with
commercially competitive remuneration, but we can at least come up with
a "Thank you" tip. But first lets discuss the technical requirements to
get an idea of what the scope is.


Finally, for the record, a big part of the reason why myself and other
Keep Bitcoin Free supporters are interested in doing this is very much
to take power over the direction of the network from big pools and put
it into the hands of thousands of individual miners. It's much easier to
convince people that changes to Bitcoin, like increasing the blocksize,
are directly impacting decentralization when individual miners are
seeing that happen to themselves.

-- 
'peter'[:-1]@petertodd.org
00000000000000c14fa7031b2431ab32785efdf1e5aaecc83555ee52a2fc550b
-------------------------------------
Merry Christmas everyone!

I've updated the proposal.

I've changed the checksum to be a double SHA256 of the private key instead of the public address string and I've added support for 3rd party KDF computation.

The full proposal with updated test vectors lives here:

https://bitcointalk.org/index.php?topic=258678

Cheers,

Jean-Paul
-------------------------------------
user back to an encrypted page

sorry, I meant unencrypted page of course
-------------------------------------
My views on censorship resistance in the face of scaling:

1) I expect if I'm not careful about preserving my privacy with the way I
use Bitcoin, then I will always run the risk of being censored by miners.
This means connecting to the network anonymously, not reusing addresses,
and perhaps even mixing my coins.  The onus is on me here to avoid
censorship, but I'm optimistic that this privacy preservation can be made
pretty automatic.

2) I expect anonymity systems to scale to accommodate Bitcoin full nodes,
not Bitcoin to stay small to avoid putting pressure on anonymity systems to
scale.

3) If 2 is too tall an order, then mining in a pool is always an option.
There should always be some countries in the world free enough to allow
mining pools to operate, and miners in countries that ban Bitcoin can
simply connect to these anonymously.  If not, then Bitcoin is toast anyway,
is it not?  If these miners are really interested in avoiding censoring
transactions, then they will do their due diligence and choose a pool that
doesn't do this.  But even if they don't, censorship can be personally
avoided by following 1.

On Thu, Mar 7, 2013 at 2:19 PM, Mike Hearn <mike@plan99.net> wrote:

-------------------------------------

I really don't understand this either/or mentality.

OF COURSE we're going to raise the block size limit. Limiting the main
blockchain to single-digit transactions-per-second is not an option,
the vision FOREVER has been to scale it up.

And OF COURSE there will be off-chain transactions-- at the very
least, we need them for "instantly confirmed" transactions.

But lets table that whole discussion until 0.8.1 is out the door.

-- 
--
Gavin Andresen


-------------------------------------
I'd like to add some historical background about how the "protocol
specification" came to be in the first place.

A bit over three years [1] ago I started an attempt to document the
network protocol, by reverse engineering it from the satoshi
client. My goal, back then, was to enable like-minded engineers to
create alternative clients and move away from the client-monoculture
that is still predominant today. It was clear from the beginning that
it would merely be a reverse engineering effort, and that it would
likely lag a bit behind the changes in the main client. It was meant
as a help for engineers that are not well versed in C/C++ to enable
them to contribute by creating new clients, but the satoshi client
would always be the de-facto standard.

With the move from Google Code to the Bitcoin.it wiki somehow this
notion of it being a reverse engineering effort was lost and people
started assuming that if the behavior of the satoshi client did not
match the protocol description it was a bug on the client
side. Instead it is because the reverse engineering of the protocol is
incorrect or simply missing some details. Although the protocol
description is far more complete than it was back when we started, I
still don't feel comfortable giving it the name specification.

I still believe that a client monoculture is bad for the system as a
whole, because a single bug might bring down the whole network. Giving
people the necessary tools to implement new clients brings
stability. I do understand the criticism that writing a specification
might hinder future development as it restricts the possible changes
to the protocol, but isn't this already the case as long as we have
legacy versions of the client participating in the network? I would
also argue that having a specification allows an application
independent review of the protocol to identify possible improvements
and bugs.

I think the protocol description has an important place in the
development of Bitcoin, so much so that we pushed a long time ago to
separate protocol version from the client version. I would love to see
the protocol specification becoming official part of the bitcoin
github repository, which would ideally be maintained alongside the
satoshi client to keep it up to date.

Regards,
Christian Decker

[1] https://bitcointalk.org/index.php?topic=231
--
Christian Decker


On Thu, Oct 24, 2013 at 9:03 AM, Martin Sustrik <sustrik@250bpm.com> wrote:


-------------------------------------
On Fri, Oct 04, 2013 at 01:58:51PM +0200, Arto Bendiken wrote:

Exactly.

Ideally code review discussions would be PGP signed and have a mechanism
for someone to sign a commit saying they had in fact reviewed it.
Combined with git's per-commit signature mechanism it'd make it possible
to write a git-pull hook that checked that whatever was being pulled had
some sufficient number of signatures from people whose reviews you
trusted. With such a system you could host code review anywhere safely,
or for that matter, use a completely distributed system.

But that's going to be a long way off. In the meantime github is
probably more trustworthy and competent than anything we ran ourselves,
and we should focus on making sure reviewers eyeballs actually look at
the code that ends up in master.

-- 
'peter'[:-1]@petertodd.org
-------------------------------------
Just a quick and dirty check if something bad actually happened. 430
transactions that were confirmed in the alt-chain, are not confirmed
in the true blockchain. The good news is that as far as I can tell
most of them are low volume transactions destined for SD.

7 transactions were true double spends, or to be more precise
transactions in which an conflicting transaction was confirmed in the
new chain (with their respective amount):

12814b8ad57ce5654ba69eb26a52ddae1bff42093ca20cef3ad96fe7fd85d195 261 BTC
cb36ba33b3ecd4d3177d786209670c9e6cdf95eb62be54986f0b49ca292714af 0.06 BTC
7192807f952b252081d0db0aa7575c4695b945820adaf7776b7189e6b3d86f96 0.01 BTC
355d4ea51c3b780cf0b10e8099a06a31484e0060bc140b63f3d6e5fb713ace5e 0.05 BTC
b961bc0c663a46893afd3166a604e7e2639533522d9fec61fdb95eb665e86f5a 0.61 BTC
138063e4bdb76feaa511f1e7f9c681eb468ef9140c141671741c965e503b84c6 1.62 BTC
a10bd194cdbf9aa4c12eb0b120056998a081a9b0d93d70570edff24dec831f90 0.81

So the one transaction that really hurt was the one published on
BitcoinTalk. We're not yet out of the woods as some of the 423
transactions still have a chance of being doublespent, but looks like
it's not that bad after all.

Cheers,
Chris

P.S.: For a complete list of transactions see http://pastebin.com/wctJU3Ln
--
Christian Decker


On Tue, Mar 12, 2013 at 7:39 PM, Gregory Maxwell <gmaxwell@gmail.com> wrote:


-------------------------------------
On Wed, Nov 06, 2013 at 01:06:47PM -0500, Christophe Biocca wrote:

Speaking of, I hadn't gotten around to doing up the math behind that
strategy properly; turns out 51% I was overly optimistic and the actual
threshold is 29.3%

Suppose I find a block. I have Q hashing power, and the rest of the
network 1-Q. Should I tell the rest of the network, or withhold that
block and hope I find a second one?

Now in a purely inflation subsidy environment, where I don't care about
the other miners success, of course I should publish. However, if my
goals are to find *more* blocks than the other miners for whatever
reason, maybe because transaction fees matter or I'm trying to get
nLockTime'd announce/commit fee sacrifices, it gets more complicated.


There are three possible outcomes:

1) I find the next block, probability Q
2) They find the next block, probability 1-Q
2.1) I find the next block, probability Q, or (1-Q)*Q in total.
2.2) They find the next block, probability (1-Q)^2 in total.

Note how only in the last option do I lose. So how much hashing power do
I need before it is just as likely that the other miners will find two
blocks before I find either one block, or two blocks? Easy enough:

Q + (1-Q)*Q = (1-Q)^2 -> Q^2 - Q + 1/2 -> Q = (1 - \sqrt(2))/2

Q ~= 29.2%

So basically, if I'm trying to beat other miners, once I have >29.3% of
the hashing power I have no incentive to publish the blocks I mine!

But hang on, does it matter if I'm the one who actually has that hashing
power? What if I just make sure that only >29.3% of the hashing power
has that block? If my goal is to make sure that someone does useless
work, and/or they are working on a lower height block than me, then no,
I don't care, which means my original "send blocks to >51% of the
hashing power" analysis was actually wrong, and the strategy is even
more crazy: "send blocks to >29.3% of the hashing power" (!)


Lets suppose I know that I'm two blocks ahead:

1) I find the next block: Q                    (3:0)
2) They find the next block: (1-Q)             (2:1)
2.1) I find the next block: (1-Q)*Q            (3:1)
2.2) They find the next block: (1-Q)^2         (2:2)
2.2.1) I find the next block: (1-Q)^2 * Q      (3:2)
2.2.2) They find the next block: (1-Q)^3       (2:3)

At what hashing power should I release my blocks? So remember, I win
this round on outcomes 1, 2.1, 2.2.1 and they only win on 2.2.2:

Q + (1-Q)*Q + (1-Q)^2*Q = (1-Q)^3 -> Q = 1 - 2^-3

Q ~= 20.6%

Interesting... so as I get further ahead, or to be exact the group of
miners who have a given block gets further ahead, I need less hashing
power for my incentives to be to *not* publish the block I just found.
Conversely this means I should try to make my blocks propagate to less
of the hashing power, by whatever means necessary.

Now remember, none of the above strategy requires me to have a special
low-latency network or anything fancy. I don't even have to have a lot
of hashing power - the strategy still works if I'm, say, a 5% pool. It
just means I don't have the incentives people thought I did to propagate
my blocks widely.

The other nasty thing about this, is suppose I'm a miner and recently
got a block from another miner: should I forward that block, or not
bother? Well, it depends: if I have no idea how much of the hashing
power has that block, I should forward the block. But again, if my goal
is to be most likely to get the next block, I should only forward in
such a way that >30% of the hashing power has the block.

This means that if I have some information about what % already has that
block, I have less incentive to forward! For instance, suppose that
every major miner has been publishing their node addresses in their
blocks - I'll have a pretty good idea of who probably has that most
recent block, so I can easily make a well-optimized decision not to
forward. Similarly because the 30% hashing power figure is the
*integral* of time * hashes/second, if miners are forwarding
near-target-headers, I might as well wait a few seconds and see if I see
any near-target-headers; if I do for this block then I have evidence
that hashing power does have it, and I shouldn't forward.


So yeah, we're fucked and have got to fix this awful incentive structure
somehow before the inflation subsidy gets any smaller. Also, raising the
blocksize, especially by just removing the limit, is utter madness given
it can be used to slow down block propagation selectively, so the
hashing power that gets a given block is limited repeatably to the same
group.


P.S: If any large pools want to try this stuff out, give me a shout. You
have my PGP key - confidentiality assured.

P.P.S: If you're mining on a pool with more than, like, 1% hashing
power, do the math on varience... Seriously, stop it and go mine on a
smaller pool, or better yet, p2pool.

-- 
'peter'[:-1]@petertodd.org
00000000000000078b970f5134bae96da021744f80e04aa9dc2e2d2c2bcb07c2
-------------------------------------
Just keep in mind it will be a little awkward that 54.3 uBTC is the
smallest unit that can be transferred [easily] and the standard fees are
500 uBTC.    It's not a deal breaker, it's just something that needs to
be taken into consideration when it comes to user perception (which is
one of the reasons we would make such a change in the first place). 

"Holy crap these fees are huge!  I thought Bitcoin didn't have fees!"


On 11/14/2013 04:55 PM, Allen Piscitello wrote:
perfectly with Satoshi's being the decimal units.  Something that costs
$10USD would be 25000uBTC.  This isn't a problem for a place like South
Korea, where 10USD is about 10,000 Won, so we aren't even off on a scale
of usable currencies in major economies.
lost coins), and possibly from a psychological perspective on price
(uBTC are worthless!).  On the other hand, it also might help people
feel like they are getting in on the ground floor still (I own 100,000
uBTC!), and reduce the perception the Bitcoins are not divisible (I have
heard several people worry that 21 million is not enough units).
helpful to solving the confusion issue.
<mailto:mark@monetize.io>> wrote:
------------------------------------------------------------------------------
Apps
server.
Native!
http://pubads.g.doubleclick.net/gampad/clk?id=63469471&iu=/4140/ostg.clktrk
<mailto:Bitcoin-development@lists.sourceforge.net>
------------------------------------------------------------------------------
http://pubads.g.doubleclick.net/gampad/clk?id=63469471&iu=/4140/ostg.clktrk


-------------------------------------
I see payment URIs rather as a replacement for bitcoin: URI rather
than an extension. It solves everything they did in a much cleaner
way, Given that bitcoin: have gotten some traction, we probably want
to reuse the moniker, but replace the rest entirely. In other words,
if a request is specified, nothing else should be.

There is just no useful way to combine them either - payments
generalize destinations to arbitrary scripts, messages are handled
inline, amounts are defined inline. And if you want to rely on the
payment infrastructure to work, you cannot risk people using the
old-style static address in the URI.



On Wed, Aug 7, 2013 at 11:47 PM, Roy Badami <roy@gnomon.org.uk> wrote:


-------------------------------------
I've got a better idea.  Ben Bernake needs a new job.  Let's just let him
set the block reward.


On Mon, Dec 9, 2013 at 5:23 PM, Jameson Lopp <jameson.lopp@gmail.com> wrote:

-------------------------------------
On Tue, Sep 10, 2013 at 2:03 PM, Matthew Mitchell
<matthewmitchell@godofgod.co.uk> wrote:

Ouch.

This sounds like something that $20 of mechanical turk time could help
out with a lot.  Put up the 2048 words and ask people to rate them for
potential offensiveness and threatening. :)

Nouns often make for fairly neutral words, though careful for place
names which have had political complications. E.g. gdansk vs danzig.


-------------------------------------
On Saturday, May 25, 2013 8:25:35 AM Melvin Carvalho wrote:

Bitcoin is a consensus system. You can't run clients with different rules on 
the same blockchain/network - it just won't work! Maybe we're now talking 
about mere client default policies? In which case, you should be able to 
configure previous behaviour...

If you want just bug fixes and rule changes, without policy default changes, 
new features, etc, you can use the 0.4.x - 0.7.x backports. But be advised 
these are short-term solutions and won't be maintained forever - so you really 
should try to get the behaviour you want from the current release. If you 
can't for some reason, please do report a bug explaining what it is the older 
version was capable of that the new one isn't!

Luke


-------------------------------------
On Tue, Oct 29, 2013 at 10:52:31AM +0100, Mike Hearn wrote:

That would prevent us from using nVersion as a soft-forking mechanism.

-- 
'peter'[:-1]@petertodd.org
000000000000000908fddb47210344de50e6d3bd842e649c68853eeee0390dcd
-------------------------------------
Hey Wendell,

Interesting idea you have there!

On Wed, Sep 4, 2013 at 9:47 PM, Wendell <w@grabhive.com> wrote:


It might be simpler to not think of it as an app store, but rather see it
as a set of affiliate schemes. To get placed into the apps section you can
say that the business must have an affiliate scheme in place (i.e. open to
more than just you) and then you use the normal mechanisms of affiliate
codes and so on. The apps don't have to be offline. They can (and probably
should) be online, so the businesses can retain control of their features
and brand. If you refer a lot of users to that business, you get the
referral bonuses. Affiliate schemes are a common way for open source
projects to monetize - e.g. Firefox development is largely paid for by
search engine referrals. It's compatible with the ideals of openness
because their income relies directly on their traffic, and there are
several competing search engines the projects can play off against each
other to get the best prices. Also, users expect search engine integration
these days, so they'd be sending search traffic regardless.

The main downside, of course, is it distorts technical judgement. You can
get projects pushing certain businesses heavily not because it's
technically the best thing for users, but because their income depends on
it.

One alternative funding model you could explore is allowing users to bid on
assurance contracts for feature development. This means you think up a
bunch of improvements you could make, then allow users to pledge
Kickstarter-style towards their development. The upside is it allows the
community to direct development, and users feel directly involved and not
exploited. The downside is, no recurring income you can use to support
yourself whilst engaged in other endeavours.

2) Although our BitcoinKit.framework supports both bitcoind and bitcoinj,

Bear in mind that regardless of how much *you* want to support the network,
it's ultimately *your users* resources that will actually get spent. That's
why I'm a bit skeptical of any schemes that rely on random end users
donating lots of cpu time or bandwidth to the network. If they want to do
it, partial UTXO sets and other interesting ideas are worthwhile, but I
guess most users won't. I think Bitcoin will over time be more and more
like Tor where relays are run on dedicated servers by people who have some
modicum of knowledge and community involvement.
-------------------------------------
Code that runs inside NativeClient has the same access level as JavaScript
does. It's just a way to do things faster.

Distribution as a Chrome app via the Chrome store is a fine approach, as
long as people understand it's just an app platform like any other. It has
pros and cons that must be weighed up. For instance, Chrome for mobile
doesn't really do apps, at least not at the moment. Also, you're still
limited by what APIs Chrome exposes, which are a strict subset of what a
real OS provides.


On Fri, Aug 9, 2013 at 2:05 PM, Wendell <w@grabhive.com> wrote:

-------------------------------------
A ban-subnet RPC would be a reasonable addition, but obviously DoS
attackers that are IP or bandwidth constrained are really just script
kiddies. Also anything that involves every node operator doing manual
intervention rather works against decentralisation and having a big
network. That's why I keep pushing for automated heuristic driven
prioritisation.


On Fri, Aug 16, 2013 at 3:41 PM, Warren Togami Jr. <wtogami@gmail.com>wrote:

-------------------------------------
Amazingly thorough, Peter. Thanks so much!

-wendell

hivewallet.com | twitter.com/hivewallet | pgp: B7179FA88C498718

On Dec 19, 2013, at 8:17 AM, Peter Todd wrote:


-------------------------------------
On Thursday, November 14, 2013 10:53:16 PM Alan Reiner wrote:

As long as we're using SI units, IMO we should stick to SI. That means "micro-
bitcoins". *Informally/spoken*, an abbreviation like "mibicoins" might make 
sense.

Luke


-------------------------------------
Patrick, could you please explain us why the solution proposed by Ittay
would drop the actual honest miners ratio, becoming so backfire? Thanks a
lot


2013/11/5 Patrick <patrick@intersango.com>

-------------------------------------
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256

On Mon, Jun 10, 2013 at 4:44 AM, Edmund Broadley <rebroad@gmail.com> wrote:

The default should *not* be set by wallets at all in fact. The default is that
by not voting, you accept the status quo, which is defined as the mean of the
old and new limits in the past year.

So lets say the limit is 1MB, and through voting it ends up at 2MB in one year.
Until that time by not voting you are in effect voting for the limit to be 1MB,
but after the next interval you not voting is equivalent to voting for a 1.5MB
limit. A subtle issue is then txout age, and at that point a 1.5 year old txout
should be like voting for the 1MB limit still, albeit weighted less. What you
don't want is your lack of vote to suddenly turn into a 1.5MB vote. This makes
sure that at all levels the increases are gradual rather than abrupt, although
the rate of increase may still be quite fast if the community votes that way.
(first derivative of the limit is a close approximation to a continuous
function)
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBCAAGBQJRtV0iAAoJEEWCsU4mNhiPRDIH+wapKxD0fc2div9gkhxZ4qVt
9Wh4u1vKM4RsxdPgh9uKFJomjErBXBROJ57cJqB1rwHt1xhUyHgbC8JstU0PWzUM
Ygwgibe9nsSjqHp2w15Bat+NmkYpxrjmVhf9woZkPQl+A1bWd3MFXOGoTIPPCl3I
KkMTaR3VbZDwqg0DlteZMR2im2DkT4zDsCkSb8KSCoaeTEdafkPceVHWU6isWxV9
Y0TGFCKaoMjxqxnkgH+vHsJlIM4E3rb0NHTo8rHD7Hm1txw/4/fVwE56/9U+8FaK
XAPXS0gkIR83V7cWMLa/q6LpZyzJmfFXCZhjT4YxVqeq/wB/SR9j2hhNdLnjuCo=
=y1c+
-----END PGP SIGNATURE-----


-------------------------------------
On Sun, Dec 8, 2013 at 12:40 PM, Drak <drak@zikula.org> wrote:

Sadly this isn't true: There are (many) CAs which will issue a
certificate (apparently sometime within minutes, though last
certificate I obtained took a couple hours total) to anyone who can
respond to http (not https) requests on behalf of the domain from the
perspective of the CA.

This means you can MITM the site, pass all traffic through except the
HTTP request from the CA, and start intercepting once the CA has
signed your certificate. This works because the CA does nothing to
verify identity except check that the requester can control the site.

If you'd like to me to demonstrate this attack for you I'd be willingâ€”
I can provide a proxy that passes on :80 and :443, run your traffic
through it and I'll get a cert with your domain name.

I'm sorry for the tangent hereâ€” I think this sub-discussion is really
unrelated to having Bitcoin.org behind SSLâ€” but "someone is wrong on
the internet", and its important to know that SSL hardly does anything
to reduce the need to check the offline signatures on the binaries.


-------------------------------------
On Sat, Mar 23, 2013 at 9:22 PM, Gregory Maxwell <gmaxwell@gmail.com> wrote:

Darn near everything can be shoehorned into a "message"   So
absolutely agreed... in theory.  Been an SCTP fan for years.

Firewall practices tend to put a damper on cool new protocols like that, though.

-- 
Jeff Garzik
exMULTI, Inc.
jgarzik@exmulti.com


-------------------------------------
On Wed, Nov 13, 2013 at 12:52:21PM +0100, Michael Gronager wrote:

Assuming t_0 is negligible is wrong in this case. Or, it should be...


So alpha has units of seconds/byte, which lets us indirectly figure out
the bandwidth the blocks are propagating at assuming t_0=0 and all links
are equal. When you realize that P_fork is basically a multiplier on the
bandwidth required to get a block out fast enough, the derivation makes
sense. In any case we get:

alpha = (1/113)*600s/134kBytes = 39.62uS/byte = 24kB/second

Which is atrocious... but when you remember that Bitcoin nodes send
blocks to all peers simultaneously,(1) thus dividing up the bandwidth and
ruining latency you see why. t_0 shouldn't be at all negligible due to
speed of light, but with this low bandwidth it is anyway.

1) To be precise, nodes answer queries for blocks from all peers
simultaneously.

This also indicates that pools haven't taken the simple step of peering
with each other using high-bandwidth nodes with restricted numbers of
peers, which shows you how little attention they are paying to
optimizing profits.  Right now mining pulls in $1.8 million/day, so
that's up to $16k wasted.

However, because miners don't orphan themselves, that $16k loss is born
disproportionately by smaller miners... which also means the 24kB/sec
bandwidth estimate is wrong, and the real number is even worse. In
theory anyway, could just as easily be the case that larger pools have
screwed up relaying still such that p2pool's forwarding wins.

-- 
'peter'[:-1]@petertodd.org
000000000000000658459cd64e63243e719106014257870d073207c2d5460137
-------------------------------------
On Sun, Oct 20, 2013 at 08:27:47PM -0400, Jeff Garzik wrote:

Done: https://github.com/petertodd/bips/

GitHub supports MediaWiki these days, so just directly copying from
'View Source' in the bitcoin.it wiki worked pretty well; I archived the
exact text of BIP. Tables, images and math is all supported by github
and look fine, although github doesn't seem to support coloration in
tables. Users wishing to edit their pull-req's or create new ones can do
so easily by forking the repository - they can see their changes as they
go in GitHub.

I've probably missed some stuff re: formatting, and I haven't changed
any of the submission guideline text in bip 1 yet, but that's probably
90% of the work done.

-- 
'peter'[:-1]@petertodd.org
000000000000000245a735ccc14b98552e152f773c07efa2e89dd7f0463f61cf
-------------------------------------
More somewhat improved crypto stuff...

On Thu, May 16, 2013 at 01:32:22PM +0200, Adam Back wrote:

Actually same K every time is not so hot, as then earlier in the committed
spend chain, can force a reveal for someone later.  A clearer requirement is
that each person should only be able to reveal committed coin chains up to
the point of their direct involvement.

So that is easily fixable, just include the K for the input committed coin
in the encrypted-tx-commit, as above but:

	encrypted-tx-commit = AES( K_i, K_{i-1} || tx-commit )
	K_i = random

(different K for each spend).

And actually for symmetric encrypted variant the coin as specified was
already evaluatable with fixed size committed spend (of the last public key)
- I just didnt realize it in the previous mail: the input public key is
necessarily revealed when processing the decrypted tx-commit, allowing
identification and validation of the txin, and validation recursively back
to the first non-committed coin.  With symmetric verification, the
limitation is one-use coin committed addresses (and inability to remove
spend to committed junk with public validation, though there is the tx fee
as a discouragement, it does bloat a recipients verification and so maybe
frustates SPV->SPV consumption of committed coins).

(blind-sender, auth-tag, encrypted-tx-commit)

         blind-sender = SHA1( SHA256( 1, pub ) )
         auth = HMAC-SHA256-128( K, encrypted-tx-commit )
         encrypted-tx-commit = AES( K, tx-commit )
         K = SHA-256( pub )

Adam

ps and it would be better and clearer to read also in terms of purpose of
hashes, to use a KDF like IEEE P1363 KDF2, or PKCS#5 PBKDF2 with 1
iteration, rather than adhoc hashes for key derivation.


-------------------------------------
There was some chat on IRC about a mining pool reaching 46%

http://blockchain.info/pools

What's the risk of a 51% attack.

I suggested that the pool itself is decentralized so you could not launch
one

On IRC people were saying that the pool owner gets to choose what goes in
the block

Surely with random non colliding nonces, it would be almost impossible to
coordinate a 51% even by the owner

Someone came back and said that creating random numbers on a GPU is hard.
But what about just creating ONE random number and incrementing from there
...

It would be great to know if this is a threat or a non issue
-------------------------------------
P2SH addresses support exotic transaction outputs, but not all exotic
transactions. This payment protocol can allow for combining multiple
outputs. A PaymentRequest for sending money to multiple parties, for
example, could not fall back to a single address.


On Wed, Jul 31, 2013 at 5:38 PM, Gavin Andresen <gavinandresen@gmail.com>wrote:

-------------------------------------
On Mon, Dec 9, 2013 at 9:07 AM, Warren Togami Jr. <wtogami@gmail.com> wrote:


I see:
  db/autocompact_test.cc

... which I assume is a leveldb unit test file that should be in
src/leveldb/db/

Not a showstopper bug.

Given we've had hundreds of downloads and no reports of insanity, I think
we should tag v0.8.6 today (same commit as v0.8.6rc1) and ship it.

-- 
--
Gavin Andresen
-------------------------------------
On 15 November 2013 01:37, Daniel F <nanotube@gmail.com> wrote:


I do agree with you here

e.g. I think the question of the ISO code (XBT vs BTC) is probably out of
scope for this thread, and there was no clear consensus, when it came up on
the forums.

As a data point, the price of bitcoin has gone up roughly 1000x since
satoshi made his suggestion that the decimal point could move 3 places.

I dont think it's a question of centralization, I was just seeking opinion
on what people felt about the reference implementation.  How about just
changing the default value in the dropdown from BTC -> to mBTC

The the other clients and exchange choose whether they want to follow suit
or not

-------------------------------------
It's not a bug (although there was recently a change to make bitcoind/qt
always send this field anyway).

I don't know where Amir is going with BIP 60. Version messages have always
been variable length. There's nothing inherent in the Bitcoin protocol that
says all messages are fixed length, indeed, tx messages are allowed to have
arbitrary data appended after them that gets relayed.


On Tue, Jun 18, 2013 at 7:45 PM, Turkey Breast <turkeybreast@yahoo.com>wrote:

-------------------------------------
A JSON-ed version of the test vectors is here: https://github.com/bitsofproof/supernode/blob/master/api/src/test/resources/BIP32.json

The Bits of Proof code matching with them is at:
https://github.com/bitsofproof/supernode/blob/master/api/src/main/java/com/bitsofproof/supernode/api/ExtendedKey.java

Tamas Blummer
-------------------------------------
but although they will expose ECC via the NSS, I dont think bitcoin's
particular curve will be supported, because it's not NIST approved. If the
use case was presented though, they may add it.

Trezor, my friend.

Slush

Sent from mobile phone.
-------------------------------------
On Saturday, November 16, 2013 12:41:56 AM Drak wrote:

"Confirmations" in a numeric context isn't correct, though. We're using to it 
because we've been using Bitcoin so long, but to the average person they would 
expect it to mean something more than it is. If not referring to blocks, then 
perhaps "witnessed N times"?


I think you might be demonstrating my point with regard to user confusion 
here. Bitcoin addresses are *not* like email addresses, paypal ids, etc. 
Bitcoin addresses aren't the destination - they're point to a destination (an 
account in a wallet), but they also represent information such as who is 
paying and what for - in other words, a specific invoice.

Luke


-------------------------------------
On Mon, Dec 16, 2013 at 11:13 AM, Drak <drak@zikula.org> wrote:


Bitcoin-qt (in master) always shows the fee and total amount that is going
to be paid in the confirmation dialog, so it is very hard to accidentally a
very high fee.

Wladimir
-------------------------------------
Thanks. By the way, your bitnodes site is excellent. Thanks for doing that.
If you're in the mood for extending it, it'd be great to gather and chart
data on block and tx propagation times.

Do you think the recent explosion in running nodes is real, or due to some
kind of custom experimental thing?


On Thu, Nov 21, 2013 at 2:55 PM, Addy Yeow <ayeowch@gmail.com> wrote:

-------------------------------------
Hi all,

we just finalized the draft and reference implementation of BIP39. Regards
to rules in BIP0001 we're asking for comments.

The aim of the proposal is to standardize algorithm across various clients
and fix some design problems of existing (but not yet standardized)
Electrum mnemonic algorithm.

BIP39 is a nice complement to BIP32, which allow users to (paper) backup
and share their wallet accross multiple clients easily.

Link to BIP: https://en.bitcoin.it/wiki/BIP_0039

Thanks for your time,
slush
-------------------------------------
On Tue, Nov 19, 2013 at 6:01 PM, Gregory Maxwell <gmaxwell@gmail.com> wrote:


Talking about complete, BIP 40 and 41 don't even have an associated
document:
https://github.com/bitcoin/bips
I agree that was over-eager number assigning.

Wladimir
-------------------------------------
Hi there,

I am not sure this wont be considered as off-topic here, but I did not find
a better place to ask. My question is - has anybody here thought about the
idea of variable block rewards where mining would essentially be popularity
based? I mean in terms either improving Bitcoin's protocol or forking a
completely new coin? I think elasticity of money supply could bring more
exchange rate stability to the hypothetical new coin (say there'd be a
demand for such a coin). I am thinking of an alternative mining scheme
where block reward would grow (or decrease) with popularity of the coin.
The rationale behind this idea is to make an exchange rate more stable
since greater interest will not result in higher coin price.

Evidence clearly shows Bitcoin lacks some basic features of money and thus
behaves more like a commodity (read gold). I have been watching the
exchange rate for several months and the volatility simply does not seem to
go away... so it seems like something has to change in order to get a more
stable currency. I am not telling I want Bitcoin to implement this, I fully
understand that a philosophy of "one coin = never changing features" can be
present that is why I also speak about a fork.

Basically there would be no reliance on external data as the network itself
would decide on reward height and everybody node would be free to do so.
Each network node would determine the popularity on its own depending on
various factors (coin valuation/exchange rate, number of transactions and
many others) and basically come up with its own block reward value. It
would then want to see a new block being mined with such reward value. In
case such a block is mined, it will include it in its own chain. There'd be
some %s of tolerance for block reward value so that the system would not
collapse.

I may be completely wrong with my idea but am asking it this was spoken
before and what opinions do developers have.

Regards,
Jan
-------------------------------------


On 06/27/2013 01:56 PM, Gregory Maxwell wrote:


If I were a Bitcoin dev, I would not want to talk about anonymity or
TOR because that's likely to attract people with paranoid dilutions
and they're really terrible users to support :)

Also yay for promoting fast, easy to use clients for casual users!

Thanks,
Caleb





-------------------------------------
I don't use testnet much anymore, partly because it sometimes kind of
breaks like this. It's a public resource and people sometimes abuse it.

You can create your own local network with -regtest and that lets you mint
new blocks instantly. It's a much simpler way to do testing and app
development.


On Fri, Nov 15, 2013 at 8:34 PM, Mike Belshe <mike@belshe.com> wrote:

-------------------------------------
We already have a wonderful system for secure updating - gitian-downloader. We just neither use it not bother making actual gitian releases so anyone can use it to verify signatures of downloads.

Jeremy Spilman <jeremy@taplink.co> wrote:
-------------------------------------
Thanks for the feedback, everybody, gist updated:
  https://gist.github.com/gavinandresen/7079034

Categories are:

0x01-0x0fProtocol syntax errors0x10-0x1fProtocol semantic errors0x40-0x4fServer
policy rule
<https://gist.github.com/gavinandresen/7079034#rejection-codes-common-to-all-message-types>

RE: why not a varint:  because we're never ever going to run out of reject
codes.  Eight are defined right now, if we ever defined eight more I'd be
surprised.

RE: why not use HTTP codes directly: because we'd be fitting round pegs
into square holes.

-- 
--
Gavin Andresen
-------------------------------------

It's a real threat, albeit an exotic one. The threat model is a malware
compromised host, with a wallet (possibly a low power hardware wallet like
a Trezor) that can understand the payment protocol and sign transactions,
but maybe not do a whole lot more than that. For instance, probably it
cannot do HTTPS connections itself. So a virus on the host could swap the
refund address for one that is owned by the attacker, and then try to make
the merchant issue an automatic refund, thus bouncing the funds back off
the merchant to the them.

If there are merchants that offer large, automatic refunds, it could be an
issue. I'm not sure how common that might be in reality. Steven or Tony
would know. Timo's protocol is an interesting solution, but again, at this
point the feature set for v1 is pretty much locked down.
-------------------------------------
On Mon, May 20, 2013 at 9:39 PM, Gavin Andresen <gavinandresen@gmail.com> wrote:

Absolutely.

(to the list:) Is there anyone who is not?  (assuming that it doesn't
allow arbitrary traffic multiplication, which is easily solved)


-------------------------------------
On Tue, May 07, 2013 at 02:16:41PM +0200, Adam Back wrote:

I think the general solution here is providing a feature-reach Python RPC client,
which can do things like remember passwords, command history/tab completion,
perhaps even batch lookups of compound commands (getblock $(getblockhash X, for
example, ...). The naive RPC client built into bitcoind is not a good fit for
many features, as they can much more efficiently be developed outside of the
core binary,



I'm quite opposed to any per-key fiddling in the GUI. This will inevitably lead
to (even more) people misunderstanding how wallets work and shooting themself in
the foot. I don't mind an expert mode ("coin control") that enables such features,
but in general, we should for entire-wallet export and import rather than
individual keys.

Import & sweep an address is something else, that sounds safe to.


This belongs in coin control, IMHO.

-- 
Pieter



-------------------------------------

Agreed Mike.

The economic parameters of Bitcoin are fixed in stone forever. Adding a
monetary authority to Bitcoin is impossible and undesirable because the
implicit contract of Bitcoin is that there would finally be a currency in
which no one could mess around with. It would betray all prior holders.

But these are ideas everyone is free to experiment with in new altcoins. If
the lack of inflation in Bitcoin ever becomes a problem in day-to-day
usage, such a parallel chain could become the de-facto cryptocurrency for
spending. Or just maybe fiat already works well enough there...

Wladimir
-------------- --------------
How do you propose to use Bitcoin on a week-long vacation or for life in
general, when it's value constantly swings up and down? Or for the average
person's paycheck to swing up and down in value every week? Awfully hard to
budget. There is also a catch-22, no altcoin can gain acceptance because
the infrastructure for Bitcoin already exists, but without infrastructure,
no altcoin can gain acceptance. Furthermore, the average merchant or
consumer lacks the idealism or knowledge to bring about such changes in
Bitcoin. It's a lofty idea that the average person will bring about such
change when they don't bring about such change already in their own lives.
It is ironic considering that there's no Bitcoin "chamber of commerce,"
just a few programmers in a development mailing list who direct the future
of Bitcoin, and thus these merchants you speak of have little to no voice
what so ever, with a few exceptions of merchants who do subscribe to this
mailing list.
What I am proposing makes sound economic sense. It is the only way to fix
the speculation crisis.
Just ask an economist.

And the economic parameters of bitcoin are not fixed in stone. If there
needs to be a change, it will be messy but it could happen.

Besides, using Austrian precepts of inflation blurs the fact that deflation
will still be possible under my proposal. Although amusingly enough
Austrian-defined inflation is still occurring within Bitcoin, in fact
faster then desired since blocks are being processed every seven minutes
now as opposed to ten, and it's quite likely when 28nm ASIC miners are
released that blocks will be processed every five minutes before the
difficulty is adjusted again.
-------------------------------------
On Mon, Aug 19, 2013 at 1:22 PM, Goss, Brian C., M.D.
<Goss.Brian@mayo.edu> wrote:

[Aside: When replying to the digest, please try to trim it]

It appears that we will soon be at a hashrate where all the desktop
CPUs in the world couldn't really make a dent in it... certainly not
desktop cpus using the slow integrated cpu miner, which is much slower
than external optimized cpu miners.

But this is why I suggest packaging up a modern mining tool that
supports CPU/GPU/FPGA/ASIC mining against a current bitcoind. Doing so
would reduce the difference between testnet and mainnet, and provide
an actually useful tool for contributing directly.

Though again, I note, that Jeff's patch doesn't actually remove the
integrated miner (I think it shouldâ€¦).  Just the getwork support for
external miners which don't use getblocktemplate... and if you're
going to download one of those you could go download bfgminer instead.


-------------------------------------
On Mon, Oct 28, 2013 at 07:17:50AM +0000, John Dillon wrote:

Here's the easy part done:

https://github.com/petertodd/bitcoin/tree/replace-for-fee

The rules are pretty simple: a replacement can only happen if every
output in the old transaction has a corresponding output in the new with
the same scriptPubKey, and of equal or greater value. All old tx outputs
must also be unspent. For implementation reasons, the order of the
outputs must also be the same, and the code will never replace two
transactions with one.

If someone wanted to mine with the above code, I'd say go right ahead.
(modulo general testing concerns)

Client-side though it shows a flaw with the Bitcoin wallet code that I
should have realized months ago: essentially a transaction in your
wallet with double-spent inputs forever blocks those inputs from being
spent. This doesn't happen too often because you're wallet will
currently never create double-spends, and will never respend unconfirmed
coins from someone else, but any CoinJoin implementation violates that
assumption and an attacker could easily cause a lot of havok.

I'll have to think about the issue further, but essentially the wallet
needs to recognize when a transaction's inputs no longer exist, and mark
the remaining inputs as unspent. Actually deleting those transactions
from your wallet is secondary to that more important concern.

-- 
'peter'[:-1]@petertodd.org
000000002fdfe6bbcffea72c934475cd4fcfe78d8d06910016d707c9b4a9e827
-------------------------------------
I think it's important to expect PaymentRequest-only bitcoin URIs in the
future. Some types of payments (exotic transactions) may not make sense to
have a single fallback address. Or, a page with a bitcoin URI link may be
relying on a separate service provider to assemble the transaction.


On Wed, Jul 31, 2013 at 5:33 AM, Gavin Andresen <gavinandresen@gmail.com>wrote:

-------------------------------------
On 19 November 2013 17:01, Gregory Maxwell <gmaxwell@gmail.com> wrote:


I wasnt suggesting people add drafts willy nilly to the repository.
When working on a proposal you can work on it in your own fork and create a
PR. When it's ready to be accepted as a working draft by the WG, then it
can be merged into the draft folder. At which point, PRs are made to that
draft copy until it gets into a ready state to become final. If passed,
it's moved to the accepted/ folder.

This way random BIPS cannot be added to the drafts/ folder in the official
repo. They are only added once they are accepted as a working draft
proposal by Gavin or whatever. Now you get all the niceties of github
workflow for collaboration and tweaking of the draft proposal.

Drak
-------------------------------------
On Wed, Feb 13, 2013 at 05:02:39PM -0800, Gregory Maxwell wrote:

Speaking of fidelity bonded banks I think it needs to be made clear that
really trustworthy bonded banks require the maximum block size to be
kept limited. The problem is that even if you don't create any
transactions on the chain yourself, you still need to be able to keep
watch the chain to keep track of what the bank is doing. For instance if
you are trying to decide if you can trust the bank with a 1BTC deposit,
and they've purchased a 1000BTC fidelity bond, you still need to be able
to determine if all the unspent transaction outputs in the blockchain
that the bank could spend, in addition to all the unspen transactions in
the mempool, are less than the value of their fidelity bond. With 1MiB
blocks that will be practical on smartphones with wireless internet
connectivity without having to trust anyone else. With 1GiB blocks that
just won't be true and you'll be forced to trust the relatively few
nodes out there with the hardware to deal with the blockchain. You'll
pay for it too.

Potentially the various UTXO proposals will help, but they will need to
be quite sophisticated; we'll need sums of all txout values by
scriptPubKey and a fraud notice system for instance. All of this stuff
is at best many months away from even beginning to be deployed on the
network, and probably years away from getting to the point where it is
truely trustworthy. Maybe it'll never become trustworthy, either because
miners just don't bother, the code doesn't get written, or a flaw in the
whole idea is found. We're just not going to know until these
technologies are implemented and tested, and without them, large blocks
force us into trusting miners blindly and make many valuable
applications impossible.

-- 
'peter'[:-1]@petertodd.org
-------------------------------------
On Fri, Oct 04, 2013 at 02:14:19PM +0200, Mike Hearn wrote:


It's a long shot, but have any of you looked into Fossil?


-------------------------------------
On Wed, May 15, 2013 at 7:22 PM, Mike Hearn <mike@plan99.net> wrote:

Zerocoin conceals the connection from everyone forever, assuming the
underlying trapdoor problem is computational infeasible, but at great
cost.

Adamcoin, depending on how its done, at most conceals the transactions
from people who aren't a party to them... though as time goes on
eventually everyone becomes a party to a sufficiently old coin, and
avoiding publication creates quadratic costs in evaluating a private
clique's claims.... so instead an implementation would make the
identities public but only once they're burred a bit.

Perhaps an extreme version of the idea is easier to understand. Ignore
DOS attacks for a moment and pretend there is never any address reuse:

Everyone creates txouts paying a P2SH addresses that have a OP_PUSH
nonce in them and tell you recipient the nonce out of band.

When the recipients spend those coins they provide the script but not the nonce.

The recipient knows what coins he's spending, but the public does not.

The public can tell there is no double spend though, because they'd
see the same script twice. The person he's paying may be skeptical
that he actually has any coin and didn't just mine some gibberish, but
our spender tells that their receiver the nonce, and that person can
see the coin available for spending in the chain and also see that
there are no double spends.

This could actually go on forever with no ambiguity over who owns
what, but the out of band proofs that you have to give people when you
spend coins would grow with the history of the coins.

Since there wouldn't be much privacy once a transaction was
sufficiently split up in any case, you instead just publish the
unblindings once transactions are sufficiently buried. Thus bounding
the growth of the proofs.   The reason I say I need to internalize
this more is mostly that I need to think about attacks on the
publication for 'tained' transactions being more or less isomorphic
to just refusing to allow spending of the 'tainted' coins in any case.


-------------------------------------
I highly recommend that if we make any move towards this, that the
software show verification in both/all units.

For instance, there should be 3 input fields, one for "BTC", one for
"mBTC" one for "uBTC".  As the user enters a value in one of the fields,
it would automatically update the other fields with the converted value
as they type.  This makes it really difficult to get it wrong... if
you're typing "10" into the BTC field, thinking it's mBTC, you'll see
10,000 mBTC showing up in the other box as you type.  Similarly, it
should display all units on all verification windows.  Users may also
use it for sanity checking conversion between units.

Personally, I'm of the opinion that this change is important in the long
run:  the current price makes Bitcoin *intimidating* to new users.  But
I'm also of the opinion that it's freakin' hard to change the base unit
in such an established system.  There is no easy way to do this that
doesn't cause more heartache than it's worth.  But it's possible if you
make it idiot-proof enough, and roll it out in the least inconvenient way.

-Alan


On 11/14/2013 06:45 AM, Melvin Carvalho wrote:

-------------------------------------
There have been a few not-quite-serious-enough-to-justify-a-release
security fixes that, along with a couple of serious bugs, we think together
DO justify a new 0.8.* release.

So I just created a 0.8.4 branch, based on the 0.8.3 branch, and will be
cherry-picking from the master branch.

Planned changes from the 0.8.3 release:

Security-related:
42656ea  Make RPC password resistant to timing attacks
159bc48  Simplify storage of orphan transactions, fix CVE-2013-4627
37c6389  Performance optimization for bloom filters (help mitigate
potential DoS attack discussed last week)

Bug fixes:
9bf2a4ab  Fix multi-block reorg transaction resurrection
bf81a3ef  Fix Gnome bitcoin: URI handler
f0784ac4  Fix non-standard disconnected transactions causing mempool orphans
2461aba1  Mempool consistency check
pull 2916  Import OSX fsync change from LevelDB subtree  (will hopefully
fix the random-OSX leveldb corruption issues)

There are lots of little fixes that could be included, but those will wait
for the 0.9 release.

-- 
--
Gavin Andresen
-------------------------------------
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Hello fellow bitcoin developers. Included below is the first draft of
a BIP for a new Merkle-compressed data structure. The need for this
data structure arose out of the misnamed "Ultimate blockchain
compression" project, but it has since been recognized to have many
other applications.

In addition to this BIP I am preparing three additional BIPs
describing the use of this data structure in stateless validation &
mining, the UBC address index for "SPV+" operating modes, document
timestamping and merged mining.

A Python implementation of this data structure is available here:

https://github.com/monetizeio/python-bitcoin

A C++ implementation is being worked on.

As per the BIP-1 procedure, I am submitting this rough draft to the
community for discussion. I welcome all comments and criticisms of
both form and content.

- -Mark


==Abstract==

This BIP describes a [http://en.wikipedia.org/wiki/Hash_tree Merkle
hash tree] variant of the [http://en.wikipedia.org/wiki/Trie
prefix-tree data structure], ideally suited for encoding key-value
indices which support memory-efficient proofs.

==Motivation==

There are a number of applications which would benefit from having a
data structure with the following properties:

* '''Arbitrary mapping of keys to values.''' A ''key'' can be any
bytestring, and its ''value'' any other bytestring.
* '''Duplicate keys disallowed.''' Every key has one, and only one
value associated with it. Some applications demand assurance that no
key value is reused, and that this constraint can be checked without
requiring access to the entire data structure.
* '''Efficient look-up by key.''' The data structure should support
sub-linear lookup operations with respect to the number of keys in the
mapping. Logarithmic time or linear with respect to the length of the
key should be achievable and would be sufficient for realistic
applications.
* '''Merkle compression of mapping structure.''' It should be possible
to produce a reduced description of the tree consisting of a single
root hash value which is deterministically calculated from the mapping
structure.
* '''Efficient proofs of inclusion.''' It should be possible to
extract a proof of key/value mapping which is limited in size and
verification time by the length of the key in the worst case.
* '''Computation of updates using local information.''' Given a set of
inclusion proofs, it should be possible to calculate adjustments to
the local mapping structure (update or deletion of included mappings,
or insertion between two included mappings which are adjacent in the
global structure).

Such applications include committed validation indices which enable
stateless mining nodes, committed wallet indices which enable
trust-less querying of the unspent transaction output set by
<code>scriptPubKey</code>, efficient document time-stamping, and
secure & efficient merged mining. This BIP describes an authenticated
prefix tree which has the above properties, but leaves the myriad
applications to be formalized in future BIPs.

==Data structure==

This BIP defines a binary prefix tree. Such a structure provides a
mapping of bitstrings (the ''keys'') to bytestrings (the ''values'').
It is an acyclic binary tree which implicitly encodes keys within the
traversal path -- a "left" branch is a 0, and a "right" branch is a 1.
Each node is reachable by only one unique path, and reading off the
branches taken (0 for each left, 1 for each right) as one follows the
path from root to target yields the node's key.

The particular binary prefix tree defined by this BIP is a hybrid
PATRICIA / de la Brandais tree structure.
[http://en.wikipedia.org/wiki/Radix_tree PATRICIA trees] compress a
long sequence of non-branching nodes into a single interior node with
a per-branch ''skip prefix''. This achieves significant savings in
storage space, root hash calculation, and traversal time.

A de la Brandais trie achieves compression by only storing branches
actually taken in a node. The space savings are minimal for a binary
tree, but place the serialized size of a non-branching interior node
under the SHA-256 block size, thereby reducing the number of hash
operations required to perform updates and validate proofs.

This BIP describes the authenticated prefix tree and its many
variations in terms of its serialized representation. Additional BIPs
describe the application of authenticated prefix trees to such
applications as committed indices, document time-stamping, and merged
mining.

==Serialization format==

As a hierarchical structure, the serialization of an entire tree is
the serialization of its root node. A serialized node is the
concatenation of five structures:

    node := flags || VARCHAR(extra) || value || left || right

The <code>flags</code> is a single byte field whose composite values
determine the bytes that follow.

    flags = (left_flags  << 0) |
            (right_flags << 2) |
            (has_value   << 4) |
            (prune_left  << 5) |
            (prune_right << 6) |
            (prune_value << 7)

The <code>left_flags</code> and <code>right_flags</code> are special
2-bit enumeration fields. A value of 0 indicates that the node does
not branch in this direction, and the corresponding <code>left</code>
or <code>right</code> branch is missing (replaced with the empty
string in the node serialization). A value of 1 indicates a single bit
key prefix for this branch, implicitly 0 for <code>left</code> and 1
for <code>right</code>. A 2 indicates up to 7 bits of additional skip
prefix (beyond the implicit first bit, making 8 bits total) are stored
in a compact single-byte format. A 3 indicates a skip prefix with
greater than 7 additional bits, stored length-prefix encoded.

The single bit <code>has_value</code> indicates whether the node
stores a data bytestring, the value associated with its key prefix.
Since keys may be any value or length, including one key being a
prefix of another, it is possible for interior nodes in addition to
leaf nodes to have values associated with them, and therefore an
explicit value-existence bit is required.

The remaining three bits are used for proof extraction, and are masked
away prior to hash operations. <code>prune_left</code> indicates that
the entire left branch has been pruned. <code>prune_right</code> has
similar meaning for the right branch. If <code>has_value</code> is
set, <code>prune_value</code> may be set to exclude the node's value
from encoded proof. This is necessary field for interior nodes, since
it is possible that their values may be pruned while their children
are not.

The <code>value</code> field is only present if the bit
<code>flags.has_value</code> is set, in which case it is a
<code>VARCHAR</code> bytestring:

    switch flags.has_value:
      case 0:
        value := Îµ
      case 1:
        value := VARCHAR(node.value)

The <code>extra</code> field is always present, and takes on a
bytestring value defined by the particular application. Use of the
<code>extra</code> field is application dependent, and will not be
covered in this specification. It can be set to the empty bytestring
(serialized as a single zero byte) if the application has no use for
the <code>extra</code> field.

    value := VARCHAR(calculate_extra(node))

The <code>left</code> and <code>right</code> non-terminals are only
present if the corresponding <code>flags.left_flags</code> or
<code>flags.right_flags</code> are non-zero. The format depends on the
value of this flags setting:

    switch branch_flags:
      case 0:
        branch := Îµ
      case 1:
        branch := branch_node_or_hash
      case 2:
        prefix  = prefix >> 1
        branch := int_to_byte(1 << len(prefix) | bits_to_int(prefix)) ||
                  branch_node_or_hash
      case 3:
        prefix  = prefix >> 1
        branch := VARINT(len(prefix) - 9) ||
                  bits_to_string(prefix) ||
                  branch_node_or_hash

<code>branch_flags</code> is a stand-in meant to describe either
<code>left_flags</code> or <code>right_flags</code>, and likewise
everywhere else in the above pseudocode <code>branch</code> can be
replaced with either <code>left</code> or <code>right</code>.

<code>prefix</code> is the key bits between the current node and the
next branching, terminal, and/or leaf node, including the implicit
leading bit for the branch (0 for the left branch, 1 for the right
branch). In the above code, <code>len(prefix)</code> returns the
number of bits in the bitstring, and <code>prefix >> 1</code> drops
the first bit reducing the size of the bitstring by one and
renumbering the indices accordingly.

The function <code>int_to_byte</code> takes an integer in the range
[0, 255] and returns the octet representing that value. This is a NOP
in many languages, but present in this pseudocode so as to be explicit
about what is going on.

The function <code>bits_to_int</code> interprets a sequence of bits as
a little-endian integer value. This is analogous to the following
pseudocode:

    def bits_to_int(bits):
        result = 0
        for idx in 1..len(bits):
            if bits[idx] == 1:
                result |= 1<<idx

The function <code>bits_to_string</code> serializes a sequence of bits
into a binary string. It uses little-endian bit and byte order, as
demonstrated by the following pseudocode:

    def bits_to_string(bits):
        bytes = [0] * ceil(len(bits) / 8)
        for idx in 1..len(bits):
            if bits[idx] == 1:
                bytes[idx / 8] |= 1 << idx % 8
        return map(int_to_byte, bytes)

<code>branch_node_or_hash</code> is either the serialized child node
or its SHA-256 hash and associated meta-data. Context determines which
value to use: during digest calculations, disk/database serialization,
and when the branch is pruned the hash value is used and serialized in
the same way as other SHA-256 values in the bitcoin protocol (note
however that it is single-SHA-256, not the double-SHA-256 more
commonly used in bitcoin). The number of terminal (value-containing)
nodes and the serialized size in bytes of the fully unpruned branch
are suffixed to the branch hash. When serializing a proof or
snapshotting tree state and the branch is not pruned, the serialized
child node is included directly and the count and size are omitted as
they can be derived from the serialization.

    if branch_pruned or SER_HASH:
        branch_node_or_hash := SHA-256(branch) ||
                               count(branch) ||
                               size(branch)
    else:
        branch_node_or_hash := serialize(branch)

As an example, here is the serialization of a prefix tree mapping the
names men and women of science to the year of their greatest publication:

    # An bytestring, broken out into parts:

    # . Root node:
    0x0e # left_flags: 2, right_flags: 3, has_value: 1
    0x00 # extra: Îµ

    # .l Inner node: 0b01000
    0x11 # 0b01000
    0x07 # left_flags: 3, right_flags: 1
    0x00 # extra: Îµ

    # .l.l Inner node: 0b01000011 0b01110101 0b01110010 0b01101001
    #                  'C'        'u'        'r'        'i'
    #                  0b01100101
    #                  'e'
    0x1abb3a599a02 # 0b01101110101011100100110100101100101
    0x10           # has_value: 1
    0x00           # extra: Îµ
    0x03fd6a07     # value: VARINT(1911)

    # .l.r Inner node: 0b010001
    0x0f # left_flags: 3, right_flags: 3
    0x00 # extra: Îµ

    # .l.r.l Inner node: 0b01000101 0b01101001 0b01101110 0b01110011
    #                    'E'        'i'        'n'        's'
    #                    0b01110100 0b01100101 0b01101001 0b01101110
    #                    't'        'e'        'i'        'n'
    0x312ded9c5d4c2ded00 # 0b1011010010110111
                         # 0b0011100110111010
                         # 0b0011001010110100
                         # 0b101101110
    0x10                 # has_value: 1
    0x00                 # extra: Îµ
    0x03fd7107           # value: VARINT(1905)

    # .l.r.r Inner node: 0b01000110 0b01101100 0b01100101 0b01101101
    #                    'F'        'l'        'e'        'm'
    #                    0b01101001 0b01101110 0b01100111
    #                    'i'        'n'        'g'
    0x296c4c6d2dedcc01 # 0b0011011000110010
                       # 0b1011011010110100
                       # 0b10110111001100111
    0x10               # has_value: 1
    0x00               # extra: Îµ
    0x03fd8807         # value: VARINT(1928)

    # .r Inner node: 0b11100100 0b10111000 0b10101101
    #                'ä¸­'
    #                0b11100110 0b10011100 0b10101100
    #                'æœ¬'
    0x27938edab39c1a # 0b1100100101110001
                     # 0b0101101111001101
                     # 0b001110010101100
    0x10             # has_value: 1
    0x00             # extra: Îµ
    0x03fdd907       # value: VARINT(2009)

==Hashing==

There are two variations of the authenticated prefix tree presented in
this draft BIP. They differ only in the way in which hash values of a
node and its left/right branches are constructed. The variations,
discussed below, tradeoff computational resources for the ability to
compose operational proofs. Whether the performance hit is
significant, and whether or not the added features are worth the
tradeoff depends very much on the application.

===Variation 1: Level-compressed hashing===

In this variation the referenced child node's hash is used in
construction of an interior node's hash digest. The interior node is
serialized just as described (using the child node's digest instead of
inline serialization), the resulting bytestring is passed through one
round of SHA-256, and the digest that comes out of that is the hash
value of the node. This is very efficient to calculate, requiring the
absolute minimum number of SHA-256 hash operations, and achieving
level-compression of computational resources in addition to reduction
of space usage.

For example:

    0x0200c3100001ff
    AuthTreeNode(
        left_prefix = 0b01100001,
        left_hash   =
0xbafa0e2bba3396c5e9804b6cbe61be82bc442c1121aed81f8d5de36e9b20dc2f,
        left_count  = 1,
        left_size   = 4)
    0xb4837376022a7c9ddaa7d685ad183bcbd5d16c362b81fa293a7b9e911766cf3c

Assuming uniform distribution of key values, level-compressed hashing
has time-complexity logarithmic with respect to the number of keys in
the prefix tree. The disadvantage is that it is not possible in
general to "rebase" an operational proof on top of a sibling,
particularly if that sibling deletes branches that result in
reorganization and level compression of internal nodes used by the
rebased proof.

===Variation 2: Proof-updatable hashing===

In this variation, level-compressed branches are expanded into a
series of chained single-branch internal nodes, each including the
hash of its direct child. For a brach with a prefix N bits in length,
this requires N chained hashes. Thanks to node-compression (excluding
empty branches from the serialization), it is possible for each hash
operation + padding to fit within a single SHA-256 block.

Note that the serialization semantics are unchanged! The variation
only changes the procedure for calculating the hash values of interior
nodes. The serialization format remains the same (modulo differing
hash values standing in for pruned branches).

Using the above example, calling <code>dict.hash</code> causes the
following internal nodes to be constructed:

        right_prefix = 0b1,
        right_hash   =
0xbafa0e2bba3396c5e9804b6cbe61be82bc442c1121aed81f8d5de36e9b20dc2f,
        right_count  = 1,
        right_size   = 4)
 left_count=1,  left_size=4)
 left_count=1,  left_size=4)
 left_count=1,  left_size=4)
 left_count=1,  left_size=4)
right_count=1, right_size=4)
right_count=1, right_size=4)
 left_count=1,  left_size=4,
                              value=0xff)
    True
    0xc3a9328eff06662ed9ff8e82aa9cc094d05f70f0953828ea8c643c4679213895

The advantage of proof-updatable hashing is that any operational proof
may be "rebased" onto the tree resulting from a sibling proof, using
only the information locally available in the proofs, even in the
presence of deletion operations that result in level-compression of
the serialized form. The disadvantage is performance: validating an
updatable proof requires a number of hash operations lower-bounded by
the length of the key in bits.

==Inclusion proofs==

An inclusion proof is a prefix tree pruned to contain a subset of its
keys. The serialization of an inclusion proof takes the following form:

    inclusion_proof := variant || root_hash || root_node || checksum

Where <code>variant</code> is a single-byte value indicating the
presence of level-compression (0 for proof-updatable hashing, 1 for
level-compressed hashing). <code>root_hash</code> is the Merkle
compression hash of the tree, the 32-byte SHA-256 hash of the root
node. <code>tree</code> is the possibly pruned, serialized
representation of the tree. And finally, <code>checksum</code> is the
first 4 bytes of the SHA-256 checksum of <code>variant</code>,
<code>root_hash</code>, and <code>root_node</code>.

For ease of transport, the standard envelope for display of an
inclusion proof is internet-standard base64 encoding in the following
format:

- -----BEGIN INCLUSION PROOF-----
ATzPZheRnns6KfqBKzZs0dXLOxithdan2p18KgJ2c4O0DgARBwAauzpZmgIQAAP9agcPADEt7Zxd
TC3tABAAA/1xBylsTG0t7cwBEAAD/YgHJ5OO2rOcGhAAA/3ZByEg+2g=
- -----END INCLUSION PROOF-----

Decoded, it looks like this:

    0x01 # Level-compressed hashing
    # Merkle root:
    0x3ccf6617919e7b3a29fa812b366cd1d5cb3b18ad85d6a7da9d7c2a02767383b4
    # Serialized tree (unpruned):
    0x0e001107001abb3a599a02100003fd6a070f00312ded9c5d4c2ded00100003fd
    0x7107296c4c6d2dedcc01100003fd880727938edab39c1a100003fdd907
    # Checksum:
    0x2120fb68

==Operational proofs==

An operational proof is a list of insert/update and delete operations
suffixed to an inclusion proof which contains the pathways necessary
to perform the specified operations. The inclusion proof must contain
the key values to be updated or deleted, and the nearest adjacent key
values for each insertion. The serialization of an operational proof
takes the following form:

    operational_proof := variant || root_hash || tree ||
                         VARLIST(delete*) || VARLIST(update*) ||
                         new_hash || checksum

    delete := VARCHAR(key)
    update := VARCHAR(key) || VARCHAR(value)

The first three fields, <code>variant</code>, <code>root_hash</code>,
and <code>tree</code> are the inclusion proof, and take the same
values described in the previous section. <code>deletes</code> is a
list of key values to be deleted; each key value in this list must
exist in the inclusion proof. <code>updates</code> is a list of key,
value mappings which are to be inserted into the tree, possibly
replacing any mapping for the key which already exists; either the key
itself if it exists (update), or the two lexicographically closest
keys on either side if it does not (insert) must be present in the
insertion proof. <code>new_hash</code> is the resulting Merkle root
after the insertion, updates, and deletes are performed, and
<code>checksum</code> is the initial 4 bytes of the SHA-256 hash of
the preceding fields.

Just like inclusion proofs, an operational proof is encoded in base64
for display and transport. Here's the same

- -----BEGIN OPERATIONAL PROOF-----
ATzPZheRnns6KfqBKzZs0dXLOxithdan2p18KgJ2c4O0LgARaIsVaQi/GdhOPOgA8p4Pu4PiEfEg
lcmy3j7bOc7hXw0DLSeTjtqznBoQAAP92QcBMOS4reacrACzuZJbyP7fqIOf5VEk4iarG4+uPoZC
oun8BztQMQBy0LHVeSY=
- -----END OPERATIONAL PROOF-----

Decoded and broken into its constituent fields:

    0x01 # Level-compressed hashing
    # Original Merkle root:
    0x3ccf6617919e7b3a29fa812b366cd1d5cb3b18ad85d6a7da9d7c2a02767383b4
    # Serialized tree (included keys: 'ä¸­æœ¬'):
    0x2e0011688b156908bf19d84e3ce800f29e0fbb83e211f12095c9b2de3edb39ce
    0xe15f0d032d27938edab39c1a100003fdd907
    # Deletion list ['ä¸­æœ¬']:
    0x01
    0x30e4b8ade69cac
    # Insertion list []:
    0x00
    # New Merkle root:
    0xb3b9925bc8fedfa8839fe55124e226ab1b8fae3e8642a2e9fc073b50310072d0
    # Checksum:
    0xb1d57926

~End of File~
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.14 (GNU/Linux)
Comment: GPGTools - http://gpgtools.org
Comment: Using GnuPG with Thunderbird - http://www.enigmail.net/

iQIcBAEBAgAGBQJSs6HIAAoJEAdzVfsmodw4gooQAJm7XNsZjgdeTSpKIvUIU38f
tQx2FD08hQdLl48me5mDUbHJgGlYINsKAgoZ8Mqwi/kHEEYhuIlLIX1p6Ovigidb
21BiVoOLdG1egGOwxp17DuwYaDPTppFTlN9TBjZzW6WKc7+4aNvyc1KtrbHIhtj/
04ekFyAn4U5UH0ht7CI79j0u3Kp85p5D4PyYZB2m82mzti6OxpSM4tXlMkDW7ihg
QJwiZSjzejqTd7WF0zr0SLeGVRSN2A0dzUCoVsI98eIa3hkw2N4ae6dRkibyStOT
V8VEDvHArEDlvu8jiryajhsom5mvtOOclNDkVXWAf/Te4gj05iYdTIvNvDEJtqsP
XDbmw6GgV1kBLlLo0mp//t/+wr+nIvy+sVAP+eqtM/0vjaVXBkXxkUMqqNkrtVpB
f3whq7nFahssUMSoWE93jgob1ayAax2XUALVMAXYsJl7b2MqBGlhiTZ8FQZ+TW4A
tIpKeUprPmDvA18rO3SCbmLMQryZqYiH0sRyvUc5kvn3qCRHrISZNkEuK591eS+x
BO1eOluPzVqeXPPSK1jvGeY0FNJtwzbov4nI1mzOvzQHLCvkHn5PhUFCK5tL5tAe
b0Z5qwDV+SvVs7W1R7ejYBzEj77U1zuzZ9AtikOuvy+bNGrkIlpI49EyXHijm7C3
Q6JacTuI0PelYji2gaBJ
=BbDs
-----END PGP SIGNATURE-----


-------------------------------------
On Tue, Apr 09, 2013 at 11:03:01PM -0400, Peter Todd wrote:

We can keep the length 160bits:

scriptPubKey: OP_HASH160 OP_HASH160 <Hash160(P2SHv2 address)> OP_EQUALVERIFY

You don't need to change the address type at all if new software is
written to check for both forms of txout in the actual
blockchain/transaction code at the deeper level. Basically now a P2SH
address could actually mean one of two scriptPubKey forms, must like a
normal address can mean either the hashed or bare OP_CHECKSIG form.


Of course, either way you have the odd side-effect that it's now
difficult to pay further funds to a random txout seen on the
blockchain... strange, although possibly not a bad thing.

-- 
'peter'[:-1]@petertodd.org
-------------------------------------
On 10 June 2013 23:09, Peter Todd <pete@petertodd.org> wrote:


Sounds very promising.  Suspect it will need a fair amount of testing ...


-------------------------------------

On Mon, Dec 09, 2013 at 01:39:51PM +0000, Drak wrote:

Perhaps because 0.8.6 hasn't been released yet?  Or did I miss the
announcement?  I think it makes sense that release candidates are not
promoted on bitcoin.org.





-------------------------------------
On Tue, Mar 12, 2013 at 11:09 AM, Gregory Maxwell <gmaxwell@gmail.com> wrote:
[snip]

https://bitcointalk.org/index.php?topic=152348.msg1616747#msg1616747


-------------------------------------
On 4/11/13, 12:26 , Mike Hearn wrote:

The suggested change is actually very simple (minutes of coding) and
elegant and addresses precisely the identified problem. It is actually a
mental shortcut in the assumption of how probability works when mining a
chain. The paper simply corrects this error - nice work!


You suggestion could perhaps be fun for other purposes, but does not
rule out pools of "selfish miners". Further, it binds physical state
(ip) to the blockchain, which has so far held no assumptions on the
technology of the system on which it is running.




-------------------------------------
As part of a roadmap for block downloading, I think this may be a good time
to look into providing an HTTP/HTTPS protocol for block downloading - this
would also allow web proxies to cache blocks and thus make it more
accessible, as well as cater for resumeable downloads.
-------------------------------------
I'm pleased to announce the release of bitcoinj 0.9, a Java library for
working with the Bitcoin protocol. Both simplified and full verification
are supported. BitcoinJ has been used to create everything from end-user
wallet apps to network crawlers to SatoshiDice.

To get bitcoinj 0.9, check out our source from git and then run *git fetch
--all; git checkout **67b187c4c4c4*. This will place you on the 0.9 branch
in a secure manner. The roots of trust are the announcement sent to
bitcoinj-announce (which is signed by the google.comDKIM key) and the Maven
page of the bitcoinj website. This paragraph is signed with the same key as
the previous releases (16vSNFP5Acsa6RBbjEA7QYCCRDRGXRFH4m). In addition,
the 0.9 release is signed by Andreas Schildbach (GPG key id 0x8B877A60,
accessible via http://bitcoin.org/andreas_schildbach.asc) and can be
verified with *git tag -v 0.9* once you have his key.

Signature for the last paragraph:
 IEVMFkGVfE5Q7mezpNc2srdMXMkE66AEW2g7AtWa2KGa2PcK5ehqGbKPOWaL2oftcN/939VHWViMLnCKGrS3E9g=

We have a new article in the documentation library, Working with
contracts<https://code.google.com/p/bitcoinj/wiki/WorkingWithContracts>.
 It shows how to create and use multi-signature transactions, signed by
different parties, using a simple API.

*New in this release*

   - Thanks to Matt Corallo, we now have a basic *fee solver* that will
   attach the correct (minimum) fee per kilobyte to a created transaction
   using the 0.8.2+ fee rules. Note that there's no attempt to minimize the
   size of a calculated transaction and thus fee, but some other optimisations
   are applied. By default bitcoinj will always attach a fee, to learn how to
   customise this refer to the article *Working with the wallet*.
   - The wallet's re-org handling code was rewritten and simplified.
   - A new class, WalletAppKit, simplifies the process of instantiating all
   the objects and files that are needed to run a basic app that can
   send/receive money.
   - Add optional support for Pieter Wiulle's native secp256k1
   implementation, which is significantly faster than Bouncy Castle.
   - Improvements to coin selection in the wallet.
   - Many new functions and minor API improvements, for instance, it's now
   easier to tell the wallet to allow spending of unconfirmed coins.
   - A new ScriptBuilder class simplifies the process of constructing
   various kinds of scripts.
   - A new block importer tool can parse bitcoind block files and process
   them, which is faster than streaming them over a network connection.
   - Support for the regtest mode added by the C++ side pull req 2632. This
   makes app development and testing easier by eliminating the need to wait
   for a block.
   - Many bug fixes and testing improvements.

*API changes*

   - NetworkParameters has now been refactored into separate classes.
   - Wallet extensions have been tweaked, please refer to the javadocs for
   details.
   - Many other minor additions and changes that are mostly backwards
   compatible.

*Known issues*
*
*
Please see the limitations and missing features
page<https://code.google.com/p/bitcoinj/wiki/Limitations> on
our website.
-------------------------------------
On Thursday, May 16, 2013 10:55:44 AM Addy Yeow wrote:

This sounds accurate for listening nodes, and similar to what my own system 
counts: http://luke.dashjr.org/programs/bitcoin/files/charts/security.html

Of course, it doesn't include the (many?) connect-only nodes (eg, mobile or 
firewall/NAT'd) or non-p2p nodes (eg, Electrum).

Luke


-------------------------------------
On Tue, Mar 12, 2013 at 9:55 AM, Alan Reiner <etotheipi@gmail.com> wrote:

Some but not much.  If someone flooded a bunch of duplicate
concurrently announcing both spends to as many nodes as they could
reach they would almost certainly gotten some conflicts into both
chains. Then both chains would have gotten >6 confirms. Then one chain
would pop and anyone on the popped side would see >6 confirm
transactions undo.

This attack would not require any particular resources, and only
enough technical sophistication to run something like pynode to give
raw txn to nodes at random.

The biggest barriers against it were people being uninterested in
attacking (as usual for all things) and there not being many (any?)
good targets who hadn't shut down their deposits.  They would have to
have accepted deposits with <12 confirms and let you withdraw. During
the event an attacker could have gotten  of their deposit-able funds.

On Tue, Mar 12, 2013 at 10:35 AM, Peter Vessenes <peter@coinlab.com> wrote:

There were circulating double-spends during the fork (as were visible
on blockchain.info). I don't know if any conflicts made it into the
losing chain, however. It's not too hard to check to see what inputs
were consumed in the losing fork and see if any have been consumed by
different transactions now.

I agree it would be good to confirm no one was ripped off, even though
we can't say there weren't any attempts.


-------------------------------------
On Mon, Dec 16, 2013 at 11:46 AM, Jim <jim618@fastmail.co.uk> wrote:

Will that also mean no longer reusing (change) addresses?

-- 
Pieter


-------------------------------------
On Sunday, April 14, 2013 5:09:58 AM Peter Todd wrote:

I think it would be wise to figure out HD wallet changes before trying to 
extend message signing. For privacy/safety, it would be a good idea to avoid 
signing with the same private key twice under any circumstances, so it might 
make sense to create a new address format the represent a chain of keys 
instead of one key or combination of keys.

Luke


-------------------------------------
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 11/4/13 10:16 AM, Peter Todd wrote:

You mean... an authenticated prefix tree? Composable/commutative
properties are not needed as far as I can see, so you could make the
path validation, traversal, and proof size smaller by using level
compression.

I had previously proposed to this list a hash256-to-UUID mechanism
explicitly for this purpose. Recap: use 122 of the low 128 bits of the
aux-chain's genesis block to form a version=4 (random) or version=6
(previously unused) UUID. However since making that proposal I am now
leaning towards simply using the hash of the genesis block directly to
identify aux chains since level compression will allow longer keys
with the same path length.

I'm in the middle of writing BIPs to this end, among my many other
tasks. But basically it's the same as you describe ("OP_RETURN
<32-byte auth tree root>" for the last output), except keys don't
necessarily have to be UUIDs.

If there is general interest, I can make finishing this a higher priority.

Mark
-----BEGIN PGP SIGNATURE-----
Version: GnuPG/MacGPG2 v2.0.19 (Darwin)
Comment: GPGTools - http://gpgtools.org
Comment: Using GnuPG with Thunderbird - http://www.enigmail.net/

iQIcBAEBAgAGBQJSd/FmAAoJEAdzVfsmodw4pA0QALtgKLKsMNFocUanKGNp5T1F
918IjFt/HASRMs4GXiPpIeTB+o5Id6aCsg1ikKRuL9xD+WKoSyo83JP5UmcxGjFA
WTPi/0/ArYRh8L7ECvWoBSanNrun3z72p3KMI1Aa8qcJCgWbPx88AYeJv0Ki4JOo
1Pxc883772bOJnazrh4f/C4gcrqrlgs29PwI1rc3yCD9dmJhVmkz+O0/yfq+U8Gg
FXrpqR14mUM36wGX2HjqEual7Ry/7TEz5Ne4o8uncaVHtGgaYVw45a5Hk6rdo1rH
F3EV9nIpsLhGyqbKPqSxSju2h3eYQxQXKUP14mJS+ja/mKFXVc3PXDV+IHtXAplk
4gW8vtTWtVIDJAGTTh5RkJu5yAr57vq9lUMTNGGk6v1C3xOPP2C097sHRLaD4kD+
olsw5M9NW/Qpn1X3SCN3K85f7dvV3+fucmWL8mPM9KMLfc38fgs7I5SQgurMngsS
2D5jSwcZVjI/4n6ocgK3Y66yKC5xuzOOi2ZV+pPM38TjUeCF8fbjRnoIWyaBPDWy
mKA0bJiw5NMzi+IsNK5YDS5Gqb3qxS6tYLCp1+hesW3pBj35Zv/LdSh5DyecRETW
J0ye56lw/DfRAfNf+YERvrznqC2WVDZcQaElACq8R/nPJ2HD53p+SfxMSbljVO+I
SDsDOSvAzfQjQBLGdkx7
=5fPS
-----END PGP SIGNATURE-----


-------------------------------------
<DIV style="font-family:Arial, sans-serif; font-size:10pt;">-----BEGIN PGP SIGNED MESSAGE-----<BR>Hash: SHA1<BR><BR>Hi guys,<BR><BR>Due to a good suggestion of my friend ripper234 (Ron Gross) I'm doing this short but sweet.<BR><BR>A new concept is in the making. And the project is moving forward.<BR><BR>WHO: <BR><BR>I'm a Bitcoin enthusiast who has been following developments in the shadows for quite a time.<BR>ZumbÃ­
 was a brave Afro-brazilian slave who became a warrior. He trained other
 fellow slaves to fight and escape opression by living in free colonies.
 Hence, my nom-de-guerre. But I am rather peaceful and believe free 
people and free markets are what unleashes human creativity and 
progress.<BR><BR>WHAT: <BR><BR>MITOSYS: A new cryptocurrency that is 
mined through a proof of work which is the capability of relaying 
encrypted transmissions over the established internet, or through 
informal parallel peer-to-peer networks.<BR><BR>HOW: <BR><BR>You help 
other people transmit encrypted data, you earn credit. Data will be 
temporarily stored in a dynamic blockchain that prunes itself to keep 
the size down, and account balances will be stored in a separate 
distributed archive called the account tree. Mobiles will be fundamental
 and the main target of this distributed network.<BR><BR>WHY:<BR><BR>- -
 To get rid of government spying and its armed forces, the oligopolic 
telecom carriers, ISPs and big data companies that provide them with all
 our information.<BR>- - To bring affordable and secure communication to the masses.<BR>- - To give people a store of wealth derived of a basic human need which is to communicate freely and universally.<BR>-
 - To provide a deeper meaning to mining, which will be not only 
acquiring the right to store financial information that cannot be 
destroyed, but also acquiring the right of having ones information 
securely delivered in time.<BR><BR>WHERE: <BR><BR>Development will take 
place in bitcointalk.org and github, plus distributed encrypted backup 
copies of all work. Maybe even copy information in Bitcoin's blockchain.<BR>Main markets are USA, Brazil, Russia, India and China.<BR><BR>WHEN: Right now!<BR><BR>I'm recruiting a peaceful army of skilled, resourceful, practical idealists who can carry this forward together.<BR><BR>For more information see: <A href="https://bitcointalk.org/index.php?topic=327186">https://bitcointalk.org/index.php?topic=327186</A><BR><BR>- -----BEGIN PGP PUBLIC KEY BLOCK-----<BR>Version: GnuPG v1.4.11 (GNU/Linux)<BR><BR>mQGNBFJ7tAEBDADLgOJFYrN5F9nJ/f8kMy5qsz6ZErAQwoqMcwNRXyDzFdUmiljF<BR>U23+1L8RgsThYPb0gd4JioQ5dWfszjIkpJeUxMVPpa6dDL88xVt3ItoH+2rcCDRp<BR>+ZIcND9gO/IgLndU071uypGtkodVaGUjx6NzvR8/TJPVriFk/9tepxFs1NDpsS4Q<BR>FxbcKtlhD7SsQAoE2GFO2Jut7Lh94XZ75AnguqJuLyJHDdZn15hOiFFKD4X/iofd<BR>Fs4y4vSt2s5CYsnAOq3Ir2qfulIztg8BQUo6kmOVMIRUGEMAWIEqePcqQlzDFSWo<BR>+js7GiiuNwMgQfcW5Fv6puB4ukFaC80JILOOR5ITOsSRpBpEsBfHZ8CRGQVd5bbI<BR>/qXFgjcxLSCd7DL3MFvkHnPMFvenPi5KMLlTnDa7qQ1rdTw7fx0QIGfAnjjEqDeU<BR>EQJBRuPszEXpN5bOJpxuiW8O/ECPUubjgzuolXSIbQEnRnZK4umY1RqdUyQqZiOt<BR>TZ+/fP44XY3MIDUAEQEAAbQ7WnVtYsOtIDxCTS1OQXhqSkRvNlV6WlVzams1YXZG<BR>aEVFOFlDMXBZZ2szWEBiaXRtZXNzYWdlLm9yZz6JAbgEEwECACIFAlJ7tAECGy8G<BR>CwkIBwMCBhUIAgkKCwQWAgMBAh4BAheAAAoJEM0M/RJqcr5wxisMALk4qoFckbZJ<BR>aE3QuxO51mnIWToMsBvFs/pbU/l1uYzTytPhSyuBqSQ6xD4ZifY2xdHarbbLNPCK<BR>vfwufhDly3/D4BANqtoLiiiXB6BkME7TG9nghVeTIxyjpTDrmouielH4OBrSM7Pj<BR>e0qpkmwlgHXxoTDZZQnrkH7rkIAA+g5goqNapCX57nI7guUMozRZ4T/Hs2aPXm0V<BR>fq2asO4F8tsJ/vgeuKtBQLdNRRxeU/a0op2p8CFhn6Yu0GIiLjZFN0NL6AiSzV/I<BR>3SverkBUcBbvTJMmGUAOFWZ94FNcl6+SNroZbPze8EfdLcZp+i3Uhg22/tkOyXoO<BR>Guu1xSoYbjKbDy7OqxIw68z0xFo30kjyF8RW75oZCUrxHrmBDog7BtLmEKrOCqkO<BR>KgAH1l+Ut4qkxuvJ5EelUKr/cJwkenqpc2+YXqVX3lMd5bqhLhEWJW0KL2uhurCf<BR>UHG0daJK0/snmsMTxB2kpzyWDkBD/cZMrXgAOXtk90W7Q7W+7/lUDw==<BR>=6mvb<BR>- -----END PGP PUBLIC KEY BLOCK-----<BR>-----BEGIN PGP SIGNATURE-----<BR>Version: GnuPG v1.4.11 (GNU/Linux)<BR><BR>iQGcBAEBAgAGBQJSfSkgAAoJEM0M/RJqcr5wUvAMALfSufvy7y/LskUN2/jOTeo5<BR>SzpkF3c/ZnjiXObARrFfsiVn7l6xx1/PEDAUHNPa0mPEgwep7n5xwbYmUFaKcmMP<BR>LOlJCYhi8SMuOMZfi3Avp9q1i0Nq9cvWrTNkBXIqpdnndSv+/8HPBr46u/kbEmTE<BR>oJR1oetiHqYaMFUlmD8HnzkVjJdcWjvGdmKgk6QFeDBGu8lZ+RybwBSGoEI3O6OV<BR>5htwlwrRAIYQCJOeYgopPBlB6Ib1tSjJYpzt9QQkzhfI6pRrBxi+v2hsoxetb3Y1<BR>65qPunfKSmH8DqyEcevAFAI0EF7rxQ3nUt4gowgSILs3kyYbmjfoOcr9eNNhb8WN<BR>U8sTI52eFOyabO4pqlkZHUSdaCgyak1dEN7h8E04f8LGWlrFI2rUp5aoiNvQdkVj<BR>g+IJ82CPLfPfiDm6ciomah+1+SK5BYqxaoBLC7U+wb5P42eNW4ifB9PjOF1n3XvR<BR>AnPekOtmKaU4NPJKsUV7lopw1QBnaCCEwP2QQrxPeA==<BR>=9T6c<BR>-----END PGP SIGNATURE-----<BR>&nbsp;<BR><HR>Join the fastest growing e-mail service in the Pilippines. It's Free. It's cool. Go to http://www.e-mail.ph and Sign up now.</DIV>
-------------------------------------
On Sat, Jul 27, 2013 at 07:49:18PM -0400, Peter Todd wrote:

Quick note for patent prior-art/my own memory - did a talk yesterday
about multifactor wallets, one time passwords and hash digest based
oracles. Someone getting involved in the business of selling bitcoins
pointed out that legally it can actually be desirable to give the
bitcoins to the customer by giving them a physical private key, perhaps
on a sheet of paper in a mailed envelope. Obviously the customer would
be wise to sweep the funds. Of course, the advantage of doing it with
paper is the legal system has a long history of dealing with the concept
of a secret on a piece of paper. (your customers won't have handy PKI to
use after all)

With multi-factor wallets you can have the customer provide one or more
keys, and you give them one final key on a sheet of paper, with
instructions to scan it on their phone via QR-code or something. Now the
transfer is absolute on your end - you can't get the funds back. If it's
a large amount you may want to split it up among multiple addresses, and
deliver the keys to the customer in a way that makes it obvious when
they are revealed. (scratch off for instance)

Finally, one-time-passwords do much the same thing, but they don't
require the second device, and the sheet of paper the customer is
dealing with can be much shorter. Similarly the final approval could
just be done over the phone by telling the customer the ~6-8 magic words
that unlock their funds - legally it could be useful to record that
phone call. Similarly for a large transfer, make it clear how much each
scratched off text field is unlocking to defend yourself in court.

Of course, in both there is still the risk of the funds ending up locked
due to a mistake, but at least there isn't financial incentive to make
that event happen. (usually)

I'll admit I hadn't thought of any of this stuff until I talked to an
actual business with real problems, worth doing.


Finally it's too bad we didn't get OP_EVAL; the customer could have
provided a P2SH script with, well, anything in it, and the unlock could
could have easily been a "bolt-on":

HASH160 <digest> EQUALVERIFY
DUP HASH160 <p2sh-code-digest> EQUALVERIFY EVAL

Oh well, MAST support can do the same thing one day.

-- 
'peter'[:-1]@petertodd.org
000000000000002f3613b5394e39a254ba4afa9f76af72cd6b4273736d7987fb
-------------------------------------
This summarizes some rambling on IRC about revising the BIPS process.

Right now, the BIPS process is a bit haphazard.  Previously, BIPS were
in a git repo, and the BIPS on the wiki were locked against editing.
The BIPS editor at the time started off well, but was eventually
M.I.A.  So the BIPS "home" moved de facto to where everyone was
reading them anyway, the wiki.  They were made editable, and it became
easier to Just Pick A Number And Write One.  However, this inevitably
became a bit disorganized.  Further, there was a recent incident --
easily reverted -- where someone hopped on the wiki and started
arbitrarily editing an existing standard.

BIPs need to move back to git, in my opinion.  Standards should be
hash-sealed against corruption.  Anything less would be uncivilized,
and un-bitcoin.  However, many on IRC pointed out requiring a git pull
request might be a burdensome process, and discourage some
contributors.  The following is a sketch of an improved process.

1) BIP Draft.

Modelled after IETF drafts.  Anybody may submit a BIP draft, as long
as it meets two very loose requirements:
* At least somewhat related to bitcoin.  Note, I did not say "crypto-currency".
* Formatted similarly to existing BIPs (i.e. markdown, or whatever the
community prefers)

BIP drafts may be submitted via git pull request, or by emailing an
attachment to bips.editor@bitcoin.org.  This mirrors the Linux kernel
change submission process:  git is preferred, but there is always a
non-git method for folks who cannot or do not wish to use git or
github.

BIP drafts are stored in git://github.com/bitcoin/bips.git/drafts/ and
are not automatically assigned a BIPS number.

2) Time passes.  Software for BIP drafts is developed, tested,
published, and publicly discussed in a typical open source manner.

3) If interest and use cases remain strong, a BIP number may be
requested, and the BIP draft is moved to
git://github.com/bitcoin/bips.git main directory.

4) If there is general consensus that the BIP should be adopted, the
BIP status is changed to "accepted."

There are no specified time limits.  Sometimes consensus about a BIP
is reached in days, sometimes 12+ months or more.  It varies widely
depending on the feature's complexity and impact.

As with the IETF, it will be q

-- 
Jeff Garzik
Senior Software Engineer and open source evangelist
BitPay, Inc.      https://bitpay.com/


-------------------------------------
On Sat, May 4, 2013 at 2:07 PM, John Dillon
<john.dillon892@googlemail.com> wrote:

Let's not confuse bootstrapping with overall peer discovery.

Peer exchange between P2P nodes is the primary and best method of
obtaining free peers.

Obviously you need to bootstrap into that, though.  DNS seed and fixed
list are those bootstrap methods (IRC code was deleted), but are only
used to limp along until you can contact a real P2P node, at which
point peer discovery truly begins.

-- 
Jeff Garzik
exMULTI, Inc.
jgarzik@exmulti.com


-------------------------------------
On Wed, Jun 26, 2013 at 01:13:25AM +0200, Jesus Cea wrote:

Just like every release ever, and probably until we reach 1.0.

-- 
Pieter



-------------------------------------
One of the strongest results from psychology is the power of defaults over
people's behavio<http://danariely.com/2008/05/05/3-main-lessons-of-psychology/>r.
Opt-in vs. opt-out national organ donation policies mean the difference
between organ donation rates under ~10% to over ~90%. Most people stick
with the default option.


On Thu, Nov 14, 2013 at 10:18 AM, Luke-Jr <luke@dashjr.org> wrote:

-------------------------------------
Please note that it was not 0.8 that had issues, but 0.7(and downwards).

I really think changing features in 0.8 aiming for a fluffy limit to avoid lock object errors on 0.7 is the wrong way to go, and it will never cover for a similar situations in the future.

Instead I would like to propose a setup for "considerate mining":
* Run pools either on newest or second newest version (up to you depending on which features you like as a pool admin) - say e.g. 0.8
* Connect to the rest of the bitcoin network _only_ through a node of the other version - say e.g. 0.7

This guarantees that no blocks will get into the network that will not be accepted by both 0.8 and 0.7. Those two  versions together should add up to say >90%.

Once everyone else (90%) have upgraded to the newest, (0.8), drop the 0.7 and start to introduce 0.9 instead.

/M




-------------------------------------
On 9 August 2013 14:08, Mike Hearn <mike@plan99.net> wrote:


You'd need to run your own email server and/or change email address, which
is not in the reach of the average user, and maybe not even of some
businesses.



You can self sign X.509 certificates quite easily (e.g. one click via
<KEYGEN>), then rely on a decentralized web of trust to remove browser
warnings.  A few people are working on this.


It is easier to use, that's a great plus.  But convenience is often a trade
off with security.

I dont user user@host, I use my home page because it's easy to dereference
and get a public key.  Email is hard to dereference.

Yes, there is a reliance on DNS, which Tim calls the 'Achilles heel' of the
web, but it's held up quite well so far (fortunately for us).

Mozilla also have a master key to most email accounts, so if anyone got
access to that they could impersonate the vast majority of users that have
not opted in.  I would not use persona for financial stuff, but if I made a
casual app with non sensitive information it would be one of the top
choices, imho
-------------------------------------
We all love bitcoin's ability to transfer value in real time across borders.

But the regulatory environment in many geographical regions in uncertain.
Do we need to pay capital gains?   Do we need to pay a sales taxs etc. etc.

At this point bitcoin is small enough for this to not be a huge issue, but
one day that may change (maybe we hope!).

So my idea is to voluntarily pre empt legislation by giving donations to
govt (aka taxation) for bitcoin service providers.

However, there is something of a problem with voluntary donations.  Most
people are not satisfied with the way they are spent.  In the UK a recent
survey said that only 18% of people thought that tax money was wisely
spent.  This is bad for govt., bad for people, and bad for the trusted
relationship.

Can we fix it?  Maybe we smart contract and voluntary donations it's
possible!

So let's say I run a business and I make 1 million euros.  I wish to donate
10% of my profits to society.  But let's say I dont want that money to go
to wars of aggression, but rather, to the fire de[department.

So we set up a smart contract that is only "cashable" if the money goes to
the right place (verified by an oracle).

At this point everyone wins.  The business person is happy to make a
contribution.  The govt. is happy that it gets more revenue.  The fire
dept. is happy that it has revenue to do its work.  And everything has gone
to the right place in a kind of democratic way.

Over time if it takes off, this could provide revenue for many essential
services that are needed by people, in a way that allows more democratic
freedom of choice.

So my question is whether it may be possible to use smart contracts to
achieve a better democracy that is good for people, good for govt, and good
for innovation?  My hope is that the answer is ...

"Yes We Can"

:)
-------------------------------------
Yes, this is an excellent observation. Thanks Jeremy and Peter. It's much
less general than full blown tx replacement+lock times, but for the case of
a channel between two people that only ever increases in one direction, it
can work. Thanks. I will try implementing this myself for testing on the
main network.
-------------------------------------
Any reason not to use actual HTTP codes?  I'm not aware of any major 
deficiency in them.  Most of them won't apply to us, which is fine, they 
don't seem to apply to HTTP either.  We can extend the scheme on our own 
if we find a good reason to.

That implies 16 bits, or a varint.  I would avoid a string or varstring 
here; we already have a text field.  Varint vs. 16 bits is a minor 
issue, and arguments can be made in both directions.  I flipped a coin 
and got heads, so I'll say varint.

Gavin Andresen wrote:

-------------------------------------
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256

On Fri, Nov 8, 2013 at 4:21 PM, Goss, Brian C., M.D.
<Goss.Brian@mayo.edu> wrote:

The propagation time you're thinking of is from the pool to the miner, and even
now that is significant for pools that do not pay for stale shares. I remember
an Australian pool mentioning that problem on their website as a reason for the
pools existence.

I would expect selfish mining, as well as orphans becoming more important in
general, to centralize the physical location of hashing power too. If the 100ms
delay to your pool impacts profits you'll have an incentive to locate your
mining equipment physically closer to the pool. The next step is pools wanting
to physically locate themselves closer to other pools.

It would not be good if all Bitcoin mining was done in Iceland...


Not ignorant at all IMO.

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBCAAGBQJSg+CpAAoJEEWCsU4mNhiPufwIAKNpBBvlRvSQZOzMJvghG7fX
lCNliohDKw9kdKJJjN1T73Ssl06wGbBe881k4c4r7fHeNDRQZbrFsj+uBsFyUhmy
CF70KiOKuowDlWwyWMxZbbyinK0mEKC7J/hJVOt15FHubLnq71Utb+I2L7seyHlo
2E2byG4UnofoD5L+hGzfD6FJ/zYEHtTKgFw7Y1+ZSmAxlIcdrcpH7tPmUzFD7JPi
RnaK1BH7hpM6FyZQUhSC/tW7mYswNEasvouBE4V1vSySZb6S43kiED2Q4uH3W0+A
UtbyRQ7yT3BOLGB2OO/L92tg6S7WRyMtvQoevJkEIAnUywD3YWaZnBbf0IM4LWg=
=6750
-----END PGP SIGNATURE-----


-------------------------------------
Preliminary:
Alice has the ability to hear of a block before all other miners do.

The Problem:
Say Alice built a block, A1, from previous block 0. She doesn't let other miners know about it. She then works on A2 with previous block A1. Bob on the other hand is still working on B1 with previous block 0. Bob now finds a block and he broadcasts it. The assumption here is Alice will be the first miner to hear of this block and she will send her previously mined block, A1, to all other miners. By the time Bobs block arrives to other miners majority of them will already have received Block A1 and Bobs block will most likely be orphaned. Alice revealed her block, A1, only when Bob broadcast his block. This means she has been mining on block A2 with previous block A1 for longer than any other miner thus gaining an advantage without increasing her hash rate.

What We Know:
Alice has gained an advantage with time. She mines longer on the valid block.
In order for this attack to work Alice must reveal her previously mined block as late as possible, gaining her the most time spent working on the valid block. Since she has such good view of the Bitcoin network she can wait until a miner finds a block to release her previously mined block.

The most obvious sign of this attack taking place is the timing. A miner will receive a block and very quickly hear of another block both built from the same previous block. 

The block that a miner hears first is the one which will be mined on.

Possible Solution:
If N amount of blocks built of the same previous block are received within a time frame of T mine on the block with the lowest hash.

Logic:
In order for Alice to pull of this attack she not only has to propagate her blocks first she must also ensure her blocks are of the smallest hash.

Alice would now have to decrease her target to pull of this attack. Since she has a lower target it will take her longer to find a valid block negating her time advantage.


colj


-------------------------------------
_*Goal*_:  An alternative address format made possible by BIP 32, which
allows one to specify a "Wallet ID" and "One-time payment" code, instead
of the standard one-use Base58-Hash160 addresses.   This allows parties
with a persistent relationship to be able to prove that payment
addresses they provide each other are linked to a particular wallet,
reducing exposure to MitM attacks without the need for SSL or a web of
trust, and without compromising the privacy of either party.    For
instance, this could be used between businesses that frequently do
business, by exchanging and verifying public keys beforehand, or could
be used by an exchange to identify if a customer withdrawal address is
related to their last deposit address, and if not enforce extra
authentication measures.

_*Background*__:_
I haven't been following the payment protocol discussions/development
much, so I apologize if this has already been addressed.   I'm calling
it "wallet-linkable" addresses, which would be an optional second form
for sending someone your address.   With BIP 32, the address is computed
by the payee (the person sending the address to receive money):

   Standard Address ~ Base58(0x00 || hash160(PubKeyParent *
Multiplier[i]) || checksum)

What I'd like to do is have the option, when specifying an address
through the payment protocol, to send *just* the {PublicKeyParent,
Multiplier[i]} and let the receiver of that address compute the address
on their own.  This is no significant burden on the receiver, but it
does provide the useful property that they can recognize when addresses
specified in this way come from the same wallet -- because the
PubKeyParent will be the same.  Remember, this is _optional_ for the
person providing the address.

One nice, accidental feature of BIP 32 is that the Multiplier[i] used
above does not actually reveal the "chaincode" (I think Pieter started
calling it the "tweak").   It is derived from the chaincode but doesn't
reveal it.  Therefore, the payer sees the parent public key, but that's
not useful to derive any of the other addresses unless they also have
the chaincode.  But they can verify that the PublicKeyParent is
identical between transactions, and thus is accessible only to that
wallet.  It allows them validate a specific address provided by the
payee, but not generate or identify any other addresses.

*_Use Cases:_*
(1)  So, just like with PGP/GPG, when two parties decide they will start
a relationship, they can start by exchanging the public keys of their
wallet and verify them in a reliable manner.  After that, when one party
requests a payment address from the other, they can optionally send
{PubKey, Multiplier}, and the payer's software will identify the owner
of that address, or let you select who you think the address belongs to
and it will verify it.  If the payee's system is compromised and address
is replaced, the address received by the payer won't validate.  This
doesn't help if the side sending the money is compromised.

(2)  When a customer first provides a deposit to an exchange, it will
send money from an address in their wallet and the software will provide
the exchange the {PubKey,Mult}.  When the customer later provides a
withdrawal address, the site can automatically trust the address as long
it is provided in the alternate form and the public keys match.  If they
don't, it might be the same customer just requesting a withdrawal to a
different wallet, which is fine, but they'll have to go through an extra
verification step to do so. 


_*Downsides:*_ 
Multi-sig/P2SH  - The only way this works with P2SH, violates one of the
goals of P2SH slightly, but may not matter much if it's all done under
the hood by the software.  Instead of providing a 20-byte hash of a
script, you provide all the public keys and multipliers for the
individual addresses.  The payer's software automatically verifies all
addresses and creates the P2SH script itself (after a divine decree that
public keys will always be sorted lexicographically in the multi-sig
script).  The blockchain still benefits from the "compression" of moving
the bulky scripts to the TxIn, but it does require revealing more
information than is necessary for the payer to pay the payee.  But it
may not /really/ be a problem, given the benefits.  It might just be
slightly longer strings to exchange during initialization and for each
transaction.

I have various reasons I'd like to use this, and it'd be nice to have
some community backing, so I don't have to twist anyone's arm to trust
me that it's legit.

-Alan




-------------------------------------
On Wednesday, March 13, 2013 3:18:36 PM Gregory Maxwell wrote:

I figured 2 MB in 2-3 years was fairly uncontroversial.
If not, let's scrap that idea for now.


It was a one-time "start the conversation" proposal.
I expect what we end up going with may be substantially different.

Luke


-------------------------------------
Hi Wendell,

What Peter describes (a hash of the current set of UTXOs as part of the coinbase) is already implemented in libcoin, on which you can easily build both a bitcoind and any client. Libcoin is a library originally based on the satoshi client, and as such it is compatible/replacable with "master". 

Have a look at github.com/libcoin/libcoin and look in the BlockChain.h/cpp and the MerkleTrie classes then you can see how it works.

What is missing from libcoin is a scheme to bootstrap the hash of UTXOs, there is some stub code for a p2pool like mining scheme ensuring several UTXO hashes every 10 minutes, but I will not have time to finalize it the first few months - anyone are of course welcome to help out ;)

Michael


On 17/07/2013, at 09:37, Wendell <w@grabhive.com> wrote:


-------------------------------------
On Tue, Jul 9, 2013 at 11:32 AM, Nick Simpson <nick@mynicknet.com> wrote:

Cloudflare is rapidly becoming a bitcoin community SPOF.
-- 
Jeff Garzik
Senior Software Engineer and open source evangelist
BitPay, Inc.      https://bitpay.com/


-------------------------------------
On 09/25/2013 01:45 PM, Mike Hearn wrote:


Now you're dver-dramaticing (-:

I'm just skipping one feature which I think is useless for QR codes
scanned in person.


Thanks. A typical request would be around 60 bytes, which should produce
an URL with around 100 chars. That should be fine for scanning, but I
will experiment.


Good to hear. Let's see if it gets momentum.


Sure. I was talking about QR codes scanned in person.


Yeah, will look at that as soon as we're implementing the payment
protocol fully.




-------------------------------------
I'm all for funding of Bitcoin development, but I suggest talking to Gavin
to find out what efforts would be the biggest win right now. I don't see
why separating wallet code from the main Bitcoin process would increase
node count, as the cost of running the node is almost all in keeping up
with transaction traffic and time spent in the wallet is likely to dominate
only for large merchants or exchanges.

That said, you can already do this today - just run an SPV wallet like
bitcoinj connected to your personal node. The wallet code in bitcoind won't
be used for anything.

There are lots of things that can be done, but the best way to approach
this is to get tightly written technical requirements from people in the
know, and then contract with developers. Bounty style development has the
risk of uncoordinated development that duplicates work and puts pressure on
Gavin or other maintainers to accept shoddy code due to the "first past the
post" winning criteria. Finding developers you trust and contracting with
them for well specified improvements minimises risk for everyone.


On Thu, May 16, 2013 at 3:02 AM, <bitcoingrant@gmx.com> wrote:

-------------------------------------
On Mon, Nov 04, 2013 at 01:03:50PM +0100, Mike Hearn wrote:

It's worth pointing out that my previous post on this list for
"near-block broadcasts" - where blocks that almost but not quite met the
proof-of-work threshold are also broadcast so that propagation of
transactions can be proven - also naturally leads to their proposed
solution. Any miner who sees a near-block-broadcast extending a chain
fork that they aren't mining on would naturally see that as evidence
that the other side has more hashing power, and thus it's in their
interest to mine it rather than the side they are mining.


You know, the whole paper follows the same logic as the point I made
months ago in how if there is no explicit blocksize limit miners have
incentives to make their blocks large enough that they only propagate to
just over 50% of the hashing power, thus causing their competitors to
waste effort.  They analyze the situation in terms of a sybil attack,
where I proposed a more fundemental mechanism to achieve the same goal
based on simple physics.

-- 
'peter'[:-1]@petertodd.org
000000000000000719f061e0fa83343ddbe80d2b6a1fefc84691ffe8652385e0
-------------------------------------
Would like to upload bootstrap.dat.torrent to
sourceforge.net/projects/bitcoin/files/Bitcoin/blockchain/ or
thereabouts.

Any objections?

-- 
Jeff Garzik
exMULTI, Inc.
jgarzik@exmulti.com


-------------------------------------
On Wed, Feb 13, 2013 at 1:02 PM, Gavin Andresen <gavinandresen@gmail.com> wrote:

That would be fantastic.


-------------------------------------
On Mon, Jun 17, 2013 at 11:48:22PM -0400, Alan Reiner wrote:

Have you seen Timo Hanke's pay-to-contract presentation at the San Jose
conference? It seems very related:

  http://www.youtube.com/watch?v=qwyALGlG33Q

-- 
Pieter



-------------------------------------
On Fri, Jun 14, 2013 at 4:06 PM, Peter Todd <pete@petertodd.org> wrote:

Interesting proposals, particularly this last.  The net result impact
is, however, that which was criticized in at least one forum thread:
replace-with-higher-fee.



In terms of packet size, I would like to look into the network-wide
costs of simply broadcasting block header + coinbase TX + TX list.  I
bet miners would love to opt into that.



With the onslaught of ASIC mining, most big pools are past a share per
second.  Variable difficulty or set-to-higher-difficulty quickly
became the norm, almost out of necessity.

Personally, I think most pools should target at _least_ 5-10 seconds
per share, no matter the strength of the miner.

-- 
Jeff Garzik
Senior Software Engineer and open source evangelist
BitPay, Inc.      https://bitpay.com/


-------------------------------------
What if a transaction is tagged as eligible for replace by fee possibly 
using the lock_time (0xFFFFFFFE) so the parties involved can decide 
which approach works best for them.  If the receiving side doesn't see 
the type of transaction they want they consider it invalid.  The payment 
protocol can be used to negotiate which method should be used.

If lock_time is final as it is now for all standard transactions, the 
current behaviour for transaction propagation would be kept with the 
addition of double spend proof notifications as I described. But if the 
transactions are tagged appropriately, they would be replaced by fee.

In the recommended implementation, once a node sees a transaction that 
is not eligible to be replaced by fee it would treat all successive 
transactions that way despite the tag.

This shouldn't hurt merchants that wish to use just double spend 
notification while still enabling replace by fee for those who think it 
is preferred.

I do find the burn coins and buyer pays twice with a merchant refund to 
be compelling solutions, but you can't always trust the merchant (face 
to face street merchant).  Also, there is a short window of time were a 
block can be mined before the burn coin counter measure is received.  It 
is isn't guaranteed this will work better than current behaviour with 
double spend notification especially considering notification don't cost 
the merchant when it works.

- Quinn



-------------------------------------
Getting back to the original proposal:

RE: uuid instead of "main" / "test" in the payment protocol:

I vote no.

The payment protocol will become at least 3 BIPs:

1) Protocol messages (current gist, essentially)
2) MIME type
3) bitcoin: URI extension

An alt coin will need its own version of (2) and (3), so when you
click on a foocoin: link a foocoin-specific MIME type is fetched and
foocoin.exe is launched to handle the request.

... or a specific MIME type is fetched and delivered to the
HandlesLotsOfCoins application (... and it knows what MIME type it is
getting, so can Do the Right Thing).

If a payment request is delivered via HTTP or email, it will be
bundled up in an envelope of some sort with the MIME type attached.

So, after further thought, I've changed my mind: which coin would be
encoded in the MIME type.  Which chain for that coin would be encoded
in PaymentDetails.network.

-- 
--
Gavin Andresen
Chief Scientist, Bitcoin Foundation
https://www.bitcoinfoundation.org/


-------------------------------------
On Thu, Dec 5, 2013 at 3:27 PM, Luke-Jr <luke@dashjr.org> wrote:




How is github a hurdle?

It's easy enough to create a fork and submit back the changes as a pull
request.

In the case of text documents, this can be completely done through the web
interface.

If anything creating a github account is a smaller hurdle than having to
pay to create a wiki account and wait for it to be activated.

Aside: my proposal is for the BIPs that are already accepted, and should
not be edited without dicussion. If people want to put their drafts in the
wiki that's a different story.

Regards,
Wladimir
-------------------------------------
On Mon, Oct 21, 2013 at 11:46 AM, Andreas Schildbach
<andreas@schildbach.de> wrote:

Cool.


Correct.  And assigning BIP numbers.  Ideally a boring administrative
position.  :)

The main tensions will be in gauging whether there is sufficient
consensus and review to boost a draft into BIP/proposed status, and
then promoting a numbered BIP to the final/accepted status.

-- 
Jeff Garzik
Senior Software Engineer and open source evangelist
BitPay, Inc.      https://bitpay.com/


-------------------------------------
For usability purposes, we at Hive would like to have an auto-updater in our wallet app.

What is a safe way to do this? I understand that Bitcoin-QT lacks such an updater for security reasons... Has been thought out in more detail since that decision was made?

We have been toying around with the idea of placing one server behind a Tor hidden service, whose only function is to output a checksum of the update package. The theory is that if it is well-secured, it will at least be immune to tampering at the physical hosting level.

Any thoughts or advice about any of this?

-wendell

grabhive.com | twitter.com/grabhive | gpg: 6C0C9411

-------------------------------------
(my post hasn't shown up for an hour, so I'm sending it again)


On 12/01/2013 02:41 PM, Mike Hearn wrote:


I assume you're right, since I do not have so much experience with game
theory.

About the UI:

Generally, for pending tx I'd like to measure time they're not being
broadcast-confirmed and count blocks that they missed being included.
Both can be combined into adapting the current generic messages ("This
payment should become spendable shortly" for incoming and "This payment
has not been transmitted yet" for outgoing transactions). Hint:
Statistics could be offered by bitcoinj.

For outgoing transactions, if it is very clear that they're never going
to be confirmed, I'd like to see a "Revoke" button. This would have
saved us some support hassles with the transmit bugs. It could also
offer a "Top up fee" button, which would replace the tx by a new one.
I'm aware about a possible double spend but who cares? It doesn't matter
which of the two transactions gets into the chain, as long as not both
will be included.



-------------------------------------
My signature:

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256

Linux distribution packaging and Bitcoin
========================================
2013-07-23

This note summarises the dangers inherent in the Linux distribution
packaging model for Bitcoin, and forms a request from upstream
maintainers to not distribute Bitcoin node software as part of
distribution package repositories without understanding the special
requirements of Bitcoin.

Distributors typically unbundle internal libraries and apply other
patches for a variety of generally good reasons, including ensuring
that security-critical fixes can be applied once, rather than multiple
times for many different packages. In most cases, the common
distribution packaging policy has many advantages.

However, Bitcoin nodes are an unusual category of software: they
implement a complex group consensus in which every client verifies the
behaviour of every other exactly. Even an exceptionally subtle change -
including apparently harmless bugfixes - can cause a failure to reach
consensus. A consensus failure of one client is a security risk to the
user of that client. A significant number of nodes failing to reach
consensus - as happened in March 2013 due to a change in database
libraries[1] - is a critical problem that threatens the functionality
and security of the system for all users.

For this reason, it is _vital_ that as much of the network as possible
uses _unmodified_ implementations that have been carefully audited and
tested, including dependencies. For instance, if the included copy
of LevelDB in bitcoind is replaced by a system-wide shared library,
_any_ change to that shared library requires auditing and testing,
a requirement generally not met by standard distributor packaging
practices.

Because distributed global consensus is a new area of computer science
research, the undersigned request that distributors refrain from
packaging Bitcoin node software (including bitcoind and Bitcoin-Qt)
and direct users to the upstream-provided binaries instead _until they
understand the unique testing procedures and other requirements to
achieve consensus_. Beyond being globally consistent, upstream binaries
are produced using a reproducible build system[2], ensuring that they
can be audited for backdoors.

1. https://en.bitcoin.it/wiki/BIP_0050
2. http://gitian.org/

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBCAAGBQJR9WC5AAoJEEWCsU4mNhiPg6UH/2oHzBWBPaQMhH/GCTHQEi5U
7GSRfqwihIs/M2ROHLNq0HhgWR7mPAh5TTI6+tG95FCGCGNZq0seqw9wW4ZyGCoc
VueY51q4hcn23405oLD/QGK2lDxxywWY8XtFYVPqAzXTq6zRzgpNJkjoRtOAUOP7
3PrRkimYYyj0KrqFg+cEvZDT27dkeX+5PXM6Ua0o7h/TlhR2RJPhej5DI8cNLXgA
f0t+mES4Apb6zLgnEYYlPp22FR9vuFcJO3z1akhVL4DLUMqr58NYHLVnH1FH0Jhn
hVuld159QtCjQ5Qyn19cn86akTQJVi+ikCXqaKriCc2jBFX7TCI8WTDc6aSZpsQ=
=oX5d
-----END PGP SIGNATURE-----


-------------------------------------

I agree in the general case, but I was talking about the mobile wallet case specifically (i.e. people who are sending money between themselves or making small purchases of physical things). I think Bitcoin should be able to scale to handle these sorts of ordinary every-day transactions. Where Id expect to see transactions falling off the edge is in more specialised cases like very small single micropayments, or optional internal transactions like mixing/re/defragmentation of wallets that dont correspond to an actual payment. Those sorts of transactions would I guess be the first to go when faced with a sudden capacity crunch, but they wouldnt show up in a mobile wallet UI anyway.


I know the existing code is, but is that fundamentally the case or just how the code has been written? I havent looked at this issue much but I know youve worked on it, so Im curious to learn about why its inefficient and whether there are any fixes possible.	
-------------------------------------
An attacker with some small hashpower isolates you (as an individual)
from the network by MITMing your network. You just switch the the
attackers chain as if nothing happened because of the network rule
that defines it as OK. Today, you will see that you're behind and warn
the user.

Was it really so hard to write a three-sentence paragraph to clarify
the attack instead of insulting people? Still, posting ideas here
without spending time to ensure you understand the Bitcoin network
well is frowned upon.

Matt

On 12/23/13 17:51, Ryan Carboni wrote:
Rapidly troubleshoot problems before they affect your business. Most IT


-------------------------------------
On Sat, Nov 9, 2013 at 9:16 PM, Chris Evans <aaxiomfinity@gmail.com> wrote:


This has been discussed many times. But in any case: If you encounter this
as a problem it means you are re-using addresses, which is discouraged for
good reasons.

Otherwise, when someone wants to send you BTC they need to request a new
receiving address from you. Along with this request they can also send a
message, over whatever channel is used to negotiate the payment.

If you're just posting a static bitcoin address somewhere for donations,
consider it an anonymous (wel, pseudonymous) gift jar.

Regards,
Wladimir
-------------------------------------
All that is good practice, but we should avoid adding burdensome
process that might discourage BIP writing.

Consider a distributed approach:  if you feel a draft needs more
sections or better language, submit a pull request yourself and help
community-edit the document.

On Tue, Oct 22, 2013 at 3:34 AM, Martin Sustrik <sustrik@250bpm.com> wrote:



-- 
Jeff Garzik
Senior Software Engineer and open source evangelist
BitPay, Inc.      https://bitpay.com/


-------------------------------------
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 7/11/13, 21:31 , Peter Todd wrote:

Great additions! - I was about to do a second iteration of the
calculations including the pool size, but you beat me to it - thanks!

Still the picture remains the same - you can half the fee if you are a
large pool


You second list of numbers is an unlikely extreme:


The propagation latency in the network is more due to the block
verification than due to its network (fiber) propagation time,
bringing down the number of hops helps tremendously, so I agree that
we can probably bring down k by a factor of ~10 (k=8-12) if we
consider only pools directly connected. This should bring us close to
break even with the current fee size, but we should really get some
empirical data for interconnected large pools. However - important
note - if you are a 1% miner - don't include transactions!



I don't see a problem of rewarding economy of scale, as long as the
effect is not too grave (raising the min fee would actually make it
more profitable for smaller miners).

Michael

November Webinars for C, C++, Fortran Developers

-----BEGIN PGP SIGNATURE-----
Version: GnuPG/MacGPG2 v2.0.22 (Darwin)
Comment: GPGTools - http://gpgtools.org
Comment: Using GnuPG with Thunderbird - http://www.enigmail.net/

iQEcBAEBAgAGBQJSfA0SAAoJEKpww0VFxdGRSEUIALFws8/nNDGPDFWKX2N19jWA
YecC7ZdMgN+1xmf+z2TNjaREvUqI1BLbYO3qQj9AsvTgkMZDwo8c5hMfJL7//V+z
vLiygTbEcorEbyM54w8yTuDVBqdNEg22Cn2T35DIEmqxGP5OSqw+vEBp2B4Y7asv
GG+JgYTVNJf6kZ1GV8cXYnXVBgfccZfXllBYOIPjyk2tdz7HMJN10WKUePbSJtg+
zcvly05JY70d1quERj/fXxVsHpPP6BrH5sH+h4WPxM27+i6R3N90JLAWbB9D4h2s
oYK9MMlH3UC3HR4AR7po4xxuOpxOK3Exa6d9ACQGPGtLRNVWmHiBFT2SViKViK4=
=gALT
-----END PGP SIGNATURE-----


-------------------------------------
I personally don't treat the relay field as optional, i.e. it is there as
0x01 if it is set. Otherwise, it is simply a trailing zero byte. Hence, the
right way of reading the packet as with any network packet is to first
retrieve the header information, get the actual payload length, then parse
the payload accordingly. I can also choose to include 0x00 for my relay
field in my outgoing packet and reflect that accordingly in my length field
in the header.


On Thu, Jun 20, 2013 at 4:20 PM, Turkey Breast <turkeybreast@yahoo.com>wrote:

-------------------------------------
On Sat, Mar 16, 2013 at 9:03 PM, Alan Reiner <etotheipi@gmail.com> wrote:


Well, he did make the bitcoin.org/may15.html page already. It would be
crazy to change that now.




-- 
*MONEY IS OVER!*
                                IF YOU WANT IT<http://www.zeitgeistmovie.com/>
=====================================================
The causes of my servitude can be traced to the tyranny of money.
-Serj Tankian
-------------------------------------
On Monday, August 19, 2013 8:09:41 PM Frank F wrote:

You missed getblocktemplate. It does everything getwork did and more.

Individual solo miners aren't being locked out at all. This is just removal of 
a protocol that has been obsolete for well over a year now.

Luke


-------------------------------------
On Fri, Dec 13, 2013 at 4:24 AM, Mike Hearn <mike@plan99.net> wrote:


Why would there be an iteration count? The payer would handle that,
wouldn't they?

If the use case is:  I give the Foundation a "here's where to pay my
salary" PaymentRequest, maybe with several Outputs each having a different
xpubkey, then it seems to me the Foundation's wallet software should take
care of iterating.

(either saving state, so it knows it used xpubkey+10 last month and should
use xpubkey+11 this month, or maybe it knows I'm paid monthly and just uses
xpubkey+(number_of_months_from_date_in_original_payment_request).

-- 
--
Gavin Andresen
-------------------------------------
On Fri, May 31, 2013 at 7:56 AM, Rune Kjr Svendsen <runesvend@gmail.com> wrote:

Similar to other suggestions in this thread,

If your -blocknotify execution is too slow, then create a solution
that simply queues work.  There is no need to add this code to
bitcoind itself.

Another solution is modifying pynode to directly listen to a trusted
node (bitcoind), and monitor blocks as they arrive and are announced.
That does not fix the problem of slow block processing on your side,
but is another way to implement -blocknotify-like behavior.

-- 
Jeff Garzik
Senior Software Engineer and open source evangelist
BitPay, Inc.      https://bitpay.com/


-------------------------------------
On Sun, Jul 28, 2013 at 07:39:08PM +0000, John Dillon wrote:

One subtlety of what you are proposing is that we should still retain
the IsStandard() check, or to be exact the AreInputsStandard() check, if
a P2SH serialized script follows a standard form.

The reason is transaction mutability. Right now other than BIP11
CHECKMULTISIG only miners can mutate transactions because any change to
the scriptSig will render the transaction non-standard. As you know this
is a good thing because it means unconfirmed transaction chains don't
get broken in flight.

BIP11 is an interesting case because CHECKMULTISIG consumes one extra
stack item, so when you spend a BIP11 n <pubkey>...<pubkey> m
CHECKMULTISIG scriptPubKey you have to provide an additional item prior
to the signatures; usually OP_0 is used.

But we don't actually check that! You can put anything there provided it
doesn't make the scriptSig go over the standard allowed scriptSig size
of 500 bytes; for instance I (ab)used that feature just now to timestamp
my Litecoin v0.8.3.6 audit report SHA256 hash:

d0dfe270e8e8e4c0196f780d42e34d8a1121f2f8a249586aa1a2c5ebcada10b1

in transaction:

15bb08318335f94a8de154dc39b03db2cdebcc7a96ab6cec0379978676d00301

It's been suggested that we consider transactions non-standard, or just
now allowed at all in a future soft-fork, if at the end of execution
there is more than one stack item left; a opcode whitelist should
probably do this. On the other hand I've come up with some soft-fork
upgrade mechanisms that would leave extra items on the stack for
non-upgraded nodes, suggesting a soft-fork imposing this is a bad idea.
(though note how it suggests considering such tx's non-standard is
reasonable in a few ways)

CHECKMULTISIG isn't helped here because the value really is ignored - a
soft-fork to force it to always be zero might not be a bad idea, though
it's far from the only example of mutability.

I'd be interested if you can come up with an example where imposing a
one stack item at the end of execution rule causes problems.


More generally, and getting a bit off topic, I think Bitcoin should have
been designed so that CHECKSIG signed hashes of scriptPubKeys, rather
than txid:vout outputs, so that malleability wouldn't affect the
validity of a signature. Of course, this would mean that signatures
could be reused if scriptPubKeys were reused, but address re-use is a
bad thing anyway! Not that I'll fault Satoshi here, type 2 deterministic
wallets were unknown back then. (though we should be careful that a
future CHECKSIG design can go back to txid:vout references - ECC is
unique in allowing for type 2 wallets)

-- 
'peter'[:-1]@petertodd.org
0000000000000053ef658095fb45c7a86955d70c76b44264c7abce79683a8a90
-------------------------------------


Actually I might find way to fund it. But I needed to have ACK &
comments from developers before anything.


That is a fair question, we will need anti-DDoS. Unless something better
(and affordable) can be recommended, this would yet put another Bitcoin
website under CloudFlare.


Obviously, I thought it would be important that the server is owned by
someone who can be trusted, with ssh access for all core developers.


I'm not sure we'll get any change on this level. I have no idea if the
domain is in good hands, except for the fact that nothing bad happened
thus far. If anything, moving it to core developers (as intended when
the domain was registered) would make more sense IMO. But again, is it
possible, I don't know.


-------------------------------------
Removing getwork and the old miner and packaging a better miner seems
the best solution for the reasons already mentioned.

Not directly related, but this remembered me that we planned to
remove the accounting features on freicoin. We don't want to adapt
them for demurrage and we think business shouldn't use it and should
code their own accounting system instead. One that keeps a full log
of the accounting, etc.
Unfortunately the first exchange to support freicoin (cryptonit) used
this feature for accounting user balances on the exchange.

So the question is, is there any good reason to maintain this?
Is any serious business really using this or anyone at all?

I'm talking about removing the following rpc calls:

getaccount
getaddressesbyaccount
getbalance
getreceivedbyaccount
listaccounts
listreceivedbyaccount
move
sendfrom
setaccount

...and modifying these:

getnewaddress
listreceivedbyaddress
listtransactions
sendmany

I think this would also leave a cleaner API, but I'm just interested
on what the objections would be to this removal.

How crazy does this sound?
Should we reconsider their removal for freicoin, proceed or create a
pull request for bitcoin?

-- 
Jorge Timn

http://freico.in/


-------------------------------------
On Tue, Apr 9, 2013 at 10:53 AM, Mike Hearn <mike@plan99.net> wrote:


"wait" is only an option if there is an alternate solution already
coded and ready for 0.8.2.
-- 
Jeff Garzik
exMULTI, Inc.
jgarzik@exmulti.com


-------------------------------------
On 10 June 2013 10:26, John Dillon <john.dillon892@googlemail.com> wrote:


Thanks for your reply.  Do you have a pointer to Satoshi being strongly
against GPU?  I'd be interested to see that.  FWIW, I've read all his forum
posts a few times, I just dont recall this one, tho I'm sure it's there...


-------------------------------------
On Thu, Jun 27, 2013 at 5:12 PM, Alex Kravets <kravets@gmail.com> wrote:

Bitcoin Wallet for Android is a decentralized client w/ network sync,
and it works just fine.  Fast, easy to use.

-- 
Jeff Garzik
Senior Software Engineer and open source evangelist
BitPay, Inc.      https://bitpay.com/


-------------------------------------

On Dec 3, 2013, at 12:29 PM, Mike Hearn <mike@plan99.net> wrote:



Why should there be two classes of transactions? Where does paying a local business at a farmers stand lie in that realm? Transactions should work the same regardless of who is on the receiving end.

The paradigm of sending money has an explicit cost is not new... I think people are used to Western Union/PayPal and associated fees, no?  Its okay to have a fee if its reasonable, so lets inform the user what the estimated cost is to send a transaction in a reasonable amount of time.

I stayed in a hotel for the first night here here in Milan, and there was an (anticipated) surcharge for the use of credit over cash. Again, nothing new here.


Fees are only confusing because existing clients do a terrible job of presenting the information to the user. In Hive Wallet, Im of the opinion that we should inform the user in an intuitive way to let them make an informed decision.
-------------------------------------
Hello,

Please see below our BIP for raising the selfish mining threshold.
Looking forward to your comments.

Best,
Ittay

---

Bitcoin Improvement Proposal

Owners: Ittay Eyal and Emin Gun Sirer

We suggest a change in the propagation and mining algorithm for chains of
the same difficulty, to raise the threshold on Selfish Mining attacks.

* Current situation:
When a miner is notified of a new chain of the same difficulty as the one
it is mining on, it will ignore it.

* Background:
The selfish mining attack and its implications were described in detail in
the following research paper:
http://arxiv.org/abs/1311.0243v1

* Proposal:
To thwart selfish mining attacks launched by less than 25% of the mining
power, we propose the following change to the protocol:
When a miner learns of more than one chain of the same difficulty, it
should propagate all of them, and choose one of them to mine on uniformly
at random among all chains of the same difficulty.

When hearing of a chain of maximal difficulty that it did not know of
before:
1. Add it to a local list of maximal difficulty chains.
2. Propagate it to its neighbors.
3. Choose a branch uniformly at random from the local list, and mine on it.

* Example:
t0: learn of chain A of difficulty x.
    propagate A to neighbors.
    start mining on A.
t1: learn of chain B of difficulty x.
    propagate B to neighbors.
    toss a coin between A and B; if B wins, switch to mining on B.
t2: learn of chain C of difficulty x.
    propagate C to neighbors.
    toss a 3 faced coin among A, B, and C; switch to mining on the winning
chain.

* Concerns and answers:
1. No harm to miners when all are honest.
Mining blocks is a random Poisson process, which is memoryless. Having
mined on the block in the past does not provide an advantage in locating a
solution in the future. Therefore, a miner is not harmed by switching the
chain on which it mines.

2. No new vulnerabilities introduced:
Currently the choice among equal-length chains is done arbitrarily,
depending on network topology. This arbitrariness is a source of
vulnerability. We replace it with explicit randomness, which is at the
control of the protocol. The change does not introduce executions that were
not possible with the old protocol.

3. Complete backward compatibility:
Any subset of the miners can switch to the proposed protocol.

4. Progressive improvement:
Each miner that adopts the change raises the threshold a little bit. The
threshold will reach 25% with universal adoption.
-------------------------------------
On 07/23/2013 11:47 AM, Peter Todd wrote:


Yes, I understand that. For this reason, I would vote for adding the
usual HTTP authentication/SSL stuff to the REST API. That way, SPV users
can decide to run their own instance of the API (providing the needed
resources themselves).

Or, a trusted party can set up a server. For example, I would be willing
to set it up for users of Bitcoin Wallet. I don't expect shitloads of
paper wallets sweeps for the forseeable future.




-------------------------------------
On 4/10/13, Peter Todd <pete@petertodd.org> wrote:

I thought about this before, I like the idea very much.
Would such a fork be controversial for anyone?
Would anyone oppose to this for some reason I'm missing?

-- 
Jorge Timn

http://freico.in/


-------------------------------------
Note that the "earn a mixture of BTC and TBC, but not both in full volume" 
only works for TBC because the price is by definition fixed with BTC.
I'm not sure how you could implement something like this for an altcoin where 
the price is floating independently of Bitcoin.. that is, how you would know 
the right amount of Bitcoin to require sacrificed.

Luke


On Friday, June 14, 2013 8:50:31 PM Adam Back wrote:


-------------------------------------
On Mon, Nov 04, 2013 at 11:11:34AM -0800, Mark Friedenbach wrote:

You don't need level compression if you adopt my per-block randomization
idea. I think we'd be better off keeping the proofs as simple as
possible, just dumb merkle paths.


I mentioned UUID more in spirit than in terms of the official UUID
standard; any large randomly picked integer is fine.


Wouldn't hurt to run the idea past forrestv, given p2pool will be
affected as it'd need to adopt the standard. He's run into some oddness
with mining hardware and nonces that would be good to understand. (note
how p2pool blocks don't commit to a fully random hash - there's some
extra bytes in there due to stratum or something IIRC)

-- 
'peter'[:-1]@petertodd.org
000000000000000601a5b2f2b4a597851fdf00f6fc3572bbc03f26857c170032
-------------------------------------
On Wed, Sep 18, 2013 at 5:16 AM, Johnathan Corgan
<johnathan@corganlabs.com> wrote:

No.

     Jeff


-------------------------------------
Ryan Carboni wrote:
This is a feature, not a bug.

Also, this is offtopic.  Political debate is thataway ->.

bitcoin-development is for development and technical discussion.
-------------------------------------
This is probably too late in the discussion, and I certainly don't
want to derail any standard being formed. But if it is controversial,
I want to offer my own suggestion.

This is a proposal I wrote a year ago, but never spent enough work to
push it as a standard:
https://bitcointalk.org/index.php?topic=102349.0

It needs some work, but I believe it may be a base for a superior
system than what is being proposed here. As the scheme linked above
has built-in configurable difficulty and checksums, the word set being
used doesn't need to function for checking anymore. You could use any
dictionary/language/text generator, and feed it into the system - the
software on the other side doesn't need to use the same dictionary.

The disadvantage is of course that it cannot encode arbitrary data -
it can only be used to generate a random seed. It does have some
theoretical advantages, though (see link).

-- 
Pieter


On Thu, Oct 24, 2013 at 8:26 PM, slush <slush@centrum.cz> wrote:


-------------------------------------
Conceptually it sounds a lot like ZeroCoin (not in implementation)?

I'm not really convinced miner cartels that try to exclude transactions are
likely to be a big deal, but such schemes could I suppose be kept in a back
pocket in case one day I'm proven wrong.


On Wed, May 15, 2013 at 6:39 PM, Gregory Maxwell <gmaxwell@gmail.com> wrote:

-------------------------------------
On Fri, May 31, 2013 at 5:56 AM, Rune KjÃ¦r Svendsen <runesvend@gmail.com>wrote:


In a similar circumstance, I changed my -blocknotify script to quickly
append necessary information to a queue and immediately exit.  A separate
script runs at all times monitoring this queue for work and performs the
labor intensive calculations.

I hope that helps.

-- 
Michael
-------------------------------------
On Fri, Jun 28, 2013 at 10:09:16AM +0000, John Dillon wrote:

Agreed.

Speaking of, I may have missed it but as far as I can tell Bitmessage
doesn't encrypt node-to-node communications, a serious oversight. Any
attacker that can sniff a large fraction of the network, like the NSA,
can easily use this to track down the originating node of any message,
just like they can do with Bitcoin.


Ah! I had a feeling that might be you. Were you the person who was
creating the 1BTC fee transactions as well?


I just got an email from someone saying they had a few Avalons with that
patch installed actually; that was probably them.


Keep in mind it's not just the mempool that needs changing - the network
protocol semantics need to change too. For the "scorched-earth" strategy
to work you need nodes tell their peers about the total fees a
transaction has attached in addition tot he tx hash. Essentially you are
advertising to your peers what would right now be an orphan, and your
peers need to recursively get dependencies; I'm sure there's a bunch of
edge cases there that would be need to thought out carefully. It's
useful for a lot of things though, for instance when a zero-fee,
zero-priority tx is given to a merchant who now wants to tell miners to
mine it anyway due to a child tx.

What I'd recommend actually for the nearer term is just adding recursive
fee evaluation with a depth*breadth anti-DoS limit, adding the rpc and
GUI adjfee and canceltx commands, adding better wallet support for
conflicts, (someone is already workng on this) and adding a service bit
with preferential peering.

By preferential peering I mean you set aside a portion of your outgoing
peer slots for peers with certain bits set and only fill those slots
with those peers. In addition you can have DNS seeds return peers with
specified service bits set: x0000000000000003.v1.seed.petertodd.org
could be nodes with the first and second bits set. (we might want to
define the upper 8 service bits as a service bit version field so we can
redefine the other 56 in the far off future if required)

-- 
'peter'[:-1]@petertodd.org
00000000000000b2b1f2ca2a2f937c2d93c41a5d089e1d3d4fe6bb663dd25db5
-------------------------------------
On Wed, Jun 05, 2013 at 05:19:16PM -0700, Peter Vessenes wrote:

A few issues:

Revocable payments are almost always invoked in cases where the decision
that a payment needs to be revoked is done by humans. To worry about the
difficulty of finding a "trusted escrow service" is irrelevant at the
protocol level - this isn't a problem that can be solved by math.

Legally speaking revocation can generally happen any time in the future,
even years in the future. Note the controversies involved around a
variety of land transactions that occured hundreds of years in the past
in North America and other parts of the world, where distant relatives
of those who made the transactions are attempting to have them reversed
partially or fully. Technical solutions with a limited revocation window
are likely to be found unacceptable in the eyes of the law.

Focusing on the need to "revoke" a transaction is taking a banking idea,
and applying it very incorrectly to the Bitcoin world; in banking
revoking a transaction can result in your balance being negative.

What you need to focus on is the spirit of what revoking a transaction
is about, which is to take money from someone who thought they had it,
and give it to someone else. We can easily replicate this effect in
Bitcoin by simply giving the private keys for our wallets to the
relevant revocation authority, or, if more auditing is desired, storing
our coins in 1-of-2 multisig addresses spendable by either us or that
authority.

In the event that a transaction needs to be revoked, simply have the
escrow service make a transaction that takes the correct amount of coins
from your wallet, and gives it to the person who sent you the money.

Problem solved.

-- 
'peter'[:-1]@petertodd.org
0000000000000108f8cf27a2a2f49384346d915ff0970554358b9544bc7f5bfd
-------------------------------------
BitPay experimented with QR codes in low light, restaurant and other
conditions.  QR codes become difficult to use even at 100 chars.

On the merchant side, we prefer a short URL that speaks payment
protocol if visited via bitcoin client, but will gracefully work if
scanned by a phone with zero bitcoin support -- you will simply be
redirected to a BitPay invoice page for a normal browser.



On Wed, Sep 25, 2013 at 7:59 AM, Andreas Schildbach
<andreas@schildbach.de> wrote:



-- 
Jeff Garzik
Senior Software Engineer and open source evangelist
BitPay, Inc.      https://bitpay.com/


-------------------------------------



i see several reasons why this is problematic. 
So how would that work in a setting where the user signs a transaction
created offline, transmitted via Bluetooth via a one-way broadcast?
does it transmit all 3 tx to the receiver and just hopes they he will do
the "right thing"?




-------------------------------------
On Tue, Jul 23, 2013 at 12:27:03PM +0100, Tier Nolan wrote:

Please provide equations and data justifying the 'magic constants' in
this proposal.

Currently we do not relay blocks to peers if they conflict with blocks
in the best known chain. What changes exactly are you proposing to that
behavior?


-- 
'peter'[:-1]@petertodd.org
000000000000001e1c3393788031c4e427b67cfd1b5e90a3b0de4fff094b2894
-------------------------------------

I thought the integrated miner was retired a version or so ago - I 
dontrecall seeing it for some time in bitcoin-qt

Now you can buy a USB stick for $20 which can be pushed to around 
500MH/s, and  there's no reason the manufacturers couldn't ship those 
with a miner-program onboard !

Rob


-------------------------------------
Hey guys,
it sounds great. I read through the bitcoinj documentation and started
reading the code.
A few years ago it wasn't a full client, but now that I see that it's
almost there, it looks much more interesting :-)
Testing the reorg looks critical.

Thanks for the help everyone,
Adam

On Sat, Apr 6, 2013 at 7:21 AM, Mike Hearn <mike@plan99.net> wrote:


-------------------------------------
On Tue, May 14, 2013 at 12:50:27PM -0400, Jeff Garzik wrote:

Yes but thats inferior in the sense that it is spamming the bitcoin payment
protocol slightly, to the small reward of miners, and involves actual money
and traceability to real-name (where did you get the coin from to spend). 

If alternatively you just proof you direct mined on a block with a coinbase
that immediately makes payment to future miners its better because: a) you
can do that with no new traffic for the bitcoin network (except when you
mine a whole block, you'll post it); and b) anyone with a reasonable
verification on the blockchain head (even if the spender has to give it to
them!) can verify it without any other network traffic; and c) if its
micro-mined on the spot it can be bound to the service whereas if you give
it to fees as an on network transaction you are limited to values above the
min tx fee.  

So idealy I think you need to be able to simultanously mine and give reward
to future block miners.

What you could do with out that is d) mine for the reward of bitcoin
foundation/software author/or service provider.  In the last case (service
provider) its an extreme form of Rivests peppercoin probabilistic payment

Adam


-------------------------------------
On Mon, Jul 15, 2013 at 03:05:52PM +0200, Jorge Timn wrote:

Which is why I'm not proposing that.


You are assuming value is the same for everyone - it's not.

If I mine in a jurisdiction where zerocoin is banned, and the blocks I
mine are public, the value of zerocoin blocks to me are at best zero.
Equally it would be easy for the local authorities to ask that I merge
mine zerocoin blocks to attack the chain - it doesn't cost me anything
so what's the harm? I may even choose to do so to preserve the value of
the coins I can mine legally - alt-coins are competition.

Incedentally keep in mind it is likely that in the future pools will not
allow miners to modify the work units they receive in any way as a means
of combating block-withholding fraud; there may not be very many people
willing or able to honestly merge-mine any given chain.

Proof-of-sacrifice can be done in a way that is opaque to the master
blockchain by creating txouts that look no different from any other
txout. Hopefully not required, but it would be a good strategy against
censorship of sacrifice-based chains.


SCIP is for now a dream. Give it a few more years and see how the
technology shakes out.

-- 
'peter'[:-1]@petertodd.org
00000000000000582cc323897a582e9368a5c3dfbcdcf73e78b261703e1bd1ba
-------------------------------------
On 21/10/13 09:07, Jean-Paul Kogelman wrote:

Sorry, I haven't meant you personally. It was just a generic question 
about using existing process instead of inventing a new one on the go.




-------------------------------------

I have never seen SCTP out there. 
Any example where it is used?


We are a bit old fashioned, indeed. 


rm
sec-guy

-------------------------------------

Perhaps I'm confused about how we're using the term soft fork. My
understanding is that this is where a new upgrade is designed to look valid
to old nodes, and if you don't upgrade you rely on the miner majority to
get you "back on track". For instance, P2SH was done this way - old nodes
that didn't upgrade during that transition believed all spends of P2SH
outputs were valid, even those spending someone elses coins.

In this case, the code you cite won't do anything because your client will
never reject a block during a soft-forking upgrade, even if it does
something that's supposed to be invalid or nonsensical.

If a new block version changes the serialization format or script language
or SIGHASH rules such that old clients reject the block, then they will end
up on a hard fork and the alerting code will trigger, which is correct and
as it should be.
-------------------------------------
On Tue, Jun 11, 2013 at 3:11 PM, Melvin Carvalho
<melvincarvalho@gmail.com>wrote:


How do you define opaque? As far as humans are concerned the addresses are
opaque. They don't tell anything about your country or location, your bank,
your name, they don't even form some kind of hierarchy.

type + hashed public key, base58 encoded" thus are not fully opaque. But
it's a long shot, as a hashed value is still very opaque.



No, there have been no changes to base58. The encoding is still exactly the
same as when Satoshi coined it. Can you show an example of what you mean?

Wladimir
-------------------------------------
On 16 August 2013 03:00, Gavin Andresen <gavinandresen@gmail.com> wrote:


+1



+1



What block size do you think is ideal?


-------------------------------------
On Tue, Nov 5, 2013 at 2:15 PM, Drak <drak@zikula.org> wrote:

uh. and so when my solution is, by chance, unusually low... I am
incentivized to hurry up and release my block because?

I've simulated non-first-block-heard strategies in the past (in the
two nearly tied miner with network latency model) and they result in
significant increase in large (e.g. >>6 block) reorgs). It's easy to
make convergence worse or to create additional perverse incentives.


-------------------------------------


Have you seen: https://en.bitcoin.it/wiki/Protocol_specification ?

-------------------------------------
No, the transactions relayed are piped through a bitcoind first (ie
fully verified by a bitcoind). For blocks, for which the timing needs to
be tighter, bitcoinj does SPV-validation. Though it is possible to
create a block which passes SPV validation but causes a DoS score, doing
so would cost a miner a full block's worth of profits, which they are
fairly unlikely to do. In any case, if it every becomes a problem, its
not hard to adapt addnode to allow higher DoS scores for individual nodes.

Matt

On 11/06/13 07:25, Tier Nolan wrote:


-------------------------------------
On 10 June 2013 06:09, John Dillon <john.dillon892@googlemail.com> wrote:


Thinking about this a little more, I guess it does not hurt to build some
kind of voting system into the clients.  But I think it's more useful for
straw polls.  For example a bug fix 100% of people should agree on.  A
protocol optimization perhaps 80% would agree on.  A protocol change that
redistributes wealth or incentives perhaps only 60% will agree on.

At this point in time it's far too easy to deliver contentious changes into
the hands of the general population.  I think that fortunately we're
blessed with a very strong dev team, but the fundamental philosophy of
bitcoin is to not put too much trust in single point, but rather, to
distribute and diversify trust to the edges.



-------------------------------------
We would only end up with few copies of the historic data if users
could choose what parts of the blockchain to store. Simply store
chunks randomly, according to users available space, and give priority
to the "N most recent" chunks to have more replicas in the network.

You don't need bittorrent specifically for a DHT, if publicity is a
problem. There are many DHT proposals and implementations, and i bet
one of them should be more suitable to the bitcoin network than
bittorrent's.



-------------------------------------
HTTP also defines success codes (2xx). Are we also talking about ACK
messages now, rather than just REJECT messages?


On 10/28/2013 03:52 AM, kjj wrote:




-------------------------------------
Do you have a specific use case in mind?

Maybe - if you have a percentage slider like with humble bundles you can
make it more explicit what part went where?

In any case, if you're really interested in this you need to write a new
BIP that extends 21. "Any syntax will do" does not help in implementation
:-)

Wladimir
Multiple recipients/amounts. Any syntax you like. Thanks!

------------------------------------------------------------------------------
Try New Relic Now & We'll Send You this Cool Shirt
New Relic is the only SaaS-based application performance monitoring service
that delivers powerful full stack analytics. Optimize and monitor your
browser, app, & servers with just a few lines of code. Try New Relic
and get this awesome Nerd Life shirt! http://p.sf.net/sfu/newrelic_d2d_may
_______________________________________________
Bitcoin-development mailing list
Bitcoin-development@lists.sourceforge.net
https://lists.sourceforge.net/lists/listinfo/bitcoin-development
-------------------------------------
Omaha - which is the automatic update framework that Google Chrome uses -
is open sourced:

https://code.google.com/p/omaha/

It might be a bit heavyweight for just one package though.

Will

On 9 July 2013 13:04, Mike Hearn <mike@plan99.net> wrote:

-------------------------------------
Mike,

If bitcoinj will be ready and you will help us, we are willing to implement it right away in Hive as well. We will also keep BitcoinKit.framework updated with the new bitcoind and bitcoinj implementations.

BitPay taking the lead here would be tremendous. Hopefully cool sites like Bitcoin Store will also be game to hit the ground running. I'll ask them.

-wendell

grabhive.com | twitter.com/grabhive | gpg: 6C0C9411

On Aug 15, 2013, at 10:09 AM, Mike Hearn wrote:




-------------------------------------
Cool. Maybe it's time for another development update on the foundation blog?


On Fri, Aug 16, 2013 at 3:00 AM, Gavin Andresen <gavinandresen@gmail.com>wrote:

-------------------------------------
On Wed, Nov 06, 2013 at 10:15:40PM -0600, Kyle Jerviss wrote:

Gamblers ruin has nothing to do with it.

At every point you want to evaluate the chance the other side will get
ahead, vs. cashing in by just publishing the blocks you have. (or some
of them) I didn't mention it in the analysis, but obviously you want to
keep track of how much the blocks you haven't published are worth to
you, and consider publishing some or all of your lead to the rest of the
network if you stand to lose more than you gain.

Right now it's a mostly theoretical attack because the inflation subsidy
is enormous and fees don't matter, but once fees do start to matter
things get a lot more complex. An extreme example is announce/commit
sacrifices to mining fees: if I'm at block n+1, the rest of the network
is at block n, and there's a 100BTC sacrifice at block n+2, I could
easily be in a situation where I have zero incentive to publish my block
to keep everyone else behind me, and just hope I find block n+2. If I
do, great! I'll immediately publish to lock-in my winnings and start
working on block n+3


Anyway, my covert suggestion that pools contact me was more to hopefully
strike fear into the people mining at a large pool and get them to
switch to a small one. :) If everyone mined solo or on p2pool none of
this stuff would matter much... but we can't force them too yet.

-- 
'peter'[:-1]@petertodd.org
0000000000000005713cac303bd2d529ebeffa82fff60be5307010a83933698d
-------------------------------------
Which again means that the statement regarding Audits through the Master
Public key, M, is wrong - only incoming and outgoing transaction of
_publicly_ derived wallets will be part of the audit... Privately
derived wallets cannot be obtained, though you could, without loss of
security, share also the addition points from privately derived wallets:
(m/i')*G, but there is no concept of a single public master key.

==
Audits: M
In case an auditor needs full access to the list of incoming and
outgoing payments, one can share the master public extended key. This
will allow the auditor to see all transactions from and to the wallet,
in all accounts, but not a single secret key.
==




-------------------------------------
+1


On Mon, Dec 9, 2013 at 2:06 PM, Gavin Andresen <gavinandresen@gmail.com>wrote:

-------------------------------------
URL: https://github.com/bitcoin/bitcoin/pull/2844

Adding an HTTP REST API for bitcoind has been occasionally tossed
about as a useful thing.  Such an API would essentially provide a
decentralized block explorer capability, enabling easy external access
to transaction/address/block indices that we maintain.

The first two implemented API calls are simple, returning a block or
TX given a simple query string based on block hash, e.g.

     GET /rest/tx/TX-HASH
or
     GET /rest/block/BLOCK-HASH

This can be easily accessed via command line cURL/wget utilities.
Output formats -- binary, hex or json -- may be selected via a
"bitcoin-format" header.

The general goal of the HTTP REST interface is to access
unauthenticated, public blockchain information.  There is no plan to
add wallet interfacing/manipulation via this API.

-- 
Jeff Garzik
Senior Software Engineer and open source evangelist
BitPay, Inc.      https://bitpay.com/


-------------------------------------
On Thu, Aug 15, 2013 at 11:02 AM, Mike Hearn <mike@plan99.net> wrote:


Our plan is to add support for that into v1 firmware, but it also depends
on readiness of surrounding infrastructure; mainly if there'll be support
for payment protocol in multibit in the time of v1 release (I suppose that
the Multibit will be the first wallet  compatible with Trezor AND
supporting payment protocol).

slush
-------------------------------------
It won't fit. But I don't see the logic. A URI contains instructions for
making a payment. If that instruction is "pay to this address" or "download
this file and do what you find there", it's no different unless there's
potential for a MITM attack. If the request URL is HTTPS or a secured
Bluetooth connection then there's no such possibility.




On Wed, Sep 25, 2013 at 12:28 PM, Andreas Schildbach
<andreas@schildbach.de>wrote:

-------------------------------------
And the moment I hit send I realised it's not necessarily true.
Conceivably, a collision attack might help you craft two commits (one
good, one bad) with the same hash.

But I still maintain what I just posted is true: if someone gets
malicious code into the repo, it's going to be by social engineering,
not by breaking the cyrpto.

roy


On Mon, Apr 01, 2013 at 11:51:07PM +0100, Roy Badami wrote:


-------------------------------------
On Wed, May 22, 2013 at 10:29 AM, Luke-Jr <luke@dashjr.org> wrote:

OK, let me qualify.  Layers on top are one thing, but we really do not
want to support cases like the fork that leaves the genesis block
intact, and leaves the subsidy at 50.0 BTC forever.

-- 
Jeff Garzik
exMULTI, Inc.
jgarzik@exmulti.com


-------------------------------------
On Tue, May 14, 2013 at 09:39:46PM +0200, Harald Schilly wrote:

Nice.  But we all kow about the security of DNS ;)

Adam


-------------------------------------
On Sat, Jun 01, 2013 at 08:34:29PM +0000, Luke-Jr wrote:

We have no way of preventing this, so ensure it's done in a way that
minimizes harm. For instance, my zookeyv key-value consensus system can
be implemented using transactions with txout pairs of the following
form:

Let H(d) = RIPEMD160(SHA256(d))

txout_k*2  : OP_DUP H(key) OP_EQUALVERIFY
txout_k*2+1: OP_DUP H(value) OP_EQUALVERIFY

With an additional rule to allow for references to previous sacrifices
with txouts of the form:

txout_n: OP_DUP H(txid:vout) OP_EQUALVERIFY

This is perfectly compatible with Gregory Maxwell's address pre-image
fix to data-in-chain storage, and at the same time is completely
unblockable by making such transactions more expensive - the whole point
is to prove you've sacrificed funds.

Yet another reason why increasing the blocksize is madness.

-- 
'peter'[:-1]@petertodd.org
0000000000000018235c41836eb88ea45343c746a3704c5a155bb90c7d2d9a48
-------------------------------------
On Fri, Apr 5, 2013 at 2:30 AM, Melvin Carvalho
<melvincarvalho@gmail.com> wrote:

The estimates on there may be a bit lossy.


The whole fixation on "51" as a magic number is a bit confusedâ€” I'll
say more below.


None of the pools listed there are meaningfully decentralizedâ€”  before
Luke whines, in theory the ones supporting GBT could be if used in a
way that no one actually uses them.  P2Pool is decentralized based on
the same technology as Bitcoin itself, but it's certainly not as point
and click easy as a centralized pool.


That is correct.

Though I'd point outâ€” the major pool ops all seem to be great folks
who care about the future of Bitcoinâ€” and the continued success of
their very profitable businesses: a 50% mining pool with a 3% fee
rakes in 54 BTC per _day_.

The more likely threat isn't that pool owners do something bad: It's
that their stuff gets hacked (again) or that they're subjected to
coercion. ... and the attacker either wants to watch the (Bitcoin)
world burn, or after raiding the pool wallet can't exploit it further
except via blockchain attacks.


That makes no sense. A centralized pool is the miner, the remote
workers are just doing whatever computation it tells them to do.
Certainly these remote workers might switch to another pool if they
knew something bad was happening... but evidence suggests that this
takes days even when the pool is overtly losing money.  Miners have
freely dumped all their hashpower on questionable parties (like the
infamous pirate40) with nary a question as to what it would be used
for when they were paid a premium for doing so.  It seems even those
with large hardware investments are not aware of or thinking carefully
about the risks.


It's important to know exactly what kind of threat you're talking
aboutâ€”  someone with a large amount of hash-power can replace
confirmed blocks with an alternative chain that contains different
transactions. This allows them to effectively reverse and respend
their own transactionsâ€” clawing back funds that perhaps had already
triggered irreversible actions.

This doesn't require some magic "51%"â€” its just that when a miner has
enough (long enough might be years if you're talking really close to
50% and he gets unlucky). Likewise, someone with a sustained
supermajority could deny all other blocksâ€” but that attack's damage
stops when they lose the supermajority or go away.

More interesting is this:  An attacker with only 40% of the hashpower
can reverse six confirmations with a success rate of ~50%. There is
source for computing this at the end of the Bitcoin paper.   I did a
quick and really lame conversion of his code JS so you can play with
it in a browser:

https://people.xiph.org/~greg/attack_success.html


-------------------------------------
On Wed, Mar 13, 2013 at 11:27 AM, Mark Friedenbach <mark@monetize.io> wrote:

In our common language a hardfork is a rule difference that can cause
irreconcilable failure in consensus; it's not some political change or
some change in the user's understanding or something fuzzy like that.
Please don't creep the definitions... but arguments over definitions
are silly.  If you really object to calling the causes consensus
failure thing something else okay, then suggest a name, but whatever
its called thats what we're talking about here.

Your proposal of having a hardfork but only on the mining nodes has
coordination problems. What happens if we don't know how to contact a
majority of the hashpower to get them to turn off their special
validation code?  This is especially a concern because it's not
unlikely that in a few months there may be solo miners with tens of
TH/s... already we have a single party with nearly a majority, though
at the moment they happen to be mining on the largest couple pools.

Far better to have this special code just triggered on a deadline,
which can be widely advertised as "you must upgrade to 0.7.4 or >0.8.1
before this time" and then all switch at once... and then we
demonstrate the viability of a general mechanism that doesn't depend
on poor miner decentralization.


-------------------------------------
On Mon, Nov 4, 2013 at 12:53 PM, Peter Todd <pete@petertodd.org> wrote:


Ah yes, good point.



They could already create such a setup, but we don't observe it in practice.




Given that IP address data is inherently transient, perhaps a better
solution is to define a short hash in the coinbase that commits to extra
data that is relayed along with block data (e.g. appended to the block
message). It can then be stored temporarily in the block db and erased
after some time, like a few months. It would therefore not really be a part
of the chain, but could be extended as we see fit with any other
semi-transient data required. A new "getextra" message would let nodes
query for it.

The hash can be short because it doesn't have to survive brute forcing
attacks longer than the expected validity period of the transient data
anyway. 80 bits would probably be overkill.
-------------------------------------
On Tue, Jul 23, 2013 at 12:00 PM, Andy Parkins <andyparkins@gmail.com> wrote:

In what way?


A partial blockchain is quite useless, as you can't build an UTXO set from it.
If you're talking simply about the storage requirements for maintaining history,
perhaps, but why rely on SPV nodes for this? Right now, those don't store any
blocks at all, and there is no reason why they should.

The only requirement is that old blocks remain available for new full
nodes to be
able to bootstrap. It's certainly not required that everyone keeps
every block ever
created. That's how the software currently works, but as soon as we get to a few
protocol changes that would allow new full nodes to find specific
peers with the data
they need, we can have fully-verifying yet (partially) pruning nodes.
I think that's a
much better idea than conflating "maintaining a wallet" with
"maintaining a subset
of historical block data".



I disagree strongly here. The rules of the network are enforced by
full nodes, not by
miners - they are just trying to satisfy the rules demaned by the network.

And as far as I know, there is no way to do some "partial validation"
using just the blocks
you care about (and remember, SPV nodes currently have none at all).
One interesting
possibility here is fraud proofs, where the network can relay proofs
that certain blocks or
transactions are violating certain network rules. In this case, even
SPV nodes can just
communicate with eachother and get some "herd immunity". But storing some blocks
doesn't matter here - it is all about whether you can maintain the
UTXO set or not.


That's assuming there is no powerful enough attacker that can benefit from doing
a sybil attack on you. For SPV nodes currently, that risk is limited
to an attacker
that can spend enough on faking a chain with valid proof-of-work, to make you
accept a transaction that will be reversed.

If you go let SPV nodes rely on unauthenticated UTXO set data, there is no such
limitation, and they can let you believe *anything*. There are some safeguards,
like combining it with merkle paths for all outputs that credit you (which again
requires a more expensive index on the other side), but you can't ever guarantee
that a particular outputs isn't spent yet.

-- 
Pieter


-------------------------------------
On 06/19/2013 03:29 PM, Jeremy Spilman wrote:

What you just described is complimentary to what I am proposing.  There
is nothing stopping you from doing it that way, except that it may be
inconvenient in some circumstances.  BIP 32 does not prescribe a way to
use multiple chains like you described with the convenient type-2
derivation (though we could create a variant that does).  And all
separate chains with their 100-address look-aheads may be fine for your
desktop or mobile device, but maybe not a HW signing device with 128 kB
of memory. 

So, some use cases might prefer having a different parent public key
[and chaincode] per contact, some may prefer to synchronize across many
contacts.  For instance, maybe there's a benefit to using the same
parent pubkey across multiple services, as a form of identity.   If I
don't want that, I use your method.  If I do want that, I use my
method.  Given its simplicity, I don't know why both can't be options.

Actually, it doesn't have to be specific to the payment protocol, it can
just be alternative address encoding that some apps would use if they
have a need for it.

-Alan
-------------------------------------
GitHub URL: https://github.com/jgarzik/python-bitcoinlib
Repository: git://github.com/jgarzik/python-bitcoinlib.git

The python library for pynode has matured sufficiently to have a home
of its own.  The python-bitcoinlib project attempts to present a
lightweight, modular, a la carte interface to bitcoin data structures
and network protocols.

Features:

 *   Easy object interface to all bitcoin core data structures: block,
transaction, addresses, ...
 *   Full transaction script engine
 *   Fully verifies main and testnet block chains (via pynode)
 *   ECDSA verification (OpenSSL wrapper)
 *   Object interface to all known network messages
 *   Binary encoding/decoding (serialization) for full bitcoin
protocol interoperability
 *   Passes many of the tests shipped with the bitcoin reference
client (bitcoind/Bitcoin-Qt)

Like pynode, this library is currently a developer-only release, not
recommended for highly secure production sites.

Pull requests, comments, questions and donations always welcome.

-- 
Jeff Garzik
exMULTI, Inc.
jgarzik@exmulti.com


-------------------------------------
On Tuesday, July 23, 2013 11:23:27 PM Greg Troxel wrote:

It was written with bitcoind/Bitcoin-Qt in mind, which don't work on BSD. :p


It should be portable to other systems, though hasn't been done yet.
Would be nice if the concepts it uses could be integrated into the package-
building systems.


The problem is that we require bugs. That is, if your library has those bugs 
fixed, you have introduced a security vulnerability.


There is no configure-time for this node software yet. The autoconf-based one 
in the works *does* make this check, however.


The review process is very slow and strict, but that is because of the same 
reasons it isn't safe to distribute patched versions in general. Merging your 
patches to mainline is not only a good idea, but it helps to ensure they get 
the necessary testing needed to be safe.

Luke
-------------------------------------

I know this will be a controversial viewpoint in some quarters, but
I'm not a fan of anonymity, or of pseudonyms.  As far as I know
(please correct me if I'm wrong) all the core devs go by their real
names with the exception of Satoshi (and I would hope he no longer has
commit access? - only because I would hope that no-one has
pseudonymous commit access these days).  I don't see why this should
be different for the domain, the DNS and the rest of the
infrastructure...

Although that's separate from the question of who the registrant of
the domain should be (the registrant being the closest thing a domain
has to a recorded legal owner).  Who currently purports to be the
current legal owner of the domain?

IMHO the registrant should obviously be real and not WhoisGuard -
anonymous stuff like this always looks shady.  And surely the Bitcoin
Foundation is the obvious candidate to own the domain (just like
kernel.org is owned by the Linux Foundation).  But this may all be
moot unless the current legal owners are willing to assign the
domain...

roy



-------------------------------------
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

There's no reason the signing can't be done all at once. The wallet
app would create and sign three transactions, paying avg-std.D, avg,
and avg+std.D fee. It just waits to broadcast the latter two until it
has to.

On 10/25/13 5:02 AM, Andreas Petersson wrote:
October Webinars: Code for Performance
_______________________________________________
-----BEGIN PGP SIGNATURE-----
Version: GnuPG/MacGPG2 v2.0.19 (Darwin)
Comment: GPGTools - http://gpgtools.org
Comment: Using GnuPG with Thunderbird - http://www.enigmail.net/

iQIcBAEBAgAGBQJSanJVAAoJEAdzVfsmodw4RHYQAKBrku4S80GXtbt4wBgkRMgx
EQuobBrwtknxHOhKyYuBeAJ+h8ao1zSSNeqLvS5fJShH7vwBD2UOePLw4Nsy5p9U
pe56c07pRmgi+EWdq/3o1tggp9HN0FR3HDRwt03U4qrPTx449kHb11aOw5KZH7VS
ZiG09gKxkMPOtUy9dmVukjkG3zQ1AWjax+aOoseCnkU8u1I4kfhOyWLIjD7ciMm4
07gD8MzBLHTfJ6/pwUczQCby76Xdg51G/5d/toT3EnXyEOC7tCbI4xunAn1eIyg3
eCUNYaOQ7WYV9tjBUDGFwjVkGDJ8KdzEUqMPEK5nAWF29vmrwBSGJ4H2C47OkTQA
58Ie0hEYc5FMNuUCUWz3IGt2zoQ/8YENtNUDKG8oVoNhAIp5zkLK8wsMAJjZP6WM
z56JUl8NZ2Ka5U1OelImGGVZIx4NXrXlccyxemAn3/c+krkpNv0CHAeMCeNbPG8i
e4l2vQandiBW4NBGVYcm5A/EO6VJHAJhLEPT0pjmbuq4qTACo4Fgeb0LpOnWb/1a
6b1SdGGhMMrXeR2IaIbnx0+0WArixsOPl9w+R9WbrMh8g7hYBLH8EpGrRj0omim7
OoJb+W599HU37XZyWtuov+8Ouh5DpnP9l4hvNxHmro77uPPq10i/ibMd0Bnm4zZd
ALtIYpYYgUCN1D9lQwPQ
=BjIH
-----END PGP SIGNATURE-----


-------------------------------------
On Sun, Apr 7, 2013 at 5:34 PM, Pieter Wuille <pieter.wuille@gmail.com>wrote:


Without significant effort, I don't think we're going to be able to get
that number down. I'd like to stress that without making these non-standard
encodings effectively invalid on the network, pretty much every full node
implementation needs to depend on OpenSSL to guarantee compatibility (and
that is hoping OpenSSL doesn't change its supported encodings), or make
assumptions about which deviations are allowed.

The next question, I guess, is at which transaction frequency it's
acceptable to move forward with this? The first step is definitely just not
accepting them into memory pools, but leaving them valid inside blocks.
Actual network rules will need to come later. However, even just not
accepting them into memory pools will it make very hard (if not impossible)
for the buggy clients that create transactions to get any confirmations.
I'm not sure... 0.6% isn't much, but 9600 transactions is.

-- 
Pieter
-------------------------------------
On Mon, Nov 04, 2013 at 12:26:30PM +0100, Mike Hearn wrote:

I proposed this as a means of giving a mechanism for wallets to get
non-sybilled peers as well.


Doing so encourages pools to only bother connecting to other pools,
which is a strong centralizing force. But given the nasty incentives
present anyway - it's in your advantage to distribute your blocks to no
more than a majority of hashing power if you can do so consistently -
I'm unconvinced that this won't happen anyway.

The maximal benefit would be if two sets of addresses were published:
public and private. The issue with publishing addresses is DoS attacks,
but publishing Tor addresses doesn't stop attacks. What would discourage
attacks however would be to encrypt that data such that only the
creators of specific prior blocks could decrypt it. This limits the
audience to those with incentives not to commit a DoS attack. (DoS
attack the IP, and you'll no longer get preferential peering)

Say what you want about centralization, but for the pools involved it's
a good idea.


On a technical level, the coinbase is limited in size, and people use it
for other purposes, so lets define a standard where this data is stored
in an OP_RETURN txout of the form:

OP_RETURN <key> <value> <key> <value> ...

Multiple values with the same key should be allowed. This data should be
placed in the last txout so that SPV nodes can eventually be given it
with a SHA256 midstate.

-- 
'peter'[:-1]@petertodd.org
00000000000000080e395c361bdf9db583d5f4c0e144f476c229285b15eae59c
-------------------------------------
On Tue, Jul 23, 2013 at 12:02 PM, Andy Parkins <andyparkins@gmail.com> wrote:

No, not really.

The UTXO set is the state you need to validate blocks and
transactions. You can see blocks as authenticated patches to the UTXO
set (consumes some outputs, produces others). During validation, we
store "undo data", basically (non-authenticated) reverse patches to
the UTXO set, so we can walk back in case of a reorganization.

-- 
Pieter


-------------------------------------
On Tue, Jul 30, 2013 at 04:11:41PM -0400, Peter Todd wrote:

s/zero-knowledge/non-interactive/

-- 
'peter'[:-1]@petertodd.org
000000000000007f87c6d7e6b8c2dbf36c72c3db4a05055b604faeec59bda024
-------------------------------------
On Sun, Jul 28, 2013 at 7:42 PM, John Dillon
<john.dillon892@googlemail.com>wrote:


It has the same statistic properties as normal blocks just 64 times faster.

Even if there is a new block 30 seconds after the previous one, that
doesn't cause a burst of 64 low POW block headers in the 30 second window.
They are all statistically independent hashing attempts.



No, it just breaks ties.  In most cases there would be only 1 contender
block, so all miners are equal.

If 10% of blocks were ties/orphans, then only 1% of blocks would be a 3-way
tie.  That probably overestimates the orphan rate.

This means the miner has to download 2 blocks 10% of the time and 3 blocks
1% of the time.

However, even then, half the network wouldn't have to download the 2nd
block of the tie, since they happened to get the winner first.  This means
5% extra bandwidth on average.

16 low POW headers at 9 seconds per header is more than 2 minutes for a
miner to switch to the other contender.

A miner would only lose out if he doesn't notice that block he is mining
against is not getting built on by anyone else.

He needs to download both tied blocks so that he can switch, but he has 2
minutes to actually switch.

I understand Pieter Wuille is working on letting Bitcoin propagate and make

That would need to happen before low POW ones are broadcast.  There is a
basic set of rules in the first post.

At the moment, the client only provides headers when asked, but never
broadcasts them.




I think distributing the low POW headers on an advisory basis a reasonable
first step.  However, just broadcasting the headers is a zeroth step.

Miners would probably break ties towards the block that seems to be getting
the most hashing anyway.

I think for orphan rate, the best is to have a system to link to orphans.
This would add the POW of the orphan to the main chain's total.

Unfortunately adding fields to the header is hard.  It could be done as a
coinbase extra-nonce thing.  A better option would be if the merkle tree
could include non-transactions.

The merkle root could be replaced by hash(auxiliary header).  This has the
advantage of not impacting ASIC miners.

Broadcasting all headers would at least allow clients to count orphans,
even if they aren't integrated into the block chain.

It wouldn't have the potential data rate issues either


I don't think the data rate is really that high.  It would be 80 bytes
every 9 seconds, or 9 bytes per second.

Blocks are 500kB every 10 minutes, or 853 bytes per second.



Right absolutely.  Headers of blocks that add to the block tree within
recent history should be forwarded.

The inv system would need to be tweaked, since it can only say block and
transaction.

A block header field would allow the node to say that it only has the
header.  Alternatively, it would reply with a header message to the
getblocks message.
-------------------------------------
On Sun, Aug 4, 2013 at 8:30 PM, Peter Vessenes <peter@coinlab.com> wrote:

Lamport signatures (and merkle tree variants that allow reuse) are
simpler, faster, trivially implemented, and intuitively secure under
both classical and quantum computation (plus unlikely some proposed QC
strong techniques they're patent clear).  They happen to be the only
digital signature scheme that you really can successfully explain to
grandma (even for values of grandma which are not cryptographers).

They have poor space/bandwidth usage properties, which is one reason
why Bitcoin doesn't use them today, but as far as I know the same is
so for all post-QC schemes.


The problems are intimately related, but under the best understanding
ECC (with suitable parameters) ends up being the maximally hard case
of that problem class.   I do sometimes worry about breakthroughs that
give index-calculus level performance for general elliptic curves,
this still wouldn't leave it any weaker than RSA but ECC is typically
used with smaller keys.


-------------------------------------
Added:  I'm happy with gmaxwell as BIP editor as well, as he is
apparently the current BIP-number-assigner-in-chief.  :)

The goal is to improve the process, hash-seal our specs, and create an
easy way for anyone with at least an email address to participate.

On Mon, Oct 21, 2013 at 10:30 AM, Jeff Garzik <jgarzik@bitpay.com> wrote:



-- 
Jeff Garzik
Senior Software Engineer and open source evangelist
BitPay, Inc.      https://bitpay.com/


-------------------------------------
On Tue, Jul 23, 2013 at 4:23 PM, Greg Troxel <gdt@work.lexort.com> wrote:

It's "portable" to anything that can run the relevant VMs.  Uh
provided you don't mind cross compiling everything from an unbuntu VM.
 It certainly would be nice if the trusted-computing-base for gitian
were a bit smaller, thats an area for long term improvement for sure.

It may need some massaging. The tor project is beginning to use the
same infrastructure, so this could be usefully conserved work.

Likewise expanding the supported output targets would be greatâ€” though
in the case of Bitcoin this is bounded by resources to adequately QA
builds on alternative targets.


In some cases packages solving bugs is problematic for Bitcoin.

This is something that it seems to take a whiteboard to explain, so I
apologize for the opacity of simple email here.

whole bunch of computers world wide to reach a bit identical agreement
on the content of a database, subject to a whole pile of rules, in the
face of potentially malicious input, without any trusted parties at
all (even the guy you got the software from, assuming you have the
resources to audit it).

I'll walk through a simple example:

Say Bitcoin used a backing database which had an unknown a bug where
any item with a key that begins with 0xDEADBEEF returns not found when
queried, even if its in the DB. Once discovered, any database library
would want to fix that quickly and they'd fix it in a point release
without reservation. They might not even release note that particular
fix it if went along with some others, it could even be fixed
accidentally.

Now say that we have a state where half the Bitcoin network is running
the old buggy version, and half is running the fixed version.  Someone
creates a transaction with ID 0xDEADBEEF...  and then subsequently
spends the output of that transaction. This could be by pure chance or
it could be a malicious act.

To half the network that spending transaction looks like someone
spending coin from nowhere, a violation of the rules.  The consensus
would then fork, effectively partitioning the network.  On each fork
any coin could be spent twice, and the fork will only be resolvable by
one side or the other abandoning their state (generally the more
permissive side would need to be abandoned because the permissive one
is tolerant of the restrictive one's behavior) by manually downgrading
or patching software.  As a result of this parties who believed some
of their transactions were safely settled would find them reversed by
people who exploited the inconsistent consensus.

To deploy such a fix in Bitcoin without creating a risk for
participants we need to make a staged revision of the network protocol
rules:  There would be a protocol update that fixed the database bug
_and_ explicitly rejected 0xDEADBEEF transactions until either some
far out future date or until triggered by quorum sensing (or both).
The users of Bitcoin would all be advised that they had to apply
fixes/workaround by the switchover point or be left out of service or
vulnerable. At designated time / quorum nodes would simultaneously
switch to the new behavior.  (Or in some cases, we'd just move the
'bug' into the Bitcoin code so that it can be fixed in the database,
and we'd then just keep it forever, depending on how harmful it was to
Bitcoin, a one if 4 billion chance of having to rewrite a transaction
wouldn't be a big deal)

We've done these organized updates to solve problems (as various flaws
in Bitcoin itself can present similar consensus risks) several times
with great success, typical time horizons spanning for months to
years.  But it cannot work if the behavior is changed out from under
the software.

Fortunately, if the number of users running with an uncontrolled
consensus relevant inconsistent behavior is small the danger is only
to themselves (and, perhaps, their customers). I'm not happy to see
anyone get harmed, but it's better if its few people than many. This
is part of the reason that it's a "linux packaging letter", since for
Bitcoin the combination of uncoordinated patching and non-trivial
userbases appears to be currently unique to GNU/Linux systems.  Though
indeed, the concerns do apply more broadly.


My understanding is that gentoo is actually able to handle this (and
does, for Bitcoin)â€” and really I presume just about everything else
could with enough effort. I certainly wouldn't ask anyone else to do
that.  If you're really getting into the rathole of building separate
libraries just for Bitcoin the value of packaging it goes away.


Running a complete set of tests is a startâ€” though the unit tests are
not and cannot be adequate. There is a full systems testing harnesses
which should be used on new platforms.  Even that though isn't really
adequate, as it is currently infeasible to even achieve complete test
coverage in things like cryptographic libraries and database
environments.

This is an area where both the Bitcoin software ecosystem and the
greater art of large scale software validation need to mature. You
won't hear anyone applauding the fact that harmless looking bugfixes
in leveldb, boost, or openssl could be major doom event makers

We're not crazy folks who insist on using formally undefined behavior
and argue that it should never be changed out from under us. When
there is a known risk we will boil the oceans to close it even if we
think that the world would be more 'proper' some other way,  but for
known-unknowns and unknown-unknowns we can only adopt a conservative
approach and try to do our best.

One of the middle term things we did was internally integrated our
validation database library (leveldb).  Since we _know_ that its a
consistency critical component, and a part of our system that is
especially difficult to validate, integrating it meant removing a lot
of risk and allowed it to be upgraded with an eye on the
Bitcoin-specific consequences.  Unfortunately distributions have been
patching Bitcoin to unbundle it.  Checking versions isn't adequate
because, at least in other packages, some distributors frequently
backport fixes or apply novel fixes which may not even be shared with
upstream.

Other considerations may drive us out of external dependencies for
many of the consensus parts of Bitcoin. E.g. Pieter has writen an
ECDSA library for our specific ECC curve which does signature
validation >6x faster than OpenSSL (but it isn't obviously
upstreamable due to some differing requirements for constant time
operations), at some point we may need to adopt a backing database
that is able to produce authentication proofs, etc.  Certainly
additional clever tests will make undiscovered surprising behavior
less likely, though figuring out how to get the tests actually run if
they take two hours and use 20GB of disk space is a challenge.

... but today we need to work with what we have, which is fragile in
some atypical ways.  Part of that is making an effort to make sure
that anyone who might create a big footgun event has some idea of the
concern space.


Configure time?  At the moment Bitcoin is built with a straight
forward makefile (though there is a switch to autotools in the
pipeline).

BE isn't currently supported (and I believe this is well documented in
the package).  Fixing this would be nice, patches accepted.   There
was an amusing incident a while back where a distributor was refusing
to take an update that added unit tests because they revealed failures
on BE, nevermind that the application itself instantly failed on BE
and never worked there. I believe that has since been resolved.


I _believe_  (and hope) we've been very accommodating system specific
fixes, even for systems we don't formally support.

I personally believe that portable software is better software.
Portability forces you to dust out nasty cobwebs, reveals dependency
on dangerous undefined behavior, encourages intelligent abstractions
and appropriate testing, and it invites contributions from more hands
and eyesâ€” I don't care if you use a weird OS: I just want you for your
code and your bug-reports.  So even if we don't consider a platform
worth supporting in any rigorous way, we should still be open to fixes
and build support.

... although we're typical very much resource bound on testing. Our
upstreaming pipeline is often somewhat slow. But it's slow because we
are serious about review, even of trivial changes. Being slow is no
reason to not submit, even if you make a decision to not block on it
(though, if you're doing that you should make the decision in full
knowledge of the potential implications). Like all things stepping up
and being willing to do the work goes a long way to getting things
done.


-------------------------------------
I think Bitcoin should have a sanity check: after three days if only four
blocks have been mined, difficulty should be adjusted downwards.

This might become important in the near future. I project a Bitcoin mining
bubble.
-------------------------------------
On Sun, Dec 8, 2013 at 11:16 AM, Drak <drak@zikula.org> wrote:

You're managing to argue against SSL. Because it actually provides
basically protection against an attacker who can actively intercept
traffic to the server. Against that threat model SSL is clearlyâ€” based
on your commentsâ€” providing a false sense of security.

We _do_ have protection that protect against thatâ€” the pgp signature,
but they are far from a solution since people do not check that.

(I'm not suggesting we shouldn't have it, I'm suggesting you stop
arguing SSL provides protection it doesn't before you manage to change
my mind!)


-------------------------------------
Hi Bazyli,

I actually do my main development on Mac OSX, so it surprises me to hear - I build Xcode projects with libcoin daily on Mac OSX and linux, on Windows it is agreeable more of a fight to build. QT is really not needed, I kept it there for BitcoinQT, that was once part of the tree too, will remove it as the qt part got split out.

Building clean on Mac requires OpenSSL, BDB and Boost - all can be installed using homebrew, also remember to use the latest cmake, and a normal cmake xcode call: cmake -GXcode should do the job. Otherwise pls send me the debug output. 

A few quick notes for building stuff there:
 - try with coinexplorer, it is the base code I am using - it splits out the wallet from the server, nice if you e.g. want to build a webcoin like server.
 - The wallet parts from bitcoind I don't use personally, so if you have problems with these I need to have a closer look.

Also note that as the first version of libcoin was a direct refactorization of bitcoin, the current one add a lot of different features and handles things quite differently - you can e.g. lookup any unspent output by script (bitcoin address) in milliseconds (nice for web wallets).

Finally: 


As I mentioned it also compiles on Linux (gcc) - gcc is quite savvy when it comes to templates - I agree that the template stuff from Database.h is quite involved, but as I mentioned before try with coinexplorer.

- I will try to do a from scratch recompilation to see if I experience similar issues...

Also - if you are good at creating frameworks on Mac OSX using cmake, help would be appreciated! I think that libcoin by defaults build using shared libs, this configurable from ccmake using the dynamic library option.

Thanks,

Michael



-------------------------------------
On Tuesday 23 July 2013 10:42:05 Pieter Wuille wrote:

Wow.  I'm surprised at that.  How does a newly received transaction have its 
inputs verified then?  Multiple linear brute force searches of the block chain 
for every new transaction?  Or is it that transactions are only recorded if 
they were in a block, and just their presence indicates they're valid?


Andy

-- 
Dr Andy Parkins
andyparkins@gmail.com


-------------------------------------

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1


On 8/18/13 8:09 PM, John Dillon wrote:
keeping proof
More than a kilobyte, probably less than a few tens of kilobytes. It
depends on parameters (branching factor, script vs hash(script)) that
are tweakable with time/space and long-term/short-term tradeoffs.
-----BEGIN PGP SIGNATURE-----
Version: GnuPG/MacGPG2 v2.0.19 (Darwin)
Comment: GPGTools - http://gpgtools.org
Comment: Using GnuPG with Thunderbird - http://www.enigmail.net/

iQIcBAEBAgAGBQJSEakMAAoJEAdzVfsmodw4B9wQAIu82nxMAyMiTpFcWW6v0fQ9
26bzOznyIhzAlFUeCXvgwtqoxjRcheLOnsFsAr0TLdLYrx00o4+MS0GepV40gEpd
Ds/itvAnW8aWdCls0qy1hljWrsp8R3IfXWchXy13kjOhTIx8JaALeHEzOCsJVxCf
nWrV7UNLRO1eXhLUnFLnZ3/HdljMZnLqLexSGXorn4I2zwg5HGNMJxIenU3vDj8s
68k4rSk/eUptG97ZmJxCysn7nt5F1cxRutsVOPxsC/4+FptMYf9YJRJDNpvttYyl
ztI2xV+ARfEvSZs0lqGAcpvKwVV4IvZDGXhUCiS6LQ99tvMid4kjIGYPwlyK6SJW
LoYVbvjbauEIPn4URW8XilMB5EEJisr5/7ZV/aDLEFcBA/is5ePuQioo/81yOWUw
k5PghJ/TBMBQhxOGCz86onCI1YwrWfhu2sz6xNIHm9lbyZQcw3N/ai77FQqxxkxp
iBbIAvhk4sQ7lPt4QHmiL4isPzaiScKVTjvzfc5hAHSmu6xQysf8VA/SwUSgAJZB
iUPYRz5URaw8a/WDlo7YA6BRV/l7RloEcWGs6br3jVYxtJSaxqDwwrUV3SdDtzBR
uiE1OVPp8ihY3OJbnZkbvy3lXXlLjwrLVwMUgprhUo793QtktZH+O0V+StcGKLGD
4rdK6Z3C8Wx9FY2fvkBy
=HZdx
-----END PGP SIGNATURE-----



-------------------------------------
Right, as I said earlier:

"The payment protocol at least would need some notion of fee, or possibly
(better?) the ability for a recipient to specify some inputs as well as
some outputs."

Having thought about it a bit more, I think it's better to just have a fee
field that lets the receiver request the sender to attach the given fee.
The outputs would have less value associated with them, so effectively the
seller folds the fee into the price. If the seller is charging a round
price like 1 mBTC, the user sees "1 mBTC" as the price, even if behind the
scenes the created tx only sends 0.99999 BTC

Allowing specification of inputs seems to add too much complexity in other
cases, like when value isn't specified at all.


On Mon, Dec 2, 2013 at 2:54 PM, Patrick Mead <patrick@meadia.com.au> wrote:

-------------------------------------
On 29 September 2013 04:28, Neil Fincham <neil@asdf.co.nz> wrote:


Hi Neil, perhaps I didnt present the use case clearly.  It was not about
evasion, it was about voluntary donations going to the correct place, being
verified by an oracle.  I dont wish to stray off topic, so I'll leave it at
that.


-------------------------------------
The problem with this is that you might have word A which is similar to B,
but B is also similar to C.  So we scrub B from the list, someone enters B,
and we have no way to know if it means A or C.  It leads to a much more
complicated scheme to ensure that all errors are correctable.

Scrubbing A, B, and C is preferable, since it leads to no ambiguity and
there is no need to try to correct an error.


On Fri, Nov 1, 2013 at 3:14 PM, Brooks Boyd <boydb@midnightdesign.ws> wrote:

-------------------------------------
On 19 December 2013 16:04, Amir Taaki <genjix@riseup.net> wrote:



Yeah, it makes no sense after reading it. Nice catch.

However, his recommendation for signing tags with `git tag -s` should
probably be incorporated into the spec as a MUST.

Drak
-------------------------------------
On 17/11/13 01:42, Timo Hanke wrote:

We'll probably use the most straightforward way:
a) trezor prints entropy A on a display (probably in hex format, this
step is triggered by sending a special flag in initialize message)
b) trezor receives entropy B from external source
c) trezor creates sha256(A + B) and uses that as a seed
d) trezor prints used seed on a display (probably in BIP39 format)
e) user can check on a trusted computer that everything was ok

(note that steps b-d are the same regardless of whether the special flag
was set)

-- 
Best Regards / S pozdravom,

Pavol Rusnak <stick@gk2.sk>


-------------------------------------
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256

Sorry I should have used the word bootstrapping there rather than discovery.
But again I think that shows my point clearly. Centralized methods like DNS
should be used for as little as possible, just simple initial bootstrapping,
and focus the development efforts towards the non-centralized peer discovery
mechanisms.
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.10 (GNU/Linux)

iQEcBAEBCAAGBQJRhlpyAAoJEEWCsU4mNhiP+NwH/3RY5vBpSYkwKgTmdKHRc/gw
BJCSV/1MEDECgBTxaRYSzYZyargjsdG50KaIaCq8M1+8DWkBEkH8JFif7UYMlZGM
WROMP6UjAnP1fJ3B2JChdMgRv1HdXJQDQVcO8UnSJschhX8lZZiUySbaqIPuRuV/
lI7/JkUZvmnms4+HGiaqwfbPO0k6ytJNKxORrk4TzFnThh4dy9WytElc8JHZOFaQ
ly159X5JuEwh8DLOoUtPhaR6tJaJbJLBEt+QJiGnSktPsJCE8p9+4HQ0kMCQr3Ha
05EHTZEw+TqEPaA7vFLgA/9tWjK9s1Y6sqLOAYiLp/0wSKzCkBO0C5LWFHsJ/XQ=
=aCgi
-----END PGP SIGNATURE-----


-------------------------------------
On Thu, Apr 18, 2013 at 10:32:24AM +0200, Mike Hearn wrote:

Yeah, an attack is a bit more subtle than perhaps John Dillon realizes.
Assuming that nodes prioritize the transactions with the fewest total
replacements first it becomes a multiplier on the standard attack of
just broadcasting transactions. So for non-replacement users it's
probably not that bad.

An attack still shuts down useful tx replacement though. For instance in
the adjusting payments example an attacker sets up a legit adjusting
payment channel, does a bunch of adjustments, and then launches their
attack. They broadcast enough adjustments that their adjustment session
looks like part of an attack, and then don't have to pay for the full
adjusted amount.

What's worse, the attack itself can be just a large number of these
micropayment sessions, IE, no bogus sessions at all.


It's *easily* DoSable, not trivially. Testnet has all the same
fee/priority rules that Bitcoin has, so any attack still costs some
amount of coins. For instance I did the math once on what it would cost
to flood testnet with 1MB blocks, and it came out to IIRC $100/month or
so in terms of lost mining revenue. Small, but still not trivial.

non-final nLockTime floods and timewarp assisted can be easily done mind
you, but the former is easy to fix and the latter is relatively tricky
to pull off and still requires some mining expenditure.


John's proposing something that would work in conjunction with fees, so
it's no different than the MIN_RELAY_FEE that has quite successfully
prevented flooding on mainnet. For that matter, what he proposed can be
used even with non-final == non-standard, which means the replacement
transactions can't be broadcast onto the network at all until they can
be mined.

Actually, that's an interesting point: one way to do replacement
anti-DoS would be to only allow each input a given number of chances to
do a replacement. Provided your design is asymmetric in who the attacker
would be, and the inputs controlled by the defender outnumber the
attacker, the defender can always count on doing the last replacement.

You would need some way of determining which input was responsible for a
replacement though - I can't think of an obvious way to within the
current transaction format, but I haven't thought hard about it yet.


How exactly do you envision replacement working with non-final ==
non-standard anyway?


If he's reasonable about the scope, IE just a initial implementation for
further evaluation, I figure it's about two days work. $250/day is
enough that I'd give it a go - I already looked into how to implement it
anyway.

-- 
'peter'[:-1]@petertodd.org
-------------------------------------
On Sun, Sep 29, 2013 at 10:49:00AM -0700, Mark Friedenbach wrote:

Thanks for providing the impetus to write down the current state, the
efficient version of which I only figured out a few days ago :)

I have been researching this for a few months on and off, because it seems
like an interesting construct in its own right, a different aspect of
payment privacy (eg for auditable but commercial sensistive information) but
also that other than its direct use it may enable some features that we have
not thought of yet.

I moved it to bitcointalk:

https://bitcointalk.org/index.php?topic=305791.new#new

Its efficient finally (after many dead ends): approximately 2x cost of
current in terms of coin size and coin verification cost, however it also
gives some perf advantages back in a different way - necessary changes to
schnorr (EC version of Schnorr based proofs) allow n of n multiparty sigs,
or k of n multiparty sigs for the verification cost and signature size of
one pair of ECS signatures, for n > 2 its a space and efficiency improvement
over current bitcoin.

Adam


-------------------------------------
On Wed, May 22, 2013 at 10:12 AM, Melvin Carvalho
<melvincarvalho@gmail.com> wrote:

That has really, really bad side effects.  The whole point of the
bitcoin consensus algorithm is to avoid situations like this.

We don't want to encourage that behavior with code.

-- 
Jeff Garzik
exMULTI, Inc.
jgarzik@exmulti.com


-------------------------------------
On Thu, Mar 07, 2013 at 02:31:10PM -0700, Daniel Lidstrom wrote:

Yes, but keep in mind the meta risk, which is that as Bitcoin becomes
centralized one of the types of transactions that will be censored are
ones that preserve your privacy. For instance, as it costs thousands of
dollars to setup a mining pool, and hence mining pools also become quite
visible, it would be very easy for local governments to start doing
things like specifying that transactions must be accompanied with a
proof of identification. With that proof of course Bitcoin can remain
totally legal, and the pool in business.


Why do you expect that? It's always harder to hide a large amount of
bandwidth than a small one, and stenography is limited by the bandwidth
of the data it's hiding it. HD video streams aren't going to require
more bandwidth in the future.


Right now the thing that keeps pools honest is that setting up another
pool is pretty easy; note how most pools are run as hobbyist projects.
Similarly you can always use P2Pool, which is totally decentralized.
But if running the validating node required to run a pool costs
thousands of dollars that competition just isn't there anymore and
starting a new pool isn't an option. Remember there will be a chicken
and egg problem in that the new pool has thousands of dollars in costs,
yet no hashing power yet.

As for constantly moving countries, The Pirate Bay is in the same
position, and as well as they've done, they still wind up getting shut
down periodically. Do you really want access to your funds contingent on
some highly visible mining pools, constantly wondering if their local
government will change their mind?


Anyway, seems that my question was answered: There aren't any clever
technical ways to avoid censorship if validating nodes and mining pools
are centralized.

-- 
'peter'[:-1]@petertodd.org
-------------------------------------
On Mon, Mar 11, 2013 at 11:36 AM, Gavin Andresen
<gavinandresen@gmail.com> wrote:

While 100% agreed, I do think there is space in the alt-currency world
for a well-done coin THAT IS NOT BITCOIN (i.e. merge-mined or
whatever) with a finite lifespan.  Call it "tempcoin"   For example:
any coin older than (144 * 365 * 4) blocks may be reclaimed by a
miner.

Even though, sadly, many of the alt-coins have been pre-mined scams,
the alt-coin concept in general is great for experimenting.  If the
idea can be proven in the field without modifying mainnet bitcoind,
then perhaps it should go onto the mainnet hard fork wishlist, many
years in the future.

That's the great thing about open source.  People can experiment with
these ideas, and bitcoin.git need not change at all :)

-- 
Jeff Garzik
exMULTI, Inc.
jgarzik@exmulti.com


-------------------------------------
On Sat, Nov 2, 2013 at 6:01 AM, <bitcoingrant@gmx.com> wrote:


http://pilif.github.io/2008/05/why-is-nobody-using-ssl-client-certificates/
-------------------------------------
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Ryan, these sort of adjustments introduce security risks. If you were
isolated from the main chain by a low-hashpower attacker, how would
you know? They'd need just three days without you noticing that
network block generation has stalled - maybe they wait for a long
weekend - then after that the block rate is normal but completely
controlled by the attacker (and isolated from mainnet).

There are fast acting alternative difficulty adjustment algorithms
being explored by some alts, such as the 9-block interval, 144-block
window, Parks-McClellan FIR filter used by Freicoin to recover from
just such a mining bubble. If it were to happen to bitcoin, there
would be sophisticated alternative to turn to, and enough time to make
the change.

On 12/22/2013 07:10 PM, Ryan Carboni wrote:
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.14 (GNU/Linux)
Comment: GPGTools - http://gpgtools.org
Comment: Using GnuPG with Thunderbird - http://www.enigmail.net/

iQIcBAEBAgAGBQJSt6yGAAoJEAdzVfsmodw4SegQAIJAWW0OgSjediSWq+EpkReS
qMvC2Y9dmVHtowYLdJVcgwFWbpU8RhA6ApQ1Ks2XF4t0hFCObYDecG6Nl3OIaLfb
snz24v8ymdxYXKNtzHHUP0VBgsaoRghIpkbf7JMUXC22sxPoPOXFt5RevLgJHrvc
oGFZSIcEcGgwhwZ745CgFZLwaKuSmg5+wFFcrjIihlHKJOl47Z7rzeqnD6mf2Oi3
hDpRuVbuhlGMliYcmhk1E6oV0in2R4Purw1WtoY8C9DxrSP2za7W1oeCkmlFfJZS
to6SzRj7nEIl0LFaPGsIdBrRdDHfvu6eP2OecI+GNLEwLY6qE5v5fkh47mcDkrN0
02PmepoX5PRzBqp4sx8WaFKuRbmTRRr3E4i9PGoyzTckkZzq+zFmb1y5fwOy17hE
C+nP+DyuaPzjypjdo6V+/oGzUKtuKPtqcB1vurbm+WBl5C1jWosAXv5pR87mdCUJ
+0e14wPra5blV6yBVqX7yx+2heDGymPKfHJ8i76Dtix7XVOJWKVY4OpIxO7YrYv8
IKcIswoKhZdSDOJLcjm4Qp4hrzgCHAHWx6vN71r5r2T6zaJTOvp98GS04Yy7VGAr
j38hojcwvJC1ahER3LV/vC0cqO+fxrvY8Q9rW2cUxCnzxzjjG0+Z/gjW8uh73lXN
DOTF7jpt0ZmCm7uhG9z7
=5Q2H
-----END PGP SIGNATURE-----


-------------------------------------
Someone needs to update the bitcoin.org website, it still points downloads
to 0.8.5
-------------------------------------
The only other thing I'd like to see there is the start of a new anti-DoS
framework. I think once the outline is in place other people will be able
to fill it in appropriately. But the current framework has to be left
behind.

If I had to choose one thing to evict to make time for that, it'd be the
whitepapers. At the moment we still have plenty of headroom in block sizes,
even post April. It can probably be safely delayed for a while.


On Fri, Aug 16, 2013 at 2:11 PM, Mike Hearn <mike@plan99.net> wrote:

-------------------------------------
On Mon, 2013-09-30 at 22:44 +0200, slush wrote:

What a coincidence. I do have observed the same thing. right now with
0.8.5. I am writing a small app. My jsonrpc client is programmed to
timeout after 2 secs and I did see a couple of timeouts once in while.

What I did is a simple test app that just hammer bitcoind with 3 rpc
requests every 30 seconds and I abort it as soon as it encountered a
timeout.

The 3 request burst is performed on the same HTTP 1.1 kept alive
connection. Then I disconnect. When I launch my app before leaving in
the morning, pretty sure that I have a core dump waiting for me when I
come back.

I choose very simple calls: getinfo,getaccount

Added a couple of traces in the RPC handling code. (BTW, timestamps in
traces would be tremendously useful for tracking problems...). I see my
request received by bitcoind but there is no trace yet to show that the
reply is sent.

Not sure yet exactly where the problem is but my current #1 suspect is:

LOCK2(cs_main, pwalletMain->cs_wallet);

with some kind of lock contention with the other threads.




-------------------------------------

Do we know for certain or at least a rough figure of the node count in
the network?

On Thu, May 16, 2013 at 8:02 PM,  <bitcoingrant@gmx.com> wrote:


-------------------------------------
To summarize your post - it's another go at arguing for strongly
limited block sizes, this time on the grounds that large blocks make
it easier for $AUTHORITY to censor transactions? Is that right?


-------------------------------------
On Tue, Nov 19, 2013 at 05:32:55PM +0100, Wladimir wrote:

I already did that:

https://github.com/petertodd/bips

GitHub can render MediaWiki just fine, so I think leaving the BIPs as
MediaWiki is the way to go. New BIPs may want to use either markdown or
MediaWiki - the latter has advantages in terms of formatting
capabilities over the former, particularly when math needs to be
displayed.

-- 
'peter'[:-1]@petertodd.org
-------------------------------------
Each block that you solve has a reward.  In practice, some blocks will 
be orphaned, so the expected reward is slightly less than the nominal 
reward.  Each second that you delay publishing a block, the expected 
reward drops somewhat.

On an infinite timeline, the total reward approaches the expected 
reward.  But reality is discrete, and zero tends to be a brick wall.  If 
you delay publishing a block, you will get either the nominal reward, or 
zero, not some fraction in between.  And if your personal random walk 
involves an excursion through negative land, you may not stick around 
long enough for it to come back.

Thus, a positive expected value is not sufficient for some strategy to 
be a good one.

Peter Todd wrote:

-------------------------------------
Couple of thoughts:

RE: the marvelous coincidence that the average fee these days is very close
to the modeled minimum orphan cost:

Engineers tend to underestimate the power of markets, even inefficient
markets, to arrive at the 'correct' price. It would not surprise me at all
if the messy, chaotic inefficient market with tens of thousands of
individual decisions ("which mining pool should I join" and "how high
should my dice site set fees" and "how large should the minimum payout be"
and "should I make my blocks bigger or smaller") might arrive at the
'correct' price, even if NOBODY involved has any clue how or why it
happened.

Or it might just be a coincidence.

RE: orphan rate:

The network-wide orphan rate has been very steady apart from the March
blockchain fork. Kudos to Ben Reeves for keeping track of the data and
giving us a nice chart:
  http://blockchain.info/charts/n-orphaned-blocks

RE: new block latency:

We should be able to reduce the size of new block announcements by about a
factor of ten with very little additional effort (transmit/relay as
"merkleblock" with full bloom filters-- the factor of 10 is because a
transaction id hash is 32 bytes, average transaction size is a few hundred
bytes).

Mining revenue is a fixed-size pie, so if EVERYBODY agreed to accept
(somewhat) higher orphan rates for more transaction volume then, in the
long run, there is no difference.  Well, except that more transaction
volume means more utility for Bitcoin as a whole, so everybody should
benefit from a higher bitcoin price.

That's a classic free-rider problem, though-- a miner could defect to try
to get a lower orphan rate.

This is one of the reasons why I think relaying all blocks in a race is
probably the right thing to do; if a miner is mildly punished (by losing
the occasional block race) for creating blocks that don't include "enough"
already-relayed transactions, that is a strong incentive to go along with
whatever consensus has been established.

The same argument applies for a miner producing too-large blocks, or blocks
with lots of transactions that were never relayed across the network.

-- 
--
Gavin Andresen
-------------------------------------
My efforts on MinorFs2 have been stalled for a large period of time
(resulting from the fact that I was writing it in Python and Google
pulling the plug on its codesearch server showed me that Python was a
language that I hadn't sufficiently mastered. Recently, after almost a
year of reluctance at starting from scratch, I finaly set myself to
rewriting what I had done so far in C++ and to continue development.

Yesterday I've also started at a library for making the usage of MinorFs
by applications like Bitcoin more convenient. The idea is that LibMinorFs
will become a simple to use library for making applications
MinorFs2-aware.

I would like to ask if the bitcoin developers would be open to using
this library within bitcoin for making BitCoin MinorFs2 aware, allowing it
to store things like the BitCoin purse in a private directory that is not
available to other unrelated (potentially trojan) processes running under
the same uid.

The API is defined in the inc/minorfs/ directory and the usage shown in
src/testmain.cpp

https://github.com/pibara/LibMinorFs2

Both the library and the filesystems are still far from being done, but I
would like to know if you guys would be open to a pull-request that would
incorporate a copy of this library into Bitcoin, making BitCoin use
private storage when available, implemented using the above API.

Please let me know what you think.

Rob



On Fri, August 26, 2011 08:48, Rob Meijer wrote:



-------------------------------------
On Thu, Feb 14, 2013 at 07:59:04AM -0500, Stephen Pair wrote:

Then don't be so agressive; target 90% as I suggested and the miner
still comes out ahead by having 10% less hashing power to compete with.
50% is only a maximum because when more than 50% of the network does not
see your blocks the majority will inevitably create a longer chain than
you, but less than 50% and your part of the network will inevitably
create a longer chain than them.


What you are describing is either *voluntary* centralization, or won't
happen. Nothing in your scenario will stop people from transacting on
the Bitcoin network directly, it will just make it more expensive. For
instance suppose fees rose to the point where the value of the fees was
10x the value of the block reward today; miners would be taking in
$972,000/day, or $6750/block. At 1MiB/block that implies transaction
fees of $6.75/KiB, or about $2 per transaction. Even if the fees were
$20 per transaction that'd be pretty cheap for direct access to the
worlds bank-to-bank financial network; I can still transfer an unlimited
amount of money across the planet, and no-one can stop me. Importantly
there will be plenty of demand to have transactions mined from people
other than banks and large corporations.

Because there will continue to be demand, and because 1MiB blocks means
running a relay node is trivial enough that people can do it just for
fun, banks won't be able to force people to use their "high-speed
backbone". Not to say they won't create one, but it won't have any real
advantage over something that can be run in your basement.

On the mining side with 1MiB blocks the fixed costs for setting up a
mining operation are just a moderately powered computer with a bunch of
harddrive space and a slow internet connection. The marginal costs are
still there of course, but the cost of power and cooling are lower at
small scale than at larger industrial scales; power is often available
for free in small amounts, and cooling isn't a problem in small setups.
Because small-scale miners will still exist, there will still be a
market for "consumer" mining gear, and trying to regulate mining
equipment will just turn it into a black-market good. Small blocks let
you setup a mining operation anywhere in the world - good luck
controlling that. Mining also will remain a way to import Bitcoins into
places.

Banks can try setting up exclusive mining contracts, but unless they
control more than 50% of the network they'll still have to accept blocks
found by these highly decentralized, small-scale miners. They'd be
better off broadcasting their transactions to those miners as well so
they don't get double-spent. Thus decentralized miners still can profit
from transaction fees, and still have an incentive to mine. Doesn't
sound like centralization to me at all.

On the other land, with large blocks, not only is mining solo
unprofitable due to the huge fixed costs required to process the blocks,
miners on pools can't effectively secure the network because they can't
independently verify that the blocks they are mining are valid. It would
be easy then to co-opt the relatively small number of pools, a number
that is not particularly large even now. Transaction relay nodes would
also be very expensive to run, and again the small number of them makes
them targets for control. Sure transactions will be cheap, but that
doesn't do you any good if the small number of miners out there are all
regulated and ignore your transactions.

Sounds like centralization to me.

-- 
'peter'[:-1]@petertodd.org
-------------------------------------
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256

On Mon, Apr 29, 2013 at 3:36 AM, Gregory Maxwell <gmaxwell@gmail.com> wrote:

Unfortunate. What makes them not work out? DHT torrents seem pretty popular.


Now don't get me wrong, I'm not proposing we do this if it requires additional
steps or other software. I only mean if it is possible in an easy way to
integrate the BitTorrent technology into Bitcoin in an automatic fashion. Yes
part of that may have to be finding a way to re-use the existing port for
instance.


Sure I guess my concern is more how do you find the specific part of the chian
you need without some structure to the network? Although I guess it may be
enough to just add that structure or depend on just walking the nodes
advertising themselves until you find what you want.

We can build this stuff incrementally I'll agree. It won't be the case that one
in a thousand nodes serve up the part of the chain you need overnight. So many
I am over engineering the solution with BitTorrent.


Good point. Sadly one that may apply to the Tor network too in the future.
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.10 (GNU/Linux)

iQEcBAEBCAAGBQJRfe1LAAoJEEWCsU4mNhiPuDgIAM1zz+ohlHgz37RgToQhInRc
1tv4Fnb6uGWyb4+U6UpK24LlXMFvOJsLm2czgbBc1Iz4z4wvb1m5IGw0ubJuV4mT
GPUJhM4sNqfeKZlSWRw4Gia6Vk1jTkue+uVYvZn2vBS4SS6vYhYCC3zXIITyb2mp
7CVjcM84bTHKxIaMW1rIgmVJmfslsFdeNOp/cDVvkNl9+WvzWPeJ32BkT522p+pT
AcPVFMsEJirYrXYi8HwdtGSeiG+mv0IemTAObJNPRrpw3x04ja6qecqzM51AkQ4t
hPems5ShXM9FyDKFQNmtoC6ULpbd3CBBjsiQj0pp55epy6UC0eiUIXP8L9v0giM=
=AOj8
-----END PGP SIGNATURE-----


-------------------------------------
On Fri, Apr 19, 2013 at 12:38 AM, John Dillon
<john.dillon892@googlemail.com> wrote:

I cannot speak for Gavin, but speaking more generally, large attackers
tend to belong in a thought-class all their own.

Example 1:  if some super-ASIC miner arises with 90% of hash power,
and he starts behaving in a way contrary to the useful functioning of
bitcoin, the community might decide to change the PoW algorithm at
block height N.

Example 2:  If someone large DDoS's the entire P2P network, which is
possible, manual intervention would be required to straighten out the
mess.

In each case, it's more about the community's mutual defense actions
than any prepared defense.

Speaking even more generally, bitcoin may be a billion-dollar
invention, but that doesn't mean it has any funding for network
defense!  Unless cost structures and user attitudes change,
development and deployment of major defense strategies seems unlikely.
 Which implies the community will simply wait for a [attack |
explosion | crisis], and then hope we can unwind/repair the damage
afterwards.

-- 
Jeff Garzik
exMULTI, Inc.
jgarzik@exmulti.com


-------------------------------------
On Fri, May 31, 2013 at 8:37 AM, Rune Kjr Svendsen <runesvend@gmail.com> wrote:

This is not a compelling need to update bitcoind for this.

The vast majority of systems are currently capable of processing a
block, before another block arrives.

As for parallel processing, your "what if" has been a solved problem
for decade(s) now.

-- 
Jeff Garzik
Senior Software Engineer and open source evangelist
BitPay, Inc.      https://bitpay.com/


-------------------------------------
Unless of course everlasting physical "bitcoins" are much more
important than smart property and colored coins...


On 3/11/13, Jorge Timn <jtimonmv@gmail.com> wrote:


-- 
Jorge Timn

http://freico.in/
http://archive.ripple-project.org/


-------------------------------------
The problem with academics is that they don't have to worry about the real
world. They get paid to publish things, not to be helpful to society.


On Tue, Nov 5, 2013 at 11:33 PM, kjj <bitcoin-devel@jerviss.org> wrote:




-- 
*MONEY IS OVER!*
                                IF YOU WANT IT<http://www.zeitgeistmovie.com/>
=====================================================
The causes of my servitude can be traced to the tyranny of money.
-Serj Tankian
-------------------------------------
Is there a relatively easy way to switch between Testnet versions in the
client? On the forums I am in discussion with one member who mentioned the
idea of a Main net, a testnet and a "beta-net" where the coins on the
beta-net would be allowed to have value. It seems like simple and logical
way to do this would be something like a "testnet=1, testnetversion=3" in
the bitcoin.conf file. Is this possible?


On Sat, Jun 15, 2013 at 3:26 PM, Dennison Bertram <
dennison@dennisonbertram.com> wrote:



-- 

Dennison Bertram, photographer and film maker

www.dennisonbertram.com

dennison@dennisonbertram.com

Milan: +39 320 781 0128
-------------------------------------
Namecoin already has an id/ and a/ (alias) namespace for such use:

{ "name" : "id/pichler", "value" : 
"\"BM-GtK6TiTtVo9toGVdk2zy3t4jGXZyZeMH\"", "expires_in" : 29397 },
{ "name" : "id/pigeons", "value" : "{ bitcoin: 
1BekNv7ezkx8eAjdkrUta2BTp9bbxU9LGG, bitmessage: 
BM-opfhTsUKdTezPiWFHxRQtM1ZMDvjKMkHf, ripple: rnziParaNb8nsU4aruQ
dwYE3j5jUcqjzFm}", "expires_in" : 10089 },
{ "name" : "id/pisces", "value" : 
"\"BM-GtK6TiTtVo9toGVdk2zy3t4jGXZyZeMH\"", "expires_in" : 32034 },
{ "name" : "id/plattler", "value" : 
"\"BM-GtK6TiTtVo9toGVdk2zy3t4jGXZyZeMH\"", "expires_in" : 30999 },
{ "name" : "id/pope", "value" : "{\n   \"bitmessage\"    : 
\"BM-2D7L1Suh1choaKt321Le3bS6PT6nxfWqpR\"\n}", "expires_in" : 29765 },

It's popular enough that it's been squat spammed by a few actors 
recently, and several bitmessage IDs are there along with Bitcoin 
addresses, etc.

On 8/2/2013 2:16 PM, Rick Wesson wrote:



-------------------------------------
On 15 May 2013 13:38, Peter Todd <pete@petertodd.org> wrote:


Isnt it potentially inviting trouble by encouraging people to insert double
spends into the block chain?

Sure, zero conf isnt 100% safe, we all know that.

But neither is the postal service.  Doesnt mean we should be going around
promoting the creation of tools to go into people's maiilboxes and open
their letters!


-------------------------------------
Go straight to uBTC. Humans and existing computer systems handle numbers to
the left of the decimals just fine (HK Dollars, Yen). The opposite is
untrue (QuickBooks really does not like 3+ decimal places).

     - Jeff
On Nov 14, 2013 4:40 PM, "Mark Friedenbach" <mark@monetize.io> wrote:

-------------------------------------
John,

I for one support your rallying cry of decentralization.

If you are implying that even 10,000 full nodes seems far, far too few for a distributed system that may ultimately face a very well-connected and well-funded threat model, I agree with you completely. However, I took Gavin's statement to mean something like a factual statement about the load-bearing nature of that many nodes, rather than an actual target number for some future iteration of the network.

Partial UTXO sets sound like a great idea -- are they really being ignored? I am pretty new to the development process here, but I assumed (as with many open source projects) that ideation, debate and implementation take a while to churn. Has a prototype of that been developed already, are you implying that you funded something like that and it never got built? If there are some GitHub links that I missed, please send them over.

Maybe you should open that topic back up in its own thread, so we can bring it back into view?

-wendell

grabhive.com | twitter.com/grabhive | gpg: 6C0C9411

On Aug 19, 2013, at 4:53 AM, John Dillon wrote:


-------------------------------------
A few replies, in order of point raised:

Jeff:
Arguments against multibit default:
* Less testing, field experience on desktop

Yes this is true - downloads of multibit have typically been around
1/7th to 1/5th of bitcoin-QT downloads. It helps of course that
the bitcoinj networking/ object model is also used by Andreas 
as you note.


Greg:
I think Mike has squashed the deadlocking problems with reentrant 
locks (primarily in the Wallet). I haven't seen one in at least a month.

We discussed proxy support on the bitcoinj mailing list a while ago 
and at the time the stumbling block was the Java library used for 
the networking (Netty) did not support it. Mike or Miron would 
know better than I if this is still the case.

Change address behaviour will improve significantly when HD
wallet support goes into multibit/ bitcoinj (I am hoping to get my
bit done over the summer). Matija Mazi has been working on a 
Java impl of HD wallets so it is coming down the pipe but
there is a lot to do yet.

Connections out from MultiBit are:
+ 4 bitcoind nodes on port 8333
+ multibit.org (188.138.113.201) for help, current version info
   (and probably more in future)
+ the currency ticker will make HTTP gets to the source of
   whichever exchange(s) you have set up e.g MtGox, CampBX.
   This calls should disappear if you switch the currency conversion
   and ticker off.

I think that is all the connections out I make.

Mainly due to the exchanges abruptly changing their APIs and
breaking things we are planning to put in intermediate 
"Exchange Data Provider" servers. Tim Molter is working on this
in his XChange project. That will enable us to patch the server
when things change and the multibits in the field won't be
affected. There will probably be a couple of these initially
for redundancy.

Alex: Yes I think most users migrate to blockchain.info or,
more recently coinbase.com. They are both good wallets
but I'd like to keep Bitcoin as P2P as possible.

Luke-Jr
I think you are right here on the number of full nodes versus
SPV nodes.
I don't think we even know yet what are the working ratios of
full nodes to SPV nodes. I haven't seen anybody do any 
analysis on this.

I doubt multibit will ever participate in the Bitcoin network 
other than as an SPV client. All the optimisation is to reduce
data traffic - it is effectively a mobile wallet that happens to
live on a desktop. It is not really intended to be more than
"a wallet for regular people to store and spend their bitcoin".

In English the nomenclature for direction of the transactions
is: "Sent to" and "Received with". To be honest I 
haven't transliterated the localisation files to check other
language packs but the localisers are pretty good in my
experience.





On Thu, Jun 27, 2013, at 07:41 PM, Gregory Maxwell wrote:


-- 
https://multibit.org    Money, reinvented


-------------------------------------

Not crazy, just inconvenient, and possibly confusing.

I'm going to be pretty stubborn about the dates. I'm just not
interested in lots of discussion about what the perfect times/dates
will be, there are much more important things that need to get done
soon.

Like hard-forking to increase the 1MB blocksize limit.  This will be
good practice for that.

-- 
--
Gavin Andresen


-------------------------------------
I was talking about bi-directional sacrifice.
If zerocoin has it, I want the same on top of freicoin so that btc/frc
can be traded p2p.
Why zerocoin and not the 20 other altchains are going to ask for it?
Ripplers will want it too, why not?

All the arguments in favor of this pegging use zerocoin's point of
view. Sure it would be much better for it, but are additional costs to
the bitcoin network and you cannot do it with every chain.

Merged mining is not mining the coin for free. The total reward (ie
btc + frc + nmc + dvc) should tend to equal the mining costs. But the
value comes from demand, not costs. So if people demand it more it
price will rise no matter how is mined. And if the price rises it will
make sense to spend more on mining.
"Bitcoins are worth because it costs to mine them" is a Marxian labor
thory of value argument.
It's the other way arround as Menger taught us.


On 7/13/13, Adam Back <adam@cypherspace.org> wrote:


-- 
Jorge Timn

http://freico.in/


-------------------------------------
On 22/10/13 16:08, Jeff Garzik wrote:

I would love to do so.

However, from what Peter Todd said above, my feeling was that spec is 
deliberately vague to force compatibility with the reference 
implementation rather than with a document.

While that kind of compatibility-via-obscurity won't probably work in a 
long run, in short run it can prevent proliferation of implementations 
and thus give protocol more space and flexibility to evolve (I've done 
the same trick with ZeroMQ myself once).

Anyway, if my impression was wrong I am happy to give it a try.

Martin



-------------------------------------
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 08/09/2013 03:01 PM, Randolph D. wrote:

Not lately.  It's pretty CPU and network intensive, which may or may
not be detrimental to your use case.

I keep meaning to read through these security analyses of Bitmessage
but I'm a little short on compute cycles at the moment:

https://bitmessage.org/forum/index.php?topic=1666.0

http://www.reddit.com/r/bitmessage/comments/1fwyx7/a_security_analysis_of_bitmessage/

- -- 
The Doctor [412/724/301/703] [ZS]
Developer, Project Byzantium: http://project-byzantium.org/

PGP: 0x807B17C1 / 7960 1CDC 85C9 0B63 8D9F  DD89 3BD8 FF2B 807B 17C1
WWW: https://drwho.virtadpt.net/

If at first you don't succeed, call for an airstrike.

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.20 (GNU/Linux)
Comment: Using GnuPG with Thunderbird - http://www.enigmail.net/

iEYEARECAAYFAlIKk94ACgkQO9j/K4B7F8FMsgCgkuM56fI4hVT9H1ueZSFwl9Kk
qRoAoJkKZf4afKgVQKtDO6zRd/Auc/RV
=zwmX
-----END PGP SIGNATURE-----


-------------------------------------
So, this
http://www.americanbanker.com/bankthink/the-last-straw-for-bitcoin-1059608-1.html?pg=1
article got posted today, noting that FinCEN thinks irrevocable
payments
are money laundering tools.

I will hold my thoughts about the net social good of rent-seeking large
corporations taking money from consumers over fraudulent reversals.
Actually, I won't, I just said it.

At any rate, it got me thinking, can we layer on revocability somehow
without any protocol change, as an opt-in?

My initial scheme is a trusted (hah) escrow service that issues time
promises for signing. If it doesn't receive a cancel message, it will sign
at the end of the time.

The addresses would be listed by the escrow service, or in an open
registry, so you could see if you were going to have a delay period when
you saw a transaction go out.

This seems sort of poor to me, it imagines that mythical thing, a trusted
escrow service, and is vulnerable to griefing, but I thought I'd see if
some of the brighter minds than me can come up with a layer-on approach
here.

When I think about it, I can imagine that I would put a good number of my
coins in a one day reversible system, because I would have warning if
someone wanted to try and spend them, and could do something about it. I'm
not sure if it gets me anything over a standard escrow arrangement, though.

Peter

-- 

------------------------------

[image: CoinLab Logo]PETER VESSENES
CEO

*peter@coinlab.com * /  206.486.6856  / SKYPE: vessenes
71 COLUMBIA ST / SUITE 300  /  SEATTLE, WA 98104
-------------------------------------
On Wednesday 01 May 2013 15:26:57 Jeff Garzik wrote:


Fair enough.

I'm usually behind the state-of-the-art when I suggest things here :-)  I 
should just trust you guys have already planned everything I might think of.


Andy

-- 
Dr Andy Parkins
andyparkins@gmail.com


-------------------------------------
On Tue, Dec 03, 2013 at 11:40:35AM +1000, Gavin Andresen wrote:

Fees are per byte of tx data; call it allowfeeperkb, and given that fees
are required - the merchant would really rather not waste up to about
twice as much on fees for a child-pays-for-parent - it should be called
requirefeeperkb.

Back to your point, the merchant wants to limit total fees that have
been deducted - 'allowfee' is still a good idea - but only in
conjunction with specifying fee-per-kb requirements.

UI once both are implemented is to not show anything in the default
case, and explain to the user why they have to pay extra in the unusual
case where they are spending a whole bunch of dust.

-- 
'peter'[:-1]@petertodd.org
000000000000000f9102d27cfd61ea9e8bb324593593ca3ce6ba53153ff251b3
-------------------------------------

That's a nice sentiment, but there's a lot more nuance to it than
"soft-forks are bad"

We're talking about rejection here: you don't want to end up on an
isolated chain fork wondering if maybe miners have been unlucky. You
want to know that a longer chain exists so as to have solid evidence
that you're local configuration isn't what miners are mining.  Thus not
only should you "accept" blocks with versions you don't know about, you
should relay those blocks as well so that other out-of-date nodes have
the highest possible chance of finding out about them. Creating a block
is expensive, so with some minor safeguards - a high minimum difficulty,
and maximum size - relaying blocks you consider invalid is perfectly
safe and doesn't enable DoS attacks. Relaying block headers has similar
logic, and even less DoS attack worry. (don't apply bloom filters to
invalid blocks though!)

I had this discussion with Warren the other day actually: Litecoin is
considering banning old node versions and rejecting their attempts to
connect. I pointed out how you wanted to be damn sure there was no-one
mining with them, least you wind up creating a slowly growing fork mined
by nodes unaware of the main chain.

Soft-forks and SPV nodes is another topic. SPV nodes don't do any
meaningful validation - they usually don't even have the transaction
inputs spent by a transaction to determine if a scriptSig is valid.
Their security is already dependent on miners, so allowing those miners
to upgrade does no harm. In addition there are even cases where what
would be a hard-fork for a full node, is a soft-fork for a SPV node. On
the other hand if your "SPV" node is more sophisticated, then by all
means use a nVersion change to trigger an alert to the user. If you're
implementation relays blockchain data, continue doing so to ensure other
nodes find out about the new version as soon as possible. (all SPV nodes
should relay block headers if possible)


Note how the nVersion field is useful for voting: the "chain height in
coinbase" soft-fork was accomplished this way, changing nVersion from 1
to 2 with full enforcement of the rule triggered by a 95% supermajority.
Bitcoin is a decentralized system, so any changes need to be done by
voting to show that a clear consensus of hashing power will enforce and
validate the new rules. (time and height deadlines can be disasters if
the upgrade is ever ignored or delayed)

Interestingly this suggests that what we actually want is two nVersions
per upgrade: the first to signal that nodes wish to upgrade, and are
showing their intent to use the new rules. The second to signal that the
upgrade has actually happened and the old rules are now ignored. Client
software can use this two stage approach to know when rules may have
changed, and the user probably should consider upgrading. As applied to
the chain height upgrade we would have gone from version 2 during the
voting, to version 3 for any block produced while the rules were in
effect. Put another way, the last in nVersion is simply to signify that
the new blockchain rules are now active, as opposed to being proposed.

-- 
'peter'[:-1]@petertodd.org
000000000000000180dabf823b09a30b4f2032b5cab7ba1d0351cab350bee91f
-------------------------------------
On Mon, May 06, 2013 at 04:58:56PM +0200, Mike Hearn wrote:

More generally, I think this shows clearly how SPV nodes have weaker
security than constantly operating full nodes, which we knew already, so
why not build a better SPV-specific system instead?

I've noticed on my Android phone how it often takes quite awhile to find
a peer that will actually accept an incoming connection, which isn't
surprising really: why should a regular node care about responding to
SPV nodes quickly?

For fast startup you would be better served with dedicated nodes that
are backed by fast hardware and high bandwidth internet connections.
You can discourage non-SPV use by refusing to relay full blocks.

You can have trusted individuals vouch for these special servers with
SSL certificates so you run less of a risk of connecting to a malicious
one trying to limit what information you see. For the initial
implementation, maybe just make a quick SSL accessible service with HTTP
GET so you don't have to integrate SSL into the network protocol and
have a couple of these HTTP GETable servers running. (IE, the trust is
actually that the SPV seed is honest)

Security will be no worse than before - if any one server/seed is honest
you're ok - and hopefully better due to the accountability. Obviously
you can use the existing bootstrap method in parallel at the same time.


What's good about partitioning between SPV and full node bootstrapping,
is the regular DNS seeds can optimize the other way: accept that some
nodes may turn out to be evil, and limit the damage by returning peers
from the widest pool possible even if some of those peers may be a bit
slow and unreliable. An attacker can't dominate the results by running a
small number of fast reliable nodes because the results returned comes
from a huge pool, so they are stuck with getting access to lots of IP
addresses, and maybe in the future we'll have even better methods of
resisting sybil attacks, and we will be able to implement those methods
even if they mean initial bootstrapping is slower.





-- 
'peter'[:-1]@petertodd.org
000000000000002a871dc011fe28fd8fbffe577c02b91d2de09aeca8216644ef
-------------------------------------
I'm happy to announce the release of bitcoinj 0.8, a Java library for
writing Bitcoin applications. Both simplified and full verification are
supported. BitcoinJ has been used to create everything from end-user wallet
apps to network crawlers to SatoshiDice.

To get bitcoinj 0.8, check out our source from git and then run *git fetch
--all; git checkout **cbbb1a2bf4d1*. This will place you on the 0.8 release
in a secure manner. This message was written on Tuesday 9th April 2013 and
is signed with the following key, which will be used in all release
announcements in future: 16vSNFP5Acsa6RBbjEA7QYCCRDRGXRFH4m.

Signature for previous
paragraph: H8itldUGHHt8jXmFwRX/gASXrhG1a/k0VG0vwFMjQCAWDpxgA17ODfSPFNgAOPDnPmT1gLLUlHsEqwXHBoj+JMU=

You can also verify the google.com DKIM signature on the official
announcement<https://groups.google.com/forum/?fromgroups=#!topic/bitcoinj-announce/IB7dlc_g9sU>
.

I'm especially happy about this release because for the first time, we have
an SPV implementation that is competitive performance-wise with more
centralised solutions that rely on custom servers. Wallets based on
bitcoinj 0.8 complete first time setup for new users in only a few seconds,
eliminating the last source of significant delays. Every operation except
key import now completes more or less immediately.


*New in this release*

   - Thanks to Jim Burton, encryption of private keys in the wallet is now
   supported. Keys are encrypted using an AES key derived using scrypt.
   - A new SPVBlockStore provides dramatically better performance and
   bounded disk usage by storing block headers in an mmapped ring buffer. This
   makes syncing headers for new chains/wallets network limited instead of
   disk io limited.
   - A new tool is provided to create lists of block header checkpoints
   that can then be used to initialize a new block store. This allows most
   headers to not be downloaded when initializing a new chain/wallet, making
   first-run of new wallets much faster.
   - Bloom-filtering capable nodes are now queried for transactions at
   startup, meaning you can receive payments that weren't confirmed yet even
   if your wallet wasn't running at the time.
   - Many static analysis warnings have been cleared.
   - All event listeners except transaction confidence listeners now run
   unlocked and core objects have been converted to use cycle detecting locks.
   Multiple lock inversions were fixed.
   - DNS seeds are now supported for testnet.
   - PeerEventListener now lets you catch and process exceptions thrown
   during peer message processing. This is useful for reporting crashes that
   don't take out your entire app, but just result in disconnection of a peer.
   - Matt Corallo's bitcoind comparison tool was merged in. It runs a large
   set of regression tests that compares the behaviour of bitcoinj in full
   verification mode against bitcoind.
   - The vast bulk of the changes in this release are bug fixes,
   optimizations and minor API improvements. They are too numerous to list
   here, please refer to the commit logs for details.

*API changes:*

   - Event listeners were previously locked before being called, and the
   object being listened to was also locked. This is no longer true - your
   event listeners must be thread safe and the objects that triggered the
   event may be changing in parallel.
   - IrcDiscovery is now deprecated, as LFnet has gone offline and DNS
   seeding can be used for both test and production networks. The code is
   still there in case you want to use IRC bootstrapping for a private
   experimental network.
   - BoundedOverheadBlockStore is now deprecated. It was replaced by
   SPVBlockStore. The file format has changed, so BOBS will stick around
   for a while so users can be upgraded.
   - The Derby based block store has been deleted. It only supported SPV
   mode and wasn't used much.
   - The static NetworkParameters methods now vend singleton objects.
   - WalletEventListener.onCoinsSent is no longer run when a transaction
   sends to self but the balance doesn't change.

*Known issues:*

   - Transaction confidence listeners are still run with the wallet lock
   held, which means it's possible to trigger unexpected lock inversions by
   doing certain things inside them. Also, confidence listeners sometimes run
   in places where the wallet code is not fully re-entrant, meaning that
   modifying the wallet whilst inside a confidence listener may cause
   problems. A simple fix is to run your listener code in a separate thread. A
   future release will fix this by ensuring that listeners only ever run at
   the end of wallet mutating operations and with the wallet unlocked. Core
   objects will also switch to using non-reentrant locks so unexpected
   reentrancy deadlocks early and reliably.
   - If multiple peers disconnect simultaneously it's possible for the
   system to deadlock due to Netty allowing uncontrolled reentrancy when
   sending outbound messages (issue
381<https://code.google.com/p/bitcoinj/issues/detail?id=381>
   ).
   - The Wallet expects that it can store all transactions in memory
   (including spent transactions), eg, for rendering in lists and availability
   during re-orgs. On highly constrained devices like old Android phones it is
   possible to run out of RAM if a wallet gets very large.
   - There are some bugs that can cause the wallet to get into an
   inconsistent state in various rare situations. The wallets can be fixed by
   replaying them. These bugs will be addressed as the next highest priority.

There is a further list of limitations and issues available on the wiki
here:

https://code.google.com/p/bitcoinj/wiki/Limitations
-------------------------------------
On Mon, Aug 19, 2013 at 1:09 PM, Frank F <frankf44@gmail.com> wrote:

They have been, resulting in a replacement called "getblocktemplate"
which (presumably) almost everyone talking to bitcoin(d|-qt) has been
using for a long time.

I think removing the ability to mine in the stock package would be
regrettable, but to be honest we already don't have it for the
mainnet. I think we should do as Jeff suggests and remove getwork. But
I think we should also package along a proper getblocktemplate miner
to remove any doubt that we're providing a full network node here.  (I
note that the choice of miner is also easy:  Regardless of people's
preferences which way or another, AFAIK only luke's bfgminer stuff can
mine directly against bitcoin getblocktemplate with no pool in the
middle.  It also supports a huge variety of hardware, and a superset
of our target platforms)


-------------------------------------
I agree with Ittay: when bugs are found, they must be fixed ASAP,
expecially when they affect a sensitive sw such as Bitcon; in IT security,
every flaw that is exploitable in abstract, is going to be exploited in
real, sooner or later, also taking into account the increasing parallel
computing power; beware of false sense of security

WebSite: http://www.startithub.com
Per rimanere aggiornato in merito a Startup, Innovazione e Normativa di
settore, sottoscrivi la nostra newsletter:
http://www.startithub.com/blog/sottoscrivi-newsletter/


2013/11/5 Mike Hearn <mike@plan99.net>

-------------------------------------
http://www.reddit.com/r/Bitcoin/comments/1bw9xg/data_in_the_blockchain_wikileaks/

<TD> petertodd: yeah somebody put a file upload tool into the chain
and then tried to upload the entire amibios source code to it. stupid.
<TD> someone thinks it's a lot more important than it really is
<petertodd> TD: and 2.5MB of wikileaks data, and a whole bunch of GPG
encrypted stuff, and the hidden wiki cp/jb sections (no idea if it's
all the same person)
<petertodd> jgarzik:
https://blockchain.info/address/3Dw3UB6VZ3a3ay5diDQVwUFXzKScJJLeVU
iirc this is gpg symmetric key encrypted
<petertodd> jgarzik: (I wrote a tool to download the tool to download data)
<petertodd> MC1984_: just checked, surprisingly no-one has put
*anything* into the litecoin chain at all, strings returns nothing

-- 
Jeff Garzik
exMULTI, Inc.
jgarzik@exmulti.com


-------------------------------------
On Fri, Feb 08, 2013 at 11:03:54AM +0100, Timo Hanke wrote:

Why don't you use namecoin or another alt-chain for this?

The UTXO set is the most expensive part of the blockchain because it
must be stored in memory with fast access times. It's good that you have
designed the system so that the addresses can be revoked, removing them
from the UTXO set, but it still will encourage the exact same type of
ugly squatting behavior we've already seen with first-bits, and again
it'll have a significant cost to the network going forward for purposes
that do not need to be done on the block chain.

In https://github.com/bcpki/bitcoin/wiki/Technical you say that you have
a minimum amount required for an outpoint to be valid, set at 0.05BTC.
That's a nice touch, and sort of works because this is a consensus
protocol, but if the exchange rate climbs significantly there will be a
lot of pressure to reduce that value. (setting minimum value by chain
height) What will happen then is there will be a mad rush to squat on
previously unaffordable domains, further disrupting Bitcoin's purpose as
a financial network.

In addition you'll also have a second problem: squatting of subsequent
transactions, particularly for valuable bcvalues. Basically if someone
already has "microsoft" insert bcvalues after their tx in case they
accidentally spend it. Of course, this will be done by people buying
bcvalues as well. Again, all this further clogs up the UTXO set.

I also can't figure out why you say signature lookup and verification
takes 10s - this should be an O(1) operation if you maintain a mapping
of candidate pubkeys to linked-lists of sorted applicable transactions.

Finally, why is this implemented within the reference client? Use the
raw transaction API and make up your own database. If you want, create a
RPC command that allows you to query the UTXO set directly; this would
be a useful feature to have. This patch will never be accepted to the
reference client, so you'll just wind up having to maintain a fork. Even
for a prototype this approach is ill-advised - prototypes have a bad way
of turning into production code.


In short, please don't do this.

-- 
'peter'[:-1]@petertodd.org
-------------------------------------
Alan,

 I highly recommend that if we make any move towards this, that the

Good point - For me its too much clutter to show multiple boxes everywhere
(we already support unit conversion by changing the dropdown box in the
amount widget), but I'm going to make the verification dialog show the
totals in all three units. This will make people learn about other units
without having to choose them consciously.

Wladimir
-------------------------------------
On Mon, Aug 19, 2013 at 5:09 AM, John Dillon
<john.dillon892@googlemail.com>wrote:


Unconfirmed transactions that are received show up as unspendable and in
most wallets they have a little graphic that changes as more peers announce
the tx. So if a peer sent non-existent transactions then they'd allow show
up as seen by only one peer, which would look different to how normal
broadcast transactions show up.

Whether users really notice this graphic or understand what it means is
debatable, of course, but all Bitcoin wallets have that problem. I've yet
to see any that would successfully communicate the notion of confidence to
new, untrained users. That's why the default is to not let you spend
unconfirmed transactions, unless they were created by yourself (you're
allowed to spend change).

bitcoinj does not attempt to handle DoS attacks by malicious remote peers
today, because such an attack has never been observed, has no obvious
profit motive and as you don't get to choose which nodes the wallets
connect to it'd be difficult to pull off. Unless you control the users
internet connection of course, but that's a well known caveat which is
documented on the website.
-------------------------------------
On 12/01/2013 12:51 PM, Mike Hearn wrote:


Thanks taking the initiative and writing this up!


As long as the tx is not confirmed (by a broadcast), apps can offer to
bump up the fee a little bit.




-------------------------------------
Hi guys,

I've seen many many non-geeks be utterly intimidated and confused by
0.000XXXXX quantities and/or mBTC & uBTC notation


Yes, $10 being rougnly 10,000 Won in South Korean is a great example where
large amounts of units work very well in a major economy.


FWIW,  I would prefer the entire switch-over be done *once* *and *at the
same time switching both BTC to XBT and using the following


Currency Code *: *XBT
Unit Definition  *: *1 Bit = 100 Satoshis

Addition benefit is splitting the term Bitcoin/bitcoin (as in Network and
currency unit) into Bitcoin (network) and Bit (the unit).


Perhaps this project/process should have a name and be listed on a road map
somewhere

*BRCS: *Bitcoin Re-denomination and [Currency] Code Standardization project


Cheers ...





On Fri, Nov 15, 2013 at 1:23 AM, Eugen Leitl <eugen@leitl.org> wrote:




-- 
Alex Kravets <http://www.linkedin.com/in/akravets>       def redPill = '
Scala <http://www.scala-lang.org/>
[[ brutal honesty <http://goo.gl/vwydt> is the best policy ]]
-------------------------------------
On Thu, Jun 27, 2013 at 3:23 AM, Arthur Gervais
<arthur.gervais@inf.ethz.ch> wrote:

It would be kind if your paper cited the one of the prior discussions
of this transaction pattern:

E.g. https://bitcointalk.org/index.php?topic=196990.msg2048297#msg2048297
(I think there are a couple others)

The family of transaction patterns you describe is one of the ones I
specifically cite as an example of why taking non-reversible actions
on unconfirmed transactions is unsafe (and why most of the Bitcoin
community resources) council the same.  You can get similar patterns
absent changes in the IsStandard rule through a number of other means.
 One obvious one is through concurrent announcement: You announce
conflicting transactions at the same time to many nodes and one
excludes another.  By performing this many times and using chains of
unconfirmed transactions and seeing which family your victim observes
you can create input mixes that are only accepted by very specific
subsets of the network.


-------------------------------------
Subject change to reflect that this is off-topic for the old thread.

Eventually, I think it makes sense to move to a system where you get seeds


This obviously makes no difference from a security perspective. If a DNS
seed is compromised it can feed you nodes that just connect you back to the
sybil. If you seed from DNS then that's your root of trust.

The problem with moving away from DNS seeding for bitcoinj clients at least
is that SPV clients are very sensitive to startup time. It isn't OK to
spend two minutes trying to connect to lots of long-dead IP addresses if
you're wanting to pay your bill in a restaurant. That means either you have
to spin up a lot of TCP connections in parallel, which I know from bitter
experience can cause problems with some crappy wifi routers (they think
it's a synflood), or you get a known fresh source of IPs like a DNS seed
response and then later on bring up connections to the P2P network from
that.

Implementing the latter is complicated - you have to partition your nodes
so the seed peers are separated from the peers you found via addr
broadcasts and seeded peers can't pollute your addr-found peers unless it's
your first run.

I've actually not experimented with this for a while. I'm hoping that by
the time this gets to the top of my todo list, network nodes will be stable
enough that actually you can always obtain at least one or two connections
if you try (say) 30 at once. But I have no idea if we're at that stage yet.
-------------------------------------
On Mon, Nov 04, 2013 at 10:25:19AM -0500, Ittay wrote:

Feedback basically. So suppose the hashing power is split exactly 50:50,
with half the hashing power hearing about one block first, and half the
other. Also suppose the near-target threshold is 1/64th, that is a block
header that means a target with difficulty 1/64th of the actual
difficulty will be broadcast around the network by nodes. With a 10
minute block interval, near-target block headers will be found on
average every 9.4 seconds.

Eventually one of the two halves will find a near-target PoW solution,
and the corresponding block-header will be broadcast on the network. Now
if you are a miner, and you receive such a PoW solution, that's evidence
that whatever block that block header built on has more hashing power
than other competing blocks. Thus you would be rational to switch, and
start mining to extend that block if you aren't already. Once miners
start doing that, very soon another near-block solution will be
generated, giving even more certainty about what block the majority are
mining on.

Of course, it may be the case that competing near-block headers are
found, but no matter: as long as miners switch to the block with the
most hashing power, this forms a feedback effect that quickly brings
everyone to consensus. With everyone mining to extend the same block,
there's nothing the selfish miner can do; there's no disagreement to
exploit.

-- 
'peter'[:-1]@petertodd.org
000000000000000771e068338fef7e2285b8a6db582e37473f42b76573677adf
-------------------------------------
Payment Protocol uses x509 certs to sign a Payment Request. This
allows wallets to display meta-data from the cert to the payer instead
of the address, which should make it easier to verify where money is
being sent, and make it harder for an attacker to change the address
displayed to a user so that coins are not sent to the wrong place.

The difficulty is that Payment Requests must be generated live, and
therefore the key used to sign those requests must also be live,
exposing the key to theft similar to a hot wallet. Steal the key,
forge payment requests, and the payer sees a 'green box' but the coins
go to the attacker. The question... is there a way to sign something
once, with a key kept offline, which verifies the address in the
Payment Request belongs to the payee?

1) Given a 'parent' cert which is kept offline, and a child
certificate of 'parent' which is kept hot on the payment server.

2) Given a public key and chain code { pubKey, code } under BIP32 we
generate child keys as I = HMAC(code, Kpar || i), Ki = I[0:32] * Kpar.

3) If we sign Kpar with the parent cert's key offline, we can sign the
remaining less critical data (address, I[0:32], amount, description,
etc.) with the child cert's key.

4) The payer verifies Kpar, and verifies the address by calculating
Hash160(Kpar * I[0:32])

In fact, there's no requirement to use BIP32 to calculate I[0:32], it
could also just be randomly generated.

Any I[0:32] included in the Payment Request, even if it is tampered
with, will correspond to an address for which the payee can calculate
the corresponding private key.

So the idea is your 'most trusted' cert would be used offline only to
sign a Kpar once, and a 'less trusted' cert would be used to sign the
other stuff, like 'amount', 'description', 'merchant-data', and the
'I[0:32]' as well.

I'm not an expert on x509, but I imagine the trouble is, how does the
payer know which cert is which? I was originally thinking the parent
cert would be an intermediate CA cert used to sign the child cert, but
I guess good look getting one of those, even with a name constraint,
from a Root CA. I'm not sure if you can do better than just a
'convention' such as one is an EV cert and one is not. Perhaps the
less trusted cert is actually self-signed using the EV cert, but that
requires special validation, since its no longer a standard
certificate chain. I would love to hear a better idea.

Any comments if this is something worth pursuing? I think there are
definitely benefits if merchants can keep the key signing the address
offline.

Thanks,--Jeremy
-------------------------------------
On Tuesday 23 July 2013 10:56:02 Pieter Wuille wrote:


It must be involved to some extent.  Certainly during a temporary fork, there 
are two branches growing, and you have to be able, when verifying a new 
transaction, to say which branch it's one... which branch of the blockchain.


Andy
-- 
Dr Andy Parkins
andyparkins@gmail.com


-------------------------------------
Guys,

I'd like to reiterate my previous request to support this alternate
address serialization in the payment protocol.  We got caught up in the
specifics of one use case, but didn't acknowledge that it's still a
valid address representation that will provide value to those who wish
to use it and can be safely ignored by others.

Current address format:   binary_to_base58( idbyte + hash160(pubkey) +
checksum)
Alternate format:         binary_to_base58( idbyte + parentpubkey +
multiplier + checksum)

The receiving party will multiply the pubkey by the multiplier, and then
hash it to get the 20-byte address to send to.  The idea is that you use
your BIP 32 parent public key, and then you generate whatever child you
want, and only send them the multiplier used (not the chaincode).  This
preserves privacy, but if the recipient has your parent public key
already, they can identify that address being linked to you, but cannot
determine any other addresses in your wallet.

This form has no drawbacks to the existing address format except for
being longer and requiring an extra EC multiplication by the person
sending to that address.  But the advantage is that it optionally allows
the sender to provide more information than currently contained in the
25-byte hash160 form.  The discussion about this got side-tracked with
the use case I presented, but I believe there are plenty of other uses
for this.

The particular use case I had in mind was that certain services could be
setup (pre-arranged), say between wallet software and a
business/exchange.  The exchange would like to be able to reliably send
addresses to the user for deposit, without risk of MITM, or even if
their own public server is compromised.  The author of wallet software
pre-verifies the public key portion of the service, and either hardcodes
it into the software, or hardcodes their own public key into the
software and makes the service's signed public key available through
query server (allowing the software author to offline-sign replacement
keys, or add keys for new service providers, as needed). 

When the user's software receives a payment address, the software can
verify it belongs to that service.  You can't use dedicated chain
technique, because it would either have to be exchanged with the user on
first transaction which half defeats the purpose, or they give them the
full public key and chaincode which allows the user to see /all
/addresses ever used by the service.  Neither one is a reasonable solution.

This use case doesn't necessarily scale, but it doesn't have to.  It
simply allows service providers to skip the SSL and go right to public
key exchange/verification for a few of the important services they
provide access to, and will provide better security than relying on
SSL/PKI.  This would simply be one, coexisting option for providing
payment details in the absence (or in addition to) SSL/PKI infrastructure.

I'm sure there's other use cases, but it seems simple enough and
non-disruptive enough that it could be supported easily for no other
reason than to support that use case (which I intend to implement in
Armory to help verify high-volume services).

-Alan





On 06/26/2013 11:29 AM, Alan Reiner wrote:

-------------------------------------
Am 07.04.2013 17:22, schrieb Scott Howard:

Yes I have made a clean start because of the the new database structure.


I see. I successfully have downloaded the Blockchain again. Thus, it 
should not occur again now. If it does, I'll be back again. :-)

Thank you for your quick help.

regards
Oliver



-------------------------------------
Great paper Ittay, thanks for all your work on this.


Fig. 2 captures this well, the threshold is only zero if 'y' is 1. In  
Section 6 and 6.1 you argue y -> 1 but the sybil attack you describe,  
isn't that more like how *all* sophisticated miners would want to ensure  
their blocks are widely propagated? I think you can't assume only the  
selfish miner is doing it.

Based on the current  'first seen' algorithm, as you say, competing  
longest chains happen about every 60 blocks.  The rest of the time, a  
single block propagates through the vast majority of the network  
'uncontested'.  If there are multiple valid longest blocks being  
simultaneously propagated, then  propagation pattern of the competing  
blocks will determine hash rate on each.

Selfish mining requires exploiting the race condition between learning  
about a competing block, and publishing your own. Usually we talk about  
minimizing publishing latency so that your block ends up uncontested 59/60  
times, and in the 1/60 times, even then your block has the best chance of  
winning.

Selfish mining forgoes the 59/60 chance of your block being uncontested,  
and instead chooses to 'race the network' every time. You start 'one step  
behind' the competing block (since of course you only learn about it after  
it starts propagating), so you must rely on being able to outrace  
propagation of the competing block through a private low-latency  
side-network which can inject your block at multiple points throughout the  
bitcoin p2p network to outrace the competitor.

I think it's a stretch to say 'y' is 0 with good connectivity. Even the  
best connected mining pools today are concerned with this 'y' factor.

Here's a probably very dumb idea... to throw out one possible "solution"...

You want a way to fake-out the 'selfish miner' into disclosing their  
blocks -- how can your force their hand to prevent them from accumulating  
longer private chains?

What if you propagate (and relay) an encrypted block header which honest  
miners will timestamp when they receive it, then 10 seconds later  
propagate the decryption key to unblind it. But here's the catch - maybe  
the decryption results in junk, maybe it results a new longer block. If  
it's a real block then it gets priority based on when the ciphertext was  
received instead of when the decryption key was received. Now 'selfish  
miner' can't race the network anymore, because they are always in state 0'  
and can't tell if they are up against a ghost, or a real competing block.  
If they wait for the decryption key to check, it's too late, and they are  
guaranteed to lose unless they can out-race the network, e.g. back at  
t=50%. Of course there would need to be some way to anti-DDoS this which  
allows for some amount of these fake-outs without letting them get out of  
hand.

Thanks,
Jeremy
-------------------------------------
Thanks for the warning; to be clear, "the Bitcoin SCI library" is this
project?
  http://bitfreak.info/index.php?page=tools&t=bitsci


On Mon, Oct 28, 2013 at 8:25 AM, Andres Home <a86551@outlook.com> wrote:




--
Gavin Andresen
-------------------------------------
Our testing of the macos leveldb parts for the past 6 days has had zero
complaints of new corruption from OMG and LTC users.  I agree it is time to
release 0.8.6.


On Sun, Dec 8, 2013 at 8:14 PM, Gavin Andresen <gavinandresen@gmail.com>wrote:

-------------------------------------
Just create a new wallet and send everything to a new address.
I don't think additional tools for this are needed.


On 2/23/13, Roy Badami <roy@gnomon.org.uk> wrote:


-- 
Jorge Timn

http://freico.in/
http://archive.ripple-project.org/


-------------------------------------
On Wed, Feb 13, 2013 at 3:10 PM, Stephen Pair <stephen@bitpay.com> wrote:

The cost to whom?  This is important because the cost of validating
blocks is borne by all the participants in Bitcoinâ€” or at least all
the participants who haven't given up on the decenteralized trustless
stuff and are simply trusting someone else.   Even a small cost
becomes large when hundreds of thousands.

And perhaps you don't lament people delegating their trust to large
entitiesâ€” but keep in mind: Bitcoin was created for the express
purpose of creating a money system which didn't require trust because
it was based on cryptographic proofâ€” mathematical lawâ€” instead of
politics and human law.  Take that away and you have a really poorly
understood inefficient system operated by entities which are less
trustworthy and rightfully entitled to authority than the ones
operating the established major currencies.


Thats absolutely trueâ€” but I don't know that it's relevant in this case.


They canâ€” but doing so would radically undermine Bitcoin.

A refresher:

If you combine digital signatures with simple transaction rules you
can have a purely autonomous monetary system based entirely on math.
It would be perfect, anonymous, scalable ...  except for the problem
of double spending.  To solve double spending the participants must
agree on which of a set of duplicated payments is one the
authoritative one. Coming to this agreement is fundamentally hard just
at the basics of physicsâ€” a result of relativity is that observers
will perceive events in different orders depending on the observer's
and the events relative locations. If no observer is privileged (a
decenteralized system) you have to have a way of reaching a consensus.

This kind of efficient consensus we needâ€” which which participants can
join or enter at any time, which doesn't require exponential
communication, and which is robust against sock-puppet participantsâ€”
was long believed to be practically impossible.  Bitcoin solved the
problem by using hashcash to voteâ€” because real resources were forever
expended in the process the sock-puppet problem is solved.  But the
vote only works if everyone can see the results of it: We assume that
the majority of hashpower isn't a dishonest party, and that honest
nodes can't be prevented from hearing the honest history. Nodes choose
then rules-valid history that has the most work (votes) expended on
it... but they can only choose among what they know of.  As Satoshi,
wrote: "[Bitcoin] takes advantage of the nature of information being
easy to spread but hard to stifle".

The requirement for everyone to hear the history doesn't get talked
about muchâ€” at least with reasonably sized blocks and today's
technical and common political climates the assumption that
information is easy to spread but hard to stifle is a very sound one.
It's a good thing, because this assumption is even more important than
the hash-power honesty assumption (a malicious party with a simple
majority of hashpower is much weaker than one who can partition the
network).  ... but that all goes out the window if communicating
blocks is costly enough that the only way to sustain it is to
jealously guard and charge for access/forwarding.

The consequence of such a change is that the Bitcoin consensus
algorithm would be handicapped. How long must you wait before you know
that the history you have won't get replaced by a more authoritative
one?  Today an hour or two seems relatively solid.  In a world with
non-uniform block forwarding perhaps it takes daysâ€” if everâ€” before
any participant is confident that there isn't a better history
lurking.

All doubly so if the bookkeeping required for this payment ends up
necessitating additional transactions and adds to the load.

[This is also the flaw in the 'Red Balloons' paper, making
transactions a dozen times longer just to attach credit for forwarding
doesn't seem wise compared to keep transactions so cheap to transmit
that even a small number of altruists make the equilibrium state be
liberally-forwarding]


Large miners would obviously locate and connect to each other. Even
enormous blocks are no problems for big industrial players.

Don't want to pay the cost to get their big blocks from them?  Your
loss:  If you don't take their blocks and they constitute the longest
history, you'll be believing the wrong history until such a time as
you wise up and pay the piper.  Your transactions will be reversed and
you'll lose money.

You can hypothesize some cartel behavior external to the rules of the
systemâ€” where by some consensus mechanism (????) some super large mass
of participants agree to reject blocks according 'extrajudicial
rules', some rule existing outside of Bitcoin itselfâ€” but there must
be a consensus because rejecting blocks by yourself only gets you
ripped off.

I don't see how this worksâ€” it basically embeds another hard consensus
problem (what is the criteria for blocks to be valid?) inside our
solution to a hard consensus problem (which are the best valid
blocks?),  but doesn't benefit from the same incentive structureâ€”
locally-greedy miners obviously want to produce the largest blocks
possibleâ€” and in hashpower consensus non-miners don't have a voice.
That might be acceptable for ordering, but now you're deciding on the
rules of the system which all non-trusting participants must validate.

You could instead solve that consensus problem with politically
stipulated regulation or industry cartels, or good old-fashion kneecap
busting or whathave you. But then Bitcoin loses the transparency and
determinism that make it worthwhile.

I sure hope to hear something better than that.

This is basically the gap:   Right now I could afford hardware that
could process multiple gigabyte blocksâ€” maybe it only costs as much as
a small house which is not an insane cost for a large business. But
the cost would be decidedly non-negligible and it would be rational
for me to let someone else take it. Applied to everyone, you end up
with a small number of the most vested parties doing all the
validation, and so they have full ability to manipulate like today's
central banks.

For a great many to perform validationâ€” keeping the system honest and
decentralized as it was envisionedâ€” without worrying about the cost
requires that the cost be almost unnoticeable. A tiny fraction of what
some industrial playerâ€” who profit from consolidation and
manipulationâ€” could easily handle.  I'm skeptical about the system
internally self-regulating the size because of what gets called
"evaporative cooling" in social sciencesâ€” the cost goes up, some
people cross their "hey, I'm better off if I externalize the cost of
keeping Bitcoin secure by not participating" boundary and lose their
voice.

There is probably some equilibrium where Bitcoin is compromised
frequently enough that more validators spin up (and ignore past rule
violations which can't be undone without economic Armageddon), and eat
the costs even though there is an insane amount of freeloading going
on.  The trustworthiness of today's monetary systems suggests to me
that if there is an equilibrium point here it isn't a very trustworthy
one.  There is an even stronger equilibrium state available too: don't
use Bitcoin at at all.  If you want a system which is dominated by
political whim and expedience and large industrial players and is, as
a result, only somewhat trustworthy you can just use government issued
currenciesâ€” they're well established and have a lot less overhead than
this decentralized stuff.

(And generallyâ€” Security makes for a terrible market, security is
naturally a lemon market. The need is only clear in hindsight. In our
case it would be one with an enormous freeloading problem)


Our current anti-spam one is primarily an economic oneâ€” transactions
prioritized based on fee per KB in scarce blocks or priority (another
scarce commodity), the only really non-very-economic part is the
very-small-output heuristic.  I would argue that our economic
anti-spam mechanisms are currently failing at their job:  Various
parties are engaging in transaction patterns with near pessimal
efficiencyâ€” using a dozen (â€” sometimes thousands) of transactions
where one or two would be adequate. This isn't limited to just one or
two sitesâ€” many parties are using inefficient transaction patternsâ€”
creating externalized costs on all future Bitcoin usersâ€”, simply
because there is hardly any incentive not to.

Though much discussion among technical people, no one has come up with
any reparametrizations that seem likely to achieve the desired
incentive alignment in the near term.  Of all the elements of the
anti-spam policy, it seems to me that the least economicâ€” the minimum
output sizeâ€” is actually the most effective (most spam suppression
relative to efficient usage suppression), especially as we move to
focusing on the UTXO set size. (The minimum output value requirement
discourages the creation of UTXOs which will never be economically
rational to redeem).


-------------------------------------
On 25 May 2013 10:53, Luke-Jr <luke@dashjr.org> wrote:


[[ Not wishing to stray too far off topic ]]

I think you are perhaps underestimating the effect of 'mere' default
policies.

It would be nice to think that every node was a free thinking individual
that is motivated to vote with their feet, but in practice most people dont
have time.

There is research showing that 80% of users tend to accept defaults.

Rule changes and changing defaults would seem to be things worth weighing.
Bug fixes hopefully should be fairly unanimous.  Of course a grey area
exists in between.


-------------------------------------
A related question...some people mentioned yesterday on #bitcoin-dev
that 0.5 appeared to be compatible with 0.8.
Was that only for the "fatal block" and would have forked 0.8 later
too or is it something else?
I'm having a hard time understanding this 0.5 thing, if someone can
bring some light to it I would appreciate it.

Thanks in advance

On 3/12/13, Pieter Wuille <pieter.wuille@gmail.com> wrote:


-- 
Jorge Timn

http://freico.in/
http://archive.ripple-project.org/


-------------------------------------
On 14 November 2013 23:01, Luke-Jr <luke@dashjr.org> wrote:


A very good idea.



I think people are more familiar with check clearance - "the payment/check
has cleared".

If "confirmation" and "n confirmations" together are problematic, I'd talk
about "cleared payments" and "n confirmations"

So "a payment clears after one confirmation, but you might want to wait
until the payment has been confirmed n times".
Then at least you are not using the same word for two different meanings
and you're using stuff more familiar in popular lexicon.
I dont think it's helpful for users if we use the word "blocks".

Without the technical details, I just explain to normal bitcoin users that
the Bitcoin network checks and confirms the payment is valid (multiple
times).

I think we all know the problems with the term "address". People naturally

I think "key id" is a bit alien at user level - it's not something they are
used to.
For years, people had a problem with  "email address", instead using "email
number" but they got there eventually. Most people nowadays use "email
address"
So "payment address" or "bitcoin address" make better sense here when
qualified as a "<foo> address" and not just an "address"

You could also call it "payment id", but I dont think "invoice id" since
no-one pays to an invoice id that's just a reference for a payment, not the
destination.

People are very familiar with Paypal these days, and are familiar with
"paypal address" or their "paypal id" so again I think valid contenders are
"bitcoin address" or "bitcoin id".

Regards,

Drak
-------------------------------------
On Mon, Apr 08, 2013 at 09:22:10PM -0400, Jeff Garzik wrote:

It must be "shit on the blockchain" week:

http://vog.github.io/bitcoinproof/

Timestamping the stupid way, but the user experience is really nice:


Like it or not, people will do what's easiest regardless of how much it
harms everyone. I'd send this guy an email about opentimestamps yadda
yada, but really, why bother.

-- 
'peter'[:-1]@petertodd.org
-------------------------------------
I am wondering if we shouldn't have a BIP32 addendum which makes the
following signing related recommendations:

(1) Recommend a specific deterministic DSA derandomization procedure
(a deterministic way to generate the DSA nonce), presumably one based
on HMAC-SHA512 (since BIP32 uses that construct) or SHA256 in the
style of RFC 6979.

DSA systems being compromised due to poor randomness at runtime is not
new. It effected other systems before it effected Bitcoin systems,
it's not a new problem and it's not going away.  It's difficult to
tell if an implementation is correct or not.

Use of a fully deterministic signature  would allow for complete test
vectors in signing and complete confidence that there is no random
number related weakness in a signing implementation.

In particular, with relevance to our ecosystem a maliciously modified
difficult to audit hardware wallet could be leaking its keys material
via its signatures. Even without producing insecure K values it could
use the choice of K to leak a couple bits of an encrypted root key
with every signature, and allow the malicious party to recover the
keys by simply observing the network. Making the signatures
deterministic would make this kind of misbehavior practically
discoverable.

We wouldn't be alone in making this change, in general industry is
moving in this direction because it has become clear that DSA is a
hazard otherwise.

The primary arguments in most spaces against derandomizing DSA are
FIPS conformance (irrelevant for us) and reasonable concerns about the
risks of using a (less) reviewed cryptographic construct. With
widespread motion towards derandomized DSA this latter concern is less
of an issue.

Libcrypt has also implemented derandomized DSA in git. The ed25519
signature system of DJB, et. al. also uses a similar derandomization.

An alternative is implementing a still random construct where K is
some H(message||key||random) which should remain secure even where the
randomness is poor, but this loses the advantage of being able to
externally verify that an implementation is not leaking information.
OpenSSL development has implemented a form of this recently.

See also: http://tools.ietf.org/rfc/rfc6979.txt

(2) Recommends a procedure for using only even S values in signatures,
eliminating this source of mutability in transactions.

This can be accomplished via post-processing of existing signatures,
but since it requires bignum math it is usually preferable to
implement it along with signing.  I believe someday this will become a
network requirement for Bitcoin, but regardless it makes sense to
implement it as a best practice sooner rather than later.

Thoughts?


-------------------------------------
I believe a better solution would to use a gitlab clone such as gitlab,
which sits on top of the git repo, and allows for custom code around the
BIP process. Potentially one could even build Bitcoin into such a BIP
system. If somebody wants to support a BIP he donates Bitcoins to that
proposal. Somebody who actually implements the BIP can receive some percent
of the bounty (while some percent goes to the Bitcoin foundation). Via such
a platform one could create assurance contracts to kickstart BIP
developments or Bitcoin extensions (public infrastructure which is not part
of the core, such as opensourced exchanges).


On Mon, Oct 21, 2013 at 9:47 PM, Luke-Jr <luke@dashjr.org> wrote:

-------------------------------------
Hi guys,

This would be a big step forward.  Anecdotally I can report that <5% of *
non-nerds* who don't abandon Bitcoin after waiting for the initial
blockchain download and *ongoing* sync on every restart, end up using
blockchain.info simply because it just works and works on their iPads &
iPhones.

Conversely, all the serious nerds end up using Armory and/or Brainwallets
for ultimate control.




On Thu, Jun 27, 2013 at 10:56 AM, Gregory Maxwell <gmaxwell@gmail.com>wrote:




-- 
Alex Kravets <http://www.linkedin.com/in/akravets>       def redPill = '
Scala <http://www.scala-lang.org/>
[[ brutal honesty <http://goo.gl/vwydt> is the best policy ]]
-------------------------------------

Your definition of P_fork is inaccurate for a miner with non-negligable
hashing power - a miner will never fork themselves. Taking that into
account we have three outcomes:

1) The block propagates without any other miner finding a block.
2) During propagation another miner finds a block. (tie)
2.1) You win the tie by finding another block.
2.2) You lose the tie because someone else finds a block.

We will define t_prop as the time it takes for a block to propagate from
you to 100% of the hashing power, and as a simplifying assumption we
will assume that until t_prop has elapsed, 0% of the hashing power has
the block, and immedately after, 100% has the block. We will also define
t_int, the average interval between blocks. (600 seconds for Bitcoin)
Finally, we will define Q as the probability that you will find the next
block.

The probabilities of the various outcomes:

1) 1 - (t_prop/t_int * (1-Q))
2) t_prop/t_int * (1-Q)
2.1) Q
2.2) 1-Q

Note that to simplify the equations we have not taking into account
propagation in our calculations for outcomes 2.1 or 2.2

Thus we can define P_fork taking into account Q:

P_fork(Q) = (t_prop/t_int * (1-Q))(1-Q) = t_pop/t_int * (1-Q)^2

Over the range 0 < Q < 0.5 the probability of a fork decreases
approximately linearly as your hashing power increases:

d/dq P_fork(Q) = 2(Q-1)

Q=0   -> d/dq P_fork(Q) = -2
Q=1/2 -> d/dq P_fork(Q) = -1

With our new, more accurate, P_fork(Q) function lets re-calculate the
break-even fee/KB using your original approach:

t_prop = t_0 + \alpha*S
E_fee = f*S

E(Q) = Q*(1 - P_fork(Q))*(E_bounty + E_fee)
E(Q) = Q*[1 - (t_0 + k*S)/t_int * (1-Q)^2]*(E_B + f*S)

d/dS E(Q) = Q*[ -2fSk/t_int*(1-Q)^2 - f*t_0/t_int*(1-Q)^2 + f - E_b*k/t_int*(1-Q)^2 ]

Again, we want to choose the fee so that the more transactions we
include the more we earn, dE/dS > 0 We find the minimum fee to include a
transaction at all by setting S=0, thus we get:

d/dS E(Q, S=0) = Q*[ f - f*t_0/t_int*(1-Q)^2 - E_b*k/t_int*(1-Q)^2 ] > 0

f(1 - t_0/t_int*(1-Q)^2) > E_b*k/t_int*(1-Q)^2

f > [E_b*k/t_int(1-Q)^2] / [1 - t_0/t_int*(1-Q)^2]

f > [E_b*k*(1-Q)^2] / [t_int - t_0*(1-Q)^2]

With Q=0:

f > E_b*k / (t_int - t_0) ~ E_b*k/t_int

This is the same result you derived. However lets look at Q != 0:

df/dQ = 2*E_b*k * [t_int*(q-1)] / [t_int - t_0(q-1)^2]^2

With negligible latency we get:

df/dQ, t_0=0 = 2*E_b*k*(q-1)/t_int

So what does that mean? Well in the region 0 < q < 1/2, df/dQ is always
negative. In other words, as you get more hashing power, the fee/KB you
can charge and still break even decreases linearly because you will
never orphan yourself. Lets trythe same assumptions as your first
analysis, based on the work by Decker et al

Based on the work by Decker et al, lets try to calculate break-even
fee/KB for negligible, 10%, 25% and 40% hashing power:

t_0 = 10s
t_int = 600s
k = 80ms/kB
E_b = 25BTC

Q=0    -> f = 0.0033 BTC/kB
Q=0.1  -> f = 0.0027 BTC/kB
Q=0.25 -> f = 0.0018 BTC/kB
Q=0.40 -> f = 0.0012 BTC/kB

Let's assume every miner is directly peered with every other miner, each
of those connections is 1MB/s, and somehow there's no latency at all:

k = 1mS/kB

Q=0    -> f = 0.000042 BTC/kB
Q=0.1  -> f = 0.000034 BTC/kB
Q=0.25 -> f = 0.000023 BTC/kB
Q=0.40 -> f = 0.000015 BTC/kB

Regardless of how you play around with the parameters, being a larger
miner has a significant advantage because you can charge lower fees for
your transactions and therefor earn more money. But it gets even more
ugly when you take into account that maybe a guy with 0.1% hashing power
can't afford the high bandwidth, low-latency, internet connection that
the larger pool has:

k = 10mS/kB, t_0=5s, Q=0.01 -> 0.000411 BTC/KB
k =  1mS/kB, t_0=1s, Q=0.15 -> 0.000030 BTC/KB

So the 1% pool has an internet connection capable of 100kB/s to each
peer, taking 5s to reach all the hashing power. The 15% pool can do
1MB/s to each peer, taking 1s to reach all the hashing power. This small
different means that the 1% pool needs to charge 13.7x more per KB for
their transactions to break even! It's a disaster for decentralization.
Businesses live and die on percentage points, let alone orders of
magnitude differences in cost, and I haven't even taken into account
second-order effects like the perverse incentives to publish your blocks
to only a minority of hashing power.(1)

This problem is inherent to the fundemental design of Bitcoin:
regardless of what the blocksize is, or how fast the network is, the
current Bitcoin consensus protocol rewards larger mining pools with
lower costs per KB to include transactions. It's a fundemental issue. An
unlimited blocksize will make the problem even worse by increasing fixed
costs, but keeping the blocksize at 1MB forever doesn't solve the
underlying problem either as the inflation subsidy becomes less
important and fees more important.

1) http://www.mail-archive.com/bitcoin-development@lists.sourceforge.net/msg03200.html

-- 
'peter'[:-1]@petertodd.org
00000000000000054eeccf3ac454892457bf4919d78efb275efd2ddd1a920c99
-------------------------------------
btw if I got that right, it means you dont even have to fix the asn.1 level
ambiguity (though its a good idea to remove openSSL asn.1 parsing code) to
have conditional payments using not yet broadcast txid outputs as inputs to
work with high assurance.  (And even in the event that a new crypto level
malleability is discovered in ECDSA it remains secure.)

Adam

Adam Back wrote:

Adam


-------------------------------------

On 2013-10-21, at 2:44 AM, Arto Bendiken <arto@bendiken.net> wrote:


Bitcoin's BIP process is directly based off of Python's PEP process. 

Quote from BIP 1, History:

This document was derived heavily from Python's PEP-0001. In many places text was simply copied and modified.
-------------------------------------
On Sat, Aug 10, 2013 at 12:14 AM, Mike Hearn <mike@plan99.net> wrote:

There's a Raw Sockets proposal at the W3C that provides TCP sockets:

<http://www.w3.org/2012/sysapps/raw-sockets/>

Firefox OS has an API that is being discussed as part of that:

<https://developer.mozilla.org/en-US/docs/WebAPI/TCP_Socket>

So there's a possibility of a standardized approach in the future.

Chris.
-- 
http://www.bluishcoder.co.nz


-------------------------------------
This was meant to go to everyone:

On 5/20/13 7:45 PM, Jeff Garzik wrote:
That is true, and perhaps we have enough clout to push an RFC specifying 
a double-SHA256 Version 6, or at least get it reserved. I proposed 
Version 4 (random) because any UUID library should allow you to specify 
the 122 supposedly random bits of that version, whereas conceivably 
there might exist UUID libraries that require a SHA1 pre-image to create 
a Version 5 UUID (I know of no examples though). Regardless, making an 
official double-SHA256 UUID version RFC is an option worth considering.
I think there are perhaps two issues being conflated here (and in Mike's 
response): the UI identifying the network/coin to the user, and the 
matching of the protocol-supplied value to the underlying network/coin 
by the client/daemon. The former necessarily involves manual adjustments 
(e.g, localization), but it's preferable for the latter to be a 
self-validating reference to the block chain. This is a trivial 
difference for multi-chain wallets (what are you doing receiving 
requests for coins in chains you don't know about?), but is important 
for colored coins. Let me explain:

I will be proposing soon a colored coin architecture that allows 
issuance of new coins by anyone for a fee, by means of a special 
category of transaction. The hash of that issuing transaction would then 
be used to generate a UUID identifying the asset for the payment 
protocol and other purposes as well, analogous to how the hash of the 
genesis block identifies the host currency, bitcoin. It is expected that 
there will be many such coins issued, as they can be used to represent 
individual loans or lines of credit. In this context, any colored-coin 
aware client could scan the block chain (or lookup a maintained index) 
to discover the UUID -> coin mapping with absolute certainty. However 
the mechanism for mapping the text "mtgoxUSD" to a specific coin is not 
clear, and using some sort of DNS-resolution system adds huge external 
dependencies. IMHO it is much better to have the identifier derived from 
block chain data directly (and therefore accessible and trusted by all 
nodes), and then carry out optional UI mappings like UUID(...) -> 
"mtgoxUSD" at a higher level.

Does that make sense?


-------------------------------------
On Tue, Dec 24, 2013 at 12:52:46AM -0800, Jeremy Spilman wrote:

The logic is that by simply connecting to peers at random you keep the
network structure as a whole randomized. You don't need to make any
specific attempt at connecting to "far-apart" peers.


Keep in mind it's easy for better knowledge of the network to be a
vulnerability; the number of full nodes is small enough that DoS
attacking all of them is quite feasible.

The other big vulnerability is that getaddr data is best effort; we
currently have no mechanism to ensure that nodes are in fact operated by
separate individuals. It'd be quite easy for someone to set up a
relatively small number of nodes that only advertise themselves in the
getaddr information. Over time they would get proportionally more
incoming connections than is "fair"

As for node addresses being a service, that's what the DNS seeds are!
bitcoinj clients, for instance, depend very heavily on those seeds and
can be easily compromised in a variety of ways by them.

-- 
'peter'[:-1]@petertodd.org
000000000000000092a315c01cfc115d7f1b40dc44edbafd504b0d7498b0704a
-------------------------------------
It feels to me like we're close to a 0.9 "feature freeze" / start of
release cycle; I'd like to talk a little bit about what we'd like to see in
the final 0.9 release.

My list:

Bug:  I'd really like to see the leveldb corruption issue (mostly on OSX,
it seems) fixed. This is hard because it can't be reliably reproduced, and,
at least on my machine, takes weeks to occur. Help needed to reproduce/fix,
see https://github.com/bitcoin/bitcoin/issues/2770 for what we know about
the problem.

Payment Protocol support is ready to be pulled (
https://github.com/bitcoin/bitcoin/pull/2539) . Unless there are major
objections, I will pull it tomorrow (it has already gone through two rounds
of bounty-driven QA testing, so I'm convinced it is ready).

I'd love for 0.9 to contain sipa's "headers first" initial block download
optimization; I think it is a big enough improvement to justify making the
0.9 test/release cycle longer.

Coin control (https://github.com/bitcoin/bitcoin/pull/2343).

The autotools work (https://github.com/bitcoin/bitcoin/pull/2805).

Gitian-build with the latest openssl and Qt5. Perhaps update the version of
Debian VMs that we gitian-build with.

I plan on spending about half my time on code review and helping get pull
requests tested, and the other half of my time working on code that
probably won't make it into the 0.9 release.

-- 
--
Gavin Andresen
-------------------------------------
Hi All, 

If any of you are interested, I've put forward a proposal for a P2P Trustless Cryptocoin Exchange. I don't have anyone around to bounce ideas off; my apologies if there's any gaping logical holes.

You can find details here:
https://bitcointalk.org/index.php?topic=198032.0

I'd really appreciate any insight any of you have on the matter. (And look forward to hopefully meeting a few of you at the conference).

Cheers,
Max
-------------------------------------

Don't the seeds already set small times? I'm not sure we want these
responses to be cacheable, otherwise there's a risk of a wall of traffic
suddenly showing up at one set of nodes if a large ISP caches a response.
(yes yes, I know, SPV node should be remembering addr broadcasts and such).
-------------------------------------
One of the things that really gets me going is when someone devises a 
model, tests it against itself, and then pretends that they've learned 
something about the real world.

Naturally, the Selfish Mining paper is exactly this sort of nonsense.  
Their model is one with no latency, and one where the attacker has total 
visibility across the network.  An iterated FSM is not a suitable 
simulation of the bitcoin system.  The bitcoin network does not have 
states, and to the extent that you can pretend that we do, you can't 
simulate transitions between them with static probabilities.

The authors understand this deep down inside, even though they didn't 
work out the implications.  They handwave the issue by assuming a total 
sybil attack, and in true academic spirit, they don't realize that the 
condition necessary for the attack is far, far worse than the attack itself.

Greg said he'd like to run some simulations, and I'm thinking about it 
too.  Unfortunately, he is busy all week, and I'm lazy (and also busy 
for most of tomorrow).

If neither of us get to it first, I'm willing to pitch in 1 BTC as a 
bounty for building a general bitcoin network simulator framework. The 
simulator should be able to account for latency between nodes, and 
ideally within a node.  It needs to be able to simulate an attacker that 
owns varying fractions of the network, and make decisions based only on 
what the attacker actually knows.  It needs to be able to simulate this 
"attack" and should be generic enough to be easily modified for other 
crazy schemes.

(Bounty offer is serious, but expires in one year [based on the earliest 
timestamp that my mail server puts on this email], and /may/ be subject 
to change if the price on any reputable exchange breaks 1000 USD per BTC 
in that period.)

Basically, the lack of a decent network simulator is what allowed this 
paper to get press.  If the author had been able to see the importance 
of the stuff he was ignoring, we wouldn't be wasting so much time 
correcting him (and sadly the reporters that have no way to check his 
claims).

https://bitcointalk.org/index.php?topic=324413.msg3495663#msg3495663




-------------------------------------
Hello, re. the dedicated server for bitcoin.org idea, I have a few thoughts

1) I have commented in a blogpost of August 2013 at
https://odinn.cyberguerrilla.org/ with some thoughts relative to possible
issues with CA related to bitcoin.org - where I mentioned something
relative to the DigiCert certificate,
"DigiCert â€œmay revoke a Certificate, without notice, for the reasons
stated in the CPS, including if DigiCert reasonably believes thatâ€ (â€¦)
â€œApplicant is added to a government list of prohibited persons or entities
or is operating from a prohibited destination under the laws of the United
Statesâ€ (â€¦) â€œthe Private Key associated with a Certificate was disclosed
or Compromisedâ€"
In the same post I mentioned
"Bitcoin.org has no certificate, no encryption â€” a situation which has its
own obvious problems. Bitcoin.org currently sends users to download the
bitcoin-qt client from sourceforge. Sourceforge is encrypted and has a
certificate based on GeoTrust:
https://www.geotrust.com/resources/repository/legal/"

(Currently (Dec. 7, 2013) bitcoin.org shows as 'not verified' and 'not
encrypted' examining it in a cursory fashion w/ Chrome)

Not sure how this would work, but it would be nice to see the content at
bitcoin.org encrypted, of course, but also further decentralized? how many
mirrors are there of bitcoin.org - not sure, but a few things that come to
mind when thinking of this are Tahoe-LAFS and also .bit stuff (namecoin). 
There are many ways to decentralize something but that is just something
that comes to mind.

This has been discussed at https://bitcointalk.org/index.php?topic=16312.0
('Is Bitcoin.org a weakness of bitcoin?) in the past and see also this
https://bitcointalk.org/index.php?topic=119652.0 which discusses mirroring
of certain content

Some things to think about.





-------------------------------------
On Sunday, October 27, 2013 10:52:25 PM Gavin Andresen wrote:

It might make sense to use the rejection reasons from BIP 22 where applicable.

https://en.bitcoin.it/wiki/BIP_0022#Appendix:_Example_Rejection_Reasons

Luke


-------------------------------------
On Tue, Jul 30, 2013 at 8:41 AM, Mike Hearn <mike@plan99.net> wrote:

This has been discussed on IRC, and would be interesting to explore.
For several applications, linking directly with a Tor library is far
superior to the fragility of requiring a properly configured external
process.  Lacking such a Tor library right now, one must be written
<hint hint>

-- 
Jeff Garzik
Senior Software Engineer and open source evangelist
BitPay, Inc.      https://bitpay.com/


-------------------------------------
Personally, I agree, but a different decision has been made by the main
devs.

The issue is this: consider two transactions in the unconfirmed pool. One
transaction has 2BTC input, 1.5BTC to one address (the payment), .4995 to
another address (change) and .0005 standard fee. Another transaction
appears - Same input, 1BTC to one address, .999 to another, and .001 fee.
Which one would a miner include? On pure self interest, the second one,
because it has twice the fee. Anyway, the miner has no real way of knowing
which transaction was real, and which the fraudulent double-spend. The
network does not keep accurate timestamps, so it has no way of really
knowing which is first. A bit of artificial DDOS-type overload on the
recipient's system, and the real transaction could easily appear last.

So the decision has been made to make 0-conf double spends trivial, so no
one will ever trust 0-confs. If a later transaction appears with a larger
fee, it will be considered to be the valid one, and the first one dropped,
as long as the first one has not been confirmed. This makes undoing a
mistaken transaction possible.

So anyone needing 0-conf-like speed will have to make other arangements,
such as contracting with enough mining pool power to never drop their
transactions unless confirmed multiple times. Secure 0-confs is an
impossible target with blockchain cyrpto-currencies as the stand. Any ideas
on how to make them work are welcome, of course - as long as we haven't
heard them too many times before.


On 21 May 2013 10:45, Quinn Harris <btcdev@quinnharris.me> wrote:

-------------------------------------
On Fri, Feb 08, 2013 at 06:01:08AM -0500, Peter Todd wrote:

Because namcoin tries to solve a different problem, DNS, whereas I want
to establish an identity for a payment protocol. Your incoming payments
will land on addresses that are derived (regardless which way) from this
idenity. This makes your identity as important (securitywise) as
anything else involved in the bitcoin protocol. Therefore I would not
want to have payment-ids rely on anything _less_ than bitcoin's own
blockchain. In particular not on PKI with centralized root CAs. But also
not on namecoin or any other (weaker) alt-chains.

You can argue that alt-chains _can_ be as strong as bitcoin, but they
don't _have to_ be. There is no guarantee how many people will
cross-mine. The alt-chain could even disappear at some point. If at some
point your alt-chain is no longer being worked on, then how do you prove
that some old bitcoin transaction went to an address for which there was
a valid id/certificate at the time of sending? If the certificate is
based inside bitcoin's blockchain then you will have a proof for the
correct destinations of all your old transactions as long as bitcoin
exists.

Besides all this, as you mentioned namecoin specifically, that is
overkill if you just want to link two hashes together. A single 2-of-2
multisig output would suffice for that. 


You are probably right that storing this in the _spent outputs_ would be
better. There doesn't seem to be any type of client out there that would
benefit from having to search UTXO only. 

Timo


-------------------------------------
On Tue, Jul 23, 2013 at 12:17 PM, Andreas Schildbach
<andreas@schildbach.de> wrote:

That means they value convenience more than the trust-freeness of a
decentralized solution. The only way to avoid that is by making sure
the decentralized one is convenient enough. But relying on
unauthenticated data itself is equally bad - it means you lose
whatever benefit the decentralization had.


The difference between script-indexed and address-indexed is
absolutely trivial compared to the effort needed to implement and
maintain such authenticated trees by all full nodes. Restricting
things at the network level (which doesn't even know about a thing
like an address) to address-based indexes is ridiculous IMHO.


Sure, once you introduce trust, a lot can be done. But it's not really
Bitcoin anymore in that case - it's relying on a third party to do the
heavy indexing for you. And if that is the best-scaling solution, sure
- but I don't think we should encourage that. Or at least, we should
first search for alternatives. And encourage infrastructure that
doesn't require it.


Yeah, those are inherent problems with how there are used today. But
today there is also little problem - the UTXO set is tiny.


Absolutely, though a slightly bigger one.

-- 
Pieter


-------------------------------------
Yes, 0.7 (yes 0.7!) was not sufficiently tested it had an undocumented and unknown criteria for block rejection, hence the upgrade went wrong.

More space in the block is needed indeed, but the real problem you are describing is actually not missing space in the block, but proper handling of mem-pool transactions. They should be pruned on two criteria:

1. if they gets to old >24hr
2. if the client is running out of space, then the oldest should probably be pruned 

clients are anyway keeping, and re-relaying, their own transactions and hence it would mean only little, and only little for clients. Dropping free / old transaction is a much a better behavior than dying... Even a scheme where the client dropped all or random mempool txes would be a tolerable way of handling things (dropping all is similar to a restart, except for no user intervention).

Following that, increase the soft and hard limit to 1 and eg 10MB, but miners should be the last to upgrade.

/M


On 12/03/2013, at 10:10, Mike Hearn <mike@plan99.net> wrote:




-------------------------------------
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256

On Sun, Jul 14, 2013 at 11:18 AM, Jorge Timn <jtimon@monetize.io> wrote:

Seems that Peter is describing a system that requires no changes at all to the
Bitcoin codebase and thus there are no costs whatsoever.

Peter: I'm a bit confused by this concept of "bi-directional sacrifice" though,
I assume there exists only a sacrifice in one direction right? Wouldn't selling
a zerocoin be just a matter of giving zerocoin a rule so that the zerocoin tx
moving it to the new owner only happens if a specific form of bitcoin tx
happens too?


Merge mining is very much mining a coin for free. Ask not what the total reward
is, ask that the marginal cost of merge mining an additional coin is. The issue
is that unless there is a cost to mining a *invalid* block the merge mined coin
has little protection from miners who mine invalid blocks, either maliciously
or through negligence. If the coin isn't worth much, either because it's market
value is low or the worth is negative to the malicious miner, your theories of
value have nothing to do with the issue.

Gregory Maxwell has written about this issue before on the #bitcoin-dev IRC
channel and on bitcointalk as well if memory serves. I advise you to look up
his description of the problem, almost everything he writes on the topic of
crypto-coin theory is spot-on correct.
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBCAAGBQJR4vpGAAoJEEWCsU4mNhiPwu0IAMrzkVfI0CQuNJRCR+jwhNts
juEerApSSpBes6CjLBJJYZWDdMReSl6izqNDancnJygYc+Q5/IkwBispyZyeIVqY
HbV+jyAFQeVaJBZp8N+ZUDfN9/35SkPb4Y30dkq6V76hBfl+59bWq4qG0dhiO915
SBWAUPLspb5GOyu494GJUr4SPzgs9mAKfNGeQR2anOLj8Qam8Khfa4Zm5T5dX8WQ
vBunUCLykPvWBC3nuTDBU5gQu4TGW9ivGB4p6yLr7MyaPQYZEnYGqgU/yIfAhnBj
MfIfs6njPwhGMwteNmwLoS0VLRBFjWZDflquJ0NK6mNLR3c9yjOFMFPTTZFVinQ=
=b40P
-----END PGP SIGNATURE-----


-------------------------------------
On Thu, Jun 27, 2013 at 11:04 AM, Luke-Jr <luke@dashjr.org> wrote:

Without validation listening isn't currently very useful. :( Maybe it
could be somewhat more with some protocol additions.


-------------------------------------
On Sun, Jul 14, 2013 at 07:22:10PM +0000, John Dillon wrote:

Exactly.

Basically you have one way of creating a Zerocoin: prove you sacrificed
a Bitcoin in a specific way. (spend to unspendable, or spend to mining
fees far into the future)

Now when you sell a Zerocoin what you do is create a Zerocoin
transaction with a txout that can only be spent if you can prove that a
Bitcoin transaction exists with specific conditions with sufficient
confirmations. The specific condition would most likely be it has a
txout of a specific value and scriptPubKey. Basically you'd have a
two-part scriptPubKey:

if <check bitcoin txout existance proof> <check zerocoin buyers signature
is correct> else <check zerocoin sellers signature is correct> <check n
blocks have passed>

Note how if the buyer screws up there is a fallback so the seller can
retrieve their funds after some reasonable amount of time.

Of course if the Bitcoin chain is re-orged Bad Things Happen(TM), but
just set the required number of confirms to something reasonable and
you're good to go. It does mean Zerocoin needs to have consensus on the
Bitcoin blockchain, but that's required to verify sacrifice proofs
anyway.

Economically the idea works because Zerocoins are gradually consumed by
the proof-of-sacrifice required to make Zerocoin transactions. If the
process by which Bitcoins are sacrificed is to fees, rather than
permanently, the overall affect is just a minor decrease in the Bitcoin
money supply. If they are sacrificed permanently, it'll result in
long-term Bitcoin deflation - potentially an issue as the blockreward
decreases.

-- 
'peter'[:-1]@petertodd.org
-------------------------------------

With lots of people having access to 100TH+ there's not really much 
'cost' to doing a 51% attack on an alt-coin beyond a short-term 
diversion away from 'profitable' mining.

At least by supporting merged mining, more miners are likely to 
'support' multiple coin types, thus making a 51% attack from an 
individual/group less straightforward.


Exactly.

Rob


-------------------------------------
I have to say I do not think you want to have it be random as to who gets
paid (by having conflicting double spends floating around with different
payee & change addresses all from the same sending address.)  

About current defacto no replacement: it is the best bitcoin currently has,
and it has value, with it you need to do a net-split to attack eg
1-confirmation, and this proposal weakens it.  Net-splits are possible but
not trivial.  This proposal moves them into spec - ie free.

About privacy: I think you are going to inherently disclose which is the
change address, because you will decrease the change when you increase the
fee.  There is no coin management in the client, and as far as I saw so far,
no privacy management of which coins to reduce coin cross linking.  Who's to
say the client has 100s of times as many coins as the payment.

If people dont want to reveal which is change and which payment, they need
to put a big enough fee up front based on a margin over prevailing fee
statistics.

It would also be better to try to get the fee right first time than to create
more traffic revising it due to experience.  Though the ability to revise
the fee IFF the best effort fee doesnt work empirically after a couple of
blocks seems like a good feature.  (But not with revised recipient/change
addresses.

Also if the bids are too flexibly different how do you stop both bids being
processed (eg one in a block, the next in the next block).

Adam

On Thu, May 09, 2013 at 07:46:05AM -0400, Peter Todd wrote:




-------------------------------------
Thanks! I'd love to see this library become usable behind a command line
flag or config setting. At some point we're going to want to switch to it.

I believe the main issue at the moment is the malleability issues? If so,
it would seem possible to use OpenSSL to parse the signature into
components and then libsecp256k1 to verify them.




On Thu, Oct 10, 2013 at 5:50 AM, Warren Togami Jr. <wtogami@gmail.com>wrote:

-------------------------------------
In many iterations of editing the wordlist we made our best to pick
words which are easy to remember, still "neutral". Unfortunately it's
almost impossible to exclude some words which may together create
negative co-notations.

Thankfully we removed all racist and religious words so I believe all
three authors mentioned in the BIP are safe against fundamentalist
bitcoin users :-).

slush

On 9/10/13, Matthew Mitchell <matthewmitchell@godofgod.co.uk> wrote:


-------------------------------------
On Tue, Jul 9, 2013 at 10:00 AM, Daniel F <nanotube@gmail.com> wrote:

Indeed.  There is no reason to worry about download bandwidth these
days, for open source software downloads.

Move the downloads to a site where such worries do not exist.

-- 
Jeff Garzik
Senior Software Engineer and open source evangelist
BitPay, Inc.      https://bitpay.com/


-------------------------------------
That's true - we could serve new users off our own servers and auto updates
off SF.net mirrors, potentially.


On Tue, Jul 9, 2013 at 4:57 PM, Daniel F <nanotube@gmail.com> wrote:

-------------------------------------
On Fri, 5 Apr 2013 11:48:51 +0200, Mike Hearn wrote:

Unless all the miners are monitoring the work they do for their pools 
and the actual miners that found the blocks noticed (unlikely) - the 
only way anyone knows which pool did anything is the source IP that 
first disseminates the new block. Also since it's unlikely that both of 
the doublespend blocks would be found by the same end miner, neither of 
them would know that the pool operator was responsible even if they were 
monitoring their work.

There's nothing stopping the pool owner from channeling the doublespend 
blocks through some other previously unknown IP, so I don't think they 
would suffer any reputational damage from doing this repeatidly.

Robert


-------------------------------------
Since you mention to use this in conjunction with the payment protocol,
note the following subtlety. Suppose the payer has to paid this address
called "destination": 
Also suppose the payee has spent the output, i.e. the pubkey
corresponding to "destination", which is PubKeyParent * Multiplier[i],
is publicly known. Then anybody can (in retrospect) create arbitrary
many pairs {PublicKeyParent, Multiplier} (in particular different
PublicKeyParent) that lead to the same "destination".

Depending on what you have in mind that the transaction should "prove"
regarding its actual receiver or regarding the receiver's PubKeyParent,
this could be an unwanted feature (or it could be just fine). If it is
unwanted then I suggest replacing
PubKeyParent * Multiplier[i] by 
PubKeyParent * HMAC(Multiplier[i],PubKeyParent)
which eliminates from the destination all ambiguity about PubKeyParent.

This modification would not be directly compatible with BIP32 anymore
(unfortunately), but seems to be better suited for use in conjunction
with a payment protocol. 

Timo

On Mon, Jun 17, 2013 at 11:48:22PM -0400, Alan Reiner wrote:

-- 
Timo Hanke
PGP 1EFF 69BC 6FB7 8744 14DB  631D 1BB5 D6E3 AB96 7DA8


-------------------------------------
Excellent!


On Tue, Sep 10, 2013 at 9:44 AM, slush <slush@centrum.cz> wrote:

-------------------------------------
Hi everyone,

We have pushed out our first test release of Hive, a new OS X wallet focused on usability and discovery:
https://bitcointalk.org/index.php?topic=304060

Hive is powered by a new version of our BitcoinKit.framework, updated recently with bitcoinj support.

Memory of a famous Reid Hoffman quote implores us to reveal that Hive is still missing _many_ basic features. This is not a release that you should give to anyone for serious use. We wanted to get the ball rolling with the community as early as possible, to gather feedback -- and hopefully a little assistance!

Thanks to everyone at Bitcoin Europe 2013 for the feedback and moral support!

-wendell

PS- If you're interested in including an app for your Bitcoin-supporting service in Hive, please be in touch!

grabhive.com | twitter.com/grabhive | gpg: 6C0C9411

-------------------------------------
Many people that I have introduced Bitcoin to have balked at the massive
blockchain download. When I showed them MultiBit (and Bitcoin Wallet) they
breathed a sigh of relief and got on with it.

A currency lives or dies by network effects. If we can provide the average
low-tech user with a great client experience right from the word go then we
can win them over quickly. Once that is accomplished then more techie users
will likely go on to use a full node which will continue to strengthen the
network overall.



On 27 June 2013 22:12, Alex Kravets <kravets@gmail.com> wrote:

-------------------------------------
On Friday, March 15, 2013 5:06:20 PM Benjamin Lindner wrote:

Note that the lock limits were explicitly set in the bitcoind source code.


-------------------------------------
On Fri, Dec 6, 2013 at 3:44 AM, Andreas Petersson <andreas@petersson.at>wrote:


This was considered (see https://github.com/bitcoin/bitcoin/pull/3305) but
deemed to risky for 0.8.6 at the last moment, see the linked pull request
for details.

It will go into 0.9, at least if the full floating fee implementation isn't
yet ready and deemed safe by then.

Wladimir
-------------------------------------
Ah, I missed this, thanks.


On 13 February 2013 15:49, Jorge TimÃ³n <jtimonmv@gmail.com> wrote:

-------------------------------------
Just a small clarification: I was referring to the actual public key,
and not the hash160 of it used for Bitcoin addresses. Its usually not
used, but it is needed for multisig transaction.

On Fri, Jun 21, 2013 at 11:25 PM, Nadav Ivgi <nadav@shesek.info> wrote:


-------------------------------------

I'm hoping that if we start promoting alternative wallets their dev
communities will get larger. Most bitcoinj code is peer reviewed, but
not to the same extent that Bitcoin-Qt is.

We're obviously not going to stop promoting Bitcoin-Qt as well. I
think the distinction should be:

 * Want to get started fast? Grab MultiBit and you'll be under way in
a couple of minutes.
 * Want to help out the Bitcoin network? Leave your computer switched
on all the time and run Bitcoin-Qt instead. It will donate some of
your computers resources to running the Bitcoin system.

The MultiBit interface is OK but all desktop wallets could use some
love from a friendly UI designer.


-------------------------------------
On Tue, Oct 22, 2013 at 12:34 AM, Martin Sustrik <sustrik@250bpm.com> wrote:

Which would say something interesting like "If the bitcoin network
implements inconsistent behavior in the consensus critical parts of
the protocol the world ends. As such, conformance or _non_-conformance
with this specification (in particular, sections 4. 5. and 6.) may be
required for security."

A Bitcoin protocol RFC would be a great place to exercise RFC 6919
keywords.  ( http://tools.ietf.org/html/rfc6919 )


-------------------------------------
On 24 April 2013 09:42, Mike Hearn <mike@plan99.net> wrote:


This is great news for bitcon, and the IANA application will be improved if
there is evidence of it being used



Not 100% sure how accurate this is, tho it may be the world view of some
folks in WHATWG.  WHATWG is not a major standards body tho.  Work on
improving the URL spec is always welcome, as it is the value proposition of
the Web.


-------------------------------------
On Mon, Mar 11, 2013 at 1:36 PM, Michael Gronager <gronager@ceptacle.com> wrote:

I believe you are confusing disjoint things.


-------------------------------------
On Tue, Apr 09, 2013 at 12:42:12PM +0200, Mike Hearn wrote:

NAK

Makes bringing up a new node dependent on other nodes having consistent
uptimes, particularly if you are on a low-bandwidth connection.


NAK

No blacklists

-- 
'peter'[:-1]@petertodd.org
-------------------------------------
On Saturday, March 23, 2013 10:42:26 AM Randy Willis wrote:

UDP is connectionless.
I would hope any UDP bitcoin protocol doesn't try to emulate a connection. :/

Luke


-------------------------------------
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256


I disagree entirely. Your example of "straw polls" for bug fixes and
features is precisely what the current method of rough consensus and
running code, an IETF expression, handles just fine.

What the method does not handle effectively are issues that are
fundementally political rather than technical in nature. Blocksize is
precisely the latter because while the tradeoffs are technical in
nature the fundemental issue at hand is what do we want Bitcoin to be?
Who are we going to allow to participate?
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBCAAGBQJRzWR7AAoJEEWCsU4mNhiPEYsIAME+VvS4vfE0PdOMv3vHWGSH
HwUJdtKPold4+p0jhPBKSMbgnpMvXsZezMIIxj8xehnblnVuUdyakibXAdgVNLvp
a6SCw+W/VnopYCw151zZ4FQS92KQuSbX+XmYTQy32oqZIXtBmTE1fydw5q6YhoXb
gCCygPRyLTIQxLZAxqqRrQ0nsSE5ID5kDcr+xRsmCvfIKrzoOCbYL+nXPCB4Zzgu
Gs7Lfa0yfTrUlQmoDseyoWrVuhfYuFNesTAs3z6imMTdHqZh8Z+a+gmC+G9qFO1h
y7hOmzW4oz7hH4R2F6M+UpV6rKdwMaNYwrDw5eHClDgGYNfjjVduQ/YMQnbjyAc=
=5mhd
-----END PGP SIGNATURE-----


-------------------------------------
On Fri, Oct 25, 2013 at 11:50 AM, Mike Caldwell
<mcaldwell@swipeclock.com> wrote:

Greetings, (repeating from our discussion on IRC)

No prior messages about your proposal have made it to the list, and no
mention of the assignment had been made in the wiki.

The first I ever heard of this scheme was long after you'd written the
document when I attempted to assign the number to something else then
noticed something existed at that name.

Since you had previously created BIP documents without public
discussion (e.g. "BIP 22"
https://en.bitcoin.it/wiki/OP_CHECKSIGEX_DRAFT_BIP [...] Or, I wonder
did your emails just get eaten that time too?), I'd just assumed
something similar had happened here.

I didn't take any action at the time I first noticed it, but after
someone complained about bitcoin-qt "not confirming with BIP38" to me
today it was clear to me that people were confusing this with
something that was "officially" (as much as anything is) supported, so
I moved the document out.  (I've since moved it back, having heard
from you that you thought that it had actually been
assigned/announced).

With respect to moving it forward: Having a wallet which can only a
single address is poor form. Jean-Paul Kogelman has a draft proposal
which is based on your BIP38 work though the encoding scheme is
different, having been revised in response to public discussion.

Perhaps efforts here can be combined?


-------------------------------------
This isn't usable for SPV wallets unless it has a birthday in it. Otherwise
you either need to scan the entire chain (slow) or find a fully indexed
copy of the block chain (expensive, more centralised). Just add a UNIX time
as an extra 4 bytes, or if you want to save a few characters then use a
uint16 that represents "days since birth of this specification".
-------------------------------------
On Tuesday, June 11, 2013 1:11:33 PM Melvin Carvalho wrote:

This is true or false based on CONTEXT.

Obviously, an implementation of transaction handling (eg, wallets) needs to be 
able to translate addresses to and from what they represent.

On the other hand, things like URI handlers do not (and should not) try to 
interpret the address as anything other than an arbitrary word (\w+).


The wiki goes into much detail on how addresses work, which is not the concern 
of most software in the Bitcoin ecosystem, but may be of interest to humans 
and developers working on the one component that operates the "black box" that 
addresses are.


These aren't FALSE, they are "true at the moment, but subject to revision by 
newer standards".


I stated (on IRC) that it was likely Bitcoin would change from the base58 
encoding for addresses ... at some unspecified time in the future, to some 
unspecified new encoding that addressed known limitations of base58. What 
those changes will be, or when, are not all established at this time. The only 
currently-planned change to addresses (very loosely defined) is inclusion of 
the Payment Protocol URIs. But the point is that software developers shouldn't 
assume that addresses will remain base58 forever.

Luke


-------------------------------------
On Tue, Apr 30, 2013 at 10:17:23AM -0700, Jeremy Spilman wrote:

The widespread disclosure we do is a good thing for sure.

Keep in mind that Bitcoin is brand new technology, and brand new fields
tend to get lots of people coming in and trying to patent them. Public
disclosure, and bitcointalk, the email list, and github all count, is a
valuable tool to ward off potential threats in the future if it ever
comes to that.

FWIW it might not be a bad idea to see if archive.org would accept some
of the key documentation like the development section of the forum, the
email list archives, and the irc logs. Some issues, especially on the
forum, with people's ability to edit posts after the fact, but we're
breaking new ground here and the history should be archived.

-- 
'peter'[:-1]@petertodd.org
00000000000000f5a3175efc20cdac41f848d47dc7d00debe821ebfa69f91db9
-------------------------------------
Given that hardly anyone checks the signatures, it's fair to say downloads
aren't protected by anything at the moment. SSL for downloads can only
raise the bar, never lower it, and if the NSA want to kick off the process
of revoking some of the big CA's then I'm game (assuming anyone detects it
of course) :)

Anyway, nobody is dragging feet, the problem is right now we get what is
effectively a huge free subsidy from github and SourceForge for site
hosting. The cost is no SSL. So getting SSL would require that "we" pay for
it ourselves, but the primary method we have for funding public
goods/infrastructure (the Foundation) which is the subject of various
conspiracy theories. Jeremy has made a generous offer further up the
thread, the issue being I guess none of us know how much traffic we
actually get :( I remember suggesting that we whack Google Analytics or
some other statistics package on when the new website design was done and
that was rejected for similar reasons ("organisations are bad").

So we are in a position where we get a subsidy of large but unknown size
from various existing US corporations, but moving to different ones is
controversial, hence no progress :)



On Tue, Dec 31, 2013 at 1:48 PM, Gregory Maxwell <gmaxwell@gmail.com> wrote:

-------------------------------------
My general hope/vague plan for bitcoinj based wallets is to get them all on
to automatic updates with threshold signatures. Combined with regular
audits of the initial downloads for new users, that should give a pretty
safe result that is immune to a developer going rogue.


On Wed, Apr 3, 2013 at 7:12 PM, grarpamp <grarpamp@gmail.com> wrote:

-------------------------------------
On Wed, Mar 13, 2013 at 2:28 PM, Pieter Wuille <pieter.wuille@gmail.com>wrote:



The way I've started thinking about it is that there is a market for
securing a payment network.  In that market you have consumers (users of
bitcoin) and providers (miners).  It's not clear to me that if the
overwhelming majority of miners stayed on 0.8 that the 0.7 fork wouldn't
have still won out in the long run because effectively what you would have
had is a situation where the providers abandon a large portion of their
customers (0.7 users) and start providing a service that is in much less
demand.  Would everyone have upgraded to 0.8?  Maybe, but maybe not.  Maybe
many people would have made the rational decision to stay on earlier
versions and the small minority of miners that choose to service the 0.7
fork could have earned more Bitcoin on that fork...and maybe in the long
run, the majority of miners on 0.8 would realize this situation and start
to trickle back over to the 0.7 fork.  The flip side of the equation is
that the users have a pretty compelling reasons to use the services of the
most secure network (less risk of double spends).  So, the users very well
could have made the rational decision to consume the services of the most
powerful network and made the switch to 0.8.

What happened in reality is that the majority of the mining community made
the rational decision to service the largest pool of customers (0.8 as well
as 0.7 and earlier users).  It was rational because the risk of servicing
only the 0.8 users would have been much greater.

Because of this dynamic, I doubt there would ever be multiple forks of any
consequence in permanent coexistence.  I would even go so far as to say
that at this point, a successful competitor to Bitcoin would have to arise
as a fork of the UTXOs in the block chain (even if the competitor didn't
even use a block chain).  That competitor might even have to begin life in
lock step co-existence with Bitcoin, recognizing all Bitcoin transactions
for some period of time while it attempts to gain market share.
-------------------------------------
Hello everyone,

've just seen many reports of 0.7 nodes getting stuck around block 225430,
due to running out of lock entries in the BDB database. 0.8 nodes do not
seem to have a problem.

In any case, if you do not have this block:

  2013-03-12 00:00:10 SetBestChain: new
best=000000000000015aab28064a4c521d6a5325ff6e251e8ca2edfdfe6cb5bf832c
 height=225439  work=853779625563004076992  tx=14269257  date=2013-03-11
23:49:08

you're likely stuck. Check debug.log and db.log (look for 'Lock table is
out of available lock entries').

If this is a widespread problem, it is an emergency. We risk having
(several) forked chains with smaller blocks, which are accepted by 0.7
nodes. Can people contact pool operators to see which fork they are on?
Blockexplorer and blockchain.info seem to be stuck as well.

Immediate solution is upgrading to 0.8, or manually setting the number of
lock objects higher in your database. I'll follow up with more concrete
instructions.

If you're unsure, please stop processing transactions.

-- 
Pieter
-------------------------------------

OK - I think I follow now.  So a third-party who does not see any of the 
communication between the payer and payee only knows the HASH160.  Let's say 
the payee denies receipt of the funds....

It's easy to prove what public key it was sent to (it's the preimage), but 
you can't prove the parent of that public key. You can provide any number of 
ParentPubKey * Multiplier that could have been used, so the 3rd party is 
unconvinced by a "matching" ParentPubKey * Multiplier.

However, if you calculated the destination using: PubKeyParent * 
HMAC(Multiplier,PubKeyParent) as Timo said, now if you give the 3rd party a 
PubKeyParent and Multiplier (or Addend) that produces the destination 
address, you've proven the payment is in fact spendable by PubKeyParent, and 
they can't deny receipt. Very cool.

Sorry for "echoing" this back, it took me a little while to work it out, so 
I thought I'd write it down. Hope I got it right...

If you give {PubKey, ChainCode} you do get this feature. If you give 
{ParentPubKey, Addend} or {ParentPubKey, Addend, ChainCode} you're back to 
having plausible deniability.

If BIP32's CKD'((Kpar, cpar), i) was actually HMAC(HMAC(cpar, i), Kpar) you 
could give HMAC(cpar, i) instead of Addend, and then you would get this 
feature; a way to 'skip down' a level in the wallet hierarchy, keep the 
'chain of custody' so to speak back to the ParentPubKey intact, without 
having to disclose the ChainCode. Meh...

Thanks,
--Jeremy





-------------------------------------
On Friday 04 October 2013 13:32:47 you wrote:

Then your request should be for better commits, not for just squashing the lot 
into some incoherent blob.

The alternatives under discussion are:

 - Coder produces long chain of commits on feature branch.  Compresses them, 
throwing away any individual and accurate messages into one large diff.  It's 
unlikely you'll get a log message that is as descriptive in the large one if 
you made them throw away the little ones.  Large diff is offered for review.  
Review is of one large diff.

 - Coder produces long chain on commits on feature branch.  Offers them for 
review.  Reviewer only likes to review large diffs, so uses the tools 
available to produce it.

Exactly the same diff is being reviewed, but in one case you're throwing away 
information.  There is no getting that information back ever.

You're also discarding the advantages of individual commits.

 - Merges are considerably harder than rebases.  You have to resolve all the 
conflicts at once with a merge, with a rebase you can resolve them with the 
log message and original isolated diff to help you.

 - Bisect doesn't give as fine-grained an answer.


Excellent.  Don't take it personally -- I only offered it in case you didn't 
know.  Not everyone is familiar with git plumbing.


That doesn't make you the only person who does code reviews.  I do plenty of 
reviews here; they're just not bitcoin reviews.  Obviously we're talking about 
bitcoin, so you get to decide in the end.


I'm not suggesting you review lots of small commits anyway.  I can't comment 
on whether github sucks or not -- that's obviously personal preference.  
However, nothing stops you doing reviews on your own local checkout.


That's not true.  There are often lots of small changes that are manifestly 
correct -- let's use string changes as an example -- in the large commit, they 
are just noise.  You want to be able to focus on the hard commits.  However -- 
I am not trying to persuade you to review small commits, I'm trying to 
persuade you not to throw away the small commits, gone forever, merely because 
your preference is to review large commits.


Since the large commit is always available, no facilities have been lost.

Personally I work hard in my repositories to make coherent, small, well 
described commits.  If I had gone to that effort for a bitcoin branch only to 
be told to collapse them all and throw away that effort, I'd think I'd been 
wasting my time.



Andy

-- 
Dr Andy Parkins
andyparkins@gmail.com


-------------------------------------
Peter,

What is the propagation time within a pool?  If my pool is made up of a ton
of fancy ASICs connected by 300 baud modems, how does that affect your
analysis (ie, Q for a mining pool is effectively a function of time as
well)?  

Brian
 P.S. I hope these are not ignorant questions; if they are, please feel free
to disregard!


Message: 1
Date: Thu, 7 Nov 2013 15:31:23 -0500
From: Peter Todd <pete@petertodd.org>
Subject: Re: [Bitcoin-development] On the optimal block size and why
	transaction fees are 8 times too low (or transactions 8 times too
big)
To: Michael Gronager <gronager@ceptacle.com>
Cc: Bitcoin Dev <bitcoin-development@lists.sourceforge.net>
Message-ID: <20131107203123.GB3805@petertodd.org>
Content-Type: text/plain; charset="us-ascii"

infinity.

Your definition of P_fork is inaccurate for a miner with non-negligable
hashing power - a miner will never fork themselves. Taking that into account
we have three outcomes:

1) The block propagates without any other miner finding a block.
2) During propagation another miner finds a block. (tie)
2.1) You win the tie by finding another block.
2.2) You lose the tie because someone else finds a block.

We will define t_prop as the time it takes for a block to propagate from you
to 100% of the hashing power, and as a simplifying assumption we will assume
that until t_prop has elapsed, 0% of the hashing power has the block, and
immedately after, 100% has the block. We will also define t_int, the average
interval between blocks. (600 seconds for Bitcoin) Finally, we will define Q
as the probability that you will find the next block.

The probabilities of the various outcomes:

1) 1 - (t_prop/t_int * (1-Q))
2) t_prop/t_int * (1-Q)
2.1) Q
2.2) 1-Q

Note that to simplify the equations we have not taking into account
propagation in our calculations for outcomes 2.1 or 2.2

Thus we can define P_fork taking into account Q:

P_fork(Q) = (t_prop/t_int * (1-Q))(1-Q) = t_pop/t_int * (1-Q)^2

Over the range 0 < Q < 0.5 the probability of a fork decreases approximately
linearly as your hashing power increases:

d/dq P_fork(Q) = 2(Q-1)

Q=0   -> d/dq P_fork(Q) = -2
Q=1/2 -> d/dq P_fork(Q) = -1

With our new, more accurate, P_fork(Q) function lets re-calculate the
break-even fee/KB using your original approach:

t_prop = t_0 + \alpha*S
E_fee = f*S

E(Q) = Q*(1 - P_fork(Q))*(E_bounty + E_fee)
E(Q) = Q*[1 - (t_0 + k*S)/t_int * (1-Q)^2]*(E_B + f*S)

d/dS E(Q) = Q*[ -2fSk/t_int*(1-Q)^2 - f*t_0/t_int*(1-Q)^2 + f -
E_b*k/t_int*(1-Q)^2 ]

Again, we want to choose the fee so that the more transactions we include
the more we earn, dE/dS > 0 We find the minimum fee to include a transaction
at all by setting S=0, thus we get:

d/dS E(Q, S=0) = Q*[ f - f*t_0/t_int*(1-Q)^2 - E_b*k/t_int*(1-Q)^2 ] > 0

f(1 - t_0/t_int*(1-Q)^2) > E_b*k/t_int*(1-Q)^2

f > [E_b*k/t_int(1-Q)^2] / [1 - t_0/t_int*(1-Q)^2]

f > [E_b*k*(1-Q)^2] / [t_int - t_0*(1-Q)^2]

With Q=0:

f > E_b*k / (t_int - t_0) ~ E_b*k/t_int

This is the same result you derived. However lets look at Q != 0:

df/dQ = 2*E_b*k * [t_int*(q-1)] / [t_int - t_0(q-1)^2]^2

With negligible latency we get:

df/dQ, t_0=0 = 2*E_b*k*(q-1)/t_int

So what does that mean? Well in the region 0 < q < 1/2, df/dQ is always
negative. In other words, as you get more hashing power, the fee/KB you can
charge and still break even decreases linearly because you will never orphan
yourself. Lets trythe same assumptions as your first analysis, based on the
work by Decker et al

Based on the work by Decker et al, lets try to calculate break-even fee/KB
for negligible, 10%, 25% and 40% hashing power:

t_0 = 10s
t_int = 600s
k = 80ms/kB
E_b = 25BTC

Q=0    -> f = 0.0033 BTC/kB
Q=0.1  -> f = 0.0027 BTC/kB
Q=0.25 -> f = 0.0018 BTC/kB
Q=0.40 -> f = 0.0012 BTC/kB

Let's assume every miner is directly peered with every other miner, each of
those connections is 1MB/s, and somehow there's no latency at all:

k = 1mS/kB

Q=0    -> f = 0.000042 BTC/kB
Q=0.1  -> f = 0.000034 BTC/kB
Q=0.25 -> f = 0.000023 BTC/kB
Q=0.40 -> f = 0.000015 BTC/kB

Regardless of how you play around with the parameters, being a larger miner
has a significant advantage because you can charge lower fees for your
transactions and therefor earn more money. But it gets even more ugly when
you take into account that maybe a guy with 0.1% hashing power can't afford
the high bandwidth, low-latency, internet connection that the larger pool
has:

k = 10mS/kB, t_0=5s, Q=0.01 -> 0.000411 BTC/KB k =  1mS/kB, t_0=1s, Q=0.15
-> 0.000030 BTC/KB

So the 1% pool has an internet connection capable of 100kB/s to each peer,
taking 5s to reach all the hashing power. The 15% pool can do 1MB/s to each
peer, taking 1s to reach all the hashing power. This small different means
that the 1% pool needs to charge 13.7x more per KB for their transactions to
break even! It's a disaster for decentralization.
Businesses live and die on percentage points, let alone orders of magnitude
differences in cost, and I haven't even taken into account second-order
effects like the perverse incentives to publish your blocks to only a
minority of hashing power.(1)

This problem is inherent to the fundemental design of Bitcoin:
regardless of what the blocksize is, or how fast the network is, the current
Bitcoin consensus protocol rewards larger mining pools with lower costs per
KB to include transactions. It's a fundemental issue. An unlimited blocksize
will make the problem even worse by increasing fixed costs, but keeping the
blocksize at 1MB forever doesn't solve the underlying problem either as the
inflation subsidy becomes less important and fees more important.

1)
http://www.mail-archive.com/bitcoin-development@lists.sourceforge.net/msg032
00.html

--
'peter'[:-1]@petertodd.org
00000000000000054eeccf3ac454892457bf4919d78efb275efd2ddd1a920c99
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 490 bytes
Desc: Digital signature

------------------------------

-------------------------------------
On Sun, Mar 3, 2013 at 10:54 AM, Roy Badami <roy@gnomon.org.uk> wrote:

While I think that it's silly that we don't have a HTTPS (only!) page,
it should be noted that an HTTPS page is in no way a replacement for
GPG, sadly:  Anyone who can MITM the server to the whole internet can
trivially obtain a fraudulent cert with only moderate cost and time.

(The reason for this is that (many? most? all?) CAs verify authority
by having you place a file at some HTTP path on the domain in
question. Effectively the current CA model only prevents those from
intercepting who cannot intercept the traffic generally. Basically
only helps with the evil hotspot/tor_exit problem.)


-------------------------------------
TPMs have come as standard with nearly all computers (except Macs, doh) for
a long time. They certainly don't cost $100. More like a few dollars at
most. That's why they're so slow.


On Tue, Jul 30, 2013 at 10:43 PM, grarpamp <grarpamp@gmail.com> wrote:

-------------------------------------
Yes it is trivial. I do not think greater complexity in the system should keep us from addressing low complexity issues.
You can't blame me or others not trying to simplify scripts, if there is such a headwind simplifying a version message.
You are right there is too much fuss about this.

Tams Blummer
Founder, CEO
http://bitsofproof.com

On 20.06.2013, at 10:31, Mike Hearn <mike@plan99.net> wrote:


-------------------------------------

Yeah. Or just scam you at all. It's hard to imagine an organisation as
a big as a mobile carrier engaging in financial scamming (roaming fees
excepted).

I've said this before, but I think it's worth repeating. The
double-spend protection the block chain gives you has a sweet spot
where it's really, really valuable (essential even) and then there are
lots of kinds of transactions on either side of that sweet spot that
don't really benefit from it.

Obvious/trivial case where you don't need a block chain - Facebook
buys Instagram for a gajillion coins. The legal system is plenty good
enough to ensure the payments are honoured. Another example, when my
employer pays me my salary. They aren't going to double spend this
except through some horrible accident that we can get sorted out some
other way.

Another case, very small payments. This is Satoshi's bag of crisps
example. If the cost/complexity of double spending is higher than what
the payment is worth, again, you don't really need the block chain.
That's why it's worth optimising unconfirmed transactions to be harder
to double spend, it optimises (pushes up) that lower bar.

Place where you really want the chain - largeish sums of money are
moving around, but not large enough to justify expensive
cross-jurisdictional legal action, or where the cost of identity
verification and all the associated paperwork is just too high. I
guess most online transactions fall into this bucket today.


-------------------------------------
That sounds workable. I take it that the P2SH address is not stored? I like
it that this denies the possibility of storing data in the block chain, but
does not block interesting uses like creating date stamps - You can still
store the 'fake P2SH' value whose checksum is secured by the blockchain.


On 10 April 2013 12:53, Gregory Maxwell <gmaxwell@gmail.com> wrote:

-------------------------------------
On Mon, Nov 04, 2013 at 12:26:30PM +0100, Mike Hearn wrote:

Actually on further reflection this idea will make the attack described
in the paper easier to carry out, rather than harder.

I think where you're misunderstanding originates is the description of
this attack as requiring a sybil attack on the network - you see this
underlying sybil as one of numerical advantage, when it's actually one
of *informational* advantage.

Remember that the selfish miner strategy outlined in the paper is
essentially a way to use knowledge of what blocks miners will be mining
on, from the "first seen" rule, and the ability to broadcast blocks you
have mined more widely than other miners. That knowledge and ability is
then used in conjunction with a small lead (obtainable by chance) to
outpace the rest of the network.

By making all miners easily identifiable you make gaining that
informational and broadcast capability easier to obtain rather than
harder. The attacker now only needs to connect to every identified miner
with especially fast nodes. With judicious use of DoS attacks and low
latency they can still gain the informational and broadcast "upper hand"
over other miners and carry out the attack.

Where the paper goes wrong is they don't recognize the fundemental
nature of the strategy being based on an informational advantage. Their
"pick a random side of the fork" strategy may work to some extent, but
it's incomplete and isn't necessarily rational for the miners
individually.

The correct, and rational, approach for a miner is to always mine to
extend the block that the majority of hashing power is trying to extend.
The current relay rules don't give you that information at all, but they
can if we do two things:

1) Relay all blocks that meet the PoW target. (as suggested in the
   paper)

2) Relay block headers that nearly meet the PoW target.

Mining strategy is now to mine to extend the first block you see, on the
assumption that the earlier one probably propagated to a large portion
of the total hashing power. But as you receive "near-blocks" that are
under the PoW target, use them to estimate the hashing power on each
fork, and if it looks like you are not on the majority side, switch.

This very effectively defeats the paper's selfish-miner strategy, as all
miners will very quickly be mining on the block that truly has the
majority of hashing power trying to extend it. This is also a better
overall outcome, because it puts the 51% attack threshhold back at 51%

-- 
'peter'[:-1]@petertodd.org
0000000000000004ee9bb13b022c412d75692b5e85454013c53f89e5d6fa8c69
-------------------------------------
On Mon, Aug 19, 2013 at 08:22:10AM +1000, Gavin Andresen wrote:


Mike's and others have been talking about persistent node-specific
identifiers, and after all at this level there are IP addresses;
fingerprinting nodes is trivial.


We need options so peopl can contribute to relaying and the health of
the network - these edge cases are going to be tested anyway by people
like me deciding to disable bloom filtering.

-- 
'peter'[:-1]@petertodd.org
-------------------------------------
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1



My Q and q are meant differently, I agree to your Q vs Q-1 argument,
but the q is "me as a miner" participating in "a pool" Q. If I
participate in a pool I pay the pool owner a fraction, e, but at the
same time I become part of an economy of scale (well actually a math
of scale...) and that can end up paying for the lost e. The question
is what is the ratio q/Q where I should rather mine on my own ? This
question is interesting as it will make bigger miners break away from
pools into solo mining, but I also agree that from pure math the most
advantageous scenario is the 100% mining rig.


Ha, yes, and then the math for p2pool starts... a math where we have
much more stales...


-----BEGIN PGP SIGNATURE-----
Version: GnuPG/MacGPG2 v2.0.22 (Darwin)
Comment: GPGTools - http://gpgtools.org
Comment: Using GnuPG with Thunderbird - http://www.enigmail.net/

iQEcBAEBAgAGBQJShgxWAAoJEKpww0VFxdGRoiwH/3RGTH503PJ8UWuyKjrxscb4
dG3TyThZCDs12DvtC+2TPKnIkQFinGx9442tZU/O+qmwsGJsNVoEcnGmKEYz/vlI
XzFF30ugslB4FKwHZYRqXELaKR4RvUtSzu6td8P3n+e6d0MZsuemMornpbXZkw3n
CbMlYuiG4h3iUAwTaOTS26cFbZoo6eyogydDjnS7Ogi2Ur85Rydi/Lj24rj7UxYB
+WUkYAv3bCqCzTkv1LxO7HwY1SICZDmoGRbuil5M7bJ+MftYt6Q6DVprGSVP0mOV
9eEVeMVY/WmMZCI/01ruXpzC3gxU60vOd/a3q9G2hd9Tn00HzugAllEXh7ZzzUs=
=unP8
-----END PGP SIGNATURE-----


-------------------------------------
I can't see this working, if 51% of the mining power doesn't like your
coins, when you create the commitment they will reject it.
If the commitment is opaque at the time of inclusion in the block then
I will create multiple commitments and then after revealing the
commitment and spend to you I will reveal the earlier commitment which
commits the coins to an address I control.

On the topic of reversibility, I suspect in the long term the lack of
chargebacks will create issues as criminals learn that for the first
time in history, kidnap & ransom is effective. Suffice to say after the
first >= $10mn kidnapping-for-bitcoin heist, governments will be forced
to decide how they view the system. It will likely fall somewhere between
"arrest/question anyone identified holding tainted coins" to something
nonsensical and reactionary like "blocking" bitcoin as Iran does TOR.

Thanks,
Caleb



On 05/15/2013 07:49 AM, Adam Back wrote:



-------------------------------------
On Fri, Nov 15, 2013 at 12:58:14PM +0100, Michael Gronager wrote:

The underlying issue is what is the pools expenses compared to yours.
There is an overhead to mining, you need to spend money and time (and
hence money) running and administering full nodes at the very minimum.
The pool can amortise that cost over many hashers; the solo miner can't.

Pools will of course have some profit margin, but why would you expect
that margin to not be sufficiently low to make it in a solo-miner's
interest to join the pool? Both the pool and the former solo-miner earn
more return after all if they centralize.

The fundemental issue is that in the design of Bitcoin there is an
incentive for miners to join into pools, and that incentive exists at
any amount of hashing power. Sure second order effects like regulation
and social pressure can counteract that incentive in some circumstances,
but that's not very strong protection.


However p2pool doesn't necessarily need a linear blockchain to function,
so there is a potential for stales to be much less relevant.

-- 
'peter'[:-1]@petertodd.org
000000000000000772f720b0a231150f22af20760c1463ef920f71ba3daab819
-------------------------------------
But... Multibit is Java. Java's security problems has made it an instant
uninstall item on windows PCs for about a year now. Java exploits are a
dime a dozen.

Yes, you can reduce some of the problems by manually disabling the browser
plugin, but how many users will do that?

Recommending a fast SPV client as a first wallet - yes, of course.
Recommending users open such a huge attack interface on their computers by
installing Java - No go. Until Multibit is provided as a compiled binary
without a Java dependency, it is DOA.


On 1 July 2013 02:39, Gary Rowe <g.rowe@froot.co.uk> wrote:

-------------------------------------
My gpg key is on the bitcoin.org homepage: http://bitcoin.org/gavinandresen.asc
.... which you can access securely (and see the history of) at:
  https://github.com/bitcoin/bitcoin.org/blob/master/gavinandresen.asc

If you're really super-duper paranoid, you could also fetch it from
the MIT pgp keyserver or look for it in the bitcointalk forums
archives.

Import it into pgp/gpg, then you can verify that the download
checksums you have are correct with:

gpg --verify SHA256SUMS.asc

All that assuming you're running Linux.  If you're Windows or OSX, the
latest downloads are code-signed and checked for integrity
automatically by Windows/OSX.

-- 
--
Gavin Andresen-----BEGIN PGP PUBLIC KEY BLOCK-----
Version: GnuPG v1.4.9 (Darwin)
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=7mXQ
-----END PGP PUBLIC KEY BLOCK-----
-------------------------------------
Once the ASIC race calms down because everyone has one, has more or less
optimal power supplies, process improvements aren't easily reachable
anymore etc then I'd expect people to dissipate from the large pools
because eliminating their fees will become the next lowest hanging fruit to
squeeze out extra profit. There's no particular reason we need only a
handful of pools that control a major fraction of the hashpower.

If we end up with a few hundred pools or lots of miners on p2pool, then a
lot of these theoretical attacks become not very relevant (I don't think ID
sacrifices will be so common or large as to justify a pile of custom mining
code+strategies at any point ...)


On Thu, Nov 7, 2013 at 2:24 PM, Peter Todd <pete@petertodd.org> wrote:

-------------------------------------
On Mon, Mar 11, 2013 at 1:34 PM, Rune KjÃ¦r Svendsen <runesvend@gmail.com> wrote:

It should be a new value.


-------------------------------------
On Tue, May 21, 2013 at 3:24 AM, Robert Backhaus <robbak@robbak.com> wrote:

This has been suggested, but I know of no such decision having been made.

-- 
Pieter


-------------------------------------
That is a great presentation, thanks for sharing that!

Though I question the validity of the claim that ECC is so much more
secure than RSA (with appropriate keysizes).  My experience from
studying quantum computing is that Factoring and DLP are intimately
related, such that a break of one is likely to break the other.  In
fact, I seem to remember that QCs use an efficient DLP-solving circuit
to "shortcut" the factoring problem.  But it's been a long time since I
looked at it, so I don't remember for sure.   Also, it's not clear
whether that relationship exists outside the scope of QCs.

It's still a good presentation, but they're pushing ECC pretty hard as
the answer to the cryptopocalypse, and I'm not convinced that's a real
answer.

-Alan



On 08/04/2013 01:13 PM, Melvin Carvalho wrote:

-------------------------------------
amending the BIP? Do we need to create a new one and mark the old one as
replaced, or can we just fix it in place given the relatively exotic nature
of most of the issues?

Those all sound like bugs in the BIP; I think they should just be fixed, I
don't think we need a new BIP.

I vote for a new meta-data item in the BIP header:

  Corrected: <date>

-- 
--
Gavin Andresen
-------------------------------------
Maybe bitcointalk.org would like to donate a few BTC from the 6,000 BTC "new forum" fund to sponsor hosting?

On Dec 8, 2013, at 5:51 PM, theymos <theymos@mm.st> wrote:


-------------------------------------
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

I would like to download the entire blockchain by hand (kind of), but
I can't find software for it. The closest thing I found is
"Bitcoin-protocol-test-harness" code, but it is two years old and
seems not to work with current bitcoin network.

Python apreciated.

Thanks for your help.

- -- 
Jess Cea Avin                         _/_/      _/_/_/        _/_/_/
jcea@jcea.es - http://www.jcea.es/     _/_/    _/_/  _/_/    _/_/  _/_/
Twitter: @jcea                        _/_/    _/_/          _/_/_/_/_/
jabber / xmpp:jcea@jabber.org  _/_/  _/_/    _/_/          _/_/  _/_/
"Things are not so easy"      _/_/  _/_/    _/_/  _/_/    _/_/  _/_/
"My name is Dump, Core Dump"   _/_/_/        _/_/_/      _/_/  _/_/
"El amor es poner tu felicidad en la felicidad de otro" - Leibniz
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.10 (GNU/Linux)
Comment: Using GnuPG with Thunderbird - http://www.enigmail.net/

iQCVAwUBUX35M5lgi5GaxT1NAQJGwQP+PtSg/cbqE87u/4axyUsOBDc/MsRB7DYx
DfeEHqOqh8uAQ/uZMzxWrCPbp53TJK888AByH3NknkiGy0HNoshHOSmy5JACFt54
fsyWDadiWBR9bu6JV4R1imR0FMzbjGuRZkc26MAsleVbho5KZBdHR1/cPQ0D174h
wu4k1yzywYg=
=Nprg
-----END PGP SIGNATURE-----


-------------------------------------

Yes.

I don't want to spend any time thinking about memory pool transaction
replacement until after we pay some technical debt:

+ Memory-limited memory pool, with relay policy matching block-creation
policy
+ Child-pays-for-parent fees
+ Auto-computed fees, based on transactions moving from the memory pool
into blocks


-- 
--
Gavin Andresen
-------------------------------------
To those of you in the know about modern browser tech:

Does it seem at all conceivable that an SPV wallet could be built entirely in JavaScript? And if indeed it is within the realm of the possible, how would such a thing be safely distributed for use? Would a signed Chrome Plugin be an ideal vehicle?

-wendell

grabhive.com | twitter.com/grabhive | gpg: 6C0C9411

-------------------------------------
Hey Taylor,

It's great to see people thinking about payment protocol extensions. I'm
not totally convinced vCard support is the best idea relative to social
network integration - I can't recall the last time I saw someone use a
vCard. However, that should not hold you back from experimenting or
prototyping. All an extension requires is some tag numbers and we're not in
danger of running out of numbers any time soon.

The reason I favour social network integration is because those are the
ID's people already have. Distributed social networks (like the PGP web of
trust) have never really taken off, and fixing that is an entirely separate
project to Bitcoin.

Doing so is quite easy. Major social networks all have a concept of a user
ID, moreover, one that can be queried without any kind of API authorization
for basic info. Examples:

https://graph.facebook.com/i.am.the.real.mike
https://plus.google.com/s2/u/0/photos/profile/114798402540078632611

So you could simply embed a social network URL into a payment request, and
use that to associate a name/photo with a payment. That would be
unauthenticated (the sender is not proving they are the real owner of the
social network profile). However, authentication may not turn out to be
necessary. If it were to be, then steganographically embedding a key into
the profile picture and signing the payment request with it would be a way
to do so.


On Sat, Nov 9, 2013 at 6:43 PM, Taylor Gerring <taylor.gerring@gmail.com>wrote:

-------------------------------------
Adam,

Take a look at this privacy enhancing solution based on fair exchange 
implemented by bitcoin contracts and cut-and-choose. It would require a 
public pool of users willing to exchange in common denominations at 
moments in time together to ensure unlinkability. It also leave a trace 
of exchange activity in the chain. This could all be added to wallet 
software to become automatic.

http://robotics.stanford.edu/~xb/fc12/index.html

Simon


On 05/14/2013 07:09 AM, Adam Back wrote:


-------------------------------------
 Im not sure I followed Johns proposal fully, why would a user sign TX1
committing funds to the MULTISIG they may never get back? I also dont see
the problem with getting a signed TX2 back from the AP before releasing
TX1... see the sequence below. But more importantly, we only need exactly
one replacement, so for starters we could anti-DoS by allowing only
nSequence of 0 or MAX.

 If this was enabled on test-net, I would be including a link to
transactions that implement the following proposal. At the moment, the best
I can do is unit test and generate the rawtransaction output at each step 
you can find source code and test output here:
https://gist.github.com/jspilman/5424310

 The initial funding transaction and time-locked refund is pretty annoying
to setup, if you want to support the general case of coins from arbitrarily
sized inputs. You will have:
 - 1 or more inputs from the user, 0 or 1 change outputs
 - 0 or more inputs from the AP, 0 or 1 change outputs
 - 1 output to 2 PK1 PK2 2 CHECKMULTISIG

 This precludes using SIGHASH_SINGLE except for the special cases where
inputs are perfectly sized (i.e. they are created in a prior step).

 0. User and AP negotiate how much to escrow, who pays the fees, and how
far in the future nLockTime will be set (how long users funds will be tied
if AP doesnt close the channel)

 1. User creates an unsigned TX1 with 1 or more inputs from users
listunspent, change going back to user (if any), and a single output of
FundAmount with scriptPubKey of 2 PK1 OP_0 CHECKMULTISIG, and sends to
the AP

 2. AP adds to TX1; their inputs (if any), their change (if any), replaces
OP_0 in the scriptPubKey with a PK they control, and signs SIGHASH_ALL, and
returns TX1 to User.

 3. User verifies TX1 is as agreed, and signs it SIGHASH_ALL, but keeps it
to himself. User, having completed TX1, knows its TxID and can now create
TX2-Locked spending TX1 back to themselves. User sets nLockTime to the
agreed point, signs SIGHASH_ALL, and sends TX2-Locked to AP.

 4. AP verifies TX2-Locked and adds their signature, and returns TX2-Locked
to User. User can now broadcast TX1 and TX2-Locked.

 5. At each payment milestone, user creates TX2-Final; TX1 as input, final
nSequence, no lock time, with a single output going back to to the user,
and an amount equal to the remaining balance of the channel. User signs
with SIGHASH_SINGLE and sends to the AP.

 6. AP can add an output to TX2-Final sending their portion of the coins
where ever they want, sign it SIGHASH_ALL, and broadcast it at any point,
closing the channel. AP must broadcast TX2-Final before nLockTime, but has
no guarantee the user hasnt offered a bribe for miners by spending
TX2-Locked with a large fee, e.g. a pissed off user spends TX2-Locked
entirely to fees just to see if they can convince miners to wait for it.

 The alternative to the TX2-Locked is a 3rd party in the MULTISIG who is
trusted to close the channel at the request of either party, based on the
latest TX2-Final which was sent by the user. In this case there is no
TX2-Locked, only a single boardcast version of TX2-Final, and you do not
need transaction replacement at all.

 Thanks,
--Jeremy
-------------------------------------
On Thu, Jul 18, 2013 at 07:13:53AM -0400, Peter Todd wrote:

jl2012 pointed out we already have an OP_DEPTH instruction that returns
the number of items on the stack. In the future we should use the terms
OP_BLOCKHEIGHT, OP_TXOUTHEIGHT, OP_TXOUTDEPTH to talk about hypothetical
instructions that put the block height, confirmed txout height, and
confirmed txout depth on the stack. Thus the above example would now be:

     <height + n> BLOCKDEPTH LESSTHAN
     IF 2 <pk-payor> <pk-payee> CHECKMULTISIG
     ELSE <pk-payor> CHECKSIG
     ENDIF

-- 
'peter'[:-1]@petertodd.org
0000000000000013030f49fe3eed5e7f9388c4ecc237b7a847ca93255836bc3b
-------------------------------------
On Wed, Mar 13, 2013 at 2:22 PM, Roy Badami <roy@gnomon.org.uk> wrote:

It does warnâ€” if its heard the fork and its on the lower difficulty
side. Extending that to also alert if its on the winning side and the
fork is long enough might be wise, though I have a little concern that
it'll be mistaken to be more dependable than it would be.


-------------------------------------
Hi Mike,

I had a similar request on the forums. I suggested adding either a 2 byte 'weeks since genesis' or 'months since genesis', but starting from spec birth works too. Would either of those work for you?


jp

On Jul 22, 2013, at 6:14 AM, Mike Hearn <mike@plan99.net> wrote:



-------------------------------------
On Tue, Jul 23, 2013 at 1:01 PM, Mike Hearn <mike@plan99.net> wrote:

Ah, this is not entirely in sync with the last (mostly minor)
copyedits that had been signed off by Gavin, Pieter, Jgarzik, and I...
but that appears to be a smaller issue than the fact that the whole
thing is now being rewritten by "anonymous beaver" and friends.


-------------------------------------
Hi Jim,

On Thu, Jun 27, 2013 at 12:18 PM, Jim <jim618@fastmail.co.uk> wrote:


Guys, being a late comer/outsider (I got into bitcoin in early 2012), I can
tell you that this particular asylum is definitely run by its inmates.

What all the nerdy devs (and I am one so I know) seem unable to comprehend,
is that regular people out there don't wanna learn all this new stuff and
new terminology they simply have no attention span for it.

Simply channelling them to a decent client that

1. Just works (no blockchain downloads and no re-sync)
2. Allows to retain control of the private keys

Would be HUGE for mass adoption.

Old tired argument about "Bitcoin needs your nodes", so we'll channel you
to get bitcoin-qt client is both manipulative and unnecessary (there's
plenty of nodes and NAT'ed home nodes which don't mine are mostly useless
anyways)

P.S. coinbase.com is just another trust-me setup takes your coins in
exchange for IOUs, whereas blockchain.info does let you to retain control
of your private keys.

P.P.S. The reason why coinbase has gotten so big is precisely because they
don't trouble regular lawyers and doctors with all the nonsense but simply
give them a
"buy" and a "sell" button.








-- 
Alex Kravets <http://www.linkedin.com/in/akravets>       def redPill = '
Scala <http://www.scala-lang.org/>
[[ brutal honesty <http://goo.gl/vwydt> is the best policy ]]
-------------------------------------
That change was made in response to user complaints. Heck we get complaints
about battery life and bandwidth impact even with Bloom filtering. We can't
just randomly start using peoples bandwidth for relaying blocks, especially
as I guess most SPV nodes are behind NAT.

If Gavin is right and the future is dominated by mobiles and tablets, then
it will require a change of thinking in how P2P networks work. I think
there are plenty of people with private servers who would be willing to run
nodes though. I'm not too worried about this.


On Fri, Aug 16, 2013 at 4:27 PM, Warren Togami Jr. <wtogami@gmail.com>wrote:

-------------------------------------
One major problem I see with this, no matter how well-thought-out it is,
it's unlikely that those with money will participate.  Those with the
most stake, likely have their private keys behind super-secure
accessibility barriers, and are not likely to go through the effort just
to sign votes.  Not only that, but it would require them to reveal their
public key, which while isn't technically so terrible, large amounts of
money intended to be kept in storage for 10+ years will prefer to avoid
any exposure at all, in the oft-chance that QCs come around a lot
earlier than we expected.  Sure, the actual risk should be pretty much
non-existent, but some of the most paranoid folks are probably the same
ones who have a lot of funds and want 100.00% of the security that is
possible.   They will see this as wildly inconvenient.

I think this a great thought experiment, and I'd like to see where this
idea goes, in terms of designing ways for a decentralized community to
find consensus for important decisions, but I don't think that any idea
that requires users to dig up their private keys is going to be feasible
(or possibly reconstruct them from pieces and/or get multiple
signatures).  Especially if the system requires some kind of persistent
voting.

-Alan


On 06/10/2013 12:46 PM, Mark Friedenbach wrote:
------------------------------------------------------------------------------


-------------------------------------
On Wed, Mar 13, 2013 at 2:06 PM, Andy Parkins <andyparkins@gmail.com> wrote:

The development of two chains was maximally bad because the state was
irreconcilable without the manual intervention. The only reason you're
saying that it was only the false confirms that were bad is because
manual intervention resolved the worse badness. :)  A whole bunch of
people spending coins that can only exist in the different exclusive
chains would have been very bad indeed.


Not reliably, you will only hear of a competing chain if some of your
peers have accepted it. If your peers were all pre-0.8 or all 0.8 you
only would have heard of one chain.

Relaying non-primary chains has some obvious and subtle challengesâ€”
Obviously you need some way of preventing it from being a DOS vector,
but thats not a fundamental issueâ€” you could rate limit by only
relaying chains which are close to the current best in sum difficultyâ€”
just a software engineering one.

A more subtle issue is it that it's not in a node's self-interest to
tell peers about a chain it thinks is invalid: it wants its peers on
_its_ view of the consensus, not some other one.  Though perhaps this
could be addressed by only relaying headers for non-primary chains.


-------------------------------------
Hi,

I am a newbie trying to get my first wallet up.  But I have a 
security/crypto background and so I know enough not to trust a http 
download.  But I don't see any other option to download bitcoin software 
from sourceforge.

I can check the SHA256 hashes, but how do I verify those?

I am familiar with gpg.  Where can I find signatures and the signing 
keys?  Hopefully, the keys are on multiple independent servers.

Or is read-only ssh/sftp/scp access possible?

Thanks in advance,

Chris


-------------------------------------
I personally like the full-measure of eliminating the "CS-PRNG" entirely  
 from signing. If the "random" component is assumed to be untrusted,  
keeping it in there adds no value, while eschewing the main benefit of  
deterministic signing (ease of testing, auditing)

This just leaves the CS-PRNG at the heart of the security system -- when  
generating the root master key of an HD wallet. Adding to what Mike said,  
a single invocation of a CS-PRNG driving all subsequent keys increases the  
attack value if that one invocation turns out to be weak. By comparison,  
at least compromised DSA signatures were one-off events which didn't allow  
theft of funds beyond the one compromised address.

Cumulative / rolling entropy collection over time through multiple CS-PRNG  
invocations, or multiple entropy sources, could serve to recover from an  
"occasionally weak" CS-PRNG. I've read claims that this is bad practice  
because a single low entropy source can take entropy out of the result,  
but this seems like FUD. If you're using SHA512-HMAC to hash chain a few  
entropy sources, even "return 4; // chosen by random dice roll" is not  
going to help, but it's not going to hurt.

The DSA 'repeated-k' basically advertises itself on the block-chain and  
people were actively scanning for this weakness, whereas a weak key in the  
BIP32 root might not be as apparent, so exploitation may be more  
difficult, but also more insidious. Of course this depends on the exact  
failure mode of the CS-PRNG being used -- I wonder if anyone is searching  
for BIP32 keys based off of one of the 32k Debian random numbers being  
used as a master key?

Smartphones in particular have lots of sensors which could provide  
entropy. For example, if you pulled 64 bytes from "secure random", you  
could at least HMAC that with the SHA512 of a picture or a short video  
sample taken by the user. I'm guessing some people would cringe at this,  
but it seems to me like it provides some measure of protection to justify  
the increased code complexity.

TL;DR - Really like the idea of minimizing CS-PRNG use whenever possible  
(deterministic signing) and also would love to learn more best practices  
for placing less trust in the so called "CS-PRNG" when we do have to use  
them.

Thanks,
Jeremy



-------------------------------------
On Fri, Aug 16, 2013 at 11:52 AM, Peter Todd <pete@petertodd.org> wrote:

Thanks for investigating this. I guess it's my fault for not checking
the diff before the final merge. I guess the simultaneous switch to a
git-subtree'd leveldb made it harder to review.

In any case, the changes seem harmless, but I think we should revert
to a codebase as close as possible to upstream LevelDB 1.12. The diff
you have between bitcoin head and bitcoin-up shows a few reverted
patches that we included during 0.9's merge window, a patch by ripple
to add a compaction delay (which they seem to have reverted now too)
and one weird ripple-specific commit (which just seems to remove
issue178_test.cc).

I've put a cleaned-up history of the LevelDB subtree in the
http://github.com/bitcoin/leveldb repository (branch bitcoin-fork),
and then used git-subtree to create a pull request (#2907) which
switches our src/leveldb directory to this tree. It correctly lists
the reverted (and sometimes re-applied) changes in the squashed commit
(please review!). The actual diff corresponds to the diff you
produced, with the reverted changes in our repository re-applied.

-- 
Pieter


-------------------------------------
On Saturday, October 19, 2013 9:16:24 PM Jean-Paul Kogelman wrote:

See BIP 1 for the process.. proposals go to this mailing list first.

Luke


-------------------------------------
After reading all 99 messages in this thread, I think allowfee is just 
about perfect.

It effectively lets merchants to give an allowance against the purchase 
price for network fees, if they choose.  It is still up to the sender 
(and/or the sender's software) to get the fees right.  Sometimes the 
sender will need to pay more fees than allowed, and sometimes the sender 
will need to pay less.

We can't solve the fee problem, in general.  I'm not sure that we can 
even define it properly.  But this is something that we can do, that 
will be useful at least occasionally, and that will cause no harm the 
rest of the time.

P.S.  Clever senders can use this to defrag their wallets.  Who wants to 
write the patch for that?

Gavin Andresen wrote:

-------------------------------------
So I had a go at deciphering BIP 038 in summary what I think its doing is
(ommitting lot and sequence and deterinistic IVs for simplicity):

user:

x1 = Scrypt( salt=random, pass )
P = x1*G

send (salt, P) to coin manufacturer -> 

				manufacturer:

				x2 = random 24bytes
				Q = x2*P
				k = Scrypt( salt2=H(Q)||salt, pass=P )
				e = AES_k( x2 )

				manufacturer puts es inside coin.

		<- send coin, (salt, e, Q) to user

				then optionally creates conf code:

				B = x2*G
				c = AES_k( B )

		<- send conf code c to user

verify code c:

(by recreating P, then k from Q & P, decrypt c to get B, check Q = x1*B)

x1 = Scrypt( salt, pass )
P = x1*G
k = Scrypt( salt2=H(Q)||salt, pass=P )

Which seems reasonable enough, however its unfortunate that you have to
repeat the Scrypt work at setup.

One thing that occurs to me eg as mentioned by Rivest et al in their
time-lock puzzle paper is that it is easy to create work, if you are ok with
parallelizable symmetric constructions (like scrypt(i) or PBKDF2(i) with i
iterations) without *doing* the work during setup.

It seems to me therefore that the above protocol could avoid the javascript
overhead issue that forces users to choose a weak iteration level if they
want to create the wallet in that way.

eg create a 32-bit random salt, replace scrypt(i=16384, salt, pass) with
scrypt(i=1,salt, pass) to be brute forced based on deleted salt.  Immediate
2^32 = 4billion iteration salt without any significant setup cost.  (Or if
you want to limit the parallelism say scrypt(i=65536, salt, pass) with a
deleted 16-bit salt.  That should be parallelizable up to 65536 GPU cores
(32x 7970 chips).

Symmetric time-lock puzzles can achieve decrypt asymmetry without repeating
the work at setup...

(Rivest et al goes on to avoid using that symmetric construct with an RSA
related mechanism, because they are trying to lock information for an
approximate future date, rather than protected by a specific amount of
grinding work.)


I proposed a different blind (securely server-offloadable) deterministic
proof of work relating to (asymmetric RSA-style) time-lock puzzles.  The
difference from time-lock is it is made blind (so the work can be securely
offloaded without the server learning your password or resulting key) and
can be easily made parallelizable also which is desirable for server
offload.

https://bitcointalk.org/index.php?topic=311000.new#new

I think that could take brain-wallets to a new level of security, if you
protect the amount by an amount of computation proportional to the value, eg
0.1% or 0.01% redemption cost paid to blind proof of work miners.

Adam


-------------------------------------
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 11/4/13 11:38 AM, Mike Hearn wrote:

The bits make a difference if you are merged mining. You can use the
birthday attack to construct two data trees whose hash match the
(truncated) value, each containing separate aux block headers. This
allows you to double-count the bitcoin PoW for more than one aux block
on the same chain, potentially facilitating aux chain attacks.

If you want 128 bits of security for merged mined aux chains, you need
256 bits of hash in the coinbase.
-----BEGIN PGP SIGNATURE-----
Version: GnuPG/MacGPG2 v2.0.19 (Darwin)
Comment: GPGTools - http://gpgtools.org
Comment: Using GnuPG with Thunderbird - http://www.enigmail.net/

iQIcBAEBAgAGBQJSd/shAAoJEAdzVfsmodw48a0P/RaCOctBDvhU0THnsUw6nRBm
A8oH3Kpio4ZltU4oIT0tznZbUOG2j2xVrmATqXDYOZQ6FuGihjmkKJ9jHgl57pb5
0qDdCBiEuWtLIh2+Awrb3Y0s8czyCQP9/1CJyzdEFmI8rSwCaqJMa6B2Ny6Xz6+8
eiK45YdXCPgdTAb56FKOi9WzOe0g1aOO5KiUOci22xRkXvh4qPYrt2F0LIgjZTdC
koyXU6dcKON9H8Cecu+ag7jJ5A9ZDj7oIq5rflEyolh2V4ie0tGQ50rFGg/ii6iQ
Tz9AWwigsHEkuinBTuN5041Xb8nAgHLvA60RQ41lWUHJxfAvDE+wN6NqgHmMVaRo
NHqlZcCuEl1jn7HW81XQTpgarrXHk1G7b2vK10pB/lUxUNIstZvCSjcp8QdtmC9v
tIhC2czSnsQaE6kIBuHxDNZxOlZ8DxBYCAgXSkycwznwzGhFPP0xB1lV9HfaP5+i
aikmx5SQmqBXQQKsxmIacoykrfu5x+O2TB/bq8JhJ1ak2jG9LVFyQqjorABVAgA7
pLEN6EomWht5qstaLVfHYpNsLMf6WA7UzRG08HKItUeDPtG7bDx8vBx5TvIUjT44
A0i09bOt8ZIgp+lJ8lFLWiPLChViAoy7fqKy2vrdsZerOF3l4LUQeQO/xnfZc+dG
AEG+7iCBOMxJSVoJ5bP6
=nydG
-----END PGP SIGNATURE-----


-------------------------------------
P2SH with 2 of 3: the payer, recipient and a trusted third party.
It is explained here:

https://en.bitcoin.it/wiki/Contracts#Example_2:_Escrow_and_dispute_mediation

Nothing can be done at the protocol level if you want it to remain
p2p. Much like the tainted coins stuff.
Maybe offtopic but I disliked what everyone but Alan said in that
bitcoin2013 "security panel" about it.
Well, I didn't like several claims on that panel...


On 6/6/13, Leszek Rychlewski <leszek@bioinfo.pl> wrote:


-- 
Jorge Timn

http://freico.in/


-------------------------------------
Hi Thomas,

can you more elaborate on that "version" bits? What is exact meaning of it?
I still think this is more an implementation problem. What stops Electrum
to do the same algorithm for searching branches as it is now for used
addresses?

These "version bits" need to be covered by the specification as well,
because if any client will use them differently (or won't use them at all),
it will break cross-compatibility between clients, which was another goal
of bip39.

Marek




On Sat, Oct 26, 2013 at 5:24 PM, Thomas Voegtlin <thomasv1@gmx.de> wrote:

-------------------------------------
First time posting to this mailing list so feel free to ignore me if
this is a stupid idea.


On Mon, Dec 2, 2013 at 3:49 AM, Mike Hearn <mike@plan99.net> wrote:


It seems to me that a common problem currently revolves around
accepting transactions in
retail scenarios, such as paying for a sandwich from Subway. A
solution could be to give the
vendor responsibility for setting the fee, which means they can choose
the trade-off that works
best for them in terms of fee size vs. speed of processing.

Idea:
Add a "fee" parameter to the payment URI specification.
When processing the transaction, the customer's UI should show only
the total price, including
both the transfer amount and the fee. The vendor only accepts the
transaction if the customer
uses the right amount and fee. If the fee is too small (for example,
the user might be using an
older wallet and has selected a fee of zero), the vendor can issue a
refund transaction
immediately and tell the user to try again.

Pros:
- could easily be implemented immediately
- old wallets would still be supported by just manually entering the
fee as users do now
- no greater risk of double spending on either side
- maintains the distributed nature of the system
- relies on humans to judge the fee (who are much less likely to
spiral infinitely upwards)
- flexible enough to support varying sizes of transaction and varying
degrees of security

Cons
- requires the vendor to have sufficient understanding of Bitcoin to
make the trade-off
- doesn't solve the problem of selecting a fee for transactions
between individuals/laymen
- doesn't solve fee selection for automated transactions such as
mixing/de/refragmentation


Thoughts?


-------------------------------------
Hi Mike,

I am glad you are still following up with Bitnodes. The recent spike in
nodes count should probably be taken with a grain of salt; run #231 (
http://getaddr.bitnodes.io/231/) does appear artificial to me, i.e.
potentially bogus nodes being added. I am still working on a more in depth
analysis on the data.

There are quite some TODOs for the project at the moment for the next
couple of months. I have included propagation data as well into the list.

Cheers,
Addy


On Fri, Nov 22, 2013 at 1:47 AM, Mike Hearn <mike@plan99.net> wrote:

-------------------------------------
On Tue, Nov 5, 2013 at 1:55 PM, Alessandro Parisi <startithub@gmail.com> wrote:

Correct.  There is significant potential that a fix can create other
problems...   and any major mistake could instantly destroy > $2
billion worth of value.

-- 
Jeff Garzik
Senior Software Engineer and open source evangelist
BitPay, Inc.      https://bitpay.com/


-------------------------------------
Here is the link to the FreeBSD build system 'port' that I am planning to
get committed when 0.8.2 is released. Any comments appreciated.

The Makefile mostly just applies the users request for GIU/QR/UPNP. The
major change is using the external port for leveldb. The files directory
contains 5 patches - 2 that add boost-crypto to LIBS because we still need
that until boost is updated, one that patches the build to use that
external leveldb, and 2 minor fixes that are needed to build. I have got
branches ready for pullreqs on those minor fixes - I'll double check them
and make pullreqs this evening.

Again, any comments very welcome.

The files are available at
https://redports.org/browser/robbak/net-p2p/bitcoin

Thanks,
Robert Backhaus.
-------------------------------------
On Wed, Aug 7, 2013 at 11:44 PM, Mike Hearn <mike@plan99.net> wrote:

By connecting to some other client, presumably. Have a small hardware
client that is able to do payments via NFC/QR/... directly with a
merchant, and can get 'recharged' by connecting with your desktop
client, for example. Maybe too futuristic to be a concern, but it
nicely illustrates how doing direct sender-to-receiver negotiation can
help decoupling tasks.


Ok.

-- 
Pieter


-------------------------------------
I've just pushed updated wordlist which is filtered to similar characters
taken from this matrix.

BIP39 now consider following character pairs as similar:

        similar = (
            ('a', 'c'), ('a', 'e'), ('a', 'o'),
            ('b', 'd'), ('b', 'h'), ('b', 'p'), ('b', 'q'), ('b', 'r'),
            ('c', 'e'), ('c', 'g'), ('c', 'n'), ('c', 'o'), ('c', 'q'),
('c', 'u'),
            ('d', 'g'), ('d', 'h'), ('d', 'o'), ('d', 'p'), ('d', 'q'),
            ('e', 'f'), ('e', 'o'),
            ('f', 'i'), ('f', 'j'), ('f', 'l'), ('f', 'p'), ('f', 't'),
            ('g', 'j'), ('g', 'o'), ('g', 'p'), ('g', 'q'), ('g', 'y'),
            ('h', 'k'), ('h', 'l'), ('h', 'm'), ('h', 'n'), ('h', 'r'),
            ('i', 'j'), ('i', 'l'), ('i', 't'), ('i', 'y'),
            ('j', 'l'), ('j', 'p'), ('j', 'q'), ('j', 'y'),
            ('k', 'x'),
            ('l', 't'),
            ('m', 'n'), ('m', 'w'),
            ('n', 'u'), ('n', 'z'),
            ('o', 'p'), ('o', 'q'), ('o', 'u'), ('o', 'v'),
            ('p', 'q'), ('p', 'r'),
            ('q', 'y'),
            ('s', 'z'),
            ('u', 'v'), ('u', 'w'), ('u', 'y'),
            ('v', 'w'), ('v', 'y')
        )

Feel free to review and comment current wordlist, but I think we're slowly
moving forward final list.

slush


On Sat, Oct 19, 2013 at 1:58 AM, Gregory Maxwell <gmaxwell@gmail.com> wrote:

-------------------------------------
In the short-term, maybe. Keep in mind that the code for tx relay is
fairly different and the bandwidth for transaction relay on these
nodes is already lower than it is for blocks (by design). That said,
I'd like to look into doing tx-less block relays for transactions that
peers already have to limit block relay times even for large blocks,
in which case tx relay is very much required.

Matt

On 11/13/13 15:13, John Dillon wrote:


-------------------------------------
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 11/14/13 2:00 PM, Alan Reiner wrote:

Well.. they are huge. 20 cents suggested fee for a irrevocable
transaction?
-----BEGIN PGP SIGNATURE-----
Version: GnuPG/MacGPG2 v2.0.19 (Darwin)
Comment: GPGTools - http://gpgtools.org
Comment: Using GnuPG with Thunderbird - http://www.enigmail.net/

iQIcBAEBAgAGBQJShU0EAAoJEAdzVfsmodw4TlAP/33KPX3ypMZ0PyHQVg3OCX21
hUXhTQBBO3JjO7x4HoNqdV0fApfCldq4cl/pNENG74inVuYNH+dUwUBIF6q6Qzfs
RU45++yytPob28ZojgrQgZq7/lAvi9qvsg5tLMyLt72uf3Kz1whmiRAHI5qaJ/xW
5w9LfOxXHFVkTQsUPzIjbD2kYAqUNILMzndKSv4YwRruYNm60gxCh2mQvgNr3s1Z
oGdLsPhx6AA1+Y6tgvnZVm71dwYUyg7OAafzGtpGEz953/cQwbgTqsZ3CrOiPk67
OJ9XxRPREOyKTDYo1WcM1GlQAq9LOHkMcU5OWS7TX2DzZAbLc7TqmqSMuAHdn6d5
eh+AgRWN1ppgVzHaCfgGSfP4NdXHRuMbDvSSoeiP+JLZ1ateT1aesklOaPRFfieW
NUJ61XAFWYCuVEK/ctUhSKMd19Rao23yuly+PtrMHvCw6Zn/LrpA4z2nD4vTFTXi
WeFyYwjIDjKBeuQMfWg5I2uMpo+9vC/DA3cwPticV7+LD7wsATHVNWVzuHlmjgTX
CPO4tVkqBPk7NsqDreOaVhvgnbAUHknyeDqguYS2LppDGu4P4XiOIHpS3reRyHuc
/NbXAvDkR23JGQFeHgdR/E983TdsqUiH3US43Cy3ikEcWm79eNG0cPGuHHVZBjPh
AACKjmPS+JR7rBAKFSGl
=f9P7
-----END PGP SIGNATURE-----


-------------------------------------




________________________________
 From: "bitcoin-development-request@lists.sourceforge.net" <bitcoin-development-request@lists.sourceforge.net>
To: bitcoin-development@lists.sourceforge.net 
Sent: Friday, December 20, 2013 12:33 PM
Subject: Bitcoin-development Digest, Vol 31, Issue 37
 

Send Bitcoin-development mailing list submissions to
 bitcoin-development@lists.sourceforge.net

When replying, please edit your Subject line so it is more specific
than "Re: Contents of Bitcoin-development digest..."

Hello all,

Is the dual elliptic curve algorithm mentioned in 
http://www.theguardian.com/world/2013/dec/20/nsa-internet-security-rsa-secret-10m-encryption 
from 2 days ago, of any concern to Bitcoin? I only ask, since I don't follow the field closely, but I see 
http://en.wikipedia.org/wiki/Elliptic_Curve_DSA 

Is this a concern for Bitcoin, or is this all "old news"?

Ron
_____________________________________
Bitcoin-development mailing list
Bitcoin-development@lists.sourceforge.net
https://lists.sourceforge.net/lists/listinfo/bitcoin-development


End of Bitcoin-development Digest, Vol 31, Issue 37
***************************************************
-------------------------------------
Thanks Warren! That's great. It's also a prerequisite for chain pruning, so
it's not only about decentralisation but also scalability.

Looking forward to reviewing and merging that.


On Tue, Dec 24, 2013 at 6:11 PM, Warren Togami Jr. <wtogami@gmail.com>wrote:

-------------------------------------
I suppose it isn't quite what you're talking about but we did push this out today:

Tor.framework, for Cocoa developers, similar to our BitcoinKit:
https://github.com/grabhive/Tor.framework

-wendell

grabhive.com | twitter.com/grabhive | gpg: 6C0C9411

On Jul 30, 2013, at 4:01 PM, Jeff Garzik wrote:




-------------------------------------
+1 and thank you. I've prototyped a couple different Bitcoin projects that
would benefit from this.

I'm traveling with poor 'net so I haven't read the patches yet. I echo pull
request comments about using Accept and Accept-Encoding headers. Same for
an API version number in the URL.

It'd be helpful, eventually, to have APIs corresponding to Bitcoin addr and
version messages.  Metadata about the network and the peer, respectively,
are valuable in my use cases.

Michael
On Jul 22, 2013 1:43 PM, "Jeff Garzik" <jgarzik@bitpay.com> wrote:

-------------------------------------
So back in 1999, in an ecash thread on cypherpunks I claimed:

http://marc.info/?l=cypherpunks&m=95280154629900&w=2


This was in the context of a discussion of digigold (e-gold stored the
physical gold, digigold offered "ecash" backed in that physical gold). 
Digigold ran on Systemics payment server/sox protocol.  Because of inferred
regulatory concerns and patent licensing issues digigold & systemics were
not using blind signatures.  However with systemics sox server, like
bitcoin, you could create multiple accounts on demand and shuffle payments
around for a degree of privacy.  The bitcoin analogy would be the
transaction log lived in the systemics server, so it had a central failure
point, but arguably more privacy as the log was not public.  Also systemics
SOX protocol (Ian Grigg & Gary Howland) had some aspect of bitcoins smart
contract concepts - ricardian contracts. 
http://iang.org/papers/ricardian_contract.html 

(Btw the anonymous reply itself was interesting -
http://marc.info/?l=cypherpunks&m=95280154629912&w=2 that could have been
Nakamoto, the only missing thing from the parts on the discussion room floor
to bitcoin is mathematical inflation control.)

The thread actually started here
http://marc.info/?l=cypherpunks&m=95280154629912&w=2 and then continues here
http://marc.info/?l=cypherpunks&m=95280154629900&w=2 because of a subject
line change and then http://marc.info/?l=cypherpunks&m=95280154629916&w=2
and http://marc.info/?l=cypherpunks&m=95280154629948&w=2
more subject line change confusion.

A related thread a few days later also covers Sander & Ta-Shma (which
zerocoin is based on):

http://marc.info/?l=cypherpunks&m=95280154630167&w=2

there were many more threads about various ecash technologies.

Adam


-------------------------------------
I missed Greg's point on confirmations.
It is definitely a challenge to explain/ visualize both:
+ has the transaction propagated the network ?
and
+ it it confirmed/ buried in a block ?

when those words probably don't mean much to
the intended audience.

The transaction status icons I *think* do it
(explained here:
https://multibit.org/en/help/v0.5/help_transactions.html).

It basically boils down to:
1) triangle or square : bad.
2) filling circle : good
3) tick mark : great.


On Thu, Jun 27, 2013, at 08:40 PM, Jim wrote:


-- 
https://multibit.org    Money, reinvented


-------------------------------------
On Mon, May 6, 2013 at 10:19 AM, Peter Todd <pete@petertodd.org> wrote:

SSL doesn't actually provide non-repudiation. We actually want
non-repudiation. I want to be able to prove to others that some node
deceived me.

(there are a number of other arguments I could make against SSL, but
that one is probably sufficientâ€” or rather, it's an argument that we
should have some way of cheaply getting non-reputable signatures
regardless of the transport)


Also look into torchat, which bundles a special tor build and runs a
hidden service.

Because of services like Blockchain.info attacking the casual privacy
users not using their webwallet service I've been thinking that even
for clients that don't normally use tor their own transaction
announcements should probably be made by bringing up a connection over
tor and announcing. But thats another matter...

I've switched to running on tor exclusively for my personal node (yay
dogfooding) and I've found it to connect and sync up very fast most of
the time. The biggest slowdown appears to be the our timeout on the
tor connections is very high and so if it gets unlucky on the first
couple attempts it can be minutes before it gets a connection. We're
short on onion peers and I sometimes get inbound connections before I
manage to get an outbound.


-------------------------------------
On Sat, Jul 13, 2013 at 11:32:39AM -0700, Peter Vessenes wrote:

Being able to have automated Bitcoin<->Zerocoin P2P trading without an
exchange is also significantly more desirable from a privacy standpoint.
Basically it reduces the privacy risks of doing the exchange to spending
the Zerocoins in the first place.

-- 
'peter'[:-1]@petertodd.org
00000000000000878c30a45104c48fd4e8037cb5b3ba1e14dc4d8bef72eff1be
-------------------------------------
On Tue, Dec 10, 2013 at 8:23 AM, Roy Badami <roy@gnomon.org.uk> wrote:


Yes could have been announced here too.
We announced the rc1 here but not the final release.
...maybe we should add a list of places to announce to the release process.

Wladimir
-------------------------------------
That would be a way to go, though iterating through all possibilities of a
similar letter misspell would take significantly more processing (4x3x3
= 36 total possibilities, only to cull it back to 2, in your example), than
iterating through a list of pre-calculated possibilities. It's definitely
not a hard computation on any modern device, though, and depending on how
"helpful" the program wants to try to be, it could even try help with
misspellings due to hitting a keyboard key next to the correct one or
hitting a letter twice, depending on how big a comparison matrix it wants
to create.

I do agree it should not be required for clients implementing the BIP to
help fix mis-translations, though keeping the similar letter unit test in
there I like, since it helps convey the thought that went into culling some
words from the dictionary. Though to Allen's point, what did happen with
the words that were found to be similar; was one of the similar words left
in the list or were all the similar words removed?

Brooks
MidnightLightning


On Fri, Nov 1, 2013 at 7:04 PM, slush <slush@centrum.cz> wrote:

-------------------------------------
This is just me making notes for myself, I'm not seriously suggesting this
be implemented any time soon.

Mozilla Persona is an infrastructure for web based single sign on. It works
by having email providers sign temporary certificates for their users,
whose browsers then sign server-provided challenges to prove their email
address.

Because an SSO system is a classic chicken/egg setup, they run various
fallback services that allow anyone with an email address to take part.
They also integrate with the Google/Yahoo SSO systems as well. The
intention being that they do this until Persona becomes big enough to
matter, and then they can remove the centralised struts and the system
becomes transparently decentralised.

In other words, they seem to do a lot of things right.

Of course you can already sign payments using an X.509 cert issued to an
email address with v1 of the payment protocol, so technically no new PKI is
needed. But the benefit of leveraging Persona would be convenience - you
can get yourself a Persona cert and use it to sign in to websites with a
single click, and the user experience is smart and professional. CAs in
contrast are designed for web site admins really so the experience of
getting a cert for an email address is rather variable and more heavyweight.

Unfortunately Persona does not use X.509. It uses a custom thing based on
JSON. However, under the hood it's just assertions signed by RSA keys, so
an implementation is likely to be quite easy. From the users perspective,
their wallet app would embed a browser and drive it as if it were signing
into a website, but stop after the user is signed into Persona and a user
cert has been provisioned. It can then sign payment requests automatically.
For many users, it'd be just one click, which is pretty neat.
-------------------------------------
On 16 November 2013 01:10, Luke-Jr <luke@dashjr.org> wrote:



If you are talking about user interface, I don't think you have to be
technically correct. It must make sense to the user.
A user cares about his balance, and did a payment "go through", and "did my
payment arrive/clear".

The UI is for their benefit.




Maybe, but again from the user's perspective they pay someone, and they
receive money - just like you do with paypal using an email address.
The technical bits in the middle dont matter to the user and trying to crap
stuff in to be technically correct is just confusing to them.

The UI needs to be about the user and fit with his experience of the world.

Drak
-------------------------------------
On Wed, Dec 04, 2013 at 02:48:08PM +0100, Mike Hearn wrote:

Other than you, replacement for fee changing isn't controversial; I know
this because no-one other than you comments on it... just like the
fundemental changes involving your proposed hardfork presumably. (which
I did comment on)


Besides, "Happily, there does not have to be One Correct Answer here.
Let wallets compete, and may the best user experience win..."

-- 
'peter'[:-1]@petertodd.org
000000000000000f9102d27cfd61ea9e8bb324593593ca3ce6ba53153ff251b3
-------------------------------------
It is irrelevant.
-------------------------------------
Well, my initial idea was that nothing was really needed too.
But if something must be done, I dislike very much the "ban
micropayments" approach. I was just offering other solutions that I
consider much better, but if nothing is done I won't be pushing for
those alternative solutions (to a problem that we may not even have).


On 3/11/13, Mike Hearn <mike@plan99.net> wrote:


-- 
Jorge Timn

http://freico.in/
http://archive.ripple-project.org/


-------------------------------------
Try https://bitcointalk.org/index.php?action=profile;u=19897?




On Fri, Nov 22, 2013 at 12:48 AM, Mike Hearn <mike@plan99.net> wrote:

-------------------------------------
Electrum version 1.9 is now released.

This version connects to multiple servers, and it also checks the SSL 
certificates of servers it knows.
Please note that the BIP32 features are postponed (to version 2.0), due 
to the discussions about mnemonic seed format.


Here is the changelog:

# Release 1.9
* The client connects to multiple servers in order to retrieve block 
headers and find the longest chain
* SSL certificate validation (to prevent MITM)
* Deterministic signatures (RFC 6979)
* Menu to create/restore/open wallets
* Create transactions with multiple outputs from CSV (comma separated 
values)
* New user interface for text mode, named "stdio" (does not use curses)
* Plugins are no longer tied to the qt GUI, they can reach all GUIs
* Proxy bugs have been fixed



-------------------------------------
Hi Brooks,

I've been already thinking about eat -> cat typing mistake. Actually there
may be simplier solution than having wordlist with duplicated words.
Because there's already a mapping of similar characters in the source code
(currently only in unit test, but it can be moved), when user type a word
which isn't in wordlist, application may try to use such mapping to find a
combination which actually is in the mapping. This may be disambiguous in
some cases, but giving a choice between few words may be better than hard
fail. And it is actually quite easy to implement. Although I think
application can do such smart suggestions and help user to recover badly
written mnemonic, I don't think it is necessary to standardize such method
directly into BIP. It may or may not be implemented by developers and it is
just nice to have feature.

Example:

user type ear, but it isn't in wordlist.

Regards the mapping,
E is similar to A, C, F, O
A is similar to E, C, O
R is similar to B, P, H

So application can calculate combinations of possible characters:

a) when app consider than the the user mistyped only one character
AAR, CAR, FAR, OAR
EER, ECR, EOR
EAB, EAP, EAH

b) when app consider than user maybe mistyped more characters, it may do
full combination matrix
AEB,  ACB, AOB,  ... OEH, OCH, OOH

and then ask user to select only these combinations which are actually
presented in the wordlist. In this particular case it may be only CAR or
FAR (both cannot be in the wordlist because of rules in similarity).

Marek


On Fri, Nov 1, 2013 at 9:14 PM, Brooks Boyd <boydb@midnightdesign.ws> wrote:

-------------------------------------
Can you explain this process for those of us not too familiar with TPM chips?

-wendell

grabhive.com | twitter.com/grabhive | gpg: 6C0C9411

On Jul 30, 2013, at 10:40 AM, Mike Hearn wrote:



-------------------------------------
On Wed, Oct 30, 2013 at 10:05 AM, Mark Friedenbach <mark@monetize.io> wrote:


I was referring to the fork alerts that Matt did. They also alert you if
there's a missed upgrade.
-------------------------------------
OK, I was under the impression that this was mostly developed for merchants. I've seen some discussion here that seemed to suggest it requiring some non-trivial (for an end user) steps like getting a CA-signed certificate.

-wendell

grabhive.com | twitter.com/grabhive | gpg: 6C0C9411

On Sep 7, 2013, at 11:44 PM, Mike Hearn wrote:




-------------------------------------
Hi,

There is currently 5 alerts pages on bitcoin.org concerning past network
events (vulnerabilities, hard fork, etc.). Those don't have any
visibility and cannot be listed or followed easily.

I've created a setup to improve this and allow developers to easily
communicate about any kind of network event worth mentionning. Code,
screenshot, live demo, instructions and details are in the pull request :
https://github.com/bitcoin/bitcoin.org/pull/194

Any comment is welcome. And since it is ultimately a tool for
developers, only you can define if it makes sense to merge it. Or if you
would like it to be done differently.

Best,

Savann
-------------------------------------
I'm pleased to announce the release of version 0.7 of the bitcoinj Java
library for working with Bitcoin. Bitcoinj forms the foundation of
MultiBit, Bitcoin Wallet for Android, SatoshiDice and more.

To get bitcoinj 0.7, check out our source from git and then run *git reset
--hard a9bd8631b904*. This will place you on the 0.7 release in a secure
manner. This paragraph was written on Tuesday 19th February 2013 and is
signed with the following key, which will be used in all release
announcements in future: 16vSNFP5Acsa6RBbjEA7QYCCRDRGXRFH4m.

Signature for the last
paragraph: IMvY1FsQobjU2t83ztQL3CTA+V+7WWKBFwMC+UWKCOMyTKA+73iSsFnCHdbFjAOEFMQH/NvJMTgGeVCSV/F9hfs=

If you want to, you can check that the original announcement mail sent to
bitcoinj@googlegroups.com is correctly signed with the google.com DKIM key,
to establish a full chain of trust.

*Release notes*

   - Thanks to Matt Corallo, we now support a* fully verifying mode* in
   addition to simplified verification. This is a tremendous amount of work
   that wouldn't have happened without Matt! Right now, we strongly discourage
   anyone from using it for mining (which is not supported out of the box
   anyway). Use it in a production environment only if you know what you're
   doing and are willing to risk losing money. If you do use it, let us know
   so we can contact you when problems are discovered. Read the documentation
   carefully before you begin.
   - Also thanks to Matt, *Bloom filtering* is now implemented and
   activated by default. When bitcoinj connects to a peer that supports Bloom
   filtering, only transactions relevant to the wallet will be downloaded
   which makes bandwidth usage scale with the size of your wallet, not global
   system activity. A configurable false positive ratio allows you to trade
   off bandwidth vs privacy. App developers don't need to do anything to take
   advantage of this, it is enabled automatically.
   - PeerGroup now pings its peers and calculates moving averages of the
   ping times. Ping time, versions and block heights are taken into account
   when selecting the peer to download the chain from.
   - You can now customize which outputs the wallet uses to create spends.
   The new default coin selector object allows you to spend unconfirmed change
   as long as it's been seen propagating across the network, addressing a
   common end-user pain point in wallet apps.
   - Optimized networking code for faster startup.
   - A new PeerMonitor example app shows how to put properties of connected
   peers into a GUI.
   - The Wallet is now decoupled from the BlockChain using the new
   BlockChainListener interface. This will simplify the development of some
   apps that want to process transactions but not maintain an actual wallet.
   - The dependencies of broadcast transactions are now downloaded and risk
   analyzed. At the moment they are only being checked for having a timelock.
   In future we may also analyze tree depth. The goal is to make certain kinds
   of protocol abuse harder. Wallets will reject timelocked transactions by
   default, this can be overridden via a property.
   - You can now create timelocked transactions with
WalletTool?<http://code.google.com/p/bitcoinj/w/edit/WalletTool> if
   you want to.
   - Compressed public keys are now used by default.
   - Support testnet3
   - Support bitcoin-qt compatible message signing and verification.
   - ECDSA key recovery is now implemented and allows you to obtain the
   public key from an extended signature. If the signature is not extended
   then there are multiple key possibilities returned.
   - Many bugfixes and minor improvements

API changes:

   - ECKey.sign() now takes a Sha256Hash as an argument and returns an
   ECDSASignature object in response. To get DER encoded signatures, use
   the encodeToDER() method of ECDSASignature.
   - ECKey.publicKeyFromPrivate now takes an additional compressed
   parameter.
   - PeerGroup.start()/PeerGroup.shutDown() now run asynchronously and
   return futures you can use to wait for them. You cannot restart a
   PeerGroup once it has been shut down any more.

*Credits*
*
*
Thanks to Matt Corallo (a.k.a. BlueMatt) for his huge contributions to this
release.

As always, thanks to Andreas Schildbach for his thorough testing, ideas and
high volume of quality bug reports. Also thanks to Jim Burton for the same
reasons.

Finally thanks to Ben (piuk) of blockchain.info for funding the ECDSA key
recovery feature.
-------------------------------------
On Fri, Nov 8, 2013 at 11:49 AM, Andreas M. Antonopoulos
<andreas@rooteleven.com> wrote:

The BC.i timestamps have historically been inaccurate relative to my
local GPS clock measurements on my own nodes... but not just that, it
sounds like he's comparing block timestamps and bc.i numbers.

Thats insane, because it tells you the delay between when the miner
_started_ a work unit and when BC.i claims to have found it. Even
assuming bc.i's times were accurate and assuming miner clocks are
accurate (they are often not) you expect there to be be a gap because
it takes time to compute work, send it to the miner, search for a
valid nonce (an average of 2^31 hash operations, often executed
sequentially on a single core taking ten seconds or so on a lot of
hardware) and then return a result.

Evidence of selfish miners wouldn't be block timestamps (which are
inaccurate and controlled by miners anyways), or data on
blockchain.info (which is inaccurate and controlled by bc.i) ... but
the existence of an unusual amount of orphan blocks. High levels of
blocks are _necessary_ evidence of this sort of things, there can be
other explanations of high orphaning levels, but they're required here
and couldn't be faked.


-------------------------------------
On Sun, 8 Dec 2013 13:14:44 -0800, Gregory Maxwell wrote:

It's just as easy to steal emails via a BGP or DNS redirect anyway.. 
you could even take over the actual domain at the registry level by 
stealing a password reset via BGP or DNS redirect and actually many 
registries will hand over control of a domain by faxing them a forged 
driving license in the owner's name anyway so it doesn't even really 
need to be a particularly sophisticated attacker. Once you have registry 
control of the domain it's easy enough to get an SSL cert too, probably 
even an 'extended validation' one.

When Afghanistan was taken over the entire .af TLD was probably 
transferred using a forged fax to ICANN 
(http://web.archive.org/web/20041017031020/http://www.iana.org/cctld/af/razeeq-letter-13aug02.pdf) 
but I guess that's a little different :p

Rob


-------------------------------------
Hi all,

yesterday I found some time and implemented RFC 6979 into python-ecdsa
module.

RFC 6979 proposes algorithm of calculating 'k' value for signature from
private key and signed data, so the 'k' is unique, but deterministic for
every signature. This enabled simple unit tests of code using ECDSA
signatures as well as some nice use cases for blackbox testing of 3rd party
software (you can calculate on your own if some software is making valid
signature, because there's no randomnes involved in the process). Yes, I'm
referring Trezor :-).

There's my fork of python-ecdsa with RFC 6979:
https://github.com/trezor/python-ecdsa/

There's pull request waiting for python-ecdsa author aproval:
https://github.com/warner/python-ecdsa/pull/10

Aaand there's RFC 6979: tools.ietf.org/html/rfc6979

Thanks,
slush
-------------------------------------
On Tuesday 30 April 2013 21:11:47 Jeff Garzik wrote:


"Most efficient" for what purpose?  There is more that one might do than just 
duplicate bitcoind exactly.  I can well imagine storing bitcoin blocks parsed 
and separated out into database fields.


If.  What if I'm writing a client and don't want to store them the way 
bitcoind has?


Except the alternative is no schema at all -- essentially it's just give 
access to a file on disk.  Well, that hardly needs discussion at all, and it 
hardly needs the involvement of bitcoind, apache could do it right now.


I don't think it's a "rewrite".  The wire protocol is only a small part of 
what bitcoind does.  Adding another thread listening for HTTP requests at the 
same time as on 8333 for stadnard format.

Anyway -- I've obviously misunderstood what the idea behind a HTTP protocol 
was, and it's not like I was volunteering to do any of the work ;-)



Andy

-- 
Dr Andy Parkins
andyparkins@gmail.com


-------------------------------------
As the title says.

Basically on testnet we should give people the chance to test how their
code handles attempts to spend the genesis block coinbase, as well as
other tx's made to the genesis block address. After all, potentially
Satoshi is still out there, still has that key, and still may cause
exactly that situation himself.

So Gavin, if you have the private key for testnet3's coinbase, I'm
asking you to release it, and otherwise fix this for the eventual
testnet4

Of course, obviously you can test this case yourself with a private
testnet, but it'd be good if people we forced to test this case against
their will...

-- 
'peter'[:-1]@petertodd.org
-------------------------------------
On Thu, Oct 24, 2013 at 7:29 PM, <thomasV1@gmx.de> wrote:

Two years ago I proposed exactly this and you refused to add extra
information to mnemonic, because "it isn't necessary" and "it makes it
longer to mnemonization". What changed since then?


Hm, what exactly do you need to store about wallet structure? I lived in
opinion that everything is able to recover using CKD function to generate
new addresses and blockchain lookups for their balances.


Yes, that's true. It isn't possible to make everybody 100% happy. At least
I wanted to be constructive and asked you to replace the most problematic
words. No pull request from you so far.


Yes, it was original idea. So far I don't think this is a problem. Of
course some words may have some meaning across languages, but it should be
easy to avoid them. There are tens of thousands words in every language and
we need to pick "only" 2048 words to wordlist.


I would like to suggest the following solution:
If I understand this well, it is basically one-way algorithm "mnemonic ->
seed", right? Seed cannot be printed out as mnemonic, because there's
hashing involved, but the bi-directionality has been the original
requirement for such algorithm (at least in Electrum and bip39).

Then, how is this different to picking 12 random words from dictionary and
hashing them together? I don't see any benefit in that "mining" part of the
proposal (except that it is lowering the entropy for given length of
mnemonic).



Are your worries about overlapping words across languages a real issue?

slush
-------------------------------------
I would like to propose a new BIP, that replaces BIP0039.

My initial problem was that BIP0039 is not backward compatible with Electrum. When trying to solve that, I realized that the seed encoding used in Electrum does not help, because it does not contain a version number information. However, BIP0039 suffers the same shortcoming: it does nothing to help a future replacement, it wants to be final. My first recommendation is to allocate a few bits of the mnemonic, in order to encode a "version number" along with the checksum bits.

The second problem is the wallet structure. There are multiple ways to use a BIP32 tree, and each client will certainly handle this differently. For Electrum, it is important to be able to recover an entire wallet from its mnemonic, using no extra information. Thus, the client needs to know which branches of the BIP32 tree are populated by default. This means that the "version number" I mentioned will not only be about the seed encoding, but it should also give some information about the wallet structure, at least in the case of Electrum.

The third problem is the dictionary. I do not like the dictionary proposed in BIP0039, because it contains too many short words, which are bad for memorization (I explained here how I designed the dictionary used by Electrum: https://bitcointalk.org/index.php?topic=153990.msg2167909#msg2167909). I had some discussions with slush about this, but I do not think it will ever be possible to find a consensus on that topic. 

BIP0039 also suggests to use localized dictionaries, with non-colliding word lists, but it is not clear how that will be achieved; it seems to be difficult, because languages often have words in common. It looks like a first-come-first-served aproach will be used. 

For these reasons, I believe that we need a dictionary-independent solution. This will allow developers to use the dictionary they like, and localization will be easy.

I would like to suggest the following solution:

1. Define a target of k bits: this target contains the metadata ("version number"), plus some extra bits for the checksum. For example, with k=16, we can allocate 8 bits for the version number, and 8 bits for checksum.

2. Pick a random number of length n+k bits, where n is the desired entropy of the seed, and k is the number of bits needed for the metadata (checksum, version number)

3. Translate this random number to a mnemonic string, using a dictionary.

4. Compute a hash of the mnemonic string (utf8 encoded).

5. Repeat steps 2, 3 and 4 until the k first bits of the hash are equal to the target defined in 1.

6. Use the final hash as input for bip32 (as the master seed)

This means that we "mine" for the seed, until the desired metadata is obtained in the hash. This "mining" also adds a bit of difficulty to the process of finding a seed (on average, it will require 2^k iterations). The entropy of the final hash is n, the number of unconstrained bits.

This solution makes it possible for developers to define new dictionaries, localized or adapted to a particular need. 
The resulting mnemonics will always be usable with other clients, even if they do not know the dictionary. 

I am willing to write a new BIP where this proposal is specified in detail.


-------------------------------------

bitcoinj separates the concept of committing a tx to the wallet from
broadcasting it. However by default transactions that weren't seen in the
chain yet will be announced when a new peer is connected to. It'd take
extra code to suppress that, and it's unclear to me why that's useful. I
agree with Pieter that it should be the merchants responsibility to get the
tx out there, but having the client do the broadcast as well can't really
hurt (except perhaps some privacy impact).
-------------------------------------
Since this came up again during the discussion of the Cornell paper I
thought I'd dig up my measurement code from the Information
Propagation paper and automate it as much as possible.

The result is the Network Propagation page on bitcoinstats.com
(http://bitcoinstats.com/network/propagation/). It takes a daily
snapshot of the situation, then calculates the time until blocks and
transactions reach a certain percentile of the nodes in the network.
There is also a detailed page showing the density function describing
at what times nodes learn about the existence of a block/transaction
(for example yesterdays distribution:
http://bitcoinstats.com/network/propagation/2013/11/23).

I intend to add more information and plots over time, but I wanted to
push this out quickly as there were some people asking for it. Hope
this helps getting the blockchain fork rate down :-)

Regards,
Chris
--
Christian Decker


-------------------------------------
There are some policy decision points in the protocol (and code) that may
become centralized risks or choke points that undermine the p2p nature.  So
the extent that those can be argued to have in principle have a technical
fix, it could be quite interesting to research the necessary technology
(advanced crypto, byzantine networking argument etc) that could address
them.  eg payee/payer blacklisting by a large group of miners and "committed
transaction" proposal to address it.

However even for that type of thing I think bitcoin-dev would probably
rather focus eg on something that has reached the stage of having a BIP.  Eg
it might be better to discuss early stage or speculative ideas on
bitcointalk.org technical thread.

https://bitcointalk.org/index.php?board=6.0

taxation in particular there are examples where even the political sphere
accepts significantly anonymous taxation.  eg for europeans with certain
types of investment in a swiss bank, the swiss bank sends however many
million as a single payment across all users per european country to their
passport home country (minus 25% cut for the swiss government).  Perhaps
such things could be possible for bitcoin.  Again I think bitcoin talk would
be a good place for such a discussion if that was the OP question
indirectly.

Adam

On Sun, Sep 29, 2013 at 06:32:10PM +1000, Gavin Andresen wrote:





-------------------------------------
On Tue, Sep 24, 2013 at 11:52 PM, Mike Hearn <mike@plan99.net> wrote:


Not too late, assuming there are no objections. Smaller QR codes is a very
good reason to change it.

-- 
--
Gavin Andresen
-------------------------------------
I've beefed up the supporting documentation for the website to make it more
accessible for developers who wish to contribute. It's a Java application
serving HTML.

It can be found here: https://github.com/jim618/multibit-website


On 30 June 2013 16:19, Jim <jim618@fastmail.co.uk> wrote:

-------------------------------------
Hi,
I am new on the list. I got a similar problem.

If I put "sendToAdress" transactions to bitcoind, it will accept between 1
and 3 transactions per minute, depending on the underlying machine.
If I try to send one transaction every 20 seconds or less, bitcoind stops
responding to RPC calls.

Does anybody know of any solution / fix / workaround for this?

Thanks in advance.


2013/9/30 Warren Togami Jr. <wtogami@gmail.com>



-- 
=================================
FÃ¡tima Castiglione Maldonado
castiglionemaldonado@gmail.com

                     ____
                   ,'_   |
 __________________|__|__|__
<_____                      )                _.------._
      `-----------,------.-'              ,-'          `-.
                 |    |  |              ,'                `.
                ,'    |  |            ,'                    `.
                |  _,-'  |__         /                        \
              _,'-'    `.   `---.___|_____________             \
          .--'  -----.  | _____________________   `-. -----     |
          |    ___|  |  |                      \  ,- \          |
          |    ___|  |===========================((|) |         |
          |       |  |  | _____________________/  `- /          |
          `--._ -----'  |        _________________,-' -----     |
               `.-._   ,' __.---'   |                          /
                |   `-.  |           \                        /
                `.    |  |            `.                    ,'
                 |    |  |              `.                ,'
 _____,----------`-------`-.              `-._        _,-'
<___________________________)                 `------'
                   | _|  |
                   `.____|



=================================
-------------------------------------
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 12/20/2013 11:48 AM, Gregory Maxwell wrote:

I got the inputs from IRC, but thank you for posting to the list so
that others can see and review.


A length-prefixed string, using the shortest representation VARINT for
the length. Same as how scripts are serialized in transactions.


Yes I considered midstate compression which is why the branch hashes
come last, but "extra" was an oversight. In every application I've
considered it's either not used (and therefore a single byte), or
updated whenever the node or its children updates.

Honestly I don't expect midestate compression to offer much since in
the nodes that are updated frequently it is unlikely that there will
be enough static data at the front to fill even a 512 bit block of the
smaller hash function.

But it doesn't hurt to prepare just in case. I'll move it to the end.


Yes, this is a great suggestion. Moving to SHA-512/256 will let most
inner nodes fit inside a single block, so long as the "extra" field is
not too long. Also apparently SHA-512 is faster on 64-bit CPUs, which
is a nice advantage. I didn't know that.

I'm concerned about speed but I did not go with a faster hash function
because users are more likely to have hardware acceleration for the
SHA-2 family.


The serialization format encodes lengths in such a way that you cannot
extend the data structure merely by appending bits. You would have to
change the prior, already hashed bits as well. I believe this makes it
immune to length extension attacks.


Well.. the UTXO tree is big. Let's assume 5,000 transactions per
block, with an average of 3 inputs/outputs per transaction. This is
close to the worst-case scenario with the current block size. That's
15,000 insert, update, or delete operations.

The number of hashes required when level-compression is used is log2
the number of items in the tree, which for bitcoin is currently about
2.5 million transactions. So that's about ~21 hashes per input/ouput,
or 315,000 hash operations. A CPU is able to do about 100,000 hashes
per second per core, that'll probably take about a second on a modern
4- or 8-core machine.

For updatable proofs, the number of hash operations is equal to the
number of bits in the key, which for the validation index is always
256. That means 3.84 million hashes, or about 10 seconds on a 4-core
machine.

The numbers for the wallet index are worse, as it scales with the
number of outputs, which is necessarily larger, and the keys are longer.

This is not an insignificant cost in the near term, although it is the
type of operation that could be easily offloaded to a GPU or FPGA.


This is something I know less about, and I welcome constructive input.
There is *no* reason that the hash serialization needs to have fancy
space-saving features. You could even make the SIG_HASH node
serialization into fixed-size, word-aligned data structures.

But this is absolutely not my field, and I may need some hand-holding.
Do the fields need to be at fixed offsets? With fixed widths? Should I
put variable-length stuff like the level-compressed prefixes and value
data at the end (midstate be damned) to keep fixed offsets? What's
expected word alignment, 32-bit or 64-bit?


I believe what you mean by "compact update proofs" is what I call
"updatable proofs", where level compression is only used in the disk
and network serialization. These are what I propose to use for the
validation and wallet indexes, if the computational costs can be
brought under control, because it allows composable proofs.

Unlike a time-ordered index, it does require that someone, somewhere
has random access to the entire UTXO set since you can't predict in
advance what your txid will be. But this is a matter of tradeoffs and
I don't believe at this time that there is a clearcut advantage of one
approach over the other. I'm pursuing a txid-indexed UTXO set because
it most closely matches the current operational model.

That said, you still want level-compression within the serialization
format itself, if for no other reason than to keep proof sizes small.


Thanks,
Mark
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.14 (GNU/Linux)
Comment: GPGTools - http://gpgtools.org
Comment: Using GnuPG with Thunderbird - http://www.enigmail.net/

iQIcBAEBAgAGBQJStL7nAAoJEAdzVfsmodw4DQcP/ilB2LTPnbK/UoU+y0d/0CUu
4PVo8VJt0KCUgWbEHIohm0rq4FUpb7FpjzAyQ171jzRykDEkUy7nDh/QsWGUvDvA
gOHKEsX3E+ei8iQMkwlw5D/Lpbb8GNr3SHrU3lvVbXOoaPua9I16778hv3wBWhiN
R70N8dQUwWD1IU0Dfmhi8v2P8OTn4OGTEwS5AQANGCroYyALF+U9EDHjWDMV+bYn
8qrX4v05xjik5YXOv8PNDDp0S9A+KxD72OKL5xlXiE7VbKrYXKt6xNfy1xYgHH8p
u9kWDFMkbis/HAiB5aiFTmxX5/k+yeJw8BfG+txj0xo7b7cWKB9cQLT8vUru2QuH
lHdurxkaBQ+6jqlxYRk7nh0h+obeAXA/CGMseaDYluBg7qTkeWnLORfm7T7fUnHw
fB5sXPUKEeYw48sfs58w/71NbCyl2yYNGlmmugk2SilD3QbUKU1xogNTHEGDuA8M
kPsWW7vRIdI3iy9adgh3LZAvySt7/a5VXXs1li7teDgV4QqH7e2hR0KR8n115N7f
r30LSctbc/MovE9VPb8I7ssQTB7So+1Ki6DbVeQO/8UlCSK5prM3n2sICmT/EVW7
2hNzwbHuEJEWYE7q89buzMRdqbUYSRdG1T1mFBeZ+/n4HH6cweMl6BH4d46LAfuq
BqzTmq5neoCKBwfMfoqg
=YmkZ
-----END PGP SIGNATURE-----


-------------------------------------
bounty++

On 06-11-13 06:33, kjj wrote:



-------------------------------------
So Sarchar and I were talking about his Bitstorage scheme(1) and we came
to the conclusion that it wouldn't work. However he came up with a less
abitious idea that I thought would work: force people to prove they were
still holding your data D by publishing transactions with scriptPubKeys
of the form:

    HASH160 H(D[i:i+n]) EQUALVERIFY {<pubkey> OP_CHECKSIG}

Where pubkey optionally lets you pick a specific person to hold your
data. (so the scheme isn't restricted to miners - hash-only
scriptPubKeys aren't secure) Basically you'd publish the data and store
a much smaller random set of D[] samples. If you ever needed the data in
full, you know it's out there, so it's just a matter of haggling on the
price to get it back. (you may want to do some dry-runs for negotiation
leverage...)

However, I realized you can improve upon this greatly by deriving the
ECC privkeys from the random samples of data instead using H(E_k(D)),
that is, use a block cipher with key k, and then hash that to form the
privkey. Then create a perfectly normal txout paying to the appropriate
pubkey. Now only people who actually have the data can claim the txout,
and everyone doesn't even know the scheme exists at all.

Furthermore you can create key k using k_i=HMAC(i, K), where i in [0,
n], so rewards for the proof can be released incrementally while only
storing a single secret key. Again, actual retrivial isn't necessarily
guaranteed, but the odd dry-run is simple enough.

One last issue is how to distribute k_i, although this is made easier by
the fact that they can be tiny 128-bit numbers - they should however be
signed to avoid DoS attacks as only by processing all the data can the
storage node know if k_i works for the given txout.


1) https://bitcointalk.org/index.php?topic=348868.new#new

-- 
'peter'[:-1]@petertodd.org
00000000000000056738baba2d1f0fb2638555529e0735e41e1ce9e0c946d48a
-------------------------------------
On Tue, Apr 09, 2013 at 07:53:38PM -0700, Gregory Maxwell wrote:

Note how we can already do this: P2SH uses Hash160, which is
RIPE160(SHA256(d)) We still need a new P2SH *address* type, that
provides the full 256 bits, but no-one uses P2SH addresses yet anyway.

This will restrict data stuffing to brute forcing hash collisions. It'd
be interesting working out the math for how effective that is, but it'll
certainely be expensive in terms of time hashing power that could solve
shares instead.


-- 
'peter'[:-1]@petertodd.org
-------------------------------------
I think trying to help miners figure out the propagation/fees tradeoff at
the moment is a non-starter until we understand it better ourselves. A
server that tracks and records block propagation times, how many fees per
passed up per block, orphan stats per size bucket etc would be tremendously
helpful.


On Thu, Nov 7, 2013 at 4:19 PM, Pieter Wuille <pieter.wuille@gmail.com>wrote:

-------------------------------------
On Fri, Aug 16, 2013 at 05:11:35PM +0200, Mike Hearn wrote:

Do find out.


Also worth finding out.


Appeal to authority.

Stop bringing up Satoshi's "vision" - our understanding of
crypto-currencies has improved in the 4.5 years since Bitcoin was
released. Satoshi didn't even forsee pool mining, which says a lot about
his economic judgement.


Right, so you're giving priority to peers that have been around for
awhile. You've succeeded in forcing attackers to wait a bit.

A) What's the definition of a peer? What stops me from pretending to be
100 peers?

B) Given an attacker willing to wait, what's your plan?

-- 
'peter'[:-1]@petertodd.org
000000000000004a52a297d9ae8ecde2ba62b681cc5a4cfbf7636032fc78e7d0
-------------------------------------
Sounds like we have consensus, Saivann, shall we do it?

I'm also going to ask Theymos again to relax the newbie restrictions
for the alt client forums. It's probably too hard to get support at
the moment and "email jim" doesn't scale at all.

On Fri, Jun 28, 2013 at 4:24 PM, Gavin Andresen <gavinandresen@gmail.com> wrote:


-------------------------------------
On Tue, Mar 12, 2013 at 8:10 AM, Luke-Jr <luke@dashjr.org> wrote:

I don't want to misrepresent what happened, but how much of that was really
a risk?  The block was rejected, but the transactions were not.  Any valid
transactions to hit the network would get added to everyone's memory pool
and mined in both chains.  Thus all nodes would still reject double-spend
attempts.  As far as I understood it, you would've had to have majority
mining power on one of the chains (and both had non-negligible computing
power on them), so double-spending still required an exceptional amount of
resources -- just not the normal 50% that is normally needed.  Perhaps...
10%?   But how many people can even have 10%?  In addition to that, a
victim needs to be found that hasn't seen the alert, is willing to execute
a large transaction, and is on the wrong side of the chain.

Is this incorrect?  Yes, there was less resources needed to execute an
attack -- but it still required a very powerful attacker, way outside the
scope of "regular users."
-------------------------------------
I think this is a useful feature, but I din't see why it should be a part
of bitcoind. I've created a simple HTTP REST wrapper around bitcoind's RPC
interface in Python:
https://github.com/runeksvendsen/btchttp/blob/master/btchttp.py

It simply runs a HTTP server that translates HTTP GET requests into the
relevant RPC request, and responds to the GET request with the relevant
data.

/Rune

On Tue, Jul 23, 2013 at 9:36 PM, Mark Friedenbach <mark@monetize.io> wrote:

-------------------------------------
Post tge malicious miners and other bits so we can evaluate the system as a whole. 

Mike Hearn <mike@plan99.net> wrote:




-------------------------------------
On Saturday, March 23, 2013 5:47:46 PM Jeff Garzik wrote:

Context is everything.
bitcoind is nowhere in the implementation of the miner end of BIP 34.


-------------------------------------
(generic comment on the discussion that spawned off: ideas about how to
allow additional protocols for block exchange are certainly interesting,
and in the long term we should certainly consider that. For now I'd like to
keep this about the more immediate way forward with making the P2P protocol
not break in the presence of pruning nodes)

On Sun, Apr 28, 2013 at 6:57 PM, Mike Hearn <mike@plan99.net> wrote:


Yes, I like that better than broadcasting the exact height starting at
which you serve (though I would put that information immediately in the
version announcement). I don't think we can rely on the addr broadcasting
mechanism for fast information exchange anyway. One more problem with this:
DNS seeds cannot convey this information (neither do they currently convey
service bits, but at least those can be indexed separately, and served
explicitly through asking for a specific subdomain or so).

So to summarize:
* Add a field to addr messages (after protocol number increase) that
maintains number of top blocks served)?
* Add a field to version message to announce the actual first block served?
* Add service bits to separately enable "relaying/verifying node" and
"serves (part of) the historic chain"? My original reason for suggesting
this was different, I think better compatibility with DNS seeds may be a
good reason for this. You could ask the seed first for a subset that at
least serves some part of the historic chain, until you hit a node that has
enough, and once caught up, ask for nodes that relay.

Disconnecting in case something is requested that isn't served seems like

I'm sure there will be cases where a new node connects based on outdated
information. I'm just stating that I agree with the generic policy of "if a
node requests something it should have known the peer doesn't serve, it is
fair to be disconnected."



Maybe it validates, maybe it doesn't. What matters is that it doesn't
guarantee relaying fresh blocks and transactions. Maybe it does validate,
maybe it just stores any blocks, and uses a validating node to know what to
announce as best chain, or it uses an SPV mechanism to determine that. Or
it only validates and relays blocks, but not transactions. My point is that
"serving historic data" and "relaying fresh data" are separate
responsibilities, and there's no need to require them to be combined.

-- 
Pieter
-------------------------------------
An approach which I see as workable in the long term is to keep the block
header and an array of bitfields representing each transaction's spent
and unspent outputs. When someone wants to spend money you ask them for the
transaction and ideally you ask them for the transaction and the merkle branch
from that transaction to the header. If they want to spend the money they have
to carry around the data.

Agreed on the legality aspect but another case which is worth considering is
what anti-virus software might do when certain streams of bytes are sent across
the tcp socket or persisted to disk. Perhaps worth contacting an AV company and
asking what is the smallest data they have a signature on.

Thanks,
Caleb


On 04/09/2013 06:42 AM, Mike Hearn wrote:



-------------------------------------
slush <slush@centrum.cz> writes:


I see this as well with 0.8.2+. I don't see it on 0.8.1. I originally
hit the '4 keep alive thread limit' where four clients on the same
bitcoind would result in other clients not being able to connect. I
resolved that and still hit the RPC hanging issue. The most problem I've
had is using 'getwork' which I believe is going the wayside anyway.



-------------------------------------
On Wednesday, March 13, 2013 9:06:44 PM Andy Parkins wrote:

These are both the same thing.

Luke


-------------------------------------
On Wed, Apr 10, 2013 at 05:58:10PM +0200, Jorge Timn wrote:

You mean https://bitcointalk.org/index.php?topic=137933.0 ?

I would oppose it, and I wrote the above proposal. The code required to
implement UTXO fraud proofs is more complex than the entire Bitcoin code
base; obviously that much new fork-critical code opens up huge technical
risks. As an example, can you think of how UTXO fraud proofs can cause
an arbitrarily deep re-org?

-- 
'peter'[:-1]@petertodd.org
-------------------------------------
So there's a slight world divide in digital payments with bitcoin using
ECDSA and GPG, payswarm / webid etc using largely RSA

Here's how to bring the two worlds together and enable bitcoins be sent
over webid or payswarm


Problem: Alice and Bob have RSA key pairs, but no public bitcoin
addresses.  Alice wants to send 1 BTC to Bob.

1. Alice takes Bob's WebID and encrpyts it with her private key (to create
entropy) ...

2. Alice uses that message as the seed to produce btc address (as per
http://brainwallet.org ) with ECDSA key pair

3. Alice sends coins to this address

4. Alice and then encrypts the seed again with Bob's public key

5. Bob decrypts the seed using his private key

6. Bob can now use the seed to recreate the wallet and spend the coins

Unless I've made an error, I believe this unites the web paradigm and
crypto currency paradigm into one potentially giant eco system ...
-------------------------------------
Two thoughts:
1. Please keep it simple, miner will override it either.
2. If block construction algorithm compares alternate chains and not individual transactions,  then receiver can bump up the fee by spending the unconfirmed output again with higher fee, no need for replacement in the mempool.

Tamas Blummer



-------------------------------------

If I find out one of the large pools decides to run this 'experiment' on
the main network, I will make it my mission to tell people to switch to a
more responsible pool.

And if you think you can get away with driving up EVERYBODY's orphan rate
without anybody noticing, you should think again.



That I agree with.

-- 
--
Gavin Andresen
-------------------------------------
On Fri, May 31, 2013 at 2:10 PM, Michael Hendricks <michael@ndrix.org>wrote:


I've thought about this as well. It just seems somewhat clunky to me. I'd
really prefer having bitcoind put out messages in batches, if it's doable,
that is.

I'd run into a lot of concurrency issues, as far as I can see, where I
can't be sure that the queue isn't written to while, for example, it is
opened by the program that needs to process the queue items.

What if a disk operation takes a long time to finish, and a two queue
operations want to add to the queue simultaneously? This really brings
forward all the horrors of concurrent programming.


On Fri, May 31, 2013 at 2:17 PM, Jeremy Spilman <jeremy@taplink.co> wrote:


I don't think that's optimal, no. That would slow down synchronization
drastically.

It would be really nimble for bitcoind to be able to synchronize at full
speed, and only send out events when necessary, batching together
previously queued items.
-------------------------------------
On 3/12/13, Mike Hearn <mike@plan99.net> wrote:

They have a vested interested in bitcoin's success. Can't they be
asked to suspend their operations temporarily until the new hard-fork
is properly prepared?

I thought they have stopped them already.


-------------------------------------
(not sure if you meant this to go to the list, my apologies if not)

On Mon, Nov 04, 2013 at 10:50:25AM -0500, Ittay wrote:

Right, but the thing is, if all miners quickly come to consensus and are
all mining on the same block, there's nothing the attacker can exploit
in the first place.

Suppose Alice the attacker is 100 blocks ahead of the main network
somehow. We'll say the other miners are working to extend block n, and
she's in posession of 100 blocks extending that. She also has just under
50% of the hashing power.

Now when the main network finds a block n+1, Alice can do one of two
things: she can publish her own n+1 block, or she can do nothing. If she
does nothing, the main network will find block n+2 faster than she finds
n+101, so eventually she loses. Thus she has to publish.

In your attack she publishes to a subset of nodes strategicly, splitting
the hashing power between nodes working to extend her n+1, and the other
n+1 found. However, with near-target headers, very quickly all hashing
power will come to consensus and all work to extend the same block,
either theirs or Alice's. Given that they have the majority, they will
find another block faster on average than Alice can extend her lead, and
thus eventually Alice will lose.

Now there is still a slight advantage for Alice in that it takes some
time for the whole network to come to consensus, but this is a much
slimmer margin, maybe a few percentage points, so at best Alice might
need, say, 45% of the total hashing power.

-- 
'peter'[:-1]@petertodd.org
0000000000000004b8381fe97338c8b710cb662160f08e391820f30a375bb9b9
-------------------------------------
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 02.11.2013 15:02, Mike Hearn wrote:
Maybe this is a bit off-topic, but the *real* answer to the question
"why-is-nobody-using-ssl-client-certificates" is that it would force
www pages to be encrypted and would make it a lot more difficult for
NSA to log www-trafic. So they have been made not-user-friendly by
default.

But what you think about this:
"White paper on passwordless secure login (based on bitcoin/bitmessage
technology)"
https://bitcointalk.org/index.php?topic=323360.0

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)
Comment: Using GnuPG with Thunderbird - http://www.enigmail.net/

iEYEARECAAYFAlJ0+/cACgkQvafo1Ths1Sw5FwCgxdJB/lazDzxRos1ogSfJQo0V
El4AnjyHxWjOXG6qjcTcWvccty+03xRa
=BikE
-----END PGP SIGNATURE-----


-------------------------------------

With this new minor bump, I'd like to encourage the project to perform
a build check on FreeBSD 8.3 (gcc), and 9.1 (should be clang/llvm).
I'll try to get to 8.x but may not be able to in time.


-------------------------------------
maybe make it so bitcoin.conf settings can be edited with in the app
instead of external editor,  and make it easier to enable rpc server mode...
-------------------------------------
On Wed, Jul 17, 2013 at 3:26 PM, Michael Gronager <gronager@mac.com> wrote:

This, however, reduces the node to SPV security of the past history.
Particularly for a wallet clientâ€” as opposed to a miner or what have
youâ€” if you are willing to accept SPV security you could simply be an
SPV client.

(I like committed UTXO trees, and I believe I was the first person to
suggest themâ€” but I think it's good to not over-hype what they do!)


-------------------------------------
On Mon, Apr 29, 2013 at 10:30:47PM +0800, Crypto Stick wrote:

A word of caution: hardware Bitcoin wallets really do need some type of
display so the wallet itself can tell you where the coins it is signing
are being sent, and that in turn implies support for the upcoming
payment protocol so the wallet can also verify that the address is
actually the address of the recipient the user is intending to send
funds too. The current Crypto Stick hardware doesn't even have a button
for user interaction. (press n times to approve an n-BTC spend)

Having said that PGP smart cards and USB keys already have that problem,
but the consequences of signing the wrong document are usually less than
the consequences of sending some or even all of the users funds to a
thief. You can usually revoke a bad signature after the fact with a
follow-up message.

Not to say hardware security for private keys isn't a bad thing, but the
protections are a lot more limited than users typically realize.


I will say though I am excited that this implies that the Crypto Stick
could have ECC key support in the future.

-- 
'peter'[:-1]@petertodd.org
-------------------------------------

As I've said to you on IRC before, I think the problem is with this loop:

https://github.com/bitcoin/bitcoin/blob/master/src/qt/sendcoinsdialog.cpp#L261

This deletes widgets, but Qt may still be referring to them internally, and
"Deleting a QObject while pending events are waiting to be delivered can
cause a crash."

Can you try replacing with ->deleteLater()?

Wladimir
-------------------------------------
Wrong patch?  This looks like node.js code for something called txtool.


-- 
Michael


On Fri, Nov 22, 2013 at 1:46 PM, Jeff Garzik <jgarzik@bitpay.com> wrote:

-------------------------------------
On Mon, May 20, 2013 at 08:54:25PM -0700, Gregory Maxwell wrote:

You can do better than that actually: you can arrange the transaction
such that the double-spender is hurt by asking them to pay an excess on
top of the initial payment, and having that excess get returned to them
in a subsequent transaction. Of course, that's trusting the merchant,
but you're trusting the merchant to ship to a product anyway so...

A really interesting example for this though would be applications where
you are making a deposit. You credit the customer account immediately
with half of the deposit amount, allowing them to immediately spend that
portion for something transferable. (perhaps an alt-coin) If the
customer tries to double-spend you burn half to fees, still leaving the
other half to pay for what they did spend. If they don't double-spend,
the rest of the balance becomes available after n confirmations. A
BTC->alt-coin exchange could use this mechanism for instance, although
it only works with widespread replace-by-fee adoption; blockchain.info's
shared-send service is another application, as is SatoshiDice. (the
failed bet tx can be the refund)

What's nice here is even if the customer tries to pay a miner to do the
dirty work, a short-term rational miner still has an incentive to screw
over the customer by accepting the merchant's double-spend. Now the
customer can promise the miner future business, but they've shown
themselves to be dishonest... how much honor is there among thieves?

-- 
'peter'[:-1]@petertodd.org
00000000000000f31f5cd20f915e3edb8e3fceea49580235b984fea63f1f882c
-------------------------------------
btw I posted some of this thread on the dev forum:

https://bitcointalk.org/index.php?topic=206303.msg2157994#msg2157994

A related idea is occuring to me that maybe these committed transactions
could actually as a side effect make bitcoin scale slightly better by
reducing the p2p flood filled transaction size.

As I said on the forum:


Surely its lower bandwidth for nodes to send only committed transactions to
the p2p network, and pass committed payment chains direct to recipients.

Say committed transaction size is c (20bytes+32bytes+16bytes +header ~ 72
bytes?) And full transaction smallest size is t (txin=20bytes, amount out
4bytes, sender pub key 32bytes, recip address 20bytes, change address
20bytes, formatting 5 bytes, ECDSA signature 64bytes, script 10 byte surely
~ 175bytes)?  Thats over twice the size.  Probably average more, and it is
sent to every node.  Its always going to be lower bandwidth to send
transactions to the recipients than to send to the network, even if you have
to increase the transaction size with each respend.  The alternative is for
the entire network to see the same transaction.

I think the commitment needs to bind the two parts together eg 

(blind-sender, auth-tag, tx-commit)

blind-sender = SHA1( SHA256( 1, pub ) )
auth = HMAC-SHA256-128( K, tx-commit )
tx-commit = SHA-256( tx )

Or some variantion, and you must not reuse the pub key, and must send change
if any to a different address, otherwise chain recipients or malicious
forwarders could lock your coin, by putting random junk onto the network
which would be unverifiable, and non-disclaimable - you cant prove you dont
know the preimage of some junk.  The MAC prevents it.  Maybe there's a more
compact way to do it even, but that works efficient demonstration of
security feasibility.

Other public key variants could be possible, P = xG is the ECDSA public key,
x the private key, G base point.  Sender could reveal P' = cP, c some fixed
constant (computing c from cP is ECDL problem considered oneway & hard), and
a signature by private key x' = cx over the tx-commit.  That is a publicly
auditable commitment also, but one tht can make an ECDSA signature over the
tx-commit hash, and can be revealed by revealing P later.  However that
imposes public key computation on the validation (which it already currently
does, but faster validation as above is nicer).  With that one you dont even
have to verify the transaction signature on reveal :)  You already did it,
just provide the tx that hashes to the signed hash, and P for the recipient
to verify the signature was made by cP.

Adam


-------------------------------------
On Mon, Jul 15, 2013 at 01:51:21AM +0000, Luke-Jr wrote:

I wasn't aware you denied that accusation, so my apologies; I retract
that statement.

-- 
'peter'[:-1]@petertodd.org
-------------------------------------
There are already descriptions as you describe on:
http://bitcoin.org/en/choose-your-wallet. 

If you hover over any of the wallet icons you get a description and a
link.

People being people, we find in practice that the very first wallet link 
on the page is what the majority of new users click.



On Fri, Jun 28, 2013, at 09:37 PM, Bill Hees wrote:


-- 
https://multibit.org    Money, reinvented


-------------------------------------
On Mon, Feb 25, 2013 at 09:44:58PM -0500, Peter Todd wrote:

One last thing: credit goes to Gregory Maxwell for his ideas about
adding unspent-chaum-token redemption op-codes to Bitcoin proper that
lead me down the path to the more general Fidelity-Bonded Ledger idea.

-- 
'peter'[:-1]@petertodd.org
-------------------------------------
On Fri, Aug 16, 2013 at 10:01:16AM -0400, Peter Todd wrote:

Oh, here's an even better way to do the "tx drop" attack: when you drop
a transaction, make a fake one that pays the same scriptPubKeys with the
same amount, and send it to the SPV peer instead. They'll see the
transaction go through and show up in their wallet, but it'll look like
it got stuck and never confirmed. They'll soon wind up with a wallet
full of useless transactions, effectively locking them out of their
money.

Here's another question for you Mike: So does bitcoinj have any
protections against peers flooding you with useless garbage? It'd be
easy to rack up a user's data bill for instance by just creating junk
unconfirmed transactions matching the bloom filter.

-- 
'peter'[:-1]@petertodd.org
0000000000000018dcf5bcc3f018a05517ba1c479b432ba422015d4506496e55
-------------------------------------
