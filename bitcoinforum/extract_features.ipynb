{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import gzip\n",
    "import pickle\n",
    "import openai\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\n",
    "    \"groupbuys\",\n",
    "    \"hardware\",\n",
    "    \"miners\",\n",
    "    \"mining\",\n",
    "    \"mining_support\",\n",
    "    \"pools\",\n",
    "]\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "#load every csv in the folder and append them\n",
    "for cat in categories:\n",
    "    with gzip.open('cleaned-data/'+cat+'.pkl.gz', 'rb') as f:\n",
    "        df_cat = pickle.load(f)\n",
    "        df_cat['category'] = cat\n",
    "        df = pd.concat([df, df_cat], ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_openai_response(prompt, tokens = 2000, model=\"gpt-3.5-turbo-instruct\"):\n",
    "    if model.__contains__(\"instruct\"):\n",
    "        response = openai.Completion.create(\n",
    "            model=model,\n",
    "            prompt=prompt,\n",
    "            temperature=0,\n",
    "            max_tokens=tokens,\n",
    "            top_p=1,\n",
    "            logit_bias = {\n",
    "                \"198\": -100, # new lines\n",
    "                },\n",
    "            logprobs= 15,\n",
    "        )\n",
    "        text = response.choices[0].text\n",
    "\n",
    "        return text\n",
    "    else:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"You are a helpful assistant\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt\n",
    "                }\n",
    "                ],\n",
    "            temperature=0,\n",
    "            max_tokens=tokens,\n",
    "            top_p=1,\n",
    "        )\n",
    "        text = response.choices[0].message.content\n",
    "\n",
    "\n",
    "        # print(\"returning ai text:\", text)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hardware name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"datasets/extracted/\"\n",
    "file_name = \"hardware_name.csv\"\n",
    "\n",
    "prompt_start = \"\"\"\n",
    "You are a bitcoin mining expert. Your task is to analyze if a forum thread contains a name of mining hardware. \n",
    "\n",
    "Here is a thread from a bitcoin forum:\n",
    "\"\"\".strip()\n",
    "\n",
    "prompt_end = \"\"\"\n",
    "Your task is to analyze if the thread contains a name of mining hardware. \n",
    "\n",
    "Example hardware names are ARM Cortex A9, X6500, AvalonMiner 1, Jupiter, RockerBox, BE300, PickAxe, Antminer S9 (there are many more)\n",
    "Sometimes common hardware is mentioned by its number only. For example, \"5870\" may refer to a Radeon card. \"S9\" may refer to the Antminer S9. Those are also valid hardware names.\n",
    "\n",
    "After reading the thread, write either \"Hardware found: Nothing\" or \"Hardware found: <hardware name>\".\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "if not os.path.exists(path+file_name):\n",
    "    dataset = pd.DataFrame()\n",
    "\n",
    "    thread_count = 0\n",
    "    for (id,row) in df.sample(10000).iterrows():\n",
    "        if(len(row[\"post\"]) < 100):\n",
    "            continue\n",
    "\n",
    "        date = row[\"dates\"].split(\"<sep>\")[-1]\n",
    "\n",
    "        thread = \"\"\n",
    "        # thread += \"Category: \" + row[\"category\"] + \"\\n\"\n",
    "        thread += \"Topic: \" + row[\"topic\"] + \"\\n\"\n",
    "        thread += \"Date: \" + date[:7] + \"\\n\\n\"\n",
    "        thread += \"### Original post:\\n\"\n",
    "        i = 1\n",
    "        for (post, date) in zip(row[\"post\"].split(\"<sep>\"), row[\"dates\"].split(\"<sep>\")):\n",
    "            if len(post) > 800:\n",
    "                thread += post[:800] + \"<rest of post truncated>\\n\\n\"\n",
    "                thread += f\"### Reply {i}:\\n\"\n",
    "                i += 1\n",
    "            elif len(post) < 5:\n",
    "                pass\n",
    "            else:\n",
    "                thread += post + \"\\n\\n\"\n",
    "                thread += f\"### Reply {i}:\\n\"\n",
    "                i += 1\n",
    "        #remove the last line\n",
    "        thread = thread[:-len(f\"### Reply {i-1}:\\n\")]\n",
    "        if len(thread) > 4000:\n",
    "            thread = thread[:4000] + \"<rest of thread truncated>\\n\"\n",
    "        \n",
    "        print(thread)\n",
    "\n",
    "        actual_prompt = prompt_start + \"\\n\" + thread + \"\\n\\n\\n\\n\\n\\n\\n\" + prompt_end + \"\\n\\n\\n\\n\\n\\n\\n\"\n",
    "        # print(actual_prompt)\n",
    "\n",
    "        response = get_openai_response(actual_prompt, tokens = 20)\n",
    "        print(\"response:\", response, \"\\n\\n\\n\\n\\n\\n\")\n",
    "\n",
    "        if \"Nothing\" in response:\n",
    "            continue\n",
    "\n",
    "        dataset = pd.concat([dataset, pd.DataFrame([{\n",
    "            \"date\": date[:-9],\n",
    "            \"hardware_name\": response.replace(\"Hardware found: \", \"\"),\n",
    "            }])], ignore_index=True)\n",
    "\n",
    "        thread_count += 1  \n",
    "        if thread_count > 20:\n",
    "            break\n",
    "        \n",
    "    print(dataset.value_counts())\n",
    "\n",
    "    #save the dataset\n",
    "    dataset.to_csv(path+file_name, index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hardware price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_name = \"hardware_price.csv\"\n",
    "\n",
    "# if not os.path.exists(path+file_name):\n",
    "#     prompt = \"\"\"\n",
    "# You are a bitcoin mining expert.\n",
    "\n",
    "# The will be given a thread from a bitcoin forum.\n",
    "\n",
    "# Your task is to analyze if the thread mentions a hardware price.\n",
    "\n",
    "# After reading the thread, write either \"Hardware price found: Nothing\" or \"Hardware price found: <hardware price>\".\n",
    "\n",
    "# The thread:\n",
    "#     \"\"\".strip()\n",
    "\n",
    "#     dataset = pd.DataFrame()\n",
    "\n",
    "#     thread_count = 0\n",
    "#     for (id,row) in df.sample(10000).iterrows():\n",
    "#         if(len(row[\"post\"]) < 100):\n",
    "#             continue\n",
    "#         # continue\n",
    "\n",
    "#         date = row[\"dates\"].split(\"<sep>\")[-1]\n",
    "\n",
    "#         thread = \"\"\n",
    "#         # thread += \"Category: \" + row[\"category\"] + \"\\n\"\n",
    "#         thread += \"Topic: \" + row[\"topic\"] + \"\\n\"\n",
    "#         thread += \"Date: \" + date[:7] + \"\\n\\n\"\n",
    "#         thread += \"### Original post:\\n\"\n",
    "#         i = 1\n",
    "#         for (post, date) in zip(row[\"post\"].split(\"<sep>\"), row[\"dates\"].split(\"<sep>\")):\n",
    "#             if len(post) > 800:\n",
    "#                 thread += post[:800] + \"<rest of post truncated>\\n\\n\"\n",
    "#                 thread += f\"### Reply {i}:\\n\"\n",
    "#                 i += 1\n",
    "#             elif len(post) < 5:\n",
    "#                 pass\n",
    "#             else:\n",
    "#                 thread += post + \"\\n\\n\"\n",
    "#                 thread += f\"### Reply {i}:\\n\"\n",
    "#                 i += 1\n",
    "#         #remove the last line\n",
    "#         thread = thread[:-len(f\"### Reply {i-1}:\\n\")]\n",
    "#         if len(thread) > 4000:\n",
    "#             thread = thread[:4000] + \"<rest of thread truncated>\\n\"\n",
    "\n",
    "#         # if not \"$\" in thread.lower():\n",
    "#         #     continue\n",
    "\n",
    "#         whitelist = [\n",
    "#             \"$\",\n",
    "#             \"usd\",\n",
    "#             \"dollar\",\n",
    "#             \"€\",\n",
    "#             \"eur\",\n",
    "#             \"euro\",\n",
    "#             \"£\",\n",
    "#             \"gbp\",\n",
    "#             \"pound\",\n",
    "#             \"yen\",\n",
    "#             \"jpy\",\n",
    "#             \"cny\",\n",
    "#             \"rmb\",\n",
    "#             \"yuan\",\n",
    "#             \"ruble\",\n",
    "#         ]\n",
    "\n",
    "#         if not any([x in thread.lower() for x in whitelist]):\n",
    "#             continue\n",
    "\n",
    "          \n",
    "#         print(thread)\n",
    "\n",
    "#         actual_prompt = prompt + \"\\n\" + thread + \"\\n\\n\\n\\n\\n\\n\\n\\n\" + \"\"\n",
    "#         # print(actual_prompt)\n",
    "\n",
    "#         response = get_openai_response(actual_prompt, tokens = 20)\n",
    "#         print(\"response:\", response, \"\\n\\n\\n\\n\\n\\n\")\n",
    "\n",
    "#         if \"Nothing\" in response:\n",
    "#             continue\n",
    "\n",
    "#         dataset = pd.concat([dataset, pd.DataFrame([{\n",
    "#             \"date\": date[:-9],\n",
    "#             \"hardware_price\": response.replace(\"Hardware price found: \", \"\").replace(\"<hardware price>\", \"\").strip(),\n",
    "#             }])], ignore_index=True)\n",
    "        \n",
    "#         thread_count += 1  \n",
    "#         if thread_count > 20:\n",
    "#             break\n",
    "        \n",
    "#     print(dataset.value_counts())\n",
    "\n",
    "#     #save the dataset\n",
    "#     dataset.to_csv(path+file_name, index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
