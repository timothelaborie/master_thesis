{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import builtins\n",
    "# original_print = print\n",
    "# def custom_print(*args, **kwargs):\n",
    "#     new_args = []\n",
    "#     for arg in args:\n",
    "#         if isinstance(arg, float):\n",
    "#             new_args.append(f'{arg:.10f}')\n",
    "#         else:\n",
    "#             new_args.append(arg)\n",
    "#     original_print(*new_args, **kwargs)\n",
    "# builtins.print = custom_print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from datetime import timedelta\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Define the variable name for the unit power efficiency column\n",
    "unit_power_efficiency = 'TH/J'\n",
    "\n",
    "# Load the data for the maximum efficiency for all dates\n",
    "max_efficiency_table = pd.read_csv('../../hardwarelist/Bitcoin max updated2.csv')\n",
    "\n",
    "# Assuming the 'Date' column in max_efficiency_table is in a format that can be converted to datetime\n",
    "max_efficiency_table['date'] = pd.to_datetime(max_efficiency_table['date'])\n",
    "\n",
    "data = pd.read_csv('../5_processing_extracted_data/plotdata.csv') # date,row_index,hardware_name,TH/J,max_efficiency,year\n",
    "\n",
    "# Convert the 'date' column to a datetime format\n",
    "data['date'] = pd.to_datetime(data['date'])\n",
    "\n",
    "# keep only data from 2013 onwards\n",
    "# data = data[data['date'] >= '2013-01-01']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# econometrics\n",
    "\n",
    "# Step 1: Average the data points on a monthly basis\n",
    "# Ensure that 'TH/J' is a numeric type\n",
    "data['TH/J'] = pd.to_numeric(data['TH/J'], errors='coerce')\n",
    "\n",
    "# Create a 'month' column by offsetting the 'date' by 15 days and then using to_period\n",
    "data['month'] = (data['date'] - timedelta(days=15)).dt.to_period('Q')\n",
    "\n",
    "# Group by 'month' and calculate the mean of 'TH/J'\n",
    "monthly_data = data.groupby('month')['TH/J'].mean().reset_index()\n",
    "\n",
    "# Convert 'month' back to datetime (first day of the month)\n",
    "monthly_data['month'] = monthly_data['month'].dt.to_timestamp()\n",
    "\n",
    "# Step 2: Create a time series for power efficiency\n",
    "# Create the time variable t (in months)\n",
    "monthly_data['t'] = np.arange(len(monthly_data))+1\n",
    "\n",
    "# Then, create t^2\n",
    "monthly_data['t_squared'] = monthly_data['t'] ** 2\n",
    "\n",
    "# Get the maximum power efficiency over time\n",
    "def get_max_efficiency(date):\n",
    "    date = str(date)[:10]\n",
    "    try:\n",
    "        return max_efficiency_table[max_efficiency_table['date'] == date]['max (TH/J)'].values[0]\n",
    "    except:\n",
    "        return -1\n",
    "monthly_data['P_max_t'] = monthly_data['month'].apply(lambda x: get_max_efficiency(x))\n",
    "\n",
    "# Create the log of P_max_t\n",
    "monthly_data['log_P_max_t'] = np.log(monthly_data['P_max_t'])\n",
    "\n",
    "# Convert 't' to float to avoid issues with negative powers\n",
    "monthly_data['t'] = monthly_data['t'].astype(float)\n",
    "\n",
    "# Define the range of lags to test for the AR and MA components\n",
    "p_range = range(1, 5)  # AR component\n",
    "q_range = range(1, 5)  # MA component\n",
    "\n",
    "best_aic = np.inf\n",
    "best_bic = np.inf\n",
    "best_order = None\n",
    "best_model_fit = None\n",
    "\n",
    "# Loop over the range of p and q values\n",
    "for p in p_range:\n",
    "    for q in q_range:\n",
    "        try:\n",
    "            # Fit the ARIMA model with the current p and q values\n",
    "            model = ARIMA(monthly_data['TH/J'], order=(p, 1, q))\n",
    "            model_fit = model.fit()\n",
    "            \n",
    "            # Check if the current model has a lower AIC or BIC than the best one found so far\n",
    "            if model_fit.aic < best_aic or model_fit.bic < best_bic:\n",
    "                best_aic = model_fit.aic\n",
    "                best_bic = model_fit.bic\n",
    "                best_order = (p, 1, q)\n",
    "                best_model_fit = model_fit\n",
    "        except Exception as e:\n",
    "            print(f\"ARIMA({p},0,{q}) - Model failed to fit: {e}\")\n",
    "\n",
    "# Print the best model's AIC, BIC, and order\n",
    "print(f\"Best ARIMA model order: {best_order}\")\n",
    "print(f\"Best ARIMA model AIC: {best_aic}\")\n",
    "print(f\"Best ARIMA model BIC: {best_bic}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the parameter values from the best model fit\n",
    "params = best_model_fit.params\n",
    "param_str = ', '.join([f'{key}={value:.3f}' for key, value in params.items()])\n",
    "\n",
    "dpi = 110\n",
    "\n",
    "# Step 4: Plot single point for each month + all the data points using the best model\n",
    "plt.figure(figsize=(12, 8), dpi=dpi)\n",
    "plt.scatter(data['date'], np.log(data[unit_power_efficiency]), c='gray', s=5, label='BitcoinTalk.org data collected with LLM', alpha=0.5)\n",
    "plt.scatter(monthly_data['month'], np.log(monthly_data['TH/J']), c='red', s=50, label='Data monthly averaged', alpha=0.5)\n",
    "plt.plot(max_efficiency_table['date'], np.log(max_efficiency_table['max (TH/J)']), color='gray', label='ln($P_{max}$)', linewidth=2)\n",
    "plt.plot(monthly_data['month'][1:], np.log(best_model_fit.fittedvalues[1:]), label='Model: ln($\\hat{P}_{eff}$)', linestyle='--')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('ln($\\hat{P}_{eff}$) (TH/J)')\n",
    "plt.yscale('linear')\n",
    "plt.legend()\n",
    "plt.grid(which='major', linestyle='-', linewidth='0.5', color='black')\n",
    "plt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\n",
    "plt.minorticks_on()\n",
    "\n",
    "# Update the box with model details\n",
    "ar_params = ', '.join([f'ar.L{i}={params[f\"ar.L{i}\"]:.1e}' for i in range(1, best_order[0]+1)])\n",
    "ma_params = ', '.join([f'ma.L{i}={params[f\"ma.L{i}\"]:.1e}' for i in range(1, best_order[2]+1)])\n",
    "sigma = params['sigma2']**0.5\n",
    "\n",
    "textstr = '\\n'.join((\n",
    "    f'Formula:',\n",
    "    r'ln($\\hat{P}_{eff,t}$) = ar.L1 * ln($\\hat{P}_{eff,t-1}$) + ar.L2 * ln($\\hat{P}_{eff,t-2}$) + ma.L1 * $ε_{t-1}$ + $ε_t$',\n",
    "    f'AR, order p={best_order[0]}, with {ar_params}',\n",
    "    f'MA, order q={best_order[2]}, with {ma_params}',\n",
    "    f'Error term variance, σ={sigma:.1e}',\n",
    "    f'Error term Ljung-Box test, p = 8.5e-01',\n",
    "    f'Model estimated through minimizing AIC and BIC',\n",
    "    f'Stationarity of first derivative tested with ADF, p = 9.9e-26',\n",
    "    f'Samples count: {len(data)}',\n",
    "))\n",
    "props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "# Adjust the position of the box to be next to the plot\n",
    "plt.gca().text(0.45, 0.44, textstr, transform=plt.gca().transAxes, fontsize=10,\n",
    "        verticalalignment='top', bbox=props)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Step 5: Plot P_eff,t(t) + Single point for each month, excluding the first month from the fitted line using the best model\n",
    "plt.figure(figsize=(12, 8), dpi=dpi)\n",
    "# Exclude the first month from the fitted values line\n",
    "plt.plot(monthly_data['month'][1:], best_model_fit.fittedvalues[1:], label='Fitted Values (Best Model)')\n",
    "plt.scatter(monthly_data['month'], monthly_data['TH/J'], c='red', s=50, label='Monthly Average', alpha=0.5)\n",
    "plt.plot(max_efficiency_table['date'], max_efficiency_table['max (TH/J)'], color='gray', label='Max possible (TH/J)', linewidth=2)\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Step 6: Plot with just the residual term using the best model, without connecting lines\n",
    "plt.figure(figsize=(12, 8), dpi=dpi)\n",
    "plt.scatter(monthly_data['month'], best_model_fit.resid, marker='*', label='Residuals (Best Model)')\n",
    "plt.yscale('linear')  # Use a linear scale to better visualize the wave pattern\n",
    "plt.xlabel('Time')  # Label for the x-axis\n",
    "plt.ylabel('Residuals')  # Label for the y-axis\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with the model's fitted values\n",
    "model_values_df = pd.DataFrame({\n",
    "    'month': monthly_data['month'][1:],  # Exclude the first month as it doesn't have a fitted value\n",
    "    'model_value': best_model_fit.fittedvalues[1:]\n",
    "})\n",
    "model_values_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Merge the model_values_df with monthly_data\n",
    "# Note: Ensure that both DataFrames have the 'date' column in the same format for a successful merge\n",
    "combined_data = pd.merge(monthly_data, model_values_df, how='left', left_on='month', right_on='month')\n",
    "\n",
    "# Drop the additional 'date' column from the merge, if needed\n",
    "# combined_data.drop('month', axis=1, inplace=True)\n",
    "\n",
    "# Export the combined_data DataFrame to a CSV file\n",
    "combined_data.to_csv('model_and_monthly_data.csv', index=False) # month,TH/J,t,t_squared,P_max_t,log_P_max_t,model_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_eff = pd.read_csv('../../hardwarelist/Bitcoin max updated2.csv') # date,max (TH/J),useless,archaicity (TH/J)\n",
    "\n",
    "# we need a csv with\n",
    "#Date (day by day from 2009)\n",
    "#ln(P_max) (TH/J)\n",
    "#Data monthly average (please put the same value for every day monthly, instead of Na, and then it just changes monthly)\n",
    "#Model ln(P_eff)\n",
    "\n",
    "max_eff[\"month\"] = max_eff[\"date\"].apply(lambda x: x[:7]+\"-01\")\n",
    "max_eff[\"month\"] = pd.to_datetime(max_eff[\"month\"])\n",
    "max_eff[\"ln(P_max)\"] = np.log(max_eff[\"max (TH/J)\"])\n",
    "# max_eff = max_eff[[\"month\",\"ln(P_max)\"]]\n",
    "\n",
    "combined_data[\"month\"] = pd.to_datetime(combined_data[\"month\"])\n",
    "\n",
    "data2 = pd.merge(max_eff, combined_data, how='left', left_on='month', right_on='month')\n",
    "data2 = data2[[\"date\",\"ln(P_max)\",\"TH/J\",\"model_value\"]]\n",
    "data2 = data2.rename(columns={\"date\":\"Date\",\"ln(P_max)\":\"ln(P_max)\",\"TH/J\":\"Data monthly average\",\"model_value\":\"Model ln(P_eff)\"})\n",
    "\n",
    "# forward fill the missing values\n",
    "data2 = data2.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.to_csv('model_and_monthly_data_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(param_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "\n",
    "# Perform the Ljung-Box test on the residuals\n",
    "lb_test_result = acorr_ljungbox(best_model_fit.resid, lags=[10], return_df=True)\n",
    "\n",
    "# Display the test results\n",
    "print(lb_test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# Perform Augmented Dickey-Fuller test\n",
    "adf_result = adfuller(monthly_data['TH/J'].dropna())\n",
    "\n",
    "print('ADF Statistic: %f' % adf_result[0])\n",
    "print('p-value: %f' % adf_result[1])\n",
    "print('Critical Values:')\n",
    "for key, value in adf_result[4].items():\n",
    "    print('\\t%s: %.3f' % (key, value))\n",
    "\n",
    "# Interpretation\n",
    "if adf_result[1] < 0.05:\n",
    "    print(\"The time series is stationary with 95% confidence.\")\n",
    "else:\n",
    "    print(\"The time series is not stationary with 95% confidence.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# Calculate the first derivative of the time series\n",
    "monthly_data['TH/J_diff'] = monthly_data['TH/J'].diff()\n",
    "\n",
    "# Drop the first row since it will be NaN after differencing\n",
    "monthly_data_diff = monthly_data.dropna(subset=['TH/J_diff'])\n",
    "\n",
    "# Perform the Augmented Dickey-Fuller test\n",
    "adf_result = adfuller(monthly_data_diff['TH/J_diff'])\n",
    "\n",
    "print('ADF Statistic: %f' % adf_result[0])\n",
    "print('p-value: %f' % adf_result[1])\n",
    "print('Critical Values:')\n",
    "for key, value in adf_result[4].items():\n",
    "    print('\\t%s: %.3f' % (key, value))\n",
    "\n",
    "# Interpret the results\n",
    "if adf_result[1] < 0.05:\n",
    "    print(\"The first derivative of the time series is stationary.\")\n",
    "else:\n",
    "    print(\"The first derivative of the time series is not stationary.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # looks like:\n",
    "# # [\n",
    "# #  (Timestamp('2011-08-04 00:00:00'), 1.9952745454545455e-06),\n",
    "# #  (Timestamp('2012-12-31 00:00:00'), 3.2042489473684216e-05),\n",
    "# #  (Timestamp('2013-12-21 00:00:00'), 0.0005635879322033898)\n",
    "# # ]\n",
    "# regression_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(columns=['date', 'max possible', 'archaicity', 'max found', 'regression'])\n",
    "# df['date'] = max_efficiency_table['date']\n",
    "# df['max possible'] = max_efficiency_table['max (TH/J)']\n",
    "# df['archaicity'] = max_efficiency_table['archaicity (TH/J)']\n",
    "\n",
    "\n",
    "# # finds the 2 closest timestamps in regression_lines and returns the interpolated value\n",
    "# def get_regression(date):\n",
    "#     closest_smaller_timestamp_index = None\n",
    "#     closest_larger_timestamp_index = None\n",
    "#     for (i,(timestamp, value)) in enumerate(regression_lines):\n",
    "#         if timestamp <= date:\n",
    "#             closest_smaller_timestamp_index = i\n",
    "#         else:\n",
    "#             closest_larger_timestamp_index = i\n",
    "#             break\n",
    "    \n",
    "#     if closest_smaller_timestamp_index is None:\n",
    "#         return regression_lines[0][1]\n",
    "#     elif closest_larger_timestamp_index is None:\n",
    "#         return regression_lines[-1][1]\n",
    "    \n",
    "#     smaller_value = regression_lines[closest_smaller_timestamp_index][1]\n",
    "#     larger_value = regression_lines[closest_larger_timestamp_index][1]\n",
    "\n",
    "#     # interpolate\n",
    "#     return smaller_value + (larger_value - smaller_value) * (date - regression_lines[closest_smaller_timestamp_index][0]) / (regression_lines[closest_larger_timestamp_index][0] - regression_lines[closest_smaller_timestamp_index][0])\n",
    "\n",
    "     \n",
    "# df['regression'] = df['date'].apply(get_regression)\n",
    "\n",
    "# # gets the max efficiency for a given date from the data table\n",
    "# def get_max_efficiency(date):\n",
    "#     return data[data['date'] == date][unit_power_efficiency].max()\n",
    "\n",
    "# df['max found'] = df['date'].apply(get_max_efficiency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.sample(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('plot.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
