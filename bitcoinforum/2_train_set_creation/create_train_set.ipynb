{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import gzip\n",
    "import pickle\n",
    "from openai import OpenAI\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_openai_response(prompt):\n",
    "    tokens = 1000\n",
    "    model=\"gpt-4-turbo-preview\"\n",
    "    # model=\"gpt-3.5-turbo-0125\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "            ],\n",
    "        temperature=0,\n",
    "        max_tokens=tokens,\n",
    "        top_p=1,\n",
    "    )\n",
    "    choice = response.choices[0]\n",
    "\n",
    "    text = choice.message.content\n",
    "\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_thread(row):\n",
    "    try:\n",
    "        date = row[\"dates\"].split(\"<sep>\")[-1]\n",
    "\n",
    "        thread = \"\"\n",
    "        thread += \"Date: \" + date[:7] + \"\\n\"\n",
    "        thread += \"Topic: \" + row[\"topic\"] + \"\\n\"        \n",
    "        thread += \"### Original post:\\n\"\n",
    "        i = 1\n",
    "        for (post, date) in zip(row[\"post\"].split(\"<sep>\"), row[\"dates\"].split(\"<sep>\")):\n",
    "            if len(post) > 1200:\n",
    "                thread += post[:1200] + \"<rest of post truncated>\\n\\n\"\n",
    "                thread += f\"### Reply {i}:\\n\"\n",
    "                i += 1\n",
    "            elif len(post) < 5:\n",
    "                pass\n",
    "            else:\n",
    "                thread += post + \"\\n\\n\"\n",
    "                thread += f\"### Reply {i}:\\n\"\n",
    "                i += 1\n",
    "        #remove the last line\n",
    "        thread = thread[:-len(f\"### Reply {i-1}:\\n\")]\n",
    "        if len(thread) > 5000:\n",
    "            thread = thread[:5000] + \"<rest of thread truncated>\\n\"\n",
    "\n",
    "        return row[\"index\"], date, thread\n",
    "\n",
    "    except:\n",
    "        print(\"Error processing thread:\" + str(row[\"index\"]))\n",
    "        return None, None, None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refresh_df = False\n",
    "# refresh_df = True\n",
    "\n",
    "if refresh_df:\n",
    "    categories = [\n",
    "        \"groupbuys\",\n",
    "        \"hardware\",\n",
    "        \"miners\",\n",
    "        \"mining\",\n",
    "        \"mining_support\",\n",
    "        # \"pools\",\n",
    "    ]\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    #load every csv in the folder and append them\n",
    "    for cat in categories:\n",
    "        with gzip.open('../1_forum_dataset/cleaned-data/'+cat+'.pkl.gz', 'rb') as f:\n",
    "            df_cat = pickle.load(f)\n",
    "            df_cat['category'] = cat\n",
    "            df = pd.concat([df, df_cat], ignore_index=True)\n",
    "\n",
    "    df[\"index\"] = df.index\n",
    "    df.to_csv(\"concatenated_threads.csv\", index=False)\n",
    "\n",
    "else:\n",
    "    df = pd.read_csv(\"concatenated_threads.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "path = \"./\"\n",
    "file_name = \"dataset.csv\"\n",
    "\n",
    "already_processed_thread_ids = []\n",
    "\n",
    "if not os.path.exists(path+file_name):\n",
    "    dataset = pd.DataFrame(columns=['index','input','output'])    \n",
    "else:\n",
    "    dataset = pd.read_csv(path+file_name)\n",
    "    already_processed_thread_ids = dataset['index'].tolist()\n",
    "\n",
    "# for each unique year, sample x threads\n",
    "x = 230\n",
    "df2 = df.sample(24000,random_state=44)\n",
    "rows = pd.DataFrame()\n",
    "unique_years = np.arange(2010, 2023+1)\n",
    "year_counts = {year: 0 for year in unique_years}\n",
    "for i in range(len(df2)):\n",
    "    index, date, thread = process_thread(df2.iloc[i])\n",
    "    if index is None:\n",
    "        continue\n",
    "    year = int(date[:4])\n",
    "    if year_counts[year] < x:\n",
    "        rows = pd.concat([rows, pd.DataFrame(df2.iloc[i]).T], ignore_index=True)\n",
    "        year_counts[year] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_rows', None)\n",
    "# rows.sort_values(by=\"date\", inplace=True)\n",
    "# rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"User:\n",
    "In the given Bitcoin forum thread, pay close attention to the language used when mentioning hardware pieces. Look for explicit statements indicating ownership or hypothetical discussions.\n",
    "\n",
    "{}\n",
    "\n",
    "\n",
    "\n",
    "Reply with a formatted JSON document containing an array of objects. Each object should represent a piece of hardware mentioned in the thread and include the following fields:\n",
    "- hardware_name: A string containing the name of the hardware.\n",
    "- hardware_is_owned: A boolean. If the mention suggests concrete ownership by any user, write true. If the hardware is discussed in a hypothetical or speculative way, write false. \n",
    "\n",
    "\n",
    "Assistant:\n",
    "Sure! Here is the requested JSON file, with the correct ownership status for each piece of hardware:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices, dates, threads = [], [], []\n",
    "for j in range(len(rows)):\n",
    "    row = rows.iloc[j]\n",
    "    if(len(row[\"post\"]) < 20):\n",
    "        print(f\"skipping {j} as it is too short\")\n",
    "        continue\n",
    "\n",
    "    id, date, thread = process_thread(row)\n",
    "\n",
    "    if id in already_processed_thread_ids:\n",
    "        print(f\"Skipping thread {id} as it is already processed\")\n",
    "        continue\n",
    "\n",
    "    indices.append(id)\n",
    "    dates.append(date)\n",
    "    threads.append(thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# for (date, thread) in tqdm(zip(dates, threads), total=len(dates)):\n",
    "for (threadid, date, thread) in zip(indices, dates, threads):\n",
    "\n",
    "    \n",
    "    print(f\"processing thread id {threadid}\\n\\n\"+ thread + \"\\n\\n\")\n",
    "\n",
    "    prompt2 = prompt.format(thread)\n",
    "    \n",
    "\n",
    "    response = get_openai_response(prompt2)\n",
    "\n",
    "    print(\"model response: \\n\\n\"+response+\"\\n\\n\\n\")\n",
    "\n",
    "    if not response.__contains__(\"```json\"):\n",
    "        print(\"ERROR: response does not contain JSON\")\n",
    "        continue\n",
    "\n",
    "    response = response.replace(\"```json\\n\",\"\")\n",
    "    response = response.split(\"```\")[0].strip()\n",
    "\n",
    "    print(\"parsed response: \\n\\n\"+response+\"\\n\\n\\n\")\n",
    "\n",
    "    try:\n",
    "        _ = json.loads(response)\n",
    "    except:\n",
    "        print(\"ERROR: could not parse response as JSON\")\n",
    "        continue\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Append the new rows to the dataset\n",
    "    input = thread\n",
    "    output = response\n",
    "    dataset = pd.concat([dataset, pd.DataFrame({'index': [threadid],'input': [input], 'output': [output]})], ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "    dataset.to_csv(path+file_name, index=False)\n",
    "    threadid+=1\n",
    "\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv(\"dataset.csv\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create inputs that will be given to trained model\n",
    "inputs = pd.DataFrame()\n",
    "for i in range(len(df)):\n",
    "    date, thread = process_thread(df.iloc[i])\n",
    "    prompt2 = prompt.format(thread)\n",
    "    inputs = pd.concat([inputs, pd.DataFrame({'input': [prompt2]})], ignore_index=True)\n",
    "\n",
    "\n",
    "inputs.to_csv(\"inputs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inputs.iloc[0].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
