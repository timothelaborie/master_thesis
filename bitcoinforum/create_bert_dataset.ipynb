{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import gzip\n",
    "import pickle\n",
    "import openai\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\n",
    "    \"groupbuys\",\n",
    "    \"hardware\",\n",
    "    \"miners\",\n",
    "    \"mining\",\n",
    "    \"mining_support\",\n",
    "    \"pools\",\n",
    "]\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "#load every csv in the folder and append them\n",
    "for cat in categories:\n",
    "    with gzip.open('cleaned-data/'+cat+'.pkl.gz', 'rb') as f:\n",
    "        df_cat = pickle.load(f)\n",
    "        df_cat['category'] = cat\n",
    "        df = pd.concat([df, df_cat], ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_openai_response(prompt, tokens = 2000, model=\"gpt-3.5-turbo-instruct\"):\n",
    "    if model.__contains__(\"instruct\"):\n",
    "        response = openai.Completion.create(\n",
    "            model=model,\n",
    "            # messages=[\n",
    "            #     {\n",
    "            #         \"role\": \"system\",\n",
    "            #         \"content\": \"Answer the prompt with a single word\"\n",
    "            #     },\n",
    "            #     {\n",
    "            #         \"role\": \"user\",\n",
    "            #         \"content\": prompt\n",
    "            #     }\n",
    "            #     ],\n",
    "            prompt=prompt,\n",
    "            temperature=0,\n",
    "            max_tokens=tokens,\n",
    "            top_p=1,\n",
    "            logit_bias = {\n",
    "                \"198\": -100, # new lines\n",
    "                },\n",
    "            logprobs= 15,\n",
    "        )\n",
    "        text = response.choices[0].text\n",
    "        # print(response.choices[0].logprobs)\n",
    "\n",
    "        # print(\"returning ai text:\", text)\n",
    "        # return text\n",
    "        logits = response.choices[0].logprobs.top_logprobs[0]\n",
    "        yes = logits[\"Yes\"]\n",
    "        no = logits[\"No\"]\n",
    "        # print(\"yes:\", yes, \"no:\", no)\n",
    "        return {\"yes\": yes, \"no\": no, \"positive\": F.softmax(torch.tensor([yes, no]), dim=0)[0].item()}\n",
    "    else:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"You are a helpful assistant\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt\n",
    "                }\n",
    "                ],\n",
    "            temperature=0,\n",
    "            max_tokens=tokens,\n",
    "            top_p=1,\n",
    "        )\n",
    "        text = response.choices[0].message.content\n",
    "\n",
    "\n",
    "        # print(\"returning ai text:\", text)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "You are a bitcoin mining expert.\n",
    "\n",
    "The will be given a thread from a bitcoin forum.\n",
    "\n",
    "Your task is to analyze if the thread contains a name of mining hardware. \n",
    "\n",
    "Example hardware names are ARM Cortex A9, X6500, AvalonMiner 1, Jupiter, RockerBox, BE300, PickAxe, Antminer S9 (there are many more)\n",
    "Sometimes common hardware is mentioned by its number only. For example, \"5870\" may refer to a Radeon card. \"S9\" may refer to the Antminer S9. Those are also valid hardware names.\n",
    "\n",
    "If the thread contains a name of mining hardware, say \"Yes\", followed by its name. Otherwise, say \"No\".\n",
    "\n",
    "The thread:\n",
    "\"\"\".strip()\n",
    "\n",
    "dataset = []\n",
    "\n",
    "for (id,row) in df.sample(2).iterrows():\n",
    "    if(len(row[\"post\"]) < 100):\n",
    "        continue\n",
    "    # continue\n",
    "\n",
    "    thread = \"\"\n",
    "    thread += \"category: \" + row[\"category\"] + \"\\n\"\n",
    "    thread += \"topic: \" + row[\"topic\"] + \"\\n\"\n",
    "    thread += \"date: \" + row[\"dates\"].split(\"<sep>\")[-1][:7] + \"\\n\\n\"\n",
    "    thread += \"### Original post:\\n\"\n",
    "    i = 1\n",
    "    for (post, date) in zip(row[\"post\"].split(\"<sep>\"), row[\"dates\"].split(\"<sep>\")):\n",
    "        if len(post) > 800:\n",
    "            thread += post[:800] + \"<rest of post truncated>\\n\\n\"\n",
    "            thread += f\"### Reply {i}:\\n\"\n",
    "            i += 1\n",
    "        elif len(post) < 5:\n",
    "            pass\n",
    "        else:\n",
    "            thread += post + \"\\n\\n\"\n",
    "            thread += f\"### Reply {i}:\\n\"\n",
    "            i += 1\n",
    "    #remove the last line\n",
    "    thread = thread[:-len(f\"### Reply {i-1}:\\n\")]\n",
    "    if len(thread) > 4000:\n",
    "        thread = thread[:4000] + \"<rest of thread truncated>\\n\"\n",
    "    \n",
    "    # print(thread)\n",
    "\n",
    "    actual_prompt = prompt + \"\\n\" + thread + \"\\n\\n\\n\\n\" + \"\"\n",
    "    # print(actual_prompt)\n",
    "\n",
    "    response = get_openai_response(actual_prompt, tokens = 3)\n",
    "    # print(\"response:\", response)\n",
    "\n",
    "    dataset.append({\n",
    "        \"thread\": thread,\n",
    "        \"response\": response,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the dataset\n",
    "torch.save(dataset, \"datasets/hardware_name.pt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = \"\"\"\n",
    "# You are a bitcoin mining expert.\n",
    "\n",
    "# The will be given a thread from a bitcoin forum.\n",
    "\n",
    "# Your task is to analyze if the thread contains a name of mining hardware. \n",
    "\n",
    "# Example hardware names are ARM Cortex A9, X6500, AvalonMiner 1, Jupiter, RockerBox, BE300, PickAxe, Antminer S9 (there are many more)\n",
    "# Sometimes common hardware is mentioned by its number only. For example, \"5870\" may refer to a Radeon card. \"S9\" may refer to the Antminer S9. Those are also valid hardware names.\n",
    "\n",
    "# If the thread contains a name of mining hardware, say \"Yes\", followed by its name. Otherwise, say \"No\".\n",
    "\n",
    "# The thread:\n",
    "# \"\"\".strip()\n",
    "\n",
    "# # thread = \"\"\"\n",
    "# # category: mining_support\n",
    "# # topic: Any help? - 5970 not hitting ~700 mhash/s\n",
    "# # date: 2012-02\n",
    "\n",
    "# # original post:\n",
    "# # Just got my 5970 in the mail and got it set up and it's getting me only ~550 mhash/s using GUIMiner.\n",
    "\n",
    "# # reply 1:\n",
    "# # Look for SDK 2.1.\n",
    "# # \"\"\".strip()\n",
    "\n",
    "# # thread = \"\"\"\n",
    "# # category: pools\n",
    "# # topic: Ghash.io good or bad\n",
    "# # date: 2014-01\n",
    "# # original post:\n",
    "# # do you think that ghash.iois good or bad pool??//\n",
    "\n",
    "# # reply 1:\n",
    "# # The pool is not bad but be prepared to sometime lose and other times to win. As a mining pool not bad as very good total hash.\n",
    "\n",
    "# # reply 2:\n",
    "# # Good if we use great hardware for mining :d\n",
    "# # Nothing wrong with the pool itself, but their closing in on 51% is VERY BAD.\n",
    "# # \"\"\".strip()\n",
    "\n",
    "# thread = \"\"\"\n",
    "# category: mining\n",
    "# topic: Recommended Safety & Cooling\n",
    "# date: 2015-10\n",
    "\n",
    "# ### Original post:\n",
    "# Hey Again Everyone!Well, I am up and running now! I did shutdown my unit last night because the units fan was LOUD! I want to make sure I am running this safe and have proper cooling! I have a extra room in the grudge that is air conditioned but I would need to connect the S5 via Wi-Fi. Any tips?\n",
    "# \"\"\".strip()\n",
    "\n",
    "# actual_prompt = prompt + \"\\n\" + thread + \"\\n\\n\\n\\n\\n\\n\\n\\n\" + \"\"\n",
    "\n",
    "# print(actual_prompt)\n",
    "\n",
    "\n",
    "# response = get_openai_response(actual_prompt, tokens = 10)\n",
    "# # response = get_openai_response(prompt + \"\\n\" + thread, tokens = 3, model=\"gpt-4\")\n",
    "# print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
