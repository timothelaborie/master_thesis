{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import builtins\n",
    "original_print = print\n",
    "def custom_print(*args, **kwargs):\n",
    "    new_args = []\n",
    "    for arg in args:\n",
    "        if isinstance(arg, float):\n",
    "            new_args.append(f'{arg:.10f}')\n",
    "        else:\n",
    "            new_args.append(arg)\n",
    "    original_print(*new_args, **kwargs)\n",
    "builtins.print = custom_print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# max_efficiency_table = pd.read_csv('../hardwarelist/Bitcoin max updated2.csv')\n",
    "\n",
    "# # Assuming the 'Date' column in max_efficiency_table is in a format that can be converted to datetime\n",
    "# max_efficiency_table['date'] = pd.to_datetime(max_efficiency_table['date'])\n",
    "\n",
    "# data = pd.read_csv('datasets/extracted/final3.csv')\n",
    "# data[\"date\"] = data[\"date\"].apply(lambda x: x[:10])\n",
    "# data2 = pd.read_csv('datasets/extracted/pre_2018.csv')\n",
    "# data = pd.concat([data2[[\"date\",\"row_index\",\"hardware_name\",\"TH/J\"]], data[[\"date\",\"row_index\",\"hardware_name\",\"TH/J\"]]])\n",
    "\n",
    "# def get_max_efficiency(date):\n",
    "#     date = str(date)[:10]\n",
    "#     try:\n",
    "#         return max_efficiency_table[max_efficiency_table['date'] == date]['max (TH/J)'].values[0]\n",
    "#     except:\n",
    "#         return -1\n",
    "    \n",
    "\n",
    "# # delete rows where TH/J is larger than the max efficiency for that date\n",
    "# data['max_efficiency'] = data['date'].apply(lambda x: get_max_efficiency(x))\n",
    "# data = data[data['TH/J'] <= data['max_efficiency']*1.01]\n",
    "\n",
    "# data.to_csv('datasets/extracted/merged.csv', index=False)\n",
    "\n",
    "# # Convert the 'date' column to a datetime format\n",
    "# data['date'] = pd.to_datetime(data['date'])\n",
    "\n",
    "# # Extract year from the 'date' column and create a new column 'year'\n",
    "# data['year'] = data['date'].dt.year\n",
    "\n",
    "# data.to_csv('plotdata.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from datetime import timedelta\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Define the variable name for the unit power efficiency column\n",
    "unit_power_efficiency = 'TH/J'\n",
    "\n",
    "# Load the data for the maximum efficiency for all dates\n",
    "max_efficiency_table = pd.read_csv('../hardwarelist/Bitcoin max updated2.csv')\n",
    "\n",
    "# Assuming the 'Date' column in max_efficiency_table is in a format that can be converted to datetime\n",
    "max_efficiency_table['date'] = pd.to_datetime(max_efficiency_table['date'])\n",
    "\n",
    "data = pd.read_csv('plotdata.csv') # date,row_index,hardware_name,TH/J,max_efficiency,year\n",
    "\n",
    "# Convert the 'date' column to a datetime format\n",
    "data['date'] = pd.to_datetime(data['date'])\n",
    "\n",
    "# keep only data from 2013 onwards\n",
    "data = data[data['date'] >= '2013-01-01']\n",
    "\n",
    "# # Create a figure and axis\n",
    "# fig, ax = plt.subplots(figsize=(12, 8), dpi=300)\n",
    "\n",
    "# # Extract years from the data\n",
    "# years = data['year'].unique()\n",
    "\n",
    "# # Initialize lists to store yearly 'TH/J' values\n",
    "# th_j_values = []\n",
    "\n",
    "# # Create an empty array to store the regression lines\n",
    "# regression_lines = []\n",
    "\n",
    "# # Iterate over each year, calculate the slope, and store the data\n",
    "# for year in years:\n",
    "#     # Filter data for the current year\n",
    "#     yearly_data = data[data['year'] == year]\n",
    "\n",
    "#     # Calculate the mean 'TH/J' value for the year\n",
    "#     th_j_mean = yearly_data[unit_power_efficiency].mean()\n",
    "\n",
    "#     # Store the yearly 'TH/J' value\n",
    "#     th_j_values.append(th_j_mean)\n",
    "\n",
    "#     # Store the regression line for the year (point at the end of the year)\n",
    "#     end_of_year_date = yearly_data['date'].max()\n",
    "#     regression_lines.append((end_of_year_date, th_j_mean))\n",
    "\n",
    "# # Create a DataFrame to store the yearly 'TH/J' values and regression points\n",
    "# results = pd.DataFrame({'Year': years, unit_power_efficiency: th_j_values})\n",
    "\n",
    "# plt.rcParams['font.family'] = 'Times New Roman'\n",
    "\n",
    "# # Scatter plot for all data points\n",
    "# plt.scatter(data['date'], data[unit_power_efficiency], c='gray', s=5, label='Data Points', alpha=0.5)\n",
    "\n",
    "# # Plot the regression lines (one point per year)\n",
    "# regression_dates, regression_th_j_values = zip(*regression_lines)\n",
    "# plt.plot(regression_dates, regression_th_j_values, marker='o', linestyle='-', color='black', label=f'Yearly {unit_power_efficiency} Regression')\n",
    "\n",
    "# # Plot the Hardware (TH/J) line\n",
    "# plt.plot(max_efficiency_table['date'], max_efficiency_table['max (TH/J)'], color='gray', label='Max possible (TH/J)', linewidth=2)\n",
    "\n",
    "# plt.yscale('log')  # Set the y-axis to a logarithmic scale base 10\n",
    "\n",
    "\n",
    "# plt.xlabel('Date', fontname='Times New Roman', fontsize=12)\n",
    "# plt.ylabel('Power Efficiency (' + unit_power_efficiency + ')', fontname='Times New Roman')\n",
    "# # plt.title(f'Yearly-Updated {unit_power_efficiency} with Data Points and Max Efficiency', fontname='Times New Roman')\n",
    "# plt.legend(loc='upper left')\n",
    "\n",
    "# # Enable minor ticks\n",
    "# plt.minorticks_on()\n",
    "\n",
    "# # Add major grid to the plot\n",
    "# plt.grid(True, which='major', axis='both', linestyle='-', linewidth=0.5, color='gray', alpha=0.7)\n",
    "\n",
    "# # Add minor grid to the plot with a lighter style\n",
    "# plt.grid(True, which='minor', axis='both', linestyle=':', linewidth=0.25, color='gray', alpha=0.7)\n",
    "\n",
    "# plt.yticks()\n",
    "\n",
    "# plt.savefig('high_res_plot.png', dpi=300)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# econometrics\n",
    "\n",
    "# Step 1: Average the data points on a monthly basis\n",
    "# Ensure that 'TH/J' is a numeric type\n",
    "data['TH/J'] = pd.to_numeric(data['TH/J'], errors='coerce')\n",
    "\n",
    "# Create a 'month' column by offsetting the 'date' by 15 days and then using to_period\n",
    "data['month'] = (data['date'] - timedelta(days=15)).dt.to_period('M')\n",
    "\n",
    "# Group by 'month' and calculate the mean of 'TH/J'\n",
    "monthly_data = data.groupby('month')['TH/J'].mean().reset_index()\n",
    "\n",
    "# Convert 'month' back to datetime (first day of the month)\n",
    "monthly_data['month'] = monthly_data['month'].dt.to_timestamp()\n",
    "\n",
    "# Step 2: Create a time series for power efficiency\n",
    "# Create the time variable t (in months)\n",
    "monthly_data['t'] = np.arange(len(monthly_data))+1\n",
    "\n",
    "# Then, create t^2\n",
    "monthly_data['t_squared'] = monthly_data['t'] ** 2\n",
    "\n",
    "# Get the maximum power efficiency over time\n",
    "def get_max_efficiency(date):\n",
    "    date = str(date)[:10]\n",
    "    try:\n",
    "        return max_efficiency_table[max_efficiency_table['date'] == date]['max (TH/J)'].values[0]\n",
    "    except:\n",
    "        return -1\n",
    "monthly_data['P_max_t'] = monthly_data['month'].apply(lambda x: get_max_efficiency(x))\n",
    "\n",
    "# Create the log of P_max_t\n",
    "monthly_data['log_P_max_t'] = np.log(monthly_data['P_max_t'])\n",
    "\n",
    "# Convert 't' to float to avoid issues with negative powers\n",
    "monthly_data['t'] = monthly_data['t'].astype(float)\n",
    "\n",
    "# Define the range of lags to test for the AR and MA components\n",
    "p_range = range(1, 11)  # AR component\n",
    "q_range = range(1, 11)  # MA component\n",
    "\n",
    "best_aic = np.inf\n",
    "best_bic = np.inf\n",
    "best_order = None\n",
    "best_model_fit = None\n",
    "\n",
    "# Loop over the range of p and q values\n",
    "for p in p_range:\n",
    "    for q in q_range:\n",
    "        try:\n",
    "            # Fit the ARIMA model with the current p and q values\n",
    "            model = ARIMA(monthly_data['TH/J'], order=(p, 1, q))\n",
    "            model_fit = model.fit()\n",
    "            \n",
    "            # Check if the current model has a lower AIC or BIC than the best one found so far\n",
    "            if model_fit.aic < best_aic or model_fit.bic < best_bic:\n",
    "                best_aic = model_fit.aic\n",
    "                best_bic = model_fit.bic\n",
    "                best_order = (p, 1, q)\n",
    "                best_model_fit = model_fit\n",
    "        except Exception as e:\n",
    "            print(f\"ARIMA({p},0,{q}) - Model failed to fit: {e}\")\n",
    "\n",
    "# Print the best model's AIC, BIC, and order\n",
    "print(f\"Best ARIMA model order: {best_order}\")\n",
    "print(f\"Best ARIMA model AIC: {best_aic}\")\n",
    "print(f\"Best ARIMA model BIC: {best_bic}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the parameter values from the best model fit\n",
    "params = best_model_fit.params\n",
    "param_str = ', '.join([f'{key}={value:.3f}' for key, value in params.items()])\n",
    "\n",
    "dpi = 110\n",
    "\n",
    "# Step 4: Plot single point for each month + all the data points using the best model\n",
    "plt.figure(figsize=(12, 8), dpi=dpi)\n",
    "plt.scatter(data['date'], np.log(data[unit_power_efficiency]), c='gray', s=5, label='BitcoinTalk.org data collected with LLM', alpha=0.5)\n",
    "plt.scatter(monthly_data['month'], np.log(monthly_data['TH/J']), c='red', s=50, label='Data monthly averaged', alpha=0.5)\n",
    "plt.plot(max_efficiency_table['date'], np.log(max_efficiency_table['max (TH/J)']), color='gray', label='ln($P_{max}$)', linewidth=2)\n",
    "plt.plot(monthly_data['month'][1:], np.log(best_model_fit.fittedvalues[1:]), label='Model: ln($\\hat{P}_{eff}$)', linestyle='--')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('ln($\\hat{P}_{eff}$) (TH/J)')\n",
    "plt.yscale('linear')\n",
    "plt.legend()\n",
    "plt.grid(which='major', linestyle='-', linewidth='0.5', color='black')\n",
    "plt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\n",
    "plt.minorticks_on()\n",
    "\n",
    "# Update the box with model details\n",
    "ar_params = ', '.join([f'ar.L{i}={params[f\"ar.L{i}\"]:.3f}' for i in range(1, best_order[0]+1)])\n",
    "ma_params = ', '.join([f'ma.L{i}={params[f\"ma.L{i}\"]:.3f}' for i in range(1, best_order[2]+1)])\n",
    "sigma = params['sigma2']**0.5\n",
    "\n",
    "textstr = '\\n'.join((\n",
    "    f'formula:',\n",
    "    r'ln($\\hat{P}_{eff_t}$) = ar.L1 * ln($\\hat{P}_{eff_{t-1}}$) + ar.L2 * ln($\\hat{P}_{eff_{t-2}}$) + ma.L1 * $ε_{t-1}$ + ε_t',\n",
    "    f'AR, order p={best_order[0]}, with {ar_params}',\n",
    "    f'MA, order q={best_order[2]}, with {ma_params}',\n",
    "    f'error term variance, σ={sigma:.3f}',\n",
    "    f'Model estimated through minimizing AIC and BIC',\n",
    "    f'Stationarity of first derivative tested with ADF, p = 0.000',\n",
    "))\n",
    "props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "# Adjust the position of the box to be next to the plot\n",
    "plt.gca().text(0.45, 0.23, textstr, transform=plt.gca().transAxes, fontsize=10,\n",
    "        verticalalignment='top', bbox=props)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Step 5: Plot P_eff,t(t) + Single point for each month, excluding the first month from the fitted line using the best model\n",
    "plt.figure(figsize=(12, 8), dpi=dpi)\n",
    "# Exclude the first month from the fitted values line\n",
    "plt.plot(monthly_data['month'][1:], best_model_fit.fittedvalues[1:], label='Fitted Values (Best Model)')\n",
    "plt.scatter(monthly_data['month'], monthly_data['TH/J'], c='red', s=50, label='Monthly Average', alpha=0.5)\n",
    "plt.plot(max_efficiency_table['date'], max_efficiency_table['max (TH/J)'], color='gray', label='Max possible (TH/J)', linewidth=2)\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Step 6: Plot with just the residual term using the best model\n",
    "plt.figure(figsize=(12, 8), dpi=dpi)\n",
    "plt.plot(monthly_data['month'], best_model_fit.resid, label='Residuals (Best Model)')\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with the model's fitted values\n",
    "model_values_df = pd.DataFrame({\n",
    "    'month': monthly_data['month'][1:],  # Exclude the first month as it doesn't have a fitted value\n",
    "    'model_value': best_model_fit.fittedvalues[1:]\n",
    "})\n",
    "model_values_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Merge the model_values_df with monthly_data\n",
    "# Note: Ensure that both DataFrames have the 'date' column in the same format for a successful merge\n",
    "combined_data = pd.merge(monthly_data, model_values_df, how='left', left_on='month', right_on='month')\n",
    "\n",
    "# Drop the additional 'date' column from the merge, if needed\n",
    "# combined_data.drop('month', axis=1, inplace=True)\n",
    "\n",
    "# Export the combined_data DataFrame to a CSV file\n",
    "combined_data.to_csv('model_and_monthly_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(param_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# Perform Augmented Dickey-Fuller test\n",
    "adf_result = adfuller(monthly_data['TH/J'].dropna())\n",
    "\n",
    "print('ADF Statistic: %f' % adf_result[0])\n",
    "print('p-value: %f' % adf_result[1])\n",
    "print('Critical Values:')\n",
    "for key, value in adf_result[4].items():\n",
    "    print('\\t%s: %.3f' % (key, value))\n",
    "\n",
    "# Interpretation\n",
    "if adf_result[1] < 0.05:\n",
    "    print(\"The time series is stationary with 95% confidence.\")\n",
    "else:\n",
    "    print(\"The time series is not stationary with 95% confidence.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# Calculate the first derivative of the time series\n",
    "monthly_data['TH/J_diff'] = monthly_data['TH/J'].diff()\n",
    "\n",
    "# Drop the first row since it will be NaN after differencing\n",
    "monthly_data_diff = monthly_data.dropna(subset=['TH/J_diff'])\n",
    "\n",
    "# Perform the Augmented Dickey-Fuller test\n",
    "adf_result = adfuller(monthly_data_diff['TH/J_diff'])\n",
    "\n",
    "print('ADF Statistic: %f' % adf_result[0])\n",
    "print('p-value: %f' % adf_result[1])\n",
    "print('Critical Values:')\n",
    "for key, value in adf_result[4].items():\n",
    "    print('\\t%s: %.3f' % (key, value))\n",
    "\n",
    "# Interpret the results\n",
    "if adf_result[1] < 0.05:\n",
    "    print(\"The first derivative of the time series is stationary.\")\n",
    "else:\n",
    "    print(\"The first derivative of the time series is not stationary.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # looks like:\n",
    "# # [\n",
    "# #  (Timestamp('2011-08-04 00:00:00'), 1.9952745454545455e-06),\n",
    "# #  (Timestamp('2012-12-31 00:00:00'), 3.2042489473684216e-05),\n",
    "# #  (Timestamp('2013-12-21 00:00:00'), 0.0005635879322033898)\n",
    "# # ]\n",
    "# regression_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(columns=['date', 'max possible', 'archaicity', 'max found', 'regression'])\n",
    "# df['date'] = max_efficiency_table['date']\n",
    "# df['max possible'] = max_efficiency_table['max (TH/J)']\n",
    "# df['archaicity'] = max_efficiency_table['archaicity (TH/J)']\n",
    "\n",
    "\n",
    "# # finds the 2 closest timestamps in regression_lines and returns the interpolated value\n",
    "# def get_regression(date):\n",
    "#     closest_smaller_timestamp_index = None\n",
    "#     closest_larger_timestamp_index = None\n",
    "#     for (i,(timestamp, value)) in enumerate(regression_lines):\n",
    "#         if timestamp <= date:\n",
    "#             closest_smaller_timestamp_index = i\n",
    "#         else:\n",
    "#             closest_larger_timestamp_index = i\n",
    "#             break\n",
    "    \n",
    "#     if closest_smaller_timestamp_index is None:\n",
    "#         return regression_lines[0][1]\n",
    "#     elif closest_larger_timestamp_index is None:\n",
    "#         return regression_lines[-1][1]\n",
    "    \n",
    "#     smaller_value = regression_lines[closest_smaller_timestamp_index][1]\n",
    "#     larger_value = regression_lines[closest_larger_timestamp_index][1]\n",
    "\n",
    "#     # interpolate\n",
    "#     return smaller_value + (larger_value - smaller_value) * (date - regression_lines[closest_smaller_timestamp_index][0]) / (regression_lines[closest_larger_timestamp_index][0] - regression_lines[closest_smaller_timestamp_index][0])\n",
    "\n",
    "     \n",
    "# df['regression'] = df['date'].apply(get_regression)\n",
    "\n",
    "# # gets the max efficiency for a given date from the data table\n",
    "# def get_max_efficiency(date):\n",
    "#     return data[data['date'] == date][unit_power_efficiency].max()\n",
    "\n",
    "# df['max found'] = df['date'].apply(get_max_efficiency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.sample(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('plot.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
